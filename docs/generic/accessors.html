<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>vectorbt.generic.accessors API documentation</title>
<meta name="description" content="Custom pandas accessors â€¦" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-2/css/all.min.css" integrity="sha256-46r060N2LrChLLb5zowXQ72/iKKNiw/lAmygmHExk/o=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/atom-one-dark.min.css" rel="stylesheet">
<style>:root{--highlight-color:#e82}.flex{display:flex !important}body{line-height:1.5em}.version{font-weight:normal;font-style:italic;font-size:.75em;color:#56b6c2}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar>*:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #eee;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold;word-break:break-all}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8}.hljs{padding:1.25rem 1.5rem;margin-left:-15px;margin-right:-15px;border:1px solid #eee;border-radius:6px;background:#282c34 !important;color:#9da29e !important}.python{color:#c5c8c6 !important}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word;font-size:90%}h1 code{background:transparent}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{padding-bottom:.5em;border-bottom:1px solid #e82}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes+dl>dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name>span:first-child{white-space:nowrap}.name.class>span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-weight:400;font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary>*{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}.badge{display:inline-block;padding:0.25em 0.4em;font-size:75%;font-weight:700;line-height:1;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0.25rem;transition:color 0.15s ease-in-out,background-color 0.15s ease-in-out,border-color 0.15s ease-in-out,box-shadow 0.15s ease-in-out}@media (prefers-reduced-motion:reduce){.badge{transition:none}}a.badge:hover,a.badge:focus{text-decoration:none}.badge:empty{display:none}.btn .badge{position:relative;top:-1px}.badge-pill{padding-right:0.6em;padding-left:0.6em;border-radius:10rem}.badge-primary{color:#fff;background-color:#007bff}a.badge-primary:hover,a.badge-primary:focus{color:#fff;background-color:#0062cc}a.badge-primary:focus,a.badge-primary.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(0,123,255,0.5)}.badge-secondary{color:#fff;background-color:#6c757d}a.badge-secondary:hover,a.badge-secondary:focus{color:#fff;background-color:#545b62}a.badge-secondary:focus,a.badge-secondary.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(108,117,125,0.5)}.badge-success{color:#fff;background-color:#28a745}a.badge-success:hover,a.badge-success:focus{color:#fff;background-color:#1e7e34}a.badge-success:focus,a.badge-success.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(40,167,69,0.5)}.badge-info{color:#fff;background-color:#17a2b8}a.badge-info:hover,a.badge-info:focus{color:#fff;background-color:#117a8b}a.badge-info:focus,a.badge-info.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(23,162,184,0.5)}.badge-warning{color:#212529;background-color:#ffc107}a.badge-warning:hover,a.badge-warning:focus{color:#212529;background-color:#d39e00}a.badge-warning:focus,a.badge-warning.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(255,193,7,0.5)}.badge-danger{color:#fff;background-color:#dc3545}a.badge-danger:hover,a.badge-danger:focus{color:#fff;background-color:#bd2130}a.badge-danger:focus,a.badge-danger.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(220,53,69,0.5)}.badge-light{color:#212529;background-color:#f8f9fa}a.badge-light:hover,a.badge-light:focus{color:#212529;background-color:#dae0e5}a.badge-light:focus,a.badge-light.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(248,249,250,0.5)}.badge-dark{color:#fff;background-color:#343a40}a.badge-dark:hover,a.badge-dark:focus{color:#fff;background-color:#1d2124}a.badge-dark:focus,a.badge-dark.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(52,58,64,0.5)}.search-container{width:100%;margin-top:15px;margin-bottom:15px}#search_input{display:inline-block;width:100%;height:40px;padding:.375rem .75rem;font-size:1rem;line-height:1.5;color:white;background:#282c34 !important;border:none;border-radius:6px;border-bottom:1px solid #e82;outline:none}.algolia-autocomplete{width:100%;background:rgba(0,0,0,.2);border:none;border-radius:6px}.algolia-autocomplete input{display:none}.index-caption{color:white}#index a,#index h3,.toc a{color:white}#index a:hover,.toc a:hover{color:#e82}#sidebar{background:#393f4a}.toc ul ul,#index ul{padding-left:1.5em}.toc>ul>li{margin-top:.5em}pre{position:relative;background:#fafafa}pre .btnIcon{position:absolute;top:4px;z-index:2;cursor:pointer;border:1px solid transparent;padding:0;color:#383a42;background-color:transparent;height:30px;transition:all .25s ease-out}pre .btnIcon:hover{text-decoration:none}.btnIcon__body{align-items:center;display:flex;color:#abb2bf}.btnIcon svg{fill:currentColor;margin-right:.4em}.btnIcon__label{font-size:11px}.btnClipboard{right:10px}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:400px;height:100vh;overflow:visible;position:sticky;top:0}#content{width:100%;max-width:100ch;padding:3em 4em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.scrollable-index{overflow-y:scroll;height:calc(100vh - 250px)}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-142521178-3', 'auto'); ga('send', 'pageview');
</script><script async src='https://www.google-analytics.com/analytics.js'></script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:white}.homelink:hover{color:#e82}.homelink img{max-width:100px;max-height:100px;margin:auto;margin-bottom:.3em}</style>
<link rel="apple-touch-icon" sizes="180x180" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon-16x16.png">
<link rel="manifest" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/site.webmanifest">
<link rel="icon" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#282c34">
<meta name="theme-color" content="#282c34">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>vectorbt.generic.accessors</code></h1>
</header>
<section id="section-intro">
<p>Custom pandas accessors.</p>
<p>Methods can be accessed as follows:</p>
<ul>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor" href="#vectorbt.generic.accessors.GenericSRAccessor">GenericSRAccessor</a></code> -&gt; <code>pd.Series.vbt.*</code></li>
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor" href="#vectorbt.generic.accessors.GenericDFAccessor">GenericDFAccessor</a></code> -&gt; <code>pd.DataFrame.vbt.*</code></li>
</ul>
<pre><code class="language-python-repl">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import vectorbt as vbt

&gt;&gt;&gt; # vectorbt.generic.accessors.GenericAccessor.rolling_mean
&gt;&gt;&gt; pd.Series([1, 2, 3, 4]).vbt.rolling_mean(2)
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64
</code></pre>
<p>The accessors inherit <code><a title="vectorbt.base.accessors" href="../base/accessors.html">vectorbt.base.accessors</a></code> and are inherited by more
specialized accessors, such as <code><a title="vectorbt.signals.accessors" href="../signals/accessors.html">vectorbt.signals.accessors</a></code> and <code><a title="vectorbt.returns.accessors" href="../returns/accessors.html">vectorbt.returns.accessors</a></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Input arrays can be of any type, but most output arrays are <code>np.float64</code>.</p>
<p>Grouping is only supported by the methods that accept the <code>group_by</code> argument.</p>
</div>
<p>Run for the examples below:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; import vectorbt as vbt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from numba import njit
&gt;&gt;&gt; from datetime import datetime, timedelta

&gt;&gt;&gt; df = pd.DataFrame({
...     'a': [1, 2, 3, 4, 5],
...     'b': [5, 4, 3, 2, 1],
...     'c': [1, 2, 3, 2, 1]
... }, index=pd.Index([
...     datetime(2020, 1, 1),
...     datetime(2020, 1, 2),
...     datetime(2020, 1, 3),
...     datetime(2020, 1, 4),
...     datetime(2020, 1, 5)
... ]))
&gt;&gt;&gt; df
            a  b  c
2020-01-01  1  5  1
2020-01-02  2  4  2
2020-01-03  3  3  3
2020-01-04  4  2  2
2020-01-05  5  1  1

&gt;&gt;&gt; index = [datetime(2020, 1, 1) + timedelta(days=i) for i in range(10)]
&gt;&gt;&gt; sr = pd.Series(np.arange(len(index)), index=index)
&gt;&gt;&gt; sr
2020-01-01    0
2020-01-02    1
2020-01-03    2
2020-01-04    3
2020-01-05    4
2020-01-06    5
2020-01-07    6
2020-01-08    7
2020-01-09    8
2020-01-10    9
dtype: int64
</code></pre>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Custom pandas accessors.

Methods can be accessed as follows:

* `GenericSRAccessor` -&gt; `pd.Series.vbt.*`
* `GenericDFAccessor` -&gt; `pd.DataFrame.vbt.*`

```python-repl
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import vectorbt as vbt

&gt;&gt;&gt; # vectorbt.generic.accessors.GenericAccessor.rolling_mean
&gt;&gt;&gt; pd.Series([1, 2, 3, 4]).vbt.rolling_mean(2)
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64
```

The accessors inherit `vectorbt.base.accessors` and are inherited by more
specialized accessors, such as `vectorbt.signals.accessors` and `vectorbt.returns.accessors`.

!!! note
    Input arrays can be of any type, but most output arrays are `np.float64`.

    Grouping is only supported by the methods that accept the `group_by` argument.

Run for the examples below:
    
```python-repl
&gt;&gt;&gt; import vectorbt as vbt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from numba import njit
&gt;&gt;&gt; from datetime import datetime, timedelta

&gt;&gt;&gt; df = pd.DataFrame({
...     &#39;a&#39;: [1, 2, 3, 4, 5],
...     &#39;b&#39;: [5, 4, 3, 2, 1],
...     &#39;c&#39;: [1, 2, 3, 2, 1]
... }, index=pd.Index([
...     datetime(2020, 1, 1),
...     datetime(2020, 1, 2),
...     datetime(2020, 1, 3),
...     datetime(2020, 1, 4),
...     datetime(2020, 1, 5)
... ]))
&gt;&gt;&gt; df
            a  b  c
2020-01-01  1  5  1
2020-01-02  2  4  2
2020-01-03  3  3  3
2020-01-04  4  2  2
2020-01-05  5  1  1

&gt;&gt;&gt; index = [datetime(2020, 1, 1) + timedelta(days=i) for i in range(10)]
&gt;&gt;&gt; sr = pd.Series(np.arange(len(index)), index=index)
&gt;&gt;&gt; sr
2020-01-01    0
2020-01-02    1
2020-01-03    2
2020-01-04    3
2020-01-05    4
2020-01-06    5
2020-01-07    6
2020-01-08    7
2020-01-09    8
2020-01-10    9
dtype: int64
```&#34;&#34;&#34;

import numpy as np
import pandas as pd
from scipy import stats
from numba.typed import Dict
import warnings
from sklearn.utils.validation import check_is_fitted
from sklearn.exceptions import NotFittedError
from sklearn.preprocessing import (
    Binarizer,
    MinMaxScaler,
    MaxAbsScaler,
    Normalizer,
    RobustScaler,
    StandardScaler,
    QuantileTransformer,
    PowerTransformer
)

from vectorbt import _typing as tp
from vectorbt.utils import checks
from vectorbt.utils.config import merge_dicts, resolve_dict
from vectorbt.utils.figure import make_figure, make_subplots
from vectorbt.utils.decorators import cached_property, cached_method
from vectorbt.base import index_fns, reshape_fns
from vectorbt.base.accessors import BaseAccessor, BaseDFAccessor, BaseSRAccessor
from vectorbt.base.class_helpers import add_nb_methods
from vectorbt.generic import plotting, nb
from vectorbt.generic.drawdowns import Drawdowns
from vectorbt.generic.splitters import SplitterT, RangeSplitter, RollingSplitter, ExpandingSplitter
from vectorbt.records.mapped_array import MappedArray

try:  # pragma: no cover
    # Adapted from https://github.com/quantopian/empyrical/blob/master/empyrical/utils.py
    import bottleneck as bn

    nanmean = bn.nanmean
    nanstd = bn.nanstd
    nansum = bn.nansum
    nanmax = bn.nanmax
    nanmin = bn.nanmin
    nanmedian = bn.nanmedian
    nanargmax = bn.nanargmax
    nanargmin = bn.nanargmin
except ImportError:
    # slower numpy
    nanmean = np.nanmean
    nanstd = np.nanstd
    nansum = np.nansum
    nanmax = np.nanmax
    nanmin = np.nanmin
    nanmedian = np.nanmedian
    nanargmax = np.nanargmax
    nanargmin = np.nanargmin


class TransformerT(tp.Protocol):
    def __init__(self, **kwargs) -&gt; None:
        ...

    def transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...

    def fit_transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...


WrapperFuncT = tp.Callable[[tp.Type[tp.T]], tp.Type[tp.T]]
TransformFuncInfoT = tp.Tuple[str, tp.Type[TransformerT]]
SplitOutputT = tp.Union[tp.MaybeTuple[tp.Tuple[tp.Frame, tp.Index]], tp.BaseFigure]


def add_transform_methods(transformers: tp.Iterable[TransformFuncInfoT]) -&gt; WrapperFuncT:
    &#34;&#34;&#34;Class decorator to add scikit-learn transformers as transform methods.&#34;&#34;&#34;

    def wrapper(cls: tp.Type[tp.T]) -&gt; tp.Type[tp.T]:
        for fname, transformer in transformers:
            def transform(self, wrap_kwargs: tp.KwargsLike = None,
                          _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
                return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)

            transform.__doc__ = f&#34;Transform using `sklearn.preprocessing.{transformer.__name__}`.&#34;
            setattr(cls, fname, transform)
        return cls

    return wrapper


@add_nb_methods([
    (nb.shuffle_nb, False),
    (nb.fillna_nb, False),
    (nb.bshift_nb, False),
    (nb.fshift_nb, False),
    (nb.diff_nb, False),
    (nb.pct_change_nb, False),
    (nb.ffill_nb, False),
    (nb.cumsum_nb, False),
    (nb.cumprod_nb, False),
    (nb.rolling_min_nb, False),
    (nb.rolling_max_nb, False),
    (nb.rolling_mean_nb, False),
    (nb.expanding_min_nb, False),
    (nb.expanding_max_nb, False),
    (nb.expanding_mean_nb, False),
    (nb.product_nb, True, &#39;product&#39;)
], module_name=&#39;vectorbt.generic.nb&#39;)
@add_transform_methods([
    (&#39;binarize&#39;, Binarizer),
    (&#39;minmax_scale&#39;, MinMaxScaler),
    (&#39;maxabs_scale&#39;, MaxAbsScaler),
    (&#39;normalize&#39;, Normalizer),
    (&#39;robust_scale&#39;, RobustScaler),
    (&#39;scale&#39;, StandardScaler),
    (&#39;quantile_transform&#39;, QuantileTransformer),
    (&#39;power_transform&#39;, PowerTransformer)
])
class GenericAccessor(BaseAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For both, Series and DataFrames.

    Accessible through `pd.Series.vbt` and `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.SeriesFrame, **kwargs) -&gt; None:
        if not checks.is_pandas(obj):  # parent accessor
            obj = obj._obj

        BaseAccessor.__init__(self, obj, **kwargs)

    def rolling_std(self, window: int, minp: tp.Optional[int] = None, ddof: int = 1,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_std_nb`.&#34;&#34;&#34;
        out = nb.rolling_std_nb(self.to_2d_array(), window, minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def expanding_std(self, minp: tp.Optional[int] = 1, ddof: int = 1,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_std_nb`.&#34;&#34;&#34;
        out = nb.expanding_std_nb(self.to_2d_array(), minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def ewm_mean(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_mean_nb`.&#34;&#34;&#34;
        out = nb.ewm_mean_nb(self.to_2d_array(), span, minp=minp, adjust=adjust)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def ewm_std(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True, ddof: int = 1,
                wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_std_nb`.&#34;&#34;&#34;
        out = nb.ewm_std_nb(self.to_2d_array(), span, minp=minp, adjust=adjust, ddof=ddof)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def apply_along_axis(self, apply_func_nb: tp.Union[nb.apply_nbT, nb.row_apply_nbT], *args, axis: int = 0,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Apply a function `apply_func_nb` along an axis.&#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if axis == 0:
            out = nb.apply_nb(self.to_2d_array(), apply_func_nb, *args)
        elif axis == 1:
            out = nb.row_apply_nb(self.to_2d_array(), apply_func_nb, *args)
        else:
            raise ValueError(&#34;Only axes 0 and 1 are supported&#34;)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def rolling_apply(self, window: int, apply_func_nb: tp.Union[nb.rolling_apply_nbT, nb.rolling_matrix_apply_nbT],
                      *args, minp: tp.Optional[int] = None, on_matrix: bool = False,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_apply_nb` and
        `vectorbt.generic.nb.rolling_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
                      a    b         c
        2020-01-01  1.0  5.0  1.000000
        2020-01-02  1.5  4.5  1.500000
        2020-01-03  2.0  4.0  2.000000
        2020-01-04  3.0  3.0  2.333333
        2020-01-05  4.0  2.0  2.000000

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.777778  2.777778  2.777778
        2020-01-05  2.666667  2.666667  2.666667
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.rolling_matrix_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        else:
            out = nb.rolling_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def expanding_apply(self, apply_func_nb: tp.Union[nb.rolling_apply_nbT, nb.rolling_matrix_apply_nbT],
                        *args, minp: tp.Optional[int] = 1, on_matrix: bool = False,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_apply_nb` and
        `vectorbt.generic.nb.expanding_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
                      a    b    c
        2020-01-01  1.0  5.0  1.0
        2020-01-02  1.5  4.5  1.5
        2020-01-03  2.0  4.0  2.0
        2020-01-04  2.5  3.5  2.0
        2020-01-05  3.0  3.0  1.8

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.666667  2.666667  2.666667
        2020-01-05  2.600000  2.600000  2.600000
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.expanding_matrix_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        else:
            out = nb.expanding_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def groupby_apply(self, by: tp.PandasGroupByLike,
                      apply_func_nb: tp.Union[nb.groupby_apply_nbT, nb.groupby_apply_matrix_nbT],
                      *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                      **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_apply_matrix_nb` for `on_matrix=True`.

        For `by`, see `pd.DataFrame.groupby`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
             a    b    c
        1  1.5  4.5  1.5
        2  3.5  2.5  2.5
        3  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
                  a         b         c
        1  2.500000  2.500000  2.500000
        2  2.833333  2.833333  2.833333
        3  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        regrouped = self._obj.groupby(by, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(regrouped.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_apply_matrix_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        wrap_kwargs = merge_dicts(dict(name_or_index=list(regrouped.indices.keys())), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def resample_apply(self, freq: tp.PandasFrequencyLike,
                       apply_func_nb: tp.Union[nb.groupby_apply_nbT, nb.groupby_apply_matrix_nbT],
                       *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                       **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_apply_matrix_nb` for `on_matrix=True`.

        For `freq`, see `pd.DataFrame.resample`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_nb)
                      a    b    c
        2020-01-01  1.5  4.5  1.5
        2020-01-03  3.5  2.5  2.5
        2020-01-05  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.500000  2.500000  2.500000
        2020-01-03  2.833333  2.833333  2.833333
        2020-01-05  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        resampled = self._obj.resample(freq, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(resampled.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_apply_matrix_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        out_obj = self.wrapper.wrap(out, index=list(resampled.indices.keys()))
        resampled_arr = np.full((resampled.ngroups, self.to_2d_array().shape[1]), np.nan)
        resampled_obj = self.wrapper.wrap(
            resampled_arr,
            index=pd.Index(list(resampled.groups.keys()), freq=freq),
            **merge_dicts({}, wrap_kwargs)
        )
        resampled_obj.loc[out_obj.index] = out_obj.values
        return resampled_obj

    def applymap(self, apply_func_nb: nb.applymap_nbT, *args,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.applymap_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
        &gt;&gt;&gt; df.vbt.applymap(multiply_nb)
                       a     b    c
        2020-01-01   1.0  25.0  1.0
        2020-01-02   4.0  16.0  4.0
        2020-01-03   9.0   9.0  9.0
        2020-01-04  16.0   4.0  4.0
        2020-01-05  25.0   1.0  1.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        out = nb.applymap_nb(self.to_2d_array(), apply_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def filter(self, filter_func_nb: nb.filter_nbT, *args,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.filter_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
        &gt;&gt;&gt; df.vbt.filter(greater_nb)
                      a    b    c
        2020-01-01  NaN  5.0  NaN
        2020-01-02  NaN  4.0  NaN
        2020-01-03  3.0  3.0  3.0
        2020-01-04  4.0  NaN  NaN
        2020-01-05  5.0  NaN  NaN
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(filter_func_nb)

        out = nb.filter_nb(self.to_2d_array(), filter_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def apply_and_reduce(self, apply_func_nb: nb.apply_and_reduce_nbAT, reduce_func_nb: nb.apply_and_reduce_nbRT,
                         apply_args: tp.Optional[tuple] = None, reduce_args: tp.Optional[tuple] = None,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;See `vectorbt.generic.nb.apply_and_reduce_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
        a    4.0
        b    4.0
        c    3.0
        dtype: float64
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)
        checks.assert_numba_func(reduce_func_nb)
        if apply_args is None:
            apply_args = ()
        if reduce_args is None:
            reduce_args = ()

        out = nb.apply_and_reduce_nb(self.to_2d_array(), apply_func_nb, apply_args, reduce_func_nb, reduce_args)
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;apply_and_reduce&#39;), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def reduce(self, reduce_func_nb: tp.Union[nb.flat_reduce_grouped_nbT,
                                              nb.flat_reduce_grouped_to_array_nbT,
                                              nb.reduce_grouped_nbT,
                                              nb.reduce_grouped_to_array_nbT,
                                              nb.reduce_nbT,
                                              nb.reduce_to_array_nbT],
               *args, to_array: bool = False, to_idx: bool = False, flatten: bool = False,
               order: str = &#39;C&#39;, idx_labeled: bool = True, group_by: tp.GroupByLike = None,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeriesFrame[float]:
        &#34;&#34;&#34;Reduce by column.

        See `vectorbt.generic.nb.flat_reduce_grouped_to_array_nb` if grouped, `to_array` is True and `flatten` is True.
        See `vectorbt.generic.nb.flat_reduce_grouped_nb` if grouped, `to_array` is False and `flatten` is True.
        See `vectorbt.generic.nb.reduce_grouped_to_array_nb` if grouped, `to_array` is True and `flatten` is False.
        See `vectorbt.generic.nb.reduce_grouped_nb` if grouped, `to_array` is False and `flatten` is False.
        See `vectorbt.generic.nb.reduce_to_array_nb` if not grouped and `to_array` is True.
        See `vectorbt.generic.nb.reduce_nb` if not grouped and `to_array` is False.

        Set `to_idx` to True if values returned by `reduce_func_nb` are indices/positions.
        Set `idx_labeled` to False to return raw positions instead of labels.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.reduce(mean_nb)
        a    3.0
        b    3.0
        c    1.8
        dtype: float64

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True)
        a   2020-01-05
        b   2020-01-01
        c   2020-01-03
        dtype: datetime64[ns]

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True, idx_labeled=False)
        a    4
        b    0
        c    2
        dtype: int64

        &gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;], to_array=True)
               a    b    c
        min  1.0  1.0  1.0
        max  5.0  5.0  3.0

        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
        group
        first     3.0
        second    1.8
        dtype: float64

        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;],
        ...     to_array=True, group_by=group_by)
        group  first  second
        min      1.0     1.0
        max      5.0     3.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(reduce_func_nb)

        if self.wrapper.grouper.is_grouped(group_by=group_by):
            group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
            if flatten:
                checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])
                in_c_order = order.upper() == &#39;C&#39;
                if to_array:
                    out = nb.flat_reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                else:
                    out = nb.flat_reduce_grouped_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                if to_idx:
                    if in_c_order:
                        out //= group_lens  # flattened in C order
                    else:
                        out %= self.wrapper.shape[0]  # flattened in F order
            else:
                if to_array:
                    out = nb.reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
                else:
                    out = nb.reduce_grouped_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
        else:
            if to_array:
                out = nb.reduce_to_array_nb(
                    self.to_2d_array(), reduce_func_nb, *args)
            else:
                out = nb.reduce_nb(
                    self.to_2d_array(), reduce_func_nb, *args)

        # Perform post-processing
        if to_idx:
            nan_mask = np.isnan(out)
            if idx_labeled:
                out = out.astype(object)
                out[~nan_mask] = self.wrapper.index[out[~nan_mask].astype(np.int_)]
            else:
                out[nan_mask] = -1
                out = out.astype(np.int_)
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;reduce&#39; if not to_array else None), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=group_by, **wrap_kwargs)

    def squeeze_grouped(self, reduce_func_nb: nb.squeeze_grouped_nbT, *args, group_by: tp.GroupByLike = None,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Squeeze each group of columns into a single column.

        See `vectorbt.generic.nb.squeeze_grouped_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; mean_nb = njit(lambda i, group, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.squeeze_grouped(mean_nb, group_by=group_by)
        group       first  second
        2020-01-01    3.0     1.0
        2020-01-02    3.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    3.0     2.0
        2020-01-05    3.0     1.0
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_numba_func(reduce_func_nb)

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        out = nb.squeeze_grouped_nb(self.to_2d_array(), group_lens, reduce_func_nb, *args)
        return self.wrapper.wrap(out, group_by=group_by, **merge_dicts({}, wrap_kwargs))

    def flatten_grouped(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Flatten each group of columns.

        See `vectorbt.generic.nb.flatten_grouped_nb`.

        !!! warning
            Make sure that the distribution of group lengths is close to uniform, otherwise
            groups with less columns will be filled with NaN and needlessly occupy memory.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;C&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    2.0     2.0
        2020-01-02    4.0     NaN
        2020-01-03    3.0     3.0
        2020-01-03    3.0     NaN
        2020-01-04    4.0     2.0
        2020-01-04    2.0     NaN
        2020-01-05    5.0     1.0
        2020-01-05    1.0     NaN

        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;F&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-02    2.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    4.0     2.0
        2020-01-05    5.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    4.0     NaN
        2020-01-03    3.0     NaN
        2020-01-04    2.0     NaN
        2020-01-05    1.0     NaN
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        if order.upper() == &#39;C&#39;:
            out = nb.flatten_grouped_nb(self.to_2d_array(), group_lens, True)
            new_index = index_fns.repeat_index(self.wrapper.index, np.max(group_lens))
        else:
            out = nb.flatten_grouped_nb(self.to_2d_array(), group_lens, False)
            new_index = index_fns.tile_index(self.wrapper.index, np.max(group_lens))
        wrap_kwargs = merge_dicts(dict(index=new_index), wrap_kwargs)
        return self.wrapper.wrap(out, group_by=group_by, **wrap_kwargs)

    def min(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;min&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.min_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmin = np.nanmin
        else:
            _nanmin = nanmin
        return self.wrapper.wrap_reduced(_nanmin(arr, axis=0), **wrap_kwargs)

    def max(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;max&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.max_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmax = np.nanmax
        else:
            _nanmax = nanmax
        return self.wrapper.wrap_reduced(_nanmax(arr, axis=0), **wrap_kwargs)

    def mean(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return mean of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;mean&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.mean_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmean = np.nanmean
        else:
            _nanmean = nanmean
        return self.wrapper.wrap_reduced(_nanmean(arr, axis=0), **wrap_kwargs)

    def median(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return median of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;median&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.median_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmedian = np.nanmedian
        else:
            _nanmedian = nanmedian
        return self.wrapper.wrap_reduced(_nanmedian(arr, axis=0), **wrap_kwargs)

    def std(self, ddof: int = 1, group_by: tp.GroupByLike = None,
            wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return standard deviation of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;std&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.std_reduce_nb, ddof, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanstd = np.nanstd
        else:
            _nanstd = nanstd
        return self.wrapper.wrap_reduced(_nanstd(arr, ddof=ddof, axis=0), **wrap_kwargs)

    def sum(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return sum of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;sum&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.sum_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nansum = np.nansum
        else:
            _nansum = nansum
        return self.wrapper.wrap_reduced(_nansum(arr, axis=0), **wrap_kwargs)

    def count(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return count of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;count&#39;, dtype=np.int_), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.count_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        return self.wrapper.wrap_reduced(np.sum(~np.isnan(self.to_2d_array()), axis=0), **wrap_kwargs)

    def idxmin(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmin&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmin_reduce_nb,
                group_by=group_by,
                flatten=True,
                to_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmin(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def idxmax(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmax&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmax_reduce_nb,
                group_by=group_by,
                flatten=True,
                to_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmax(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def describe(self, percentiles: tp.Optional[tp.ArrayLike] = None, ddof: int = 1,
                 group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.describe_reduce_nb`.

        For `percentiles`, see `pd.DataFrame.describe`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.describe()
                      a         b        c
        count  5.000000  5.000000  5.00000
        mean   3.000000  3.000000  1.80000
        std    1.581139  1.581139  0.83666
        min    1.000000  1.000000  1.00000
        25%    2.000000  2.000000  1.00000
        50%    3.000000  3.000000  2.00000
        75%    4.000000  4.000000  2.00000
        max    5.000000  5.000000  3.00000
        ```
        &#34;&#34;&#34;
        if percentiles is not None:
            percentiles = reshape_fns.to_1d(percentiles, raw=True)
        else:
            percentiles = np.array([0.25, 0.5, 0.75])
        percentiles = percentiles.tolist()
        if 0.5 not in percentiles:
            percentiles.append(0.5)
        percentiles = np.unique(percentiles)
        perc_formatted = pd.io.formats.format.format_percentiles(percentiles)
        index = pd.Index([&#39;count&#39;, &#39;mean&#39;, &#39;std&#39;, &#39;min&#39;, *perc_formatted, &#39;max&#39;])
        wrap_kwargs = merge_dicts(dict(name_or_index=index), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.describe_reduce_nb, percentiles, ddof,
                group_by=group_by, flatten=True, to_array=True,
                wrap_kwargs=wrap_kwargs)
        return self.reduce(
            nb.describe_reduce_nb, percentiles, ddof,
            to_array=True, wrap_kwargs=wrap_kwargs)

    def drawdown(self, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Drawdown series.&#34;&#34;&#34;
        out = self.to_2d_array() / nb.expanding_max_nb(self.to_2d_array()) - 1
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    @cached_property
    def drawdowns(self) -&gt; Drawdowns:
        &#34;&#34;&#34;`GenericAccessor.get_drawdowns` with default arguments.&#34;&#34;&#34;
        return self.get_drawdowns()

    @cached_method
    def get_drawdowns(self, group_by: tp.GroupByLike = None, **kwargs) -&gt; Drawdowns:
        &#34;&#34;&#34;Generate drawdown records.

        See `vectorbt.generic.drawdowns.Drawdowns`.&#34;&#34;&#34;
        if group_by is None:
            group_by = self.wrapper.grouper.group_by
        return Drawdowns.from_ts(self._obj, freq=self.wrapper.freq, group_by=group_by, **kwargs)

    def to_mapped_array(self, dropna: bool = True, group_by: tp.GroupByLike = None, **kwargs) -&gt; MappedArray:
        &#34;&#34;&#34;Convert this object into an instance of `vectorbt.records.mapped_array.MappedArray`.&#34;&#34;&#34;
        mapped_arr = reshape_fns.to_2d(self._obj, raw=True).flatten(order=&#39;F&#39;)
        col_arr = np.repeat(np.arange(self.wrapper.shape_2d[1]), self.wrapper.shape_2d[0])
        idx_arr = np.tile(np.arange(self.wrapper.shape_2d[0]), self.wrapper.shape_2d[1])
        if dropna:
            not_nan_mask = ~np.isnan(mapped_arr)
            mapped_arr = mapped_arr[not_nan_mask]
            col_arr = col_arr[not_nan_mask]
            idx_arr = idx_arr[not_nan_mask]
        if group_by is None:
            group_by = self.wrapper.grouper.group_by
        return MappedArray(self.wrapper, mapped_arr, col_arr, idx_arr=idx_arr, **kwargs).regroup(group_by)

    # ############# Transforming ############# #

    def transform(self, transformer: TransformerT, wrap_kwargs: tp.KwargsLike = None, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Transform using a transformer.

        A transformer can be any class instance that has `transform` and `fit_transform` methods,
        ideally subclassing `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`.

        Will fit `transformer` if not fitted.

        `**kwargs` are passed to the `transform` or `fit_transform` method.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

        &gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
                      a    b    c
        2020-01-01 -1.0  1.0 -1.0
        2020-01-02 -0.5  0.5  0.0
        2020-01-03  0.0  0.0  1.0
        2020-01-04  0.5 -0.5  0.0
        2020-01-05  1.0 -1.0 -1.0

        &gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
        &gt;&gt;&gt; df.vbt.transform(fitted_scaler)
                      a    b    c
        2020-01-01 -2.0  2.0 -2.0
        2020-01-02 -1.0  1.0 -1.0
        2020-01-03  0.0  0.0  0.0
        2020-01-04  1.0 -1.0 -1.0
        2020-01-05  2.0 -2.0 -2.0
        ```&#34;&#34;&#34;
        is_fitted = True
        try:
            check_is_fitted(transformer)
        except NotFittedError:
            is_fitted = False
        if not is_fitted:
            result = transformer.fit_transform(self.to_2d_array(), **kwargs)
        else:
            result = transformer.transform(self.to_2d_array(), **kwargs)
        return self.wrapper.wrap(result, **merge_dicts({}, wrap_kwargs))

    def zscore(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Compute z-score using `sklearn.preprocessing.StandardScaler`.&#34;&#34;&#34;
        return self.scale(with_mean=True, with_std=True, **kwargs)

    # ############# Splitting ############# #

    def split(self, splitter: SplitterT, stack_kwargs: tp.KwargsLike = None, keys: tp.Optional[tp.IndexLike] = None,
              plot: bool = False, trace_names: tp.TraceNames = None, heatmap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using a splitter.

        Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.

        A splitter can be any class instance that has `split` method, ideally subclassing
        `sklearn.model_selection.BaseCrossValidator` or `vectorbt.generic.splitters.BaseSplitter`.

        `heatmap_kwargs` are passed to `vectorbt.generic.plotting.Heatmap` if `plot` is True,
        can be a dictionary or a list per set, for example, to set trace name for each set (&#39;train&#39;, &#39;test&#39;, etc.).

        `**kwargs` are passed to the `split` method.

        !!! note
            The datetime-like format of the index will be lost as result of this operation.
            Make sure to store the index metadata such as frequency information beforehand.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

        &gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
        &gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

        &gt;&gt;&gt; train_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          3.0  3.0  3
        4          NaN  4.0  4
        5          NaN  5.0  5
        6          NaN  NaN  6
        7          NaN  NaN  7
        &gt;&gt;&gt; train_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]
        &gt;&gt;&gt; test_df
        split_idx  0  1  2
        0          4  6  8
        1          5  7  9
        &gt;&gt;&gt; test_indexes
        [DatetimeIndex([&#39;2020-01-05&#39;, &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-09&#39;, &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=[&#39;train&#39;, &#39;test&#39;])
        ```

        ![](/vectorbt/docs/img/split_plot.svg)
        &#34;&#34;&#34;
        total_range_sr = pd.Series(np.arange(len(self.wrapper.index)), index=self.wrapper.index)
        set_ranges = list(splitter.split(total_range_sr, **kwargs))
        if len(set_ranges) == 0:
            raise ValueError(&#34;No splits were generated&#34;)
        idxs_by_split_and_set = list(zip(*set_ranges))

        results = []
        if keys is not None:
            if not isinstance(keys, pd.Index):
                keys = pd.Index(keys)
        for idxs_by_split in idxs_by_split_and_set:
            split_dfs = []
            split_indexes = []
            for split_idx, idxs in enumerate(idxs_by_split):
                split_dfs.append(self._obj.iloc[idxs].reset_index(drop=True))
                if keys is not None:
                    split_name = keys[split_idx]
                else:
                    split_name = &#39;split_&#39; + str(split_idx)
                split_indexes.append(pd.Index(self.wrapper.index[idxs], name=split_name))
            set_df = pd.concat(split_dfs, axis=1).reset_index(drop=True)
            if keys is not None:
                split_columns = keys
            else:
                split_columns = pd.Index(np.arange(len(split_indexes)), name=&#39;split_idx&#39;)
            split_columns = index_fns.repeat_index(split_columns, len(self.wrapper.columns))
            if stack_kwargs is None:
                stack_kwargs = {}
            set_df = set_df.vbt.stack_index(split_columns, **stack_kwargs)
            results.append((set_df, split_indexes))

        if plot:  # pragma: no cover
            if trace_names is None:
                trace_names = list(range(len(results)))
            if isinstance(trace_names, str):
                trace_names = [trace_names]
            nan_df = pd.DataFrame(np.nan, columns=pd.RangeIndex(stop=len(results[0][1])), index=self.wrapper.index)
            fig = None
            for i, (_, split_indexes) in enumerate(results):
                heatmap_df = nan_df.copy()
                for j in range(len(split_indexes)):
                    heatmap_df.loc[split_indexes[j], j] = i
                _heatmap_kwargs = resolve_dict(heatmap_kwargs, i=i)
                fig = heatmap_df.vbt.ts_heatmap(fig=fig, **merge_dicts(
                    dict(
                        trace_kwargs=dict(
                            showscale=False,
                            name=str(trace_names[i]),
                            showlegend=True
                        )
                    ),
                    _heatmap_kwargs
                ))
                if fig.layout.colorway is not None:
                    colorway = fig.layout.colorway
                else:
                    colorway = fig.layout.template.layout.colorway
                if &#39;colorscale&#39; not in _heatmap_kwargs:
                    fig.data[-1].update(colorscale=[colorway[i], colorway[i]])
            return fig

        if len(results) == 1:
            return results[0]
        return tuple(results)

    def range_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RangeSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  5
        1          1  6
        2          2  7
        3          3  8
        4          4  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
        &gt;&gt;&gt; range_df
        split_idx  0  1  2  3  4  5  6
        0          0  1  2  3  4  5  6
        1          1  2  3  4  5  6  7
        2          2  3  4  5  6  7  8
        3          3  4  5  6  7  8  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;),
         DatetimeIndex([&#39;2020-01-04&#39;, ..., &#39;2020-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_3&#39;),
         DatetimeIndex([&#39;2020-01-05&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_4&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-09&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_5&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_6&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  2
        1          1  3
        2          2  4
        3          3  5
        4          4  6
        5          5  7
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
        &gt;&gt;&gt; range_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          NaN  3.0  3
        4          NaN  NaN  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-03&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
        ...     start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;]),
        ...     end_idxs=pd.Index([&#39;2020-01-04&#39;, &#39;2020-01-05&#39;])
        ... )
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  1
        1          1  2
        2          2  3
        3          3  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

         &gt;&gt;&gt; sr.vbt.range_split(
         ...    start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;, &#39;2020-01-01&#39;]),
         ...    end_idxs=pd.Index([&#39;2020-01-08&#39;, &#39;2020-01-04&#39;, &#39;2020-01-07&#39;]),
         ...    plot=True
         ... )
        ```

        ![](/vectorbt/docs/img/range_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RangeSplitter(), **kwargs)

    def rolling_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RollingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx  0  1  2  3  4  5
        0          0  1  2  3  4  5
        1          1  2  3  4  5  6
        2          2  3  4  5  6  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5
        0          3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5
        0          4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/vectorbt/docs/img/rolling_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RollingSplitter(), **kwargs)

    def expanding_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.ExpandingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
        ...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx    0    1    2    3    4    5    6  7
        0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
        1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
        2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
        3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
        4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
        5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
        6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
        7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          1  2  3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          2  3  4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.expanding_split(
        ...     set_lens=(1, 1), min_len=3, left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/vectorbt/docs/img/expanding_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(ExpandingSplitter(), **kwargs)

    # ############# Enums ############# #

    def map_enum(self, enum: tp.NamedTuple) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Map integer values to field names of an enum.&#34;&#34;&#34;
        def _mapper(x: int) -&gt; str:
            if x in enum:
                return enum._fields[x]
            if x == -1:
                return &#39;&#39;
            return &#39;UNK&#39;

        if self.is_series():
            return self._obj.map(_mapper)
        return self._obj.applymap(_mapper)

    # ############# Plotting ############# #

    def plot(self,
             trace_names: tp.TraceNames = None,
             x_labels: tp.Optional[tp.Labels] = None,
             return_fig: bool = True,
             **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Scatter` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.plot()
        ```

        ![](/vectorbt/docs/img/df_plot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        scatter = plotting.Scatter(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return scatter.fig
        return scatter

    def lineplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;lines&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.lineplot()
        ```

        ![](/vectorbt/docs/img/df_lineplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;lines&#39;)), kwargs))

    def scatterplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;markers&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.scatterplot()
        ```

        ![](/vectorbt/docs/img/df_scatterplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;markers&#39;)), kwargs))

    def barplot(self,
                trace_names: tp.TraceNames = None,
                x_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Bar]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Bar` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.barplot()
        ```

        ![](/vectorbt/docs/img/df_barplot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        bar = plotting.Bar(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return bar.fig
        return bar

    def histplot(self,
                 trace_names: tp.TraceNames = None,
                 group_by: tp.GroupByLike = None,
                 return_fig: bool = True,
                 **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Histogram]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Histogram` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.histplot()
        ```

        ![](/vectorbt/docs/img/df_histplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.histplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        hist = plotting.Histogram(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return hist.fig
        return hist

    def boxplot(self,
                trace_names: tp.TraceNames = None,
                group_by: tp.GroupByLike = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Box]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Box` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.boxplot()
        ```

        ![](/vectorbt/docs/img/df_boxplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.boxplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        box = plotting.Box(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return box.fig
        return box


class GenericSRAccessor(GenericAccessor, BaseSRAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For Series only.

    Accessible through `pd.Series.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Series, **kwargs) -&gt; None:
        if not checks.is_pandas(obj):  # parent accessor
            obj = obj._obj

        BaseSRAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, **kwargs)

    def plot_against(self,
                     other: tp.ArrayLike,
                     trace_kwargs: tp.KwargsLike = None,
                     other_trace_kwargs: tp.Union[str, tp.KwargsLike] = None,
                     pos_trace_kwargs: tp.KwargsLike = None,
                     neg_trace_kwargs: tp.KwargsLike = None,
                     hidden_trace_kwargs: tp.KwargsLike = None,
                     add_trace_kwargs: tp.KwargsLike = None,
                     fig: tp.Optional[tp.BaseFigure] = None,
                     **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line against another line.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            other_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for `other`.

                Set to &#39;hidden&#39; to hide.
            pos_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for positive line.
            neg_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for negative line.
            hidden_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for hidden lines.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.plot_against(df[&#39;b&#39;])
        ```

        ![](/vectorbt/docs/img/sr_plot_against.svg)
        &#34;&#34;&#34;
        if trace_kwargs is None:
            trace_kwargs = {}
        if other_trace_kwargs is None:
            other_trace_kwargs = {}
        if pos_trace_kwargs is None:
            pos_trace_kwargs = {}
        if neg_trace_kwargs is None:
            neg_trace_kwargs = {}
        if hidden_trace_kwargs is None:
            hidden_trace_kwargs = {}
        obj, other = reshape_fns.broadcast(self._obj, other, columns_from=&#39;keep&#39;)
        checks.assert_type(other, pd.Series)
        if fig is None:
            fig = make_figure()
        fig.update_layout(**layout_kwargs)

        # TODO: Using masks feels hacky
        pos_mask = self._obj &gt; other
        if pos_mask.any():
            # Fill positive area
            pos_obj = self._obj.copy()
            pos_obj[~pos_mask] = other[~pos_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None,
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            pos_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    fillcolor=&#39;rgba(0, 128, 0, 0.3)&#39;,
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), pos_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
        neg_mask = self._obj &lt; other
        if neg_mask.any():
            # Fill negative area
            neg_obj = self._obj.copy()
            neg_obj[~neg_mask] = other[~neg_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            neg_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    fillcolor=&#39;rgba(255, 0, 0, 0.3)&#39;,
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), neg_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )

        # Plot main traces
        self.plot(trace_kwargs=trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        if other_trace_kwargs == &#39;hidden&#39;:
            other_trace_kwargs = dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0.,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            )
        other.vbt.plot(trace_kwargs=other_trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        return fig

    def overlay_with_heatmap(self,
                             other: tp.ArrayLike,
                             trace_kwargs: tp.KwargsLike = None,
                             heatmap_kwargs: tp.KwargsLike = None,
                             add_trace_kwargs: tp.KwargsLike = None,
                             fig: tp.Optional[tp.BaseFigure] = None,
                             **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line and overlays it with a heatmap.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            heatmap_kwargs (dict): Keyword arguments passed to `GenericDFAccessor.heatmap`.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.overlay_with_heatmap(df[&#39;b&#39;])
        ```

        ![](/vectorbt/docs/img/sr_overlay_with_heatmap.svg)
        &#34;&#34;&#34;
        from vectorbt._settings import settings
        plotting_cfg = settings[&#39;plotting&#39;]

        if trace_kwargs is None:
            trace_kwargs = {}
        if heatmap_kwargs is None:
            heatmap_kwargs = {}
        if add_trace_kwargs is None:
            add_trace_kwargs = {}

        obj, other = reshape_fns.broadcast(self._obj, other, columns_from=&#39;keep&#39;)
        checks.assert_type(other, pd.Series)
        if fig is None:
            fig = make_subplots(specs=[[{&#34;secondary_y&#34;: True}]])
            if &#39;width&#39; in plotting_cfg[&#39;layout&#39;]:
                fig.update_layout(width=plotting_cfg[&#39;layout&#39;][&#39;width&#39;] + 100)
        fig.update_layout(**layout_kwargs)

        other.vbt.ts_heatmap(**heatmap_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        self.plot(
            trace_kwargs=merge_dicts(dict(line=dict(color=plotting_cfg[&#39;color_schema&#39;][&#39;blue&#39;])), trace_kwargs),
            add_trace_kwargs=merge_dicts(dict(secondary_y=True), add_trace_kwargs),
            fig=fig
        )
        return fig

    def heatmap(self,
                x_level: tp.Optional[tp.Level] = None,
                y_level: tp.Optional[tp.Level] = None,
                symmetric: bool = False,
                sort: bool = True,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                slider_level: tp.Optional[tp.Level] = None,
                active: int = 0,
                slider_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                fig: tp.Optional[tp.BaseFigure] = None,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create a heatmap figure based on object&#39;s multi-index and values.

        If index is not a multi-index, converts Series into a DataFrame and calls `GenericDFAccessor.heatmap`.

        If multi-index contains more than two levels or you want them in specific order,
        pass `x_level` and `y_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the heatmap. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Heatmap` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1),
        ...     (2, 2),
        ...     (3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1    0
        2  2    1
        3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap()
        ```

        ![](/vectorbt/docs/img/sr_heatmap.svg)

        Using one level as a slider:

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (1, 2, 2),
        ...     (1, 3, 3),
        ...     (2, 3, 3),
        ...     (2, 2, 2),
        ...     (2, 1, 1)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
           2  2    1
           3  3    2
        2  3  3    3
           2  2    4
           1  1    5
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
        ```

        ![](/vectorbt/docs/img/sr_heatmap_slider.gif)
        &#34;&#34;&#34;
        if not isinstance(self.wrapper.index, pd.MultiIndex):
            return self._obj.to_frame().vbt.heatmap(
                x_labels=x_labels, y_labels=y_labels,
                return_fig=return_fig, fig=fig, **kwargs)

        (x_level, y_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        kwargs = merge_dicts(dict(
            trace_kwargs=dict(
                hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                              f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                              &#34;value: %{z}&lt;extra&gt;&lt;/extra&gt;&#34;
            ),
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name
        ), kwargs)

        if slider_level is None:
            # No grouping
            df = self.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            return df.vbt.heatmap(x_labels=x_labels, y_labels=y_labels, fig=fig, return_fig=return_fig, **kwargs)

        # Requires grouping
        # See https://plotly.com/python/sliders/
        if not return_fig:
            raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
        _slider_labels = []
        for i, (name, group) in enumerate(self._obj.groupby(level=slider_level)):
            if slider_labels is not None:
                name = slider_labels[i]
            _slider_labels.append(name)
            df = group.vbt.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            if x_labels is None:
                x_labels = df.columns
            if y_labels is None:
                y_labels = df.index
            _kwargs = merge_dicts(dict(
                trace_kwargs=dict(
                    name=str(name) if name is not None else None,
                    visible=False
                ),
            ), kwargs)
            default_size = fig is None and &#39;height&#39; not in _kwargs
            fig = plotting.Heatmap(
                data=df.vbt.to_2d_array(),
                x_labels=x_labels,
                y_labels=y_labels,
                fig=fig,
                **_kwargs
            ).fig
            if default_size:
                fig.layout[&#39;height&#39;] += 100  # slider takes up space
        fig.data[active].visible = True
        steps = []
        for i in range(len(fig.data)):
            step = dict(
                method=&#34;update&#34;,
                args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
            )
            step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
            steps.append(step)
        prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
            if self.wrapper.index.names[slider_level] is not None else None
        sliders = [dict(
            active=active,
            currentvalue={&#34;prefix&#34;: prefix},
            pad={&#34;t&#34;: 50},
            steps=steps
        )]
        fig.update_layout(
            sliders=sliders
        )
        return fig

    def ts_heatmap(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self._obj.to_frame().vbt.ts_heatmap(**kwargs)

    def volume(self,
               x_level: tp.Optional[tp.Level] = None,
               y_level: tp.Optional[tp.Level] = None,
               z_level: tp.Optional[tp.Level] = None,
               x_labels: tp.Optional[tp.Labels] = None,
               y_labels: tp.Optional[tp.Labels] = None,
               z_labels: tp.Optional[tp.Labels] = None,
               slider_level: tp.Optional[tp.Level] = None,
               slider_labels: tp.Optional[tp.Labels] = None,
               active: int = 0,
               scene_name: str = &#39;scene&#39;,
               fillna: tp.Optional[tp.Number] = None,
               fig: tp.Optional[tp.BaseFigure] = None,
               return_fig: bool = True,
               **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Volume]:  # pragma: no cover
        &#34;&#34;&#34;Create a 3D volume figure based on object&#39;s multi-index and values.

        If multi-index contains more than three levels or you want them in specific order, pass
        `x_level`, `y_level`, and `z_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the volume. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Volume` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (2, 2, 2),
        ...     (3, 3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
        2  2  2    1
        3  3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.volume().show()
        ```

        ![](/vectorbt/docs/img/sr_volume.svg)
        &#34;&#34;&#34;
        (x_level, y_level, z_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level, z_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        z_level_vals = self.wrapper.index.get_level_values(z_level)
        # Labels are just unique level values
        if x_labels is None:
            x_labels = np.unique(x_level_vals)
        if y_labels is None:
            y_labels = np.unique(y_level_vals)
        if z_labels is None:
            z_labels = np.unique(z_level_vals)

        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        z_name = z_level_vals.name if z_level_vals.name is not None else &#39;z&#39;
        def_kwargs = dict()
        def_kwargs[&#39;trace_kwargs&#39;] = dict(
            hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                          f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                          f&#34;{z_name}: %{{z}}&lt;br&gt;&#34; +
                          &#34;value: %{value}&lt;extra&gt;&lt;/extra&gt;&#34;
        )
        def_kwargs[scene_name] = dict(
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name,
            zaxis_title=z_level_vals.name
        )
        def_kwargs[&#39;scene_name&#39;] = scene_name
        kwargs = merge_dicts(def_kwargs, kwargs)

        contains_nan = False
        if slider_level is None:
            # No grouping
            v = self.unstack_to_array(levels=(x_level, y_level, z_level))
            if fillna is not None:
                v = np.nan_to_num(v, nan=fillna)
            if np.isnan(v).any():
                contains_nan = True
            volume = plotting.Volume(
                data=v,
                x_labels=x_labels,
                y_labels=y_labels,
                z_labels=z_labels,
                fig=fig,
                **kwargs
            )
            if return_fig:
                fig = volume.fig
            else:
                fig = volume
        else:
            # Requires grouping
            # See https://plotly.com/python/sliders/
            if not return_fig:
                raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
            _slider_labels = []
            for i, (name, group) in enumerate(self._obj.groupby(level=slider_level)):
                if slider_labels is not None:
                    name = slider_labels[i]
                _slider_labels.append(name)
                v = group.vbt.unstack_to_array(levels=(x_level, y_level, z_level))
                if fillna is not None:
                    v = np.nan_to_num(v, nan=fillna)
                if np.isnan(v).any():
                    contains_nan = True
                _kwargs = merge_dicts(dict(
                    trace_kwargs=dict(
                        name=str(name) if name is not None else None,
                        visible=False
                    )
                ), kwargs)
                default_size = fig is None and &#39;height&#39; not in _kwargs
                fig = plotting.Volume(
                    data=v,
                    x_labels=x_labels,
                    y_labels=y_labels,
                    z_labels=z_labels,
                    fig=fig,
                    **_kwargs
                ).fig
                if default_size:
                    fig.layout[&#39;height&#39;] += 100  # slider takes up space
            fig.data[active].visible = True
            steps = []
            for i in range(len(fig.data)):
                step = dict(
                    method=&#34;update&#34;,
                    args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                    label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
                )
                step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
                steps.append(step)
            prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
                if self.wrapper.index.names[slider_level] is not None else None
            sliders = [dict(
                active=active,
                currentvalue={&#34;prefix&#34;: prefix},
                pad={&#34;t&#34;: 50},
                steps=steps
            )]
            fig.update_layout(
                sliders=sliders
            )

        if contains_nan:
            warnings.warn(&#34;Data contains NaNs. Use `fillna` argument or &#34;
                          &#34;`show` method in case of visualization issues.&#34;, stacklevel=2)
        return fig

    def qqplot(self,
               sparams: tp.Union[tp.Iterable, tuple, None] = (),
               dist: str = &#39;norm&#39;,
               plot_line: bool = True,
               line_shape_kwargs: tp.KwargsLike = None,
               xref: str = &#39;x&#39;,
               yref: str = &#39;y&#39;,
               fig: tp.Optional[tp.BaseFigure] = None,
               **kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot probability plot using `scipy.stats.probplot`.

        `**kwargs` are passed to `GenericAccessor.scatterplot`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
        ```

        ![](/vectorbt/docs/img/sr_qqplot.svg)
        &#34;&#34;&#34;
        qq = stats.probplot(self._obj, sparams=sparams, dist=dist)
        fig = pd.Series(qq[0][1], index=qq[0][0]).vbt.scatterplot(fig=fig, **kwargs)

        if plot_line:
            if line_shape_kwargs is None:
                line_shape_kwargs = {}
            x = np.array([qq[0][0][0], qq[0][0][-1]])
            y = qq[1][1] + qq[1][0] * x
            fig.add_shape(**merge_dicts(dict(
                type=&#34;line&#34;,
                xref=xref,
                yref=yref,
                x0=x[0],
                y0=y[0],
                x1=x[1],
                y1=y[1],
                line=dict(
                    color=&#39;red&#39;
                )
            ), line_shape_kwargs))

        return fig


class GenericDFAccessor(GenericAccessor, BaseDFAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For DataFrames only.

    Accessible through `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Frame, **kwargs) -&gt; None:
        if not checks.is_pandas(obj):  # parent accessor
            obj = obj._obj

        BaseDFAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, **kwargs)

    def heatmap(self,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Heatmap` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df = pd.DataFrame([
        ...     [0, np.nan, np.nan],
        ...     [np.nan, 1, np.nan],
        ...     [np.nan, np.nan, 2]
        ... ])
        &gt;&gt;&gt; df.vbt.heatmap()
        ```

        ![](/vectorbt/docs/img/df_heatmap.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.columns
        if y_labels is None:
            y_labels = self.wrapper.index
        heatmap = plotting.Heatmap(
            data=self.to_2d_array(),
            x_labels=x_labels,
            y_labels=y_labels,
            **kwargs
        )
        if return_fig:
            return heatmap.fig
        return heatmap

    def ts_heatmap(self, is_y_category: bool = True,
                   **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self._obj.transpose().iloc[::-1].vbt.heatmap(is_y_category=is_y_category, **kwargs)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="vectorbt.generic.accessors.add_transform_methods"><code class="name flex">
<span>def <span class="ident">add_transform_methods</span></span>(<span>transformers)</span>
</code></dt>
<dd>
<div class="desc"><p>Class decorator to add scikit-learn transformers as transform methods.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_transform_methods(transformers: tp.Iterable[TransformFuncInfoT]) -&gt; WrapperFuncT:
    &#34;&#34;&#34;Class decorator to add scikit-learn transformers as transform methods.&#34;&#34;&#34;

    def wrapper(cls: tp.Type[tp.T]) -&gt; tp.Type[tp.T]:
        for fname, transformer in transformers:
            def transform(self, wrap_kwargs: tp.KwargsLike = None,
                          _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
                return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)

            transform.__doc__ = f&#34;Transform using `sklearn.preprocessing.{transformer.__name__}`.&#34;
            setattr(cls, fname, transform)
        return cls

    return wrapper</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor"><code class="flex name class">
<span>class <span class="ident">GenericAccessor</span></span>
<span>(</span><span>obj, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Accessor on top of data of any type. For both, Series and DataFrames.</p>
<p>Accessible through <code>pd.Series.vbt</code> and <code>pd.DataFrame.vbt</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenericAccessor(BaseAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For both, Series and DataFrames.

    Accessible through `pd.Series.vbt` and `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.SeriesFrame, **kwargs) -&gt; None:
        if not checks.is_pandas(obj):  # parent accessor
            obj = obj._obj

        BaseAccessor.__init__(self, obj, **kwargs)

    def rolling_std(self, window: int, minp: tp.Optional[int] = None, ddof: int = 1,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_std_nb`.&#34;&#34;&#34;
        out = nb.rolling_std_nb(self.to_2d_array(), window, minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def expanding_std(self, minp: tp.Optional[int] = 1, ddof: int = 1,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_std_nb`.&#34;&#34;&#34;
        out = nb.expanding_std_nb(self.to_2d_array(), minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def ewm_mean(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_mean_nb`.&#34;&#34;&#34;
        out = nb.ewm_mean_nb(self.to_2d_array(), span, minp=minp, adjust=adjust)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def ewm_std(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True, ddof: int = 1,
                wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_std_nb`.&#34;&#34;&#34;
        out = nb.ewm_std_nb(self.to_2d_array(), span, minp=minp, adjust=adjust, ddof=ddof)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def apply_along_axis(self, apply_func_nb: tp.Union[nb.apply_nbT, nb.row_apply_nbT], *args, axis: int = 0,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Apply a function `apply_func_nb` along an axis.&#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if axis == 0:
            out = nb.apply_nb(self.to_2d_array(), apply_func_nb, *args)
        elif axis == 1:
            out = nb.row_apply_nb(self.to_2d_array(), apply_func_nb, *args)
        else:
            raise ValueError(&#34;Only axes 0 and 1 are supported&#34;)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def rolling_apply(self, window: int, apply_func_nb: tp.Union[nb.rolling_apply_nbT, nb.rolling_matrix_apply_nbT],
                      *args, minp: tp.Optional[int] = None, on_matrix: bool = False,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_apply_nb` and
        `vectorbt.generic.nb.rolling_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
                      a    b         c
        2020-01-01  1.0  5.0  1.000000
        2020-01-02  1.5  4.5  1.500000
        2020-01-03  2.0  4.0  2.000000
        2020-01-04  3.0  3.0  2.333333
        2020-01-05  4.0  2.0  2.000000

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.777778  2.777778  2.777778
        2020-01-05  2.666667  2.666667  2.666667
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.rolling_matrix_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        else:
            out = nb.rolling_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def expanding_apply(self, apply_func_nb: tp.Union[nb.rolling_apply_nbT, nb.rolling_matrix_apply_nbT],
                        *args, minp: tp.Optional[int] = 1, on_matrix: bool = False,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_apply_nb` and
        `vectorbt.generic.nb.expanding_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
                      a    b    c
        2020-01-01  1.0  5.0  1.0
        2020-01-02  1.5  4.5  1.5
        2020-01-03  2.0  4.0  2.0
        2020-01-04  2.5  3.5  2.0
        2020-01-05  3.0  3.0  1.8

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.666667  2.666667  2.666667
        2020-01-05  2.600000  2.600000  2.600000
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.expanding_matrix_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        else:
            out = nb.expanding_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def groupby_apply(self, by: tp.PandasGroupByLike,
                      apply_func_nb: tp.Union[nb.groupby_apply_nbT, nb.groupby_apply_matrix_nbT],
                      *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                      **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_apply_matrix_nb` for `on_matrix=True`.

        For `by`, see `pd.DataFrame.groupby`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
             a    b    c
        1  1.5  4.5  1.5
        2  3.5  2.5  2.5
        3  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
                  a         b         c
        1  2.500000  2.500000  2.500000
        2  2.833333  2.833333  2.833333
        3  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        regrouped = self._obj.groupby(by, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(regrouped.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_apply_matrix_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        wrap_kwargs = merge_dicts(dict(name_or_index=list(regrouped.indices.keys())), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def resample_apply(self, freq: tp.PandasFrequencyLike,
                       apply_func_nb: tp.Union[nb.groupby_apply_nbT, nb.groupby_apply_matrix_nbT],
                       *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                       **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_apply_matrix_nb` for `on_matrix=True`.

        For `freq`, see `pd.DataFrame.resample`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_nb)
                      a    b    c
        2020-01-01  1.5  4.5  1.5
        2020-01-03  3.5  2.5  2.5
        2020-01-05  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.500000  2.500000  2.500000
        2020-01-03  2.833333  2.833333  2.833333
        2020-01-05  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        resampled = self._obj.resample(freq, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(resampled.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_apply_matrix_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        out_obj = self.wrapper.wrap(out, index=list(resampled.indices.keys()))
        resampled_arr = np.full((resampled.ngroups, self.to_2d_array().shape[1]), np.nan)
        resampled_obj = self.wrapper.wrap(
            resampled_arr,
            index=pd.Index(list(resampled.groups.keys()), freq=freq),
            **merge_dicts({}, wrap_kwargs)
        )
        resampled_obj.loc[out_obj.index] = out_obj.values
        return resampled_obj

    def applymap(self, apply_func_nb: nb.applymap_nbT, *args,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.applymap_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
        &gt;&gt;&gt; df.vbt.applymap(multiply_nb)
                       a     b    c
        2020-01-01   1.0  25.0  1.0
        2020-01-02   4.0  16.0  4.0
        2020-01-03   9.0   9.0  9.0
        2020-01-04  16.0   4.0  4.0
        2020-01-05  25.0   1.0  1.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        out = nb.applymap_nb(self.to_2d_array(), apply_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def filter(self, filter_func_nb: nb.filter_nbT, *args,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.filter_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
        &gt;&gt;&gt; df.vbt.filter(greater_nb)
                      a    b    c
        2020-01-01  NaN  5.0  NaN
        2020-01-02  NaN  4.0  NaN
        2020-01-03  3.0  3.0  3.0
        2020-01-04  4.0  NaN  NaN
        2020-01-05  5.0  NaN  NaN
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(filter_func_nb)

        out = nb.filter_nb(self.to_2d_array(), filter_func_nb, *args)
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    def apply_and_reduce(self, apply_func_nb: nb.apply_and_reduce_nbAT, reduce_func_nb: nb.apply_and_reduce_nbRT,
                         apply_args: tp.Optional[tuple] = None, reduce_args: tp.Optional[tuple] = None,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;See `vectorbt.generic.nb.apply_and_reduce_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
        a    4.0
        b    4.0
        c    3.0
        dtype: float64
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)
        checks.assert_numba_func(reduce_func_nb)
        if apply_args is None:
            apply_args = ()
        if reduce_args is None:
            reduce_args = ()

        out = nb.apply_and_reduce_nb(self.to_2d_array(), apply_func_nb, apply_args, reduce_func_nb, reduce_args)
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;apply_and_reduce&#39;), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def reduce(self, reduce_func_nb: tp.Union[nb.flat_reduce_grouped_nbT,
                                              nb.flat_reduce_grouped_to_array_nbT,
                                              nb.reduce_grouped_nbT,
                                              nb.reduce_grouped_to_array_nbT,
                                              nb.reduce_nbT,
                                              nb.reduce_to_array_nbT],
               *args, to_array: bool = False, to_idx: bool = False, flatten: bool = False,
               order: str = &#39;C&#39;, idx_labeled: bool = True, group_by: tp.GroupByLike = None,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeriesFrame[float]:
        &#34;&#34;&#34;Reduce by column.

        See `vectorbt.generic.nb.flat_reduce_grouped_to_array_nb` if grouped, `to_array` is True and `flatten` is True.
        See `vectorbt.generic.nb.flat_reduce_grouped_nb` if grouped, `to_array` is False and `flatten` is True.
        See `vectorbt.generic.nb.reduce_grouped_to_array_nb` if grouped, `to_array` is True and `flatten` is False.
        See `vectorbt.generic.nb.reduce_grouped_nb` if grouped, `to_array` is False and `flatten` is False.
        See `vectorbt.generic.nb.reduce_to_array_nb` if not grouped and `to_array` is True.
        See `vectorbt.generic.nb.reduce_nb` if not grouped and `to_array` is False.

        Set `to_idx` to True if values returned by `reduce_func_nb` are indices/positions.
        Set `idx_labeled` to False to return raw positions instead of labels.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.reduce(mean_nb)
        a    3.0
        b    3.0
        c    1.8
        dtype: float64

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True)
        a   2020-01-05
        b   2020-01-01
        c   2020-01-03
        dtype: datetime64[ns]

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True, idx_labeled=False)
        a    4
        b    0
        c    2
        dtype: int64

        &gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;], to_array=True)
               a    b    c
        min  1.0  1.0  1.0
        max  5.0  5.0  3.0

        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
        group
        first     3.0
        second    1.8
        dtype: float64

        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;],
        ...     to_array=True, group_by=group_by)
        group  first  second
        min      1.0     1.0
        max      5.0     3.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(reduce_func_nb)

        if self.wrapper.grouper.is_grouped(group_by=group_by):
            group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
            if flatten:
                checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])
                in_c_order = order.upper() == &#39;C&#39;
                if to_array:
                    out = nb.flat_reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                else:
                    out = nb.flat_reduce_grouped_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                if to_idx:
                    if in_c_order:
                        out //= group_lens  # flattened in C order
                    else:
                        out %= self.wrapper.shape[0]  # flattened in F order
            else:
                if to_array:
                    out = nb.reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
                else:
                    out = nb.reduce_grouped_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
        else:
            if to_array:
                out = nb.reduce_to_array_nb(
                    self.to_2d_array(), reduce_func_nb, *args)
            else:
                out = nb.reduce_nb(
                    self.to_2d_array(), reduce_func_nb, *args)

        # Perform post-processing
        if to_idx:
            nan_mask = np.isnan(out)
            if idx_labeled:
                out = out.astype(object)
                out[~nan_mask] = self.wrapper.index[out[~nan_mask].astype(np.int_)]
            else:
                out[nan_mask] = -1
                out = out.astype(np.int_)
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;reduce&#39; if not to_array else None), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=group_by, **wrap_kwargs)

    def squeeze_grouped(self, reduce_func_nb: nb.squeeze_grouped_nbT, *args, group_by: tp.GroupByLike = None,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Squeeze each group of columns into a single column.

        See `vectorbt.generic.nb.squeeze_grouped_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; mean_nb = njit(lambda i, group, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.squeeze_grouped(mean_nb, group_by=group_by)
        group       first  second
        2020-01-01    3.0     1.0
        2020-01-02    3.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    3.0     2.0
        2020-01-05    3.0     1.0
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_numba_func(reduce_func_nb)

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        out = nb.squeeze_grouped_nb(self.to_2d_array(), group_lens, reduce_func_nb, *args)
        return self.wrapper.wrap(out, group_by=group_by, **merge_dicts({}, wrap_kwargs))

    def flatten_grouped(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Flatten each group of columns.

        See `vectorbt.generic.nb.flatten_grouped_nb`.

        !!! warning
            Make sure that the distribution of group lengths is close to uniform, otherwise
            groups with less columns will be filled with NaN and needlessly occupy memory.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;C&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    2.0     2.0
        2020-01-02    4.0     NaN
        2020-01-03    3.0     3.0
        2020-01-03    3.0     NaN
        2020-01-04    4.0     2.0
        2020-01-04    2.0     NaN
        2020-01-05    5.0     1.0
        2020-01-05    1.0     NaN

        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;F&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-02    2.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    4.0     2.0
        2020-01-05    5.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    4.0     NaN
        2020-01-03    3.0     NaN
        2020-01-04    2.0     NaN
        2020-01-05    1.0     NaN
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        if order.upper() == &#39;C&#39;:
            out = nb.flatten_grouped_nb(self.to_2d_array(), group_lens, True)
            new_index = index_fns.repeat_index(self.wrapper.index, np.max(group_lens))
        else:
            out = nb.flatten_grouped_nb(self.to_2d_array(), group_lens, False)
            new_index = index_fns.tile_index(self.wrapper.index, np.max(group_lens))
        wrap_kwargs = merge_dicts(dict(index=new_index), wrap_kwargs)
        return self.wrapper.wrap(out, group_by=group_by, **wrap_kwargs)

    def min(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;min&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.min_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmin = np.nanmin
        else:
            _nanmin = nanmin
        return self.wrapper.wrap_reduced(_nanmin(arr, axis=0), **wrap_kwargs)

    def max(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;max&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.max_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmax = np.nanmax
        else:
            _nanmax = nanmax
        return self.wrapper.wrap_reduced(_nanmax(arr, axis=0), **wrap_kwargs)

    def mean(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return mean of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;mean&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.mean_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmean = np.nanmean
        else:
            _nanmean = nanmean
        return self.wrapper.wrap_reduced(_nanmean(arr, axis=0), **wrap_kwargs)

    def median(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return median of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;median&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.median_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmedian = np.nanmedian
        else:
            _nanmedian = nanmedian
        return self.wrapper.wrap_reduced(_nanmedian(arr, axis=0), **wrap_kwargs)

    def std(self, ddof: int = 1, group_by: tp.GroupByLike = None,
            wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return standard deviation of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;std&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.std_reduce_nb, ddof, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanstd = np.nanstd
        else:
            _nanstd = nanstd
        return self.wrapper.wrap_reduced(_nanstd(arr, ddof=ddof, axis=0), **wrap_kwargs)

    def sum(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return sum of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;sum&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.sum_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nansum = np.nansum
        else:
            _nansum = nansum
        return self.wrapper.wrap_reduced(_nansum(arr, axis=0), **wrap_kwargs)

    def count(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return count of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;count&#39;, dtype=np.int_), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.count_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        return self.wrapper.wrap_reduced(np.sum(~np.isnan(self.to_2d_array()), axis=0), **wrap_kwargs)

    def idxmin(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmin&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmin_reduce_nb,
                group_by=group_by,
                flatten=True,
                to_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmin(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def idxmax(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmax&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmax_reduce_nb,
                group_by=group_by,
                flatten=True,
                to_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmax(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, **wrap_kwargs)

    def describe(self, percentiles: tp.Optional[tp.ArrayLike] = None, ddof: int = 1,
                 group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.describe_reduce_nb`.

        For `percentiles`, see `pd.DataFrame.describe`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.describe()
                      a         b        c
        count  5.000000  5.000000  5.00000
        mean   3.000000  3.000000  1.80000
        std    1.581139  1.581139  0.83666
        min    1.000000  1.000000  1.00000
        25%    2.000000  2.000000  1.00000
        50%    3.000000  3.000000  2.00000
        75%    4.000000  4.000000  2.00000
        max    5.000000  5.000000  3.00000
        ```
        &#34;&#34;&#34;
        if percentiles is not None:
            percentiles = reshape_fns.to_1d(percentiles, raw=True)
        else:
            percentiles = np.array([0.25, 0.5, 0.75])
        percentiles = percentiles.tolist()
        if 0.5 not in percentiles:
            percentiles.append(0.5)
        percentiles = np.unique(percentiles)
        perc_formatted = pd.io.formats.format.format_percentiles(percentiles)
        index = pd.Index([&#39;count&#39;, &#39;mean&#39;, &#39;std&#39;, &#39;min&#39;, *perc_formatted, &#39;max&#39;])
        wrap_kwargs = merge_dicts(dict(name_or_index=index), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.describe_reduce_nb, percentiles, ddof,
                group_by=group_by, flatten=True, to_array=True,
                wrap_kwargs=wrap_kwargs)
        return self.reduce(
            nb.describe_reduce_nb, percentiles, ddof,
            to_array=True, wrap_kwargs=wrap_kwargs)

    def drawdown(self, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Drawdown series.&#34;&#34;&#34;
        out = self.to_2d_array() / nb.expanding_max_nb(self.to_2d_array()) - 1
        return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))

    @cached_property
    def drawdowns(self) -&gt; Drawdowns:
        &#34;&#34;&#34;`GenericAccessor.get_drawdowns` with default arguments.&#34;&#34;&#34;
        return self.get_drawdowns()

    @cached_method
    def get_drawdowns(self, group_by: tp.GroupByLike = None, **kwargs) -&gt; Drawdowns:
        &#34;&#34;&#34;Generate drawdown records.

        See `vectorbt.generic.drawdowns.Drawdowns`.&#34;&#34;&#34;
        if group_by is None:
            group_by = self.wrapper.grouper.group_by
        return Drawdowns.from_ts(self._obj, freq=self.wrapper.freq, group_by=group_by, **kwargs)

    def to_mapped_array(self, dropna: bool = True, group_by: tp.GroupByLike = None, **kwargs) -&gt; MappedArray:
        &#34;&#34;&#34;Convert this object into an instance of `vectorbt.records.mapped_array.MappedArray`.&#34;&#34;&#34;
        mapped_arr = reshape_fns.to_2d(self._obj, raw=True).flatten(order=&#39;F&#39;)
        col_arr = np.repeat(np.arange(self.wrapper.shape_2d[1]), self.wrapper.shape_2d[0])
        idx_arr = np.tile(np.arange(self.wrapper.shape_2d[0]), self.wrapper.shape_2d[1])
        if dropna:
            not_nan_mask = ~np.isnan(mapped_arr)
            mapped_arr = mapped_arr[not_nan_mask]
            col_arr = col_arr[not_nan_mask]
            idx_arr = idx_arr[not_nan_mask]
        if group_by is None:
            group_by = self.wrapper.grouper.group_by
        return MappedArray(self.wrapper, mapped_arr, col_arr, idx_arr=idx_arr, **kwargs).regroup(group_by)

    # ############# Transforming ############# #

    def transform(self, transformer: TransformerT, wrap_kwargs: tp.KwargsLike = None, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Transform using a transformer.

        A transformer can be any class instance that has `transform` and `fit_transform` methods,
        ideally subclassing `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`.

        Will fit `transformer` if not fitted.

        `**kwargs` are passed to the `transform` or `fit_transform` method.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

        &gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
                      a    b    c
        2020-01-01 -1.0  1.0 -1.0
        2020-01-02 -0.5  0.5  0.0
        2020-01-03  0.0  0.0  1.0
        2020-01-04  0.5 -0.5  0.0
        2020-01-05  1.0 -1.0 -1.0

        &gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
        &gt;&gt;&gt; df.vbt.transform(fitted_scaler)
                      a    b    c
        2020-01-01 -2.0  2.0 -2.0
        2020-01-02 -1.0  1.0 -1.0
        2020-01-03  0.0  0.0  0.0
        2020-01-04  1.0 -1.0 -1.0
        2020-01-05  2.0 -2.0 -2.0
        ```&#34;&#34;&#34;
        is_fitted = True
        try:
            check_is_fitted(transformer)
        except NotFittedError:
            is_fitted = False
        if not is_fitted:
            result = transformer.fit_transform(self.to_2d_array(), **kwargs)
        else:
            result = transformer.transform(self.to_2d_array(), **kwargs)
        return self.wrapper.wrap(result, **merge_dicts({}, wrap_kwargs))

    def zscore(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Compute z-score using `sklearn.preprocessing.StandardScaler`.&#34;&#34;&#34;
        return self.scale(with_mean=True, with_std=True, **kwargs)

    # ############# Splitting ############# #

    def split(self, splitter: SplitterT, stack_kwargs: tp.KwargsLike = None, keys: tp.Optional[tp.IndexLike] = None,
              plot: bool = False, trace_names: tp.TraceNames = None, heatmap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using a splitter.

        Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.

        A splitter can be any class instance that has `split` method, ideally subclassing
        `sklearn.model_selection.BaseCrossValidator` or `vectorbt.generic.splitters.BaseSplitter`.

        `heatmap_kwargs` are passed to `vectorbt.generic.plotting.Heatmap` if `plot` is True,
        can be a dictionary or a list per set, for example, to set trace name for each set (&#39;train&#39;, &#39;test&#39;, etc.).

        `**kwargs` are passed to the `split` method.

        !!! note
            The datetime-like format of the index will be lost as result of this operation.
            Make sure to store the index metadata such as frequency information beforehand.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

        &gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
        &gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

        &gt;&gt;&gt; train_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          3.0  3.0  3
        4          NaN  4.0  4
        5          NaN  5.0  5
        6          NaN  NaN  6
        7          NaN  NaN  7
        &gt;&gt;&gt; train_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]
        &gt;&gt;&gt; test_df
        split_idx  0  1  2
        0          4  6  8
        1          5  7  9
        &gt;&gt;&gt; test_indexes
        [DatetimeIndex([&#39;2020-01-05&#39;, &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-09&#39;, &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=[&#39;train&#39;, &#39;test&#39;])
        ```

        ![](/vectorbt/docs/img/split_plot.svg)
        &#34;&#34;&#34;
        total_range_sr = pd.Series(np.arange(len(self.wrapper.index)), index=self.wrapper.index)
        set_ranges = list(splitter.split(total_range_sr, **kwargs))
        if len(set_ranges) == 0:
            raise ValueError(&#34;No splits were generated&#34;)
        idxs_by_split_and_set = list(zip(*set_ranges))

        results = []
        if keys is not None:
            if not isinstance(keys, pd.Index):
                keys = pd.Index(keys)
        for idxs_by_split in idxs_by_split_and_set:
            split_dfs = []
            split_indexes = []
            for split_idx, idxs in enumerate(idxs_by_split):
                split_dfs.append(self._obj.iloc[idxs].reset_index(drop=True))
                if keys is not None:
                    split_name = keys[split_idx]
                else:
                    split_name = &#39;split_&#39; + str(split_idx)
                split_indexes.append(pd.Index(self.wrapper.index[idxs], name=split_name))
            set_df = pd.concat(split_dfs, axis=1).reset_index(drop=True)
            if keys is not None:
                split_columns = keys
            else:
                split_columns = pd.Index(np.arange(len(split_indexes)), name=&#39;split_idx&#39;)
            split_columns = index_fns.repeat_index(split_columns, len(self.wrapper.columns))
            if stack_kwargs is None:
                stack_kwargs = {}
            set_df = set_df.vbt.stack_index(split_columns, **stack_kwargs)
            results.append((set_df, split_indexes))

        if plot:  # pragma: no cover
            if trace_names is None:
                trace_names = list(range(len(results)))
            if isinstance(trace_names, str):
                trace_names = [trace_names]
            nan_df = pd.DataFrame(np.nan, columns=pd.RangeIndex(stop=len(results[0][1])), index=self.wrapper.index)
            fig = None
            for i, (_, split_indexes) in enumerate(results):
                heatmap_df = nan_df.copy()
                for j in range(len(split_indexes)):
                    heatmap_df.loc[split_indexes[j], j] = i
                _heatmap_kwargs = resolve_dict(heatmap_kwargs, i=i)
                fig = heatmap_df.vbt.ts_heatmap(fig=fig, **merge_dicts(
                    dict(
                        trace_kwargs=dict(
                            showscale=False,
                            name=str(trace_names[i]),
                            showlegend=True
                        )
                    ),
                    _heatmap_kwargs
                ))
                if fig.layout.colorway is not None:
                    colorway = fig.layout.colorway
                else:
                    colorway = fig.layout.template.layout.colorway
                if &#39;colorscale&#39; not in _heatmap_kwargs:
                    fig.data[-1].update(colorscale=[colorway[i], colorway[i]])
            return fig

        if len(results) == 1:
            return results[0]
        return tuple(results)

    def range_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RangeSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  5
        1          1  6
        2          2  7
        3          3  8
        4          4  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
        &gt;&gt;&gt; range_df
        split_idx  0  1  2  3  4  5  6
        0          0  1  2  3  4  5  6
        1          1  2  3  4  5  6  7
        2          2  3  4  5  6  7  8
        3          3  4  5  6  7  8  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;),
         DatetimeIndex([&#39;2020-01-04&#39;, ..., &#39;2020-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_3&#39;),
         DatetimeIndex([&#39;2020-01-05&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_4&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-09&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_5&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_6&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  2
        1          1  3
        2          2  4
        3          3  5
        4          4  6
        5          5  7
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
        &gt;&gt;&gt; range_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          NaN  3.0  3
        4          NaN  NaN  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-03&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
        ...     start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;]),
        ...     end_idxs=pd.Index([&#39;2020-01-04&#39;, &#39;2020-01-05&#39;])
        ... )
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  1
        1          1  2
        2          2  3
        3          3  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

         &gt;&gt;&gt; sr.vbt.range_split(
         ...    start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;, &#39;2020-01-01&#39;]),
         ...    end_idxs=pd.Index([&#39;2020-01-08&#39;, &#39;2020-01-04&#39;, &#39;2020-01-07&#39;]),
         ...    plot=True
         ... )
        ```

        ![](/vectorbt/docs/img/range_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RangeSplitter(), **kwargs)

    def rolling_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RollingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx  0  1  2  3  4  5
        0          0  1  2  3  4  5
        1          1  2  3  4  5  6
        2          2  3  4  5  6  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5
        0          3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5
        0          4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/vectorbt/docs/img/rolling_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RollingSplitter(), **kwargs)

    def expanding_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.ExpandingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
        ...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx    0    1    2    3    4    5    6  7
        0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
        1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
        2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
        3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
        4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
        5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
        6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
        7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          1  2  3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          2  3  4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.expanding_split(
        ...     set_lens=(1, 1), min_len=3, left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/vectorbt/docs/img/expanding_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(ExpandingSplitter(), **kwargs)

    # ############# Enums ############# #

    def map_enum(self, enum: tp.NamedTuple) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Map integer values to field names of an enum.&#34;&#34;&#34;
        def _mapper(x: int) -&gt; str:
            if x in enum:
                return enum._fields[x]
            if x == -1:
                return &#39;&#39;
            return &#39;UNK&#39;

        if self.is_series():
            return self._obj.map(_mapper)
        return self._obj.applymap(_mapper)

    # ############# Plotting ############# #

    def plot(self,
             trace_names: tp.TraceNames = None,
             x_labels: tp.Optional[tp.Labels] = None,
             return_fig: bool = True,
             **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Scatter` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.plot()
        ```

        ![](/vectorbt/docs/img/df_plot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        scatter = plotting.Scatter(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return scatter.fig
        return scatter

    def lineplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;lines&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.lineplot()
        ```

        ![](/vectorbt/docs/img/df_lineplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;lines&#39;)), kwargs))

    def scatterplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;markers&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.scatterplot()
        ```

        ![](/vectorbt/docs/img/df_scatterplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;markers&#39;)), kwargs))

    def barplot(self,
                trace_names: tp.TraceNames = None,
                x_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Bar]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Bar` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.barplot()
        ```

        ![](/vectorbt/docs/img/df_barplot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        bar = plotting.Bar(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return bar.fig
        return bar

    def histplot(self,
                 trace_names: tp.TraceNames = None,
                 group_by: tp.GroupByLike = None,
                 return_fig: bool = True,
                 **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Histogram]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Histogram` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.histplot()
        ```

        ![](/vectorbt/docs/img/df_histplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.histplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        hist = plotting.Histogram(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return hist.fig
        return hist

    def boxplot(self,
                trace_names: tp.TraceNames = None,
                group_by: tp.GroupByLike = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Box]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Box` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.boxplot()
        ```

        ![](/vectorbt/docs/img/df_boxplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.boxplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        box = plotting.Box(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return box.fig
        return box</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></li>
</ul>
<h3 class="section-subtitle">Subclasses</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.accessors.GenericDFAccessor" href="#vectorbt.generic.accessors.GenericDFAccessor">GenericDFAccessor</a></li>
<li><a title="vectorbt.generic.accessors.GenericSRAccessor" href="#vectorbt.generic.accessors.GenericSRAccessor">GenericSRAccessor</a></li>
<li><a title="vectorbt.returns.accessors.ReturnsAccessor" href="../returns/accessors.html#vectorbt.returns.accessors.ReturnsAccessor">ReturnsAccessor</a></li>
<li><a title="vectorbt.signals.accessors.SignalsAccessor" href="../signals/accessors.html#vectorbt.signals.accessors.SignalsAccessor">SignalsAccessor</a></li>
</ul>
<h3 class="section-subtitle">Instance variables</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor.drawdowns"><code class="name">var <span class="ident">drawdowns</span></code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">GenericAccessor.get_drawdowns()</a></code> with default arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __get__(self, instance: tp.Any, owner: tp.Optional[tp.Type] = None) -&gt; tp.Any:
    if instance is None:
        return self
    if not should_cache(self.name, instance, func=self.func, **self.flags):
        return super().__get__(instance, owner=owner)
    cache = instance.__dict__
    val = cache.get(self.attrname, _NOT_FOUND)
    if val is _NOT_FOUND:
        with self.lock:
            # check if another thread filled cache while we awaited lock
            val = cache.get(self.attrname, _NOT_FOUND)
            if val is _NOT_FOUND:
                val = self.func(instance)
                cache[self.attrname] = val
    return val</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor.apply_along_axis"><code class="name flex">
<span>def <span class="ident">apply_along_axis</span></span>(<span>self, apply_func_nb, *args, axis=0, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a function <code>apply_func_nb</code> along an axis.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_along_axis(self, apply_func_nb: tp.Union[nb.apply_nbT, nb.row_apply_nbT], *args, axis: int = 0,
                     wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Apply a function `apply_func_nb` along an axis.&#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    if axis == 0:
        out = nb.apply_nb(self.to_2d_array(), apply_func_nb, *args)
    elif axis == 1:
        out = nb.row_apply_nb(self.to_2d_array(), apply_func_nb, *args)
    else:
        raise ValueError(&#34;Only axes 0 and 1 are supported&#34;)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce"><code class="name flex">
<span>def <span class="ident">apply_and_reduce</span></span>(<span>self, apply_func_nb, reduce_func_nb, apply_args=None, reduce_args=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.apply_and_reduce_nb" href="nb.html#vectorbt.generic.nb.apply_and_reduce_nb">apply_and_reduce_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
&gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
a    4.0
b    4.0
c    3.0
dtype: float64
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_and_reduce(self, apply_func_nb: nb.apply_and_reduce_nbAT, reduce_func_nb: nb.apply_and_reduce_nbRT,
                     apply_args: tp.Optional[tuple] = None, reduce_args: tp.Optional[tuple] = None,
                     wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;See `vectorbt.generic.nb.apply_and_reduce_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
    &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
    a    4.0
    b    4.0
    c    3.0
    dtype: float64
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)
    checks.assert_numba_func(reduce_func_nb)
    if apply_args is None:
        apply_args = ()
    if reduce_args is None:
        reduce_args = ()

    out = nb.apply_and_reduce_nb(self.to_2d_array(), apply_func_nb, apply_args, reduce_func_nb, reduce_args)
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;apply_and_reduce&#39;), wrap_kwargs)
    return self.wrapper.wrap_reduced(out, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.applymap"><code class="name flex">
<span>def <span class="ident">applymap</span></span>(<span>self, apply_func_nb, *args, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.applymap_nb" href="nb.html#vectorbt.generic.nb.applymap_nb">applymap_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
&gt;&gt;&gt; df.vbt.applymap(multiply_nb)
               a     b    c
2020-01-01   1.0  25.0  1.0
2020-01-02   4.0  16.0  4.0
2020-01-03   9.0   9.0  9.0
2020-01-04  16.0   4.0  4.0
2020-01-05  25.0   1.0  1.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def applymap(self, apply_func_nb: nb.applymap_nbT, *args,
             wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.applymap_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
    &gt;&gt;&gt; df.vbt.applymap(multiply_nb)
                   a     b    c
    2020-01-01   1.0  25.0  1.0
    2020-01-02   4.0  16.0  4.0
    2020-01-03   9.0   9.0  9.0
    2020-01-04  16.0   4.0  4.0
    2020-01-05  25.0   1.0  1.0
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    out = nb.applymap_nb(self.to_2d_array(), apply_func_nb, *args)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.barplot"><code class="name flex">
<span>def <span class="ident">barplot</span></span>(<span>self, trace_names=None, x_labels=None, return_fig=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Bar" href="plotting.html#vectorbt.generic.plotting.Bar">Bar</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.barplot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_barplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def barplot(self,
            trace_names: tp.TraceNames = None,
            x_labels: tp.Optional[tp.Labels] = None,
            return_fig: bool = True,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Bar]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Bar` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.barplot()
    ```

    ![](/vectorbt/docs/img/df_barplot.svg)
    &#34;&#34;&#34;
    if x_labels is None:
        x_labels = self.wrapper.index
    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    bar = plotting.Bar(
        data=self.to_2d_array(),
        trace_names=trace_names,
        x_labels=x_labels,
        **kwargs
    )
    if return_fig:
        return bar.fig
    return bar</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.binarize"><code class="name flex">
<span>def <span class="ident">binarize</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.Binarizer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.boxplot"><code class="name flex">
<span>def <span class="ident">boxplot</span></span>(<span>self, trace_names=None, group_by=None, return_fig=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Box" href="plotting.html#vectorbt.generic.plotting.Box">Box</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.boxplot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_boxplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def boxplot(self,
            trace_names: tp.TraceNames = None,
            group_by: tp.GroupByLike = None,
            return_fig: bool = True,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Box]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Box` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.boxplot()
    ```

    ![](/vectorbt/docs/img/df_boxplot.svg)
    &#34;&#34;&#34;
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.flatten_grouped(group_by=group_by).vbt.boxplot(trace_names=trace_names, **kwargs)

    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    box = plotting.Box(
        data=self.to_2d_array(),
        trace_names=trace_names,
        **kwargs
    )
    if return_fig:
        return box.fig
    return box</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.bshift"><code class="name flex">
<span>def <span class="ident">bshift</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.bshift_nb" href="nb.html#vectorbt.generic.nb.bshift_nb">bshift_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return count of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return count of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;count&#39;, dtype=np.int_), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.count_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    return self.wrapper.wrap_reduced(np.sum(~np.isnan(self.to_2d_array()), axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.cumprod"><code class="name flex">
<span>def <span class="ident">cumprod</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.cumprod_nb" href="nb.html#vectorbt.generic.nb.cumprod_nb">cumprod_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.cumsum"><code class="name flex">
<span>def <span class="ident">cumsum</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.cumsum_nb" href="nb.html#vectorbt.generic.nb.cumsum_nb">cumsum_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.describe"><code class="name flex">
<span>def <span class="ident">describe</span></span>(<span>self, percentiles=None, ddof=1, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.describe_reduce_nb" href="nb.html#vectorbt.generic.nb.describe_reduce_nb">describe_reduce_nb()</a></code>.</p>
<p>For <code>percentiles</code>, see <code>pd.DataFrame.describe</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.describe()
              a         b        c
count  5.000000  5.000000  5.00000
mean   3.000000  3.000000  1.80000
std    1.581139  1.581139  0.83666
min    1.000000  1.000000  1.00000
25%    2.000000  2.000000  1.00000
50%    3.000000  3.000000  2.00000
75%    4.000000  4.000000  2.00000
max    5.000000  5.000000  3.00000
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def describe(self, percentiles: tp.Optional[tp.ArrayLike] = None, ddof: int = 1,
             group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.describe_reduce_nb`.

    For `percentiles`, see `pd.DataFrame.describe`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.describe()
                  a         b        c
    count  5.000000  5.000000  5.00000
    mean   3.000000  3.000000  1.80000
    std    1.581139  1.581139  0.83666
    min    1.000000  1.000000  1.00000
    25%    2.000000  2.000000  1.00000
    50%    3.000000  3.000000  2.00000
    75%    4.000000  4.000000  2.00000
    max    5.000000  5.000000  3.00000
    ```
    &#34;&#34;&#34;
    if percentiles is not None:
        percentiles = reshape_fns.to_1d(percentiles, raw=True)
    else:
        percentiles = np.array([0.25, 0.5, 0.75])
    percentiles = percentiles.tolist()
    if 0.5 not in percentiles:
        percentiles.append(0.5)
    percentiles = np.unique(percentiles)
    perc_formatted = pd.io.formats.format.format_percentiles(percentiles)
    index = pd.Index([&#39;count&#39;, &#39;mean&#39;, &#39;std&#39;, &#39;min&#39;, *perc_formatted, &#39;max&#39;])
    wrap_kwargs = merge_dicts(dict(name_or_index=index), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.describe_reduce_nb, percentiles, ddof,
            group_by=group_by, flatten=True, to_array=True,
            wrap_kwargs=wrap_kwargs)
    return self.reduce(
        nb.describe_reduce_nb, percentiles, ddof,
        to_array=True, wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.diff"><code class="name flex">
<span>def <span class="ident">diff</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.diff_nb" href="nb.html#vectorbt.generic.nb.diff_nb">diff_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.drawdown"><code class="name flex">
<span>def <span class="ident">drawdown</span></span>(<span>self, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Drawdown series.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drawdown(self, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Drawdown series.&#34;&#34;&#34;
    out = self.to_2d_array() / nb.expanding_max_nb(self.to_2d_array()) - 1
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ewm_mean"><code class="name flex">
<span>def <span class="ident">ewm_mean</span></span>(<span>self, span, minp=0, adjust=True, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.ewm_mean_nb" href="nb.html#vectorbt.generic.nb.ewm_mean_nb">ewm_mean_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ewm_mean(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True,
             wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_mean_nb`.&#34;&#34;&#34;
    out = nb.ewm_mean_nb(self.to_2d_array(), span, minp=minp, adjust=adjust)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ewm_std"><code class="name flex">
<span>def <span class="ident">ewm_std</span></span>(<span>self, span, minp=0, adjust=True, ddof=1, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.ewm_std_nb" href="nb.html#vectorbt.generic.nb.ewm_std_nb">ewm_std_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ewm_std(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True, ddof: int = 1,
            wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_std_nb`.&#34;&#34;&#34;
    out = nb.ewm_std_nb(self.to_2d_array(), span, minp=minp, adjust=adjust, ddof=ddof)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_apply"><code class="name flex">
<span>def <span class="ident">expanding_apply</span></span>(<span>self, apply_func_nb, *args, minp=1, on_matrix=False, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_apply_nb" href="nb.html#vectorbt.generic.nb.expanding_apply_nb">expanding_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.expanding_matrix_apply_nb" href="nb.html#vectorbt.generic.nb.expanding_matrix_apply_nb">expanding_matrix_apply_nb()</a></code> for <code>on_matrix=True</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
              a    b    c
2020-01-01  1.0  5.0  1.0
2020-01-02  1.5  4.5  1.5
2020-01-03  2.0  4.0  2.0
2020-01-04  2.5  3.5  2.0
2020-01-05  3.0  3.0  1.8

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                   a         b         c
2020-01-01  2.333333  2.333333  2.333333
2020-01-02  2.500000  2.500000  2.500000
2020-01-03  2.666667  2.666667  2.666667
2020-01-04  2.666667  2.666667  2.666667
2020-01-05  2.600000  2.600000  2.600000
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expanding_apply(self, apply_func_nb: tp.Union[nb.rolling_apply_nbT, nb.rolling_matrix_apply_nbT],
                    *args, minp: tp.Optional[int] = 1, on_matrix: bool = False,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_apply_nb` and
    `vectorbt.generic.nb.expanding_matrix_apply_nb` for `on_matrix=True`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
                  a    b    c
    2020-01-01  1.0  5.0  1.0
    2020-01-02  1.5  4.5  1.5
    2020-01-03  2.0  4.0  2.0
    2020-01-04  2.5  3.5  2.0
    2020-01-05  3.0  3.0  1.8

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                       a         b         c
    2020-01-01  2.333333  2.333333  2.333333
    2020-01-02  2.500000  2.500000  2.500000
    2020-01-03  2.666667  2.666667  2.666667
    2020-01-04  2.666667  2.666667  2.666667
    2020-01-05  2.600000  2.600000  2.600000
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    if on_matrix:
        out = nb.expanding_matrix_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
    else:
        out = nb.expanding_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_max"><code class="name flex">
<span>def <span class="ident">expanding_max</span></span>(<span>self, minp=1)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_max_nb" href="nb.html#vectorbt.generic.nb.expanding_max_nb">expanding_max_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_mean"><code class="name flex">
<span>def <span class="ident">expanding_mean</span></span>(<span>self, minp=1)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_mean_nb" href="nb.html#vectorbt.generic.nb.expanding_mean_nb">expanding_mean_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_min"><code class="name flex">
<span>def <span class="ident">expanding_min</span></span>(<span>self, minp=1)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_min_nb" href="nb.html#vectorbt.generic.nb.expanding_min_nb">expanding_min_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_split"><code class="name flex">
<span>def <span class="ident">expanding_split</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Split using <code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">GenericAccessor.split()</a></code> on <code><a title="vectorbt.generic.splitters.ExpandingSplitter" href="splitters.html#vectorbt.generic.splitters.ExpandingSplitter">ExpandingSplitter</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
&gt;&gt;&gt; train_set[0]
split_idx    0    1    2    3    4    5    6  7
0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
&gt;&gt;&gt; valid_set[0]
split_idx  0  1  2  3  4  5  6  7
0          1  2  3  4  5  6  7  8
&gt;&gt;&gt; test_set[0]
split_idx  0  1  2  3  4  5  6  7
0          2  3  4  5  6  7  8  9

&gt;&gt;&gt; sr.vbt.expanding_split(
...     set_lens=(1, 1), min_len=3, left_to_right=False,
...     plot=True, trace_names=['train', 'valid', 'test'])
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/expanding_split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expanding_split(self, **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.ExpandingSplitter`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
    ...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
    &gt;&gt;&gt; train_set[0]
    split_idx    0    1    2    3    4    5    6  7
    0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
    1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
    2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
    3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
    4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
    5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
    6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
    7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
    &gt;&gt;&gt; valid_set[0]
    split_idx  0  1  2  3  4  5  6  7
    0          1  2  3  4  5  6  7  8
    &gt;&gt;&gt; test_set[0]
    split_idx  0  1  2  3  4  5  6  7
    0          2  3  4  5  6  7  8  9

    &gt;&gt;&gt; sr.vbt.expanding_split(
    ...     set_lens=(1, 1), min_len=3, left_to_right=False,
    ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
    ```

    ![](/vectorbt/docs/img/expanding_split_plot.svg)
    &#34;&#34;&#34;
    return self.split(ExpandingSplitter(), **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_std"><code class="name flex">
<span>def <span class="ident">expanding_std</span></span>(<span>self, minp=1, ddof=1, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_std_nb" href="nb.html#vectorbt.generic.nb.expanding_std_nb">expanding_std_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expanding_std(self, minp: tp.Optional[int] = 1, ddof: int = 1,
                  wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_std_nb`.&#34;&#34;&#34;
    out = nb.expanding_std_nb(self.to_2d_array(), minp=minp, ddof=ddof)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ffill"><code class="name flex">
<span>def <span class="ident">ffill</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.ffill_nb" href="nb.html#vectorbt.generic.nb.ffill_nb">ffill_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.fillna"><code class="name flex">
<span>def <span class="ident">fillna</span></span>(<span>self, value)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.fillna_nb" href="nb.html#vectorbt.generic.nb.fillna_nb">fillna_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, filter_func_nb, *args, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.filter_nb" href="nb.html#vectorbt.generic.nb.filter_nb">filter_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
&gt;&gt;&gt; df.vbt.filter(greater_nb)
              a    b    c
2020-01-01  NaN  5.0  NaN
2020-01-02  NaN  4.0  NaN
2020-01-03  3.0  3.0  3.0
2020-01-04  4.0  NaN  NaN
2020-01-05  5.0  NaN  NaN
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, filter_func_nb: nb.filter_nbT, *args,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.filter_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
    &gt;&gt;&gt; df.vbt.filter(greater_nb)
                  a    b    c
    2020-01-01  NaN  5.0  NaN
    2020-01-02  NaN  4.0  NaN
    2020-01-03  3.0  3.0  3.0
    2020-01-04  4.0  NaN  NaN
    2020-01-05  5.0  NaN  NaN
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(filter_func_nb)

    out = nb.filter_nb(self.to_2d_array(), filter_func_nb, *args)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.flatten_grouped"><code class="name flex">
<span>def <span class="ident">flatten_grouped</span></span>(<span>self, group_by=None, order='C', wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Flatten each group of columns.</p>
<p>See <code><a title="vectorbt.generic.nb.flatten_grouped_nb" href="nb.html#vectorbt.generic.nb.flatten_grouped_nb">flatten_grouped_nb()</a></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Make sure that the distribution of group lengths is close to uniform, otherwise
groups with less columns will be filled with NaN and needlessly occupy memory.</p>
</div>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; group_by = pd.Series(['first', 'first', 'second'], name='group')
&gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order='C')
group       first  second
2020-01-01    1.0     1.0
2020-01-01    5.0     NaN
2020-01-02    2.0     2.0
2020-01-02    4.0     NaN
2020-01-03    3.0     3.0
2020-01-03    3.0     NaN
2020-01-04    4.0     2.0
2020-01-04    2.0     NaN
2020-01-05    5.0     1.0
2020-01-05    1.0     NaN

&gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order='F')
group       first  second
2020-01-01    1.0     1.0
2020-01-02    2.0     2.0
2020-01-03    3.0     3.0
2020-01-04    4.0     2.0
2020-01-05    5.0     1.0
2020-01-01    5.0     NaN
2020-01-02    4.0     NaN
2020-01-03    3.0     NaN
2020-01-04    2.0     NaN
2020-01-05    1.0     NaN
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flatten_grouped(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Flatten each group of columns.

    See `vectorbt.generic.nb.flatten_grouped_nb`.

    !!! warning
        Make sure that the distribution of group lengths is close to uniform, otherwise
        groups with less columns will be filled with NaN and needlessly occupy memory.

    ## Example

    ```python-repl
    &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
    &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;C&#39;)
    group       first  second
    2020-01-01    1.0     1.0
    2020-01-01    5.0     NaN
    2020-01-02    2.0     2.0
    2020-01-02    4.0     NaN
    2020-01-03    3.0     3.0
    2020-01-03    3.0     NaN
    2020-01-04    4.0     2.0
    2020-01-04    2.0     NaN
    2020-01-05    5.0     1.0
    2020-01-05    1.0     NaN

    &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;F&#39;)
    group       first  second
    2020-01-01    1.0     1.0
    2020-01-02    2.0     2.0
    2020-01-03    3.0     3.0
    2020-01-04    4.0     2.0
    2020-01-05    5.0     1.0
    2020-01-01    5.0     NaN
    2020-01-02    4.0     NaN
    2020-01-03    3.0     NaN
    2020-01-04    2.0     NaN
    2020-01-05    1.0     NaN
    ```
    &#34;&#34;&#34;
    if not self.wrapper.grouper.is_grouped(group_by=group_by):
        raise ValueError(&#34;Grouping required&#34;)
    checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])

    group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
    if order.upper() == &#39;C&#39;:
        out = nb.flatten_grouped_nb(self.to_2d_array(), group_lens, True)
        new_index = index_fns.repeat_index(self.wrapper.index, np.max(group_lens))
    else:
        out = nb.flatten_grouped_nb(self.to_2d_array(), group_lens, False)
        new_index = index_fns.tile_index(self.wrapper.index, np.max(group_lens))
    wrap_kwargs = merge_dicts(dict(index=new_index), wrap_kwargs)
    return self.wrapper.wrap(out, group_by=group_by, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.fshift"><code class="name flex">
<span>def <span class="ident">fshift</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.fshift_nb" href="nb.html#vectorbt.generic.nb.fshift_nb">fshift_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.get_drawdowns"><code class="name flex">
<span>def <span class="ident">get_drawdowns</span></span>(<span>self, group_by=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate drawdown records.</p>
<p>See <code><a title="vectorbt.generic.drawdowns.Drawdowns" href="drawdowns.html#vectorbt.generic.drawdowns.Drawdowns">Drawdowns</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@cached_method
def get_drawdowns(self, group_by: tp.GroupByLike = None, **kwargs) -&gt; Drawdowns:
    &#34;&#34;&#34;Generate drawdown records.

    See `vectorbt.generic.drawdowns.Drawdowns`.&#34;&#34;&#34;
    if group_by is None:
        group_by = self.wrapper.grouper.group_by
    return Drawdowns.from_ts(self._obj, freq=self.wrapper.freq, group_by=group_by, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.groupby_apply"><code class="name flex">
<span>def <span class="ident">groupby_apply</span></span>(<span>self, by, apply_func_nb, *args, on_matrix=False, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.groupby_apply_nb" href="nb.html#vectorbt.generic.nb.groupby_apply_nb">groupby_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.groupby_apply_matrix_nb" href="nb.html#vectorbt.generic.nb.groupby_apply_matrix_nb">groupby_apply_matrix_nb()</a></code> for <code>on_matrix=True</code>.</p>
<p>For <code>by</code>, see <code>pd.DataFrame.groupby</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
     a    b    c
1  1.5  4.5  1.5
2  3.5  2.5  2.5
3  5.0  1.0  1.0

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
          a         b         c
1  2.500000  2.500000  2.500000
2  2.833333  2.833333  2.833333
3  2.333333  2.333333  2.333333
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupby_apply(self, by: tp.PandasGroupByLike,
                  apply_func_nb: tp.Union[nb.groupby_apply_nbT, nb.groupby_apply_matrix_nbT],
                  *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                  **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
    `vectorbt.generic.nb.groupby_apply_matrix_nb` for `on_matrix=True`.

    For `by`, see `pd.DataFrame.groupby`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
         a    b    c
    1  1.5  4.5  1.5
    2  3.5  2.5  2.5
    3  5.0  1.0  1.0

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
              a         b         c
    1  2.500000  2.500000  2.500000
    2  2.833333  2.833333  2.833333
    3  2.333333  2.333333  2.333333
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    regrouped = self._obj.groupby(by, axis=0, **kwargs)
    groups = Dict()
    for i, (k, v) in enumerate(regrouped.indices.items()):
        groups[i] = np.asarray(v)
    if on_matrix:
        out = nb.groupby_apply_matrix_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    else:
        out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    wrap_kwargs = merge_dicts(dict(name_or_index=list(regrouped.indices.keys())), wrap_kwargs)
    return self.wrapper.wrap_reduced(out, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.histplot"><code class="name flex">
<span>def <span class="ident">histplot</span></span>(<span>self, trace_names=None, group_by=None, return_fig=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Histogram" href="plotting.html#vectorbt.generic.plotting.Histogram">Histogram</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.histplot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_histplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def histplot(self,
             trace_names: tp.TraceNames = None,
             group_by: tp.GroupByLike = None,
             return_fig: bool = True,
             **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Histogram]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Histogram` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.histplot()
    ```

    ![](/vectorbt/docs/img/df_histplot.svg)
    &#34;&#34;&#34;
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.flatten_grouped(group_by=group_by).vbt.histplot(trace_names=trace_names, **kwargs)

    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    hist = plotting.Histogram(
        data=self.to_2d_array(),
        trace_names=trace_names,
        **kwargs
    )
    if return_fig:
        return hist.fig
    return hist</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.idxmax"><code class="name flex">
<span>def <span class="ident">idxmax</span></span>(<span>self, group_by=None, order='C', wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return labeled index of max of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def idxmax(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return labeled index of max of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmax&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.argmax_reduce_nb,
            group_by=group_by,
            flatten=True,
            to_idx=True,
            order=order,
            wrap_kwargs=wrap_kwargs
        )

    obj = self.to_2d_array()
    out = np.full(obj.shape[1], np.nan, dtype=object)
    nan_mask = np.all(np.isnan(obj), axis=0)
    out[~nan_mask] = self.wrapper.index[nanargmax(obj[:, ~nan_mask], axis=0)]
    return self.wrapper.wrap_reduced(out, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.idxmin"><code class="name flex">
<span>def <span class="ident">idxmin</span></span>(<span>self, group_by=None, order='C', wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return labeled index of min of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def idxmin(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return labeled index of min of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmin&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.argmin_reduce_nb,
            group_by=group_by,
            flatten=True,
            to_idx=True,
            order=order,
            wrap_kwargs=wrap_kwargs
        )

    obj = self.to_2d_array()
    out = np.full(obj.shape[1], np.nan, dtype=object)
    nan_mask = np.all(np.isnan(obj), axis=0)
    out[~nan_mask] = self.wrapper.index[nanargmin(obj[:, ~nan_mask], axis=0)]
    return self.wrapper.wrap_reduced(out, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.lineplot"><code class="name flex">
<span>def <span class="ident">lineplot</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">GenericAccessor.plot()</a></code> with 'lines' mode.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.lineplot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_lineplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lineplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
    &#34;&#34;&#34;`GenericAccessor.plot` with &#39;lines&#39; mode.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.lineplot()
    ```

    ![](/vectorbt/docs/img/df_lineplot.svg)
    &#34;&#34;&#34;
    return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;lines&#39;)), kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.map_enum"><code class="name flex">
<span>def <span class="ident">map_enum</span></span>(<span>self, enum)</span>
</code></dt>
<dd>
<div class="desc"><p>Map integer values to field names of an enum.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_enum(self, enum: tp.NamedTuple) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Map integer values to field names of an enum.&#34;&#34;&#34;
    def _mapper(x: int) -&gt; str:
        if x in enum:
            return enum._fields[x]
        if x == -1:
            return &#39;&#39;
        return &#39;UNK&#39;

    if self.is_series():
        return self._obj.map(_mapper)
    return self._obj.applymap(_mapper)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return max of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return max of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;max&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.max_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmax = np.nanmax
    else:
        _nanmax = nanmax
    return self.wrapper.wrap_reduced(_nanmax(arr, axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.maxabs_scale"><code class="name flex">
<span>def <span class="ident">maxabs_scale</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.MaxAbsScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return mean of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return mean of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;mean&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.mean_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmean = np.nanmean
    else:
        _nanmean = nanmean
    return self.wrapper.wrap_reduced(_nanmean(arr, axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.median"><code class="name flex">
<span>def <span class="ident">median</span></span>(<span>self, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return median of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def median(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return median of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;median&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.median_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmedian = np.nanmedian
    else:
        _nanmedian = nanmedian
    return self.wrapper.wrap_reduced(_nanmedian(arr, axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return min of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return min of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;min&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.min_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmin = np.nanmin
    else:
        _nanmin = nanmin
    return self.wrapper.wrap_reduced(_nanmin(arr, axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.minmax_scale"><code class="name flex">
<span>def <span class="ident">minmax_scale</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.MinMaxScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.Normalizer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.pct_change"><code class="name flex">
<span>def <span class="ident">pct_change</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.pct_change_nb" href="nb.html#vectorbt.generic.nb.pct_change_nb">pct_change_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, trace_names=None, x_labels=None, return_fig=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Scatter" href="plotting.html#vectorbt.generic.plotting.Scatter">Scatter</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.plot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self,
         trace_names: tp.TraceNames = None,
         x_labels: tp.Optional[tp.Labels] = None,
         return_fig: bool = True,
         **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Scatter` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.plot()
    ```

    ![](/vectorbt/docs/img/df_plot.svg)
    &#34;&#34;&#34;
    if x_labels is None:
        x_labels = self.wrapper.index
    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    scatter = plotting.Scatter(
        data=self.to_2d_array(),
        trace_names=trace_names,
        x_labels=x_labels,
        **kwargs
    )
    if return_fig:
        return scatter.fig
    return scatter</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.power_transform"><code class="name flex">
<span>def <span class="ident">power_transform</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.PowerTransformer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.product"><code class="name flex">
<span>def <span class="ident">product</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.product_nb" href="nb.html#vectorbt.generic.nb.product_nb">product_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.quantile_transform"><code class="name flex">
<span>def <span class="ident">quantile_transform</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.QuantileTransformer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.range_split"><code class="name flex">
<span>def <span class="ident">range_split</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Split using <code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">GenericAccessor.split()</a></code> on <code><a title="vectorbt.generic.splitters.RangeSplitter" href="splitters.html#vectorbt.generic.splitters.RangeSplitter">RangeSplitter</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
&gt;&gt;&gt; range_df
split_idx  0  1
0          0  5
1          1  6
2          2  7
3          3  8
4          4  9
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-06', ..., '2020-01-10'], dtype='datetime64[ns]', name='split_1')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
&gt;&gt;&gt; range_df
split_idx  0  1  2  3  4  5  6
0          0  1  2  3  4  5  6
1          1  2  3  4  5  6  7
2          2  3  4  5  6  7  8
3          3  4  5  6  7  8  9
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-02', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-03', ..., '2020-01-06'], dtype='datetime64[ns]', name='split_2'),
 DatetimeIndex(['2020-01-04', ..., '2020-01-07'], dtype='datetime64[ns]', name='split_3'),
 DatetimeIndex(['2020-01-05', ..., '2020-01-08'], dtype='datetime64[ns]', name='split_4'),
 DatetimeIndex(['2020-01-06', ..., '2020-01-09'], dtype='datetime64[ns]', name='split_5'),
 DatetimeIndex(['2020-01-07', ..., '2020-01-10'], dtype='datetime64[ns]', name='split_6')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
&gt;&gt;&gt; range_df
split_idx  0  1
0          0  2
1          1  3
2          2  4
3          3  5
4          4  6
5          5  7
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-06'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-03', ..., '2020-01-08'], dtype='datetime64[ns]', name='split_1')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
&gt;&gt;&gt; range_df
split_idx    0    1  2
0          0.0  0.0  0
1          1.0  1.0  1
2          2.0  2.0  2
3          NaN  3.0  3
4          NaN  NaN  4
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-03'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_2')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
...     start_idxs=pd.Index(['2020-01-01', '2020-01-02']),
...     end_idxs=pd.Index(['2020-01-04', '2020-01-05'])
... )
&gt;&gt;&gt; range_df
split_idx  0  1
0          0  1
1          1  2
2          2  3
3          3  4
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-02', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_1')]

 &gt;&gt;&gt; sr.vbt.range_split(
 ...    start_idxs=pd.Index(['2020-01-01', '2020-01-02', '2020-01-01']),
 ...    end_idxs=pd.Index(['2020-01-08', '2020-01-04', '2020-01-07']),
 ...    plot=True
 ... )
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/range_split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def range_split(self, **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RangeSplitter`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
    &gt;&gt;&gt; range_df
    split_idx  0  1
    0          0  5
    1          1  6
    2          2  7
    3          3  8
    4          4  9
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
    &gt;&gt;&gt; range_df
    split_idx  0  1  2  3  4  5  6
    0          0  1  2  3  4  5  6
    1          1  2  3  4  5  6  7
    2          2  3  4  5  6  7  8
    3          3  4  5  6  7  8  9
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;),
     DatetimeIndex([&#39;2020-01-04&#39;, ..., &#39;2020-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_3&#39;),
     DatetimeIndex([&#39;2020-01-05&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_4&#39;),
     DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-09&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_5&#39;),
     DatetimeIndex([&#39;2020-01-07&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_6&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
    &gt;&gt;&gt; range_df
    split_idx  0  1
    0          0  2
    1          1  3
    2          2  4
    3          3  5
    4          4  6
    5          5  7
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
    &gt;&gt;&gt; range_df
    split_idx    0    1  2
    0          0.0  0.0  0
    1          1.0  1.0  1
    2          2.0  2.0  2
    3          NaN  3.0  3
    4          NaN  NaN  4
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-03&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
    ...     start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;]),
    ...     end_idxs=pd.Index([&#39;2020-01-04&#39;, &#39;2020-01-05&#39;])
    ... )
    &gt;&gt;&gt; range_df
    split_idx  0  1
    0          0  1
    1          1  2
    2          2  3
    3          3  4
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

     &gt;&gt;&gt; sr.vbt.range_split(
     ...    start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;, &#39;2020-01-01&#39;]),
     ...    end_idxs=pd.Index([&#39;2020-01-08&#39;, &#39;2020-01-04&#39;, &#39;2020-01-07&#39;]),
     ...    plot=True
     ... )
    ```

    ![](/vectorbt/docs/img/range_split_plot.svg)
    &#34;&#34;&#34;
    return self.split(RangeSplitter(), **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.reduce"><code class="name flex">
<span>def <span class="ident">reduce</span></span>(<span>self, reduce_func_nb, *args, to_array=False, to_idx=False, flatten=False, order='C', idx_labeled=True, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Reduce by column.</p>
<p>See <code><a title="vectorbt.generic.nb.flat_reduce_grouped_to_array_nb" href="nb.html#vectorbt.generic.nb.flat_reduce_grouped_to_array_nb">flat_reduce_grouped_to_array_nb()</a></code> if grouped, <code>to_array</code> is True and <code>flatten</code> is True.
See <code><a title="vectorbt.generic.nb.flat_reduce_grouped_nb" href="nb.html#vectorbt.generic.nb.flat_reduce_grouped_nb">flat_reduce_grouped_nb()</a></code> if grouped, <code>to_array</code> is False and <code>flatten</code> is True.
See <code><a title="vectorbt.generic.nb.reduce_grouped_to_array_nb" href="nb.html#vectorbt.generic.nb.reduce_grouped_to_array_nb">reduce_grouped_to_array_nb()</a></code> if grouped, <code>to_array</code> is True and <code>flatten</code> is False.
See <code><a title="vectorbt.generic.nb.reduce_grouped_nb" href="nb.html#vectorbt.generic.nb.reduce_grouped_nb">reduce_grouped_nb()</a></code> if grouped, <code>to_array</code> is False and <code>flatten</code> is False.
See <code><a title="vectorbt.generic.nb.reduce_to_array_nb" href="nb.html#vectorbt.generic.nb.reduce_to_array_nb">reduce_to_array_nb()</a></code> if not grouped and <code>to_array</code> is True.
See <code><a title="vectorbt.generic.nb.reduce_nb" href="nb.html#vectorbt.generic.nb.reduce_nb">reduce_nb()</a></code> if not grouped and <code>to_array</code> is False.</p>
<p>Set <code>to_idx</code> to True if values returned by <code>reduce_func_nb</code> are indices/positions.
Set <code>idx_labeled</code> to False to return raw positions instead of labels.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.reduce(mean_nb)
a    3.0
b    3.0
c    1.8
dtype: float64

&gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
&gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True)
a   2020-01-05
b   2020-01-01
c   2020-01-03
dtype: datetime64[ns]

&gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
&gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True, idx_labeled=False)
a    4
b    0
c    2
dtype: int64

&gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
&gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=['min', 'max'], to_array=True)
       a    b    c
min  1.0  1.0  1.0
max  5.0  5.0  3.0

&gt;&gt;&gt; group_by = pd.Series(['first', 'first', 'second'], name='group')
&gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
group
first     3.0
second    1.8
dtype: float64

&gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=['min', 'max'],
...     to_array=True, group_by=group_by)
group  first  second
min      1.0     1.0
max      5.0     3.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reduce(self, reduce_func_nb: tp.Union[nb.flat_reduce_grouped_nbT,
                                          nb.flat_reduce_grouped_to_array_nbT,
                                          nb.reduce_grouped_nbT,
                                          nb.reduce_grouped_to_array_nbT,
                                          nb.reduce_nbT,
                                          nb.reduce_to_array_nbT],
           *args, to_array: bool = False, to_idx: bool = False, flatten: bool = False,
           order: str = &#39;C&#39;, idx_labeled: bool = True, group_by: tp.GroupByLike = None,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeriesFrame[float]:
    &#34;&#34;&#34;Reduce by column.

    See `vectorbt.generic.nb.flat_reduce_grouped_to_array_nb` if grouped, `to_array` is True and `flatten` is True.
    See `vectorbt.generic.nb.flat_reduce_grouped_nb` if grouped, `to_array` is False and `flatten` is True.
    See `vectorbt.generic.nb.reduce_grouped_to_array_nb` if grouped, `to_array` is True and `flatten` is False.
    See `vectorbt.generic.nb.reduce_grouped_nb` if grouped, `to_array` is False and `flatten` is False.
    See `vectorbt.generic.nb.reduce_to_array_nb` if not grouped and `to_array` is True.
    See `vectorbt.generic.nb.reduce_nb` if not grouped and `to_array` is False.

    Set `to_idx` to True if values returned by `reduce_func_nb` are indices/positions.
    Set `idx_labeled` to False to return raw positions instead of labels.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.reduce(mean_nb)
    a    3.0
    b    3.0
    c    1.8
    dtype: float64

    &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
    &gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True)
    a   2020-01-05
    b   2020-01-01
    c   2020-01-03
    dtype: datetime64[ns]

    &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
    &gt;&gt;&gt; df.vbt.reduce(argmax_nb, to_idx=True, idx_labeled=False)
    a    4
    b    0
    c    2
    dtype: int64

    &gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
    &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;], to_array=True)
           a    b    c
    min  1.0  1.0  1.0
    max  5.0  5.0  3.0

    &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
    &gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
    group
    first     3.0
    second    1.8
    dtype: float64

    &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;],
    ...     to_array=True, group_by=group_by)
    group  first  second
    min      1.0     1.0
    max      5.0     3.0
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(reduce_func_nb)

    if self.wrapper.grouper.is_grouped(group_by=group_by):
        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        if flatten:
            checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])
            in_c_order = order.upper() == &#39;C&#39;
            if to_array:
                out = nb.flat_reduce_grouped_to_array_nb(
                    self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
            else:
                out = nb.flat_reduce_grouped_nb(
                    self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
            if to_idx:
                if in_c_order:
                    out //= group_lens  # flattened in C order
                else:
                    out %= self.wrapper.shape[0]  # flattened in F order
        else:
            if to_array:
                out = nb.reduce_grouped_to_array_nb(
                    self.to_2d_array(), group_lens, reduce_func_nb, *args)
            else:
                out = nb.reduce_grouped_nb(
                    self.to_2d_array(), group_lens, reduce_func_nb, *args)
    else:
        if to_array:
            out = nb.reduce_to_array_nb(
                self.to_2d_array(), reduce_func_nb, *args)
        else:
            out = nb.reduce_nb(
                self.to_2d_array(), reduce_func_nb, *args)

    # Perform post-processing
    if to_idx:
        nan_mask = np.isnan(out)
        if idx_labeled:
            out = out.astype(object)
            out[~nan_mask] = self.wrapper.index[out[~nan_mask].astype(np.int_)]
        else:
            out[nan_mask] = -1
            out = out.astype(np.int_)
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;reduce&#39; if not to_array else None), wrap_kwargs)
    return self.wrapper.wrap_reduced(out, group_by=group_by, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.resample_apply"><code class="name flex">
<span>def <span class="ident">resample_apply</span></span>(<span>self, freq, apply_func_nb, *args, on_matrix=False, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.groupby_apply_nb" href="nb.html#vectorbt.generic.nb.groupby_apply_nb">groupby_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.groupby_apply_matrix_nb" href="nb.html#vectorbt.generic.nb.groupby_apply_matrix_nb">groupby_apply_matrix_nb()</a></code> for <code>on_matrix=True</code>.</p>
<p>For <code>freq</code>, see <code>pd.DataFrame.resample</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.resample_apply('2d', mean_nb)
              a    b    c
2020-01-01  1.5  4.5  1.5
2020-01-03  3.5  2.5  2.5
2020-01-05  5.0  1.0  1.0

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.resample_apply('2d', mean_matrix_nb, on_matrix=True)
                   a         b         c
2020-01-01  2.500000  2.500000  2.500000
2020-01-03  2.833333  2.833333  2.833333
2020-01-05  2.333333  2.333333  2.333333
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resample_apply(self, freq: tp.PandasFrequencyLike,
                   apply_func_nb: tp.Union[nb.groupby_apply_nbT, nb.groupby_apply_matrix_nbT],
                   *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                   **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
    `vectorbt.generic.nb.groupby_apply_matrix_nb` for `on_matrix=True`.

    For `freq`, see `pd.DataFrame.resample`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_nb)
                  a    b    c
    2020-01-01  1.5  4.5  1.5
    2020-01-03  3.5  2.5  2.5
    2020-01-05  5.0  1.0  1.0

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_matrix_nb, on_matrix=True)
                       a         b         c
    2020-01-01  2.500000  2.500000  2.500000
    2020-01-03  2.833333  2.833333  2.833333
    2020-01-05  2.333333  2.333333  2.333333
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    resampled = self._obj.resample(freq, axis=0, **kwargs)
    groups = Dict()
    for i, (k, v) in enumerate(resampled.indices.items()):
        groups[i] = np.asarray(v)
    if on_matrix:
        out = nb.groupby_apply_matrix_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    else:
        out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    out_obj = self.wrapper.wrap(out, index=list(resampled.indices.keys()))
    resampled_arr = np.full((resampled.ngroups, self.to_2d_array().shape[1]), np.nan)
    resampled_obj = self.wrapper.wrap(
        resampled_arr,
        index=pd.Index(list(resampled.groups.keys()), freq=freq),
        **merge_dicts({}, wrap_kwargs)
    )
    resampled_obj.loc[out_obj.index] = out_obj.values
    return resampled_obj</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.robust_scale"><code class="name flex">
<span>def <span class="ident">robust_scale</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.RobustScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_apply"><code class="name flex">
<span>def <span class="ident">rolling_apply</span></span>(<span>self, window, apply_func_nb, *args, minp=None, on_matrix=False, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_apply_nb" href="nb.html#vectorbt.generic.nb.rolling_apply_nb">rolling_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.rolling_matrix_apply_nb" href="nb.html#vectorbt.generic.nb.rolling_matrix_apply_nb">rolling_matrix_apply_nb()</a></code> for <code>on_matrix=True</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
              a    b         c
2020-01-01  1.0  5.0  1.000000
2020-01-02  1.5  4.5  1.500000
2020-01-03  2.0  4.0  2.000000
2020-01-04  3.0  3.0  2.333333
2020-01-05  4.0  2.0  2.000000

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                   a         b         c
2020-01-01  2.333333  2.333333  2.333333
2020-01-02  2.500000  2.500000  2.500000
2020-01-03  2.666667  2.666667  2.666667
2020-01-04  2.777778  2.777778  2.777778
2020-01-05  2.666667  2.666667  2.666667
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rolling_apply(self, window: int, apply_func_nb: tp.Union[nb.rolling_apply_nbT, nb.rolling_matrix_apply_nbT],
                  *args, minp: tp.Optional[int] = None, on_matrix: bool = False,
                  wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_apply_nb` and
    `vectorbt.generic.nb.rolling_matrix_apply_nb` for `on_matrix=True`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
                  a    b         c
    2020-01-01  1.0  5.0  1.000000
    2020-01-02  1.5  4.5  1.500000
    2020-01-03  2.0  4.0  2.000000
    2020-01-04  3.0  3.0  2.333333
    2020-01-05  4.0  2.0  2.000000

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                       a         b         c
    2020-01-01  2.333333  2.333333  2.333333
    2020-01-02  2.500000  2.500000  2.500000
    2020-01-03  2.666667  2.666667  2.666667
    2020-01-04  2.777778  2.777778  2.777778
    2020-01-05  2.666667  2.666667  2.666667
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    if on_matrix:
        out = nb.rolling_matrix_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
    else:
        out = nb.rolling_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_max"><code class="name flex">
<span>def <span class="ident">rolling_max</span></span>(<span>self, window, minp=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_max_nb" href="nb.html#vectorbt.generic.nb.rolling_max_nb">rolling_max_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_mean"><code class="name flex">
<span>def <span class="ident">rolling_mean</span></span>(<span>self, window, minp=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_mean_nb" href="nb.html#vectorbt.generic.nb.rolling_mean_nb">rolling_mean_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_min"><code class="name flex">
<span>def <span class="ident">rolling_min</span></span>(<span>self, window, minp=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_min_nb" href="nb.html#vectorbt.generic.nb.rolling_min_nb">rolling_min_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_split"><code class="name flex">
<span>def <span class="ident">rolling_split</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Split using <code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">GenericAccessor.split()</a></code> on <code><a title="vectorbt.generic.splitters.RollingSplitter" href="splitters.html#vectorbt.generic.splitters.RollingSplitter">RollingSplitter</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
...     window_len=5, set_lens=(1, 1), left_to_right=False)
&gt;&gt;&gt; train_set[0]
split_idx  0  1  2  3  4  5
0          0  1  2  3  4  5
1          1  2  3  4  5  6
2          2  3  4  5  6  7
&gt;&gt;&gt; valid_set[0]
split_idx  0  1  2  3  4  5
0          3  4  5  6  7  8
&gt;&gt;&gt; test_set[0]
split_idx  0  1  2  3  4  5
0          4  5  6  7  8  9

&gt;&gt;&gt; sr.vbt.rolling_split(
...     window_len=5, set_lens=(1, 1), left_to_right=False,
...     plot=True, trace_names=['train', 'valid', 'test'])
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/rolling_split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rolling_split(self, **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RollingSplitter`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
    ...     window_len=5, set_lens=(1, 1), left_to_right=False)
    &gt;&gt;&gt; train_set[0]
    split_idx  0  1  2  3  4  5
    0          0  1  2  3  4  5
    1          1  2  3  4  5  6
    2          2  3  4  5  6  7
    &gt;&gt;&gt; valid_set[0]
    split_idx  0  1  2  3  4  5
    0          3  4  5  6  7  8
    &gt;&gt;&gt; test_set[0]
    split_idx  0  1  2  3  4  5
    0          4  5  6  7  8  9

    &gt;&gt;&gt; sr.vbt.rolling_split(
    ...     window_len=5, set_lens=(1, 1), left_to_right=False,
    ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
    ```

    ![](/vectorbt/docs/img/rolling_split_plot.svg)
    &#34;&#34;&#34;
    return self.split(RollingSplitter(), **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_std"><code class="name flex">
<span>def <span class="ident">rolling_std</span></span>(<span>self, window, minp=None, ddof=1, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_std_nb" href="nb.html#vectorbt.generic.nb.rolling_std_nb">rolling_std_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rolling_std(self, window: int, minp: tp.Optional[int] = None, ddof: int = 1,
                wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_std_nb`.&#34;&#34;&#34;
    out = nb.rolling_std_nb(self.to_2d_array(), window, minp=minp, ddof=ddof)
    return self.wrapper.wrap(out, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.scale"><code class="name flex">
<span>def <span class="ident">scale</span></span>(<span>self, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using <code>sklearn.preprocessing.StandardScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, wrap_kwargs: tp.KwargsLike = None,
              _transformer: tp.Type[TransformerT] = transformer, **kwargs) -&gt; tp.SeriesFrame:
    return self.transform(_transformer(**kwargs), wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.scatterplot"><code class="name flex">
<span>def <span class="ident">scatterplot</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">GenericAccessor.plot()</a></code> with 'markers' mode.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.scatterplot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_scatterplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scatterplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
    &#34;&#34;&#34;`GenericAccessor.plot` with &#39;markers&#39; mode.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.scatterplot()
    ```

    ![](/vectorbt/docs/img/df_scatterplot.svg)
    &#34;&#34;&#34;
    return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;markers&#39;)), kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.shuffle"><code class="name flex">
<span>def <span class="ident">shuffle</span></span>(<span>self, seed=None)</span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.shuffle_nb" href="nb.html#vectorbt.generic.nb.shuffle_nb">shuffle_nb()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_method(self,
              *args,
              _nb_func: tp.Callable = nb_func,
              _is_reducing: bool = is_reducing,
              _name_or_index: tp.NameIndex = name_or_index,
              wrap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; tp.SeriesFrame:
    default_kwargs = get_kwargs(nb_func)
    wrap_kwargs = merge_dicts({}, wrap_kwargs)
    if &#39;_1d&#39; in _nb_func.__name__:
        # One-dimensional array as input
        a = _nb_func(self.to_1d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)
    else:
        # Two-dimensional array as input
        a = _nb_func(self.to_2d_array(), *args, **{**default_kwargs, **kwargs})
        if _is_reducing:
            return self.wrapper.wrap_reduced(a, name_or_index=_name_or_index, **wrap_kwargs)
        return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.split"><code class="name flex">
<span>def <span class="ident">split</span></span>(<span>self, splitter, stack_kwargs=None, keys=None, plot=False, trace_names=None, heatmap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Split using a splitter.</p>
<p>Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.</p>
<p>A splitter can be any class instance that has <code>split</code> method, ideally subclassing
<code>sklearn.model_selection.BaseCrossValidator</code> or <code><a title="vectorbt.generic.splitters.BaseSplitter" href="splitters.html#vectorbt.generic.splitters.BaseSplitter">BaseSplitter</a></code>.</p>
<p><code>heatmap_kwargs</code> are passed to <code><a title="vectorbt.generic.plotting.Heatmap" href="plotting.html#vectorbt.generic.plotting.Heatmap">Heatmap</a></code> if <code>plot</code> is True,
can be a dictionary or a list per set, for example, to set trace name for each set ('train', 'test', etc.).</p>
<p><code>**kwargs</code> are passed to the <code>split</code> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The datetime-like format of the index will be lost as result of this operation.
Make sure to store the index metadata such as frequency information beforehand.</p>
</div>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

&gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
&gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

&gt;&gt;&gt; train_df
split_idx    0    1  2
0          0.0  0.0  0
1          1.0  1.0  1
2          2.0  2.0  2
3          3.0  3.0  3
4          NaN  4.0  4
5          NaN  5.0  5
6          NaN  NaN  6
7          NaN  NaN  7
&gt;&gt;&gt; train_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-06'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-08'], dtype='datetime64[ns]', name='split_2')]
&gt;&gt;&gt; test_df
split_idx  0  1  2
0          4  6  8
1          5  7  9
&gt;&gt;&gt; test_indexes
[DatetimeIndex(['2020-01-05', '2020-01-06'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-07', '2020-01-08'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-09', '2020-01-10'], dtype='datetime64[ns]', name='split_2')]

&gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=['train', 'test'])
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split(self, splitter: SplitterT, stack_kwargs: tp.KwargsLike = None, keys: tp.Optional[tp.IndexLike] = None,
          plot: bool = False, trace_names: tp.TraceNames = None, heatmap_kwargs: tp.KwargsLike = None,
          **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using a splitter.

    Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.

    A splitter can be any class instance that has `split` method, ideally subclassing
    `sklearn.model_selection.BaseCrossValidator` or `vectorbt.generic.splitters.BaseSplitter`.

    `heatmap_kwargs` are passed to `vectorbt.generic.plotting.Heatmap` if `plot` is True,
    can be a dictionary or a list per set, for example, to set trace name for each set (&#39;train&#39;, &#39;test&#39;, etc.).

    `**kwargs` are passed to the `split` method.

    !!! note
        The datetime-like format of the index will be lost as result of this operation.
        Make sure to store the index metadata such as frequency information beforehand.

    ## Example

    ```python-repl
    &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

    &gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
    &gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

    &gt;&gt;&gt; train_df
    split_idx    0    1  2
    0          0.0  0.0  0
    1          1.0  1.0  1
    2          2.0  2.0  2
    3          3.0  3.0  3
    4          NaN  4.0  4
    5          NaN  5.0  5
    6          NaN  NaN  6
    7          NaN  NaN  7
    &gt;&gt;&gt; train_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]
    &gt;&gt;&gt; test_df
    split_idx  0  1  2
    0          4  6  8
    1          5  7  9
    &gt;&gt;&gt; test_indexes
    [DatetimeIndex([&#39;2020-01-05&#39;, &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-07&#39;, &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-09&#39;, &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

    &gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=[&#39;train&#39;, &#39;test&#39;])
    ```

    ![](/vectorbt/docs/img/split_plot.svg)
    &#34;&#34;&#34;
    total_range_sr = pd.Series(np.arange(len(self.wrapper.index)), index=self.wrapper.index)
    set_ranges = list(splitter.split(total_range_sr, **kwargs))
    if len(set_ranges) == 0:
        raise ValueError(&#34;No splits were generated&#34;)
    idxs_by_split_and_set = list(zip(*set_ranges))

    results = []
    if keys is not None:
        if not isinstance(keys, pd.Index):
            keys = pd.Index(keys)
    for idxs_by_split in idxs_by_split_and_set:
        split_dfs = []
        split_indexes = []
        for split_idx, idxs in enumerate(idxs_by_split):
            split_dfs.append(self._obj.iloc[idxs].reset_index(drop=True))
            if keys is not None:
                split_name = keys[split_idx]
            else:
                split_name = &#39;split_&#39; + str(split_idx)
            split_indexes.append(pd.Index(self.wrapper.index[idxs], name=split_name))
        set_df = pd.concat(split_dfs, axis=1).reset_index(drop=True)
        if keys is not None:
            split_columns = keys
        else:
            split_columns = pd.Index(np.arange(len(split_indexes)), name=&#39;split_idx&#39;)
        split_columns = index_fns.repeat_index(split_columns, len(self.wrapper.columns))
        if stack_kwargs is None:
            stack_kwargs = {}
        set_df = set_df.vbt.stack_index(split_columns, **stack_kwargs)
        results.append((set_df, split_indexes))

    if plot:  # pragma: no cover
        if trace_names is None:
            trace_names = list(range(len(results)))
        if isinstance(trace_names, str):
            trace_names = [trace_names]
        nan_df = pd.DataFrame(np.nan, columns=pd.RangeIndex(stop=len(results[0][1])), index=self.wrapper.index)
        fig = None
        for i, (_, split_indexes) in enumerate(results):
            heatmap_df = nan_df.copy()
            for j in range(len(split_indexes)):
                heatmap_df.loc[split_indexes[j], j] = i
            _heatmap_kwargs = resolve_dict(heatmap_kwargs, i=i)
            fig = heatmap_df.vbt.ts_heatmap(fig=fig, **merge_dicts(
                dict(
                    trace_kwargs=dict(
                        showscale=False,
                        name=str(trace_names[i]),
                        showlegend=True
                    )
                ),
                _heatmap_kwargs
            ))
            if fig.layout.colorway is not None:
                colorway = fig.layout.colorway
            else:
                colorway = fig.layout.template.layout.colorway
            if &#39;colorscale&#39; not in _heatmap_kwargs:
                fig.data[-1].update(colorscale=[colorway[i], colorway[i]])
        return fig

    if len(results) == 1:
        return results[0]
    return tuple(results)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.squeeze_grouped"><code class="name flex">
<span>def <span class="ident">squeeze_grouped</span></span>(<span>self, reduce_func_nb, *args, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Squeeze each group of columns into a single column.</p>
<p>See <code><a title="vectorbt.generic.nb.squeeze_grouped_nb" href="nb.html#vectorbt.generic.nb.squeeze_grouped_nb">squeeze_grouped_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; group_by = pd.Series(['first', 'first', 'second'], name='group')
&gt;&gt;&gt; mean_nb = njit(lambda i, group, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.squeeze_grouped(mean_nb, group_by=group_by)
group       first  second
2020-01-01    3.0     1.0
2020-01-02    3.0     2.0
2020-01-03    3.0     3.0
2020-01-04    3.0     2.0
2020-01-05    3.0     1.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squeeze_grouped(self, reduce_func_nb: nb.squeeze_grouped_nbT, *args, group_by: tp.GroupByLike = None,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Squeeze each group of columns into a single column.

    See `vectorbt.generic.nb.squeeze_grouped_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
    &gt;&gt;&gt; mean_nb = njit(lambda i, group, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.squeeze_grouped(mean_nb, group_by=group_by)
    group       first  second
    2020-01-01    3.0     1.0
    2020-01-02    3.0     2.0
    2020-01-03    3.0     3.0
    2020-01-04    3.0     2.0
    2020-01-05    3.0     1.0
    ```
    &#34;&#34;&#34;
    if not self.wrapper.grouper.is_grouped(group_by=group_by):
        raise ValueError(&#34;Grouping required&#34;)
    checks.assert_numba_func(reduce_func_nb)

    group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
    out = nb.squeeze_grouped_nb(self.to_2d_array(), group_lens, reduce_func_nb, *args)
    return self.wrapper.wrap(out, group_by=group_by, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.std"><code class="name flex">
<span>def <span class="ident">std</span></span>(<span>self, ddof=1, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return standard deviation of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self, ddof: int = 1, group_by: tp.GroupByLike = None,
        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return standard deviation of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;std&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.std_reduce_nb, ddof, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanstd = np.nanstd
    else:
        _nanstd = nanstd
    return self.wrapper.wrap_reduced(_nanstd(arr, ddof=ddof, axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self, group_by=None, wrap_kwargs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return sum of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return sum of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;sum&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.sum_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nansum = np.nansum
    else:
        _nansum = nansum
    return self.wrapper.wrap_reduced(_nansum(arr, axis=0), **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.to_mapped_array"><code class="name flex">
<span>def <span class="ident">to_mapped_array</span></span>(<span>self, dropna=True, group_by=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert this object into an instance of <code><a title="vectorbt.records.mapped_array.MappedArray" href="../records/mapped_array.html#vectorbt.records.mapped_array.MappedArray">MappedArray</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_mapped_array(self, dropna: bool = True, group_by: tp.GroupByLike = None, **kwargs) -&gt; MappedArray:
    &#34;&#34;&#34;Convert this object into an instance of `vectorbt.records.mapped_array.MappedArray`.&#34;&#34;&#34;
    mapped_arr = reshape_fns.to_2d(self._obj, raw=True).flatten(order=&#39;F&#39;)
    col_arr = np.repeat(np.arange(self.wrapper.shape_2d[1]), self.wrapper.shape_2d[0])
    idx_arr = np.tile(np.arange(self.wrapper.shape_2d[0]), self.wrapper.shape_2d[1])
    if dropna:
        not_nan_mask = ~np.isnan(mapped_arr)
        mapped_arr = mapped_arr[not_nan_mask]
        col_arr = col_arr[not_nan_mask]
        idx_arr = idx_arr[not_nan_mask]
    if group_by is None:
        group_by = self.wrapper.grouper.group_by
    return MappedArray(self.wrapper, mapped_arr, col_arr, idx_arr=idx_arr, **kwargs).regroup(group_by)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, transformer, wrap_kwargs=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform using a transformer.</p>
<p>A transformer can be any class instance that has <code>transform</code> and <code>fit_transform</code> methods,
ideally subclassing <code>sklearn.base.TransformerMixin</code> and <code>sklearn.base.BaseEstimator</code>.</p>
<p>Will fit <code>transformer</code> if not fitted.</p>
<p><code>**kwargs</code> are passed to the <code>transform</code> or <code>fit_transform</code> method.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

&gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
              a    b    c
2020-01-01 -1.0  1.0 -1.0
2020-01-02 -0.5  0.5  0.0
2020-01-03  0.0  0.0  1.0
2020-01-04  0.5 -0.5  0.0
2020-01-05  1.0 -1.0 -1.0

&gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
&gt;&gt;&gt; df.vbt.transform(fitted_scaler)
              a    b    c
2020-01-01 -2.0  2.0 -2.0
2020-01-02 -1.0  1.0 -1.0
2020-01-03  0.0  0.0  0.0
2020-01-04  1.0 -1.0 -1.0
2020-01-05  2.0 -2.0 -2.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, transformer: TransformerT, wrap_kwargs: tp.KwargsLike = None, **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Transform using a transformer.

    A transformer can be any class instance that has `transform` and `fit_transform` methods,
    ideally subclassing `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`.

    Will fit `transformer` if not fitted.

    `**kwargs` are passed to the `transform` or `fit_transform` method.

    ## Example

    ```python-repl
    &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

    &gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
                  a    b    c
    2020-01-01 -1.0  1.0 -1.0
    2020-01-02 -0.5  0.5  0.0
    2020-01-03  0.0  0.0  1.0
    2020-01-04  0.5 -0.5  0.0
    2020-01-05  1.0 -1.0 -1.0

    &gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
    &gt;&gt;&gt; df.vbt.transform(fitted_scaler)
                  a    b    c
    2020-01-01 -2.0  2.0 -2.0
    2020-01-02 -1.0  1.0 -1.0
    2020-01-03  0.0  0.0  0.0
    2020-01-04  1.0 -1.0 -1.0
    2020-01-05  2.0 -2.0 -2.0
    ```&#34;&#34;&#34;
    is_fitted = True
    try:
        check_is_fitted(transformer)
    except NotFittedError:
        is_fitted = False
    if not is_fitted:
        result = transformer.fit_transform(self.to_2d_array(), **kwargs)
    else:
        result = transformer.transform(self.to_2d_array(), **kwargs)
    return self.wrapper.wrap(result, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.zscore"><code class="name flex">
<span>def <span class="ident">zscore</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute z-score using <code>sklearn.preprocessing.StandardScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def zscore(self, **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Compute z-score using `sklearn.preprocessing.StandardScaler`.&#34;&#34;&#34;
    return self.scale(with_mean=True, with_std=True, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.base.accessors.BaseAccessor.align_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.align_to">align_to</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.apply" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply">apply</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.apply_and_concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_and_concat">apply_and_concat</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.apply_on_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_on_index">apply_on_index</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.broadcast" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast">broadcast</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.broadcast_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast_to">broadcast_to</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.combine" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.combine">combine</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.concat">concat</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels">drop_duplicate_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.drop_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_levels">drop_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.drop_redundant_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_redundant_levels">drop_redundant_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.empty" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty">empty</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.empty_like" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty_like">empty_like</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.make_symmetric" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.make_symmetric">make_symmetric</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.rename_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.rename_levels">rename_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.repeat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.repeat">repeat</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.select_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.select_levels">select_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.stack_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.stack_index">stack_index</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.tile" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.tile">tile</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.to_1d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_1d_array">to_1d_array</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.to_2d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_2d_array">to_2d_array</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.unstack_to_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_array">unstack_to_array</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.unstack_to_df" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_df">unstack_to_df</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.wrapper" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.wrapper">wrapper</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.GenericDFAccessor"><code class="flex name class">
<span>class <span class="ident">GenericDFAccessor</span></span>
<span>(</span><span>obj, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Accessor on top of data of any type. For DataFrames only.</p>
<p>Accessible through <code>pd.DataFrame.vbt</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenericDFAccessor(GenericAccessor, BaseDFAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For DataFrames only.

    Accessible through `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Frame, **kwargs) -&gt; None:
        if not checks.is_pandas(obj):  # parent accessor
            obj = obj._obj

        BaseDFAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, **kwargs)

    def heatmap(self,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Heatmap` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df = pd.DataFrame([
        ...     [0, np.nan, np.nan],
        ...     [np.nan, 1, np.nan],
        ...     [np.nan, np.nan, 2]
        ... ])
        &gt;&gt;&gt; df.vbt.heatmap()
        ```

        ![](/vectorbt/docs/img/df_heatmap.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.columns
        if y_labels is None:
            y_labels = self.wrapper.index
        heatmap = plotting.Heatmap(
            data=self.to_2d_array(),
            x_labels=x_labels,
            y_labels=y_labels,
            **kwargs
        )
        if return_fig:
            return heatmap.fig
        return heatmap

    def ts_heatmap(self, is_y_category: bool = True,
                   **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self._obj.transpose().iloc[::-1].vbt.heatmap(is_y_category=is_y_category, **kwargs)</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseDFAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseDFAccessor">BaseDFAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></li>
</ul>
<h3 class="section-subtitle">Subclasses</h3>
<ul class="hlist">
<li><a title="vectorbt.ohlcv_accessors.OHLCVDFAccessor" href="../ohlcv_accessors.html#vectorbt.ohlcv_accessors.OHLCVDFAccessor">OHLCVDFAccessor</a></li>
<li><a title="vectorbt.returns.accessors.ReturnsDFAccessor" href="../returns/accessors.html#vectorbt.returns.accessors.ReturnsDFAccessor">ReturnsDFAccessor</a></li>
<li><a title="vectorbt.root_accessors.Vbt_DFAccessor" href="../root_accessors.html#vectorbt.root_accessors.Vbt_DFAccessor">Vbt_DFAccessor</a></li>
<li><a title="vectorbt.signals.accessors.SignalsDFAccessor" href="../signals/accessors.html#vectorbt.signals.accessors.SignalsDFAccessor">SignalsDFAccessor</a></li>
</ul>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericDFAccessor.heatmap"><code class="name flex">
<span>def <span class="ident">heatmap</span></span>(<span>self, x_labels=None, y_labels=None, return_fig=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Heatmap" href="plotting.html#vectorbt.generic.plotting.Heatmap">Heatmap</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = pd.DataFrame([
...     [0, np.nan, np.nan],
...     [np.nan, 1, np.nan],
...     [np.nan, np.nan, 2]
... ])
&gt;&gt;&gt; df.vbt.heatmap()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/df_heatmap.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatmap(self,
            x_labels: tp.Optional[tp.Labels] = None,
            y_labels: tp.Optional[tp.Labels] = None,
            return_fig: bool = True,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Heatmap` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df = pd.DataFrame([
    ...     [0, np.nan, np.nan],
    ...     [np.nan, 1, np.nan],
    ...     [np.nan, np.nan, 2]
    ... ])
    &gt;&gt;&gt; df.vbt.heatmap()
    ```

    ![](/vectorbt/docs/img/df_heatmap.svg)
    &#34;&#34;&#34;
    if x_labels is None:
        x_labels = self.wrapper.columns
    if y_labels is None:
        y_labels = self.wrapper.index
    heatmap = plotting.Heatmap(
        data=self.to_2d_array(),
        x_labels=x_labels,
        y_labels=y_labels,
        **kwargs
    )
    if return_fig:
        return heatmap.fig
    return heatmap</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericDFAccessor.ts_heatmap"><code class="name flex">
<span>def <span class="ident">ts_heatmap</span></span>(<span>self, is_y_category=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Heatmap of time-series data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ts_heatmap(self, is_y_category: bool = True,
               **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
    return self._obj.transpose().iloc[::-1].vbt.heatmap(is_y_category=is_y_category, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.align_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.align_to">align_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply">apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_along_axis" href="#vectorbt.generic.accessors.GenericAccessor.apply_along_axis">apply_along_axis</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_and_concat">apply_and_concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce" href="#vectorbt.generic.accessors.GenericAccessor.apply_and_reduce">apply_and_reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_on_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_on_index">apply_on_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.applymap" href="#vectorbt.generic.accessors.GenericAccessor.applymap">applymap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.barplot" href="#vectorbt.generic.accessors.GenericAccessor.barplot">barplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.binarize" href="#vectorbt.generic.accessors.GenericAccessor.binarize">binarize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.boxplot" href="#vectorbt.generic.accessors.GenericAccessor.boxplot">boxplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast">broadcast</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast_to">broadcast_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bshift" href="#vectorbt.generic.accessors.GenericAccessor.bshift">bshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.combine" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.combine">combine</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.concat">concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.count" href="#vectorbt.generic.accessors.GenericAccessor.count">count</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumprod" href="#vectorbt.generic.accessors.GenericAccessor.cumprod">cumprod</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumsum" href="#vectorbt.generic.accessors.GenericAccessor.cumsum">cumsum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.describe" href="#vectorbt.generic.accessors.GenericAccessor.describe">describe</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.diff" href="#vectorbt.generic.accessors.GenericAccessor.diff">diff</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdown" href="#vectorbt.generic.accessors.GenericAccessor.drawdown">drawdown</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.drawdowns">drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_duplicate_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels">drop_duplicate_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_levels">drop_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_redundant_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_redundant_levels">drop_redundant_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty">empty</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty_like" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty_like">empty_like</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_mean" href="#vectorbt.generic.accessors.GenericAccessor.ewm_mean">ewm_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_std" href="#vectorbt.generic.accessors.GenericAccessor.ewm_std">ewm_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_apply" href="#vectorbt.generic.accessors.GenericAccessor.expanding_apply">expanding_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_max" href="#vectorbt.generic.accessors.GenericAccessor.expanding_max">expanding_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_mean" href="#vectorbt.generic.accessors.GenericAccessor.expanding_mean">expanding_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_min" href="#vectorbt.generic.accessors.GenericAccessor.expanding_min">expanding_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_split" href="#vectorbt.generic.accessors.GenericAccessor.expanding_split">expanding_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_std" href="#vectorbt.generic.accessors.GenericAccessor.expanding_std">expanding_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ffill" href="#vectorbt.generic.accessors.GenericAccessor.ffill">ffill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fillna" href="#vectorbt.generic.accessors.GenericAccessor.fillna">fillna</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.filter" href="#vectorbt.generic.accessors.GenericAccessor.filter">filter</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.flatten_grouped" href="#vectorbt.generic.accessors.GenericAccessor.flatten_grouped">flatten_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fshift" href="#vectorbt.generic.accessors.GenericAccessor.fshift">fshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">get_drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.groupby_apply" href="#vectorbt.generic.accessors.GenericAccessor.groupby_apply">groupby_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.histplot" href="#vectorbt.generic.accessors.GenericAccessor.histplot">histplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmax" href="#vectorbt.generic.accessors.GenericAccessor.idxmax">idxmax</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmin" href="#vectorbt.generic.accessors.GenericAccessor.idxmin">idxmin</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.lineplot" href="#vectorbt.generic.accessors.GenericAccessor.lineplot">lineplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.make_symmetric" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.make_symmetric">make_symmetric</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.map_enum" href="#vectorbt.generic.accessors.GenericAccessor.map_enum">map_enum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.max" href="#vectorbt.generic.accessors.GenericAccessor.max">max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.maxabs_scale" href="#vectorbt.generic.accessors.GenericAccessor.maxabs_scale">maxabs_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mean" href="#vectorbt.generic.accessors.GenericAccessor.mean">mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.median" href="#vectorbt.generic.accessors.GenericAccessor.median">median</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.min" href="#vectorbt.generic.accessors.GenericAccessor.min">min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.minmax_scale" href="#vectorbt.generic.accessors.GenericAccessor.minmax_scale">minmax_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.normalize" href="#vectorbt.generic.accessors.GenericAccessor.normalize">normalize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pct_change" href="#vectorbt.generic.accessors.GenericAccessor.pct_change">pct_change</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">plot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.power_transform" href="#vectorbt.generic.accessors.GenericAccessor.power_transform">power_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.product" href="#vectorbt.generic.accessors.GenericAccessor.product">product</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.quantile_transform" href="#vectorbt.generic.accessors.GenericAccessor.quantile_transform">quantile_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.range_split" href="#vectorbt.generic.accessors.GenericAccessor.range_split">range_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.reduce" href="#vectorbt.generic.accessors.GenericAccessor.reduce">reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rename_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.rename_levels">rename_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.repeat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.repeat">repeat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resample_apply" href="#vectorbt.generic.accessors.GenericAccessor.resample_apply">resample_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.robust_scale" href="#vectorbt.generic.accessors.GenericAccessor.robust_scale">robust_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_apply" href="#vectorbt.generic.accessors.GenericAccessor.rolling_apply">rolling_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_max" href="#vectorbt.generic.accessors.GenericAccessor.rolling_max">rolling_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_mean" href="#vectorbt.generic.accessors.GenericAccessor.rolling_mean">rolling_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_min" href="#vectorbt.generic.accessors.GenericAccessor.rolling_min">rolling_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_split" href="#vectorbt.generic.accessors.GenericAccessor.rolling_split">rolling_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_std" href="#vectorbt.generic.accessors.GenericAccessor.rolling_std">rolling_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scale" href="#vectorbt.generic.accessors.GenericAccessor.scale">scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">scatterplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.select_levels">select_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.shuffle" href="#vectorbt.generic.accessors.GenericAccessor.shuffle">shuffle</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.squeeze_grouped" href="#vectorbt.generic.accessors.GenericAccessor.squeeze_grouped">squeeze_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stack_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.stack_index">stack_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.std" href="#vectorbt.generic.accessors.GenericAccessor.std">std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sum" href="#vectorbt.generic.accessors.GenericAccessor.sum">sum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.tile" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.tile">tile</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_1d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_1d_array">to_1d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_2d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_2d_array">to_2d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_mapped_array" href="#vectorbt.generic.accessors.GenericAccessor.to_mapped_array">to_mapped_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.transform" href="#vectorbt.generic.accessors.GenericAccessor.transform">transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_array">unstack_to_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_df" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_df">unstack_to_df</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.wrapper" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.wrapper">wrapper</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.zscore" href="#vectorbt.generic.accessors.GenericAccessor.zscore">zscore</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor"><code class="flex name class">
<span>class <span class="ident">GenericSRAccessor</span></span>
<span>(</span><span>obj, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Accessor on top of data of any type. For Series only.</p>
<p>Accessible through <code>pd.Series.vbt</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenericSRAccessor(GenericAccessor, BaseSRAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For Series only.

    Accessible through `pd.Series.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Series, **kwargs) -&gt; None:
        if not checks.is_pandas(obj):  # parent accessor
            obj = obj._obj

        BaseSRAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, **kwargs)

    def plot_against(self,
                     other: tp.ArrayLike,
                     trace_kwargs: tp.KwargsLike = None,
                     other_trace_kwargs: tp.Union[str, tp.KwargsLike] = None,
                     pos_trace_kwargs: tp.KwargsLike = None,
                     neg_trace_kwargs: tp.KwargsLike = None,
                     hidden_trace_kwargs: tp.KwargsLike = None,
                     add_trace_kwargs: tp.KwargsLike = None,
                     fig: tp.Optional[tp.BaseFigure] = None,
                     **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line against another line.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            other_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for `other`.

                Set to &#39;hidden&#39; to hide.
            pos_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for positive line.
            neg_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for negative line.
            hidden_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for hidden lines.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.plot_against(df[&#39;b&#39;])
        ```

        ![](/vectorbt/docs/img/sr_plot_against.svg)
        &#34;&#34;&#34;
        if trace_kwargs is None:
            trace_kwargs = {}
        if other_trace_kwargs is None:
            other_trace_kwargs = {}
        if pos_trace_kwargs is None:
            pos_trace_kwargs = {}
        if neg_trace_kwargs is None:
            neg_trace_kwargs = {}
        if hidden_trace_kwargs is None:
            hidden_trace_kwargs = {}
        obj, other = reshape_fns.broadcast(self._obj, other, columns_from=&#39;keep&#39;)
        checks.assert_type(other, pd.Series)
        if fig is None:
            fig = make_figure()
        fig.update_layout(**layout_kwargs)

        # TODO: Using masks feels hacky
        pos_mask = self._obj &gt; other
        if pos_mask.any():
            # Fill positive area
            pos_obj = self._obj.copy()
            pos_obj[~pos_mask] = other[~pos_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None,
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            pos_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    fillcolor=&#39;rgba(0, 128, 0, 0.3)&#39;,
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), pos_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
        neg_mask = self._obj &lt; other
        if neg_mask.any():
            # Fill negative area
            neg_obj = self._obj.copy()
            neg_obj[~neg_mask] = other[~neg_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            neg_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    fillcolor=&#39;rgba(255, 0, 0, 0.3)&#39;,
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), neg_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )

        # Plot main traces
        self.plot(trace_kwargs=trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        if other_trace_kwargs == &#39;hidden&#39;:
            other_trace_kwargs = dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0.,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            )
        other.vbt.plot(trace_kwargs=other_trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        return fig

    def overlay_with_heatmap(self,
                             other: tp.ArrayLike,
                             trace_kwargs: tp.KwargsLike = None,
                             heatmap_kwargs: tp.KwargsLike = None,
                             add_trace_kwargs: tp.KwargsLike = None,
                             fig: tp.Optional[tp.BaseFigure] = None,
                             **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line and overlays it with a heatmap.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            heatmap_kwargs (dict): Keyword arguments passed to `GenericDFAccessor.heatmap`.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.overlay_with_heatmap(df[&#39;b&#39;])
        ```

        ![](/vectorbt/docs/img/sr_overlay_with_heatmap.svg)
        &#34;&#34;&#34;
        from vectorbt._settings import settings
        plotting_cfg = settings[&#39;plotting&#39;]

        if trace_kwargs is None:
            trace_kwargs = {}
        if heatmap_kwargs is None:
            heatmap_kwargs = {}
        if add_trace_kwargs is None:
            add_trace_kwargs = {}

        obj, other = reshape_fns.broadcast(self._obj, other, columns_from=&#39;keep&#39;)
        checks.assert_type(other, pd.Series)
        if fig is None:
            fig = make_subplots(specs=[[{&#34;secondary_y&#34;: True}]])
            if &#39;width&#39; in plotting_cfg[&#39;layout&#39;]:
                fig.update_layout(width=plotting_cfg[&#39;layout&#39;][&#39;width&#39;] + 100)
        fig.update_layout(**layout_kwargs)

        other.vbt.ts_heatmap(**heatmap_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        self.plot(
            trace_kwargs=merge_dicts(dict(line=dict(color=plotting_cfg[&#39;color_schema&#39;][&#39;blue&#39;])), trace_kwargs),
            add_trace_kwargs=merge_dicts(dict(secondary_y=True), add_trace_kwargs),
            fig=fig
        )
        return fig

    def heatmap(self,
                x_level: tp.Optional[tp.Level] = None,
                y_level: tp.Optional[tp.Level] = None,
                symmetric: bool = False,
                sort: bool = True,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                slider_level: tp.Optional[tp.Level] = None,
                active: int = 0,
                slider_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                fig: tp.Optional[tp.BaseFigure] = None,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create a heatmap figure based on object&#39;s multi-index and values.

        If index is not a multi-index, converts Series into a DataFrame and calls `GenericDFAccessor.heatmap`.

        If multi-index contains more than two levels or you want them in specific order,
        pass `x_level` and `y_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the heatmap. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Heatmap` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1),
        ...     (2, 2),
        ...     (3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1    0
        2  2    1
        3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap()
        ```

        ![](/vectorbt/docs/img/sr_heatmap.svg)

        Using one level as a slider:

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (1, 2, 2),
        ...     (1, 3, 3),
        ...     (2, 3, 3),
        ...     (2, 2, 2),
        ...     (2, 1, 1)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
           2  2    1
           3  3    2
        2  3  3    3
           2  2    4
           1  1    5
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
        ```

        ![](/vectorbt/docs/img/sr_heatmap_slider.gif)
        &#34;&#34;&#34;
        if not isinstance(self.wrapper.index, pd.MultiIndex):
            return self._obj.to_frame().vbt.heatmap(
                x_labels=x_labels, y_labels=y_labels,
                return_fig=return_fig, fig=fig, **kwargs)

        (x_level, y_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        kwargs = merge_dicts(dict(
            trace_kwargs=dict(
                hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                              f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                              &#34;value: %{z}&lt;extra&gt;&lt;/extra&gt;&#34;
            ),
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name
        ), kwargs)

        if slider_level is None:
            # No grouping
            df = self.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            return df.vbt.heatmap(x_labels=x_labels, y_labels=y_labels, fig=fig, return_fig=return_fig, **kwargs)

        # Requires grouping
        # See https://plotly.com/python/sliders/
        if not return_fig:
            raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
        _slider_labels = []
        for i, (name, group) in enumerate(self._obj.groupby(level=slider_level)):
            if slider_labels is not None:
                name = slider_labels[i]
            _slider_labels.append(name)
            df = group.vbt.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            if x_labels is None:
                x_labels = df.columns
            if y_labels is None:
                y_labels = df.index
            _kwargs = merge_dicts(dict(
                trace_kwargs=dict(
                    name=str(name) if name is not None else None,
                    visible=False
                ),
            ), kwargs)
            default_size = fig is None and &#39;height&#39; not in _kwargs
            fig = plotting.Heatmap(
                data=df.vbt.to_2d_array(),
                x_labels=x_labels,
                y_labels=y_labels,
                fig=fig,
                **_kwargs
            ).fig
            if default_size:
                fig.layout[&#39;height&#39;] += 100  # slider takes up space
        fig.data[active].visible = True
        steps = []
        for i in range(len(fig.data)):
            step = dict(
                method=&#34;update&#34;,
                args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
            )
            step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
            steps.append(step)
        prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
            if self.wrapper.index.names[slider_level] is not None else None
        sliders = [dict(
            active=active,
            currentvalue={&#34;prefix&#34;: prefix},
            pad={&#34;t&#34;: 50},
            steps=steps
        )]
        fig.update_layout(
            sliders=sliders
        )
        return fig

    def ts_heatmap(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self._obj.to_frame().vbt.ts_heatmap(**kwargs)

    def volume(self,
               x_level: tp.Optional[tp.Level] = None,
               y_level: tp.Optional[tp.Level] = None,
               z_level: tp.Optional[tp.Level] = None,
               x_labels: tp.Optional[tp.Labels] = None,
               y_labels: tp.Optional[tp.Labels] = None,
               z_labels: tp.Optional[tp.Labels] = None,
               slider_level: tp.Optional[tp.Level] = None,
               slider_labels: tp.Optional[tp.Labels] = None,
               active: int = 0,
               scene_name: str = &#39;scene&#39;,
               fillna: tp.Optional[tp.Number] = None,
               fig: tp.Optional[tp.BaseFigure] = None,
               return_fig: bool = True,
               **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Volume]:  # pragma: no cover
        &#34;&#34;&#34;Create a 3D volume figure based on object&#39;s multi-index and values.

        If multi-index contains more than three levels or you want them in specific order, pass
        `x_level`, `y_level`, and `z_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the volume. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Volume` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (2, 2, 2),
        ...     (3, 3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
        2  2  2    1
        3  3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.volume().show()
        ```

        ![](/vectorbt/docs/img/sr_volume.svg)
        &#34;&#34;&#34;
        (x_level, y_level, z_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level, z_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        z_level_vals = self.wrapper.index.get_level_values(z_level)
        # Labels are just unique level values
        if x_labels is None:
            x_labels = np.unique(x_level_vals)
        if y_labels is None:
            y_labels = np.unique(y_level_vals)
        if z_labels is None:
            z_labels = np.unique(z_level_vals)

        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        z_name = z_level_vals.name if z_level_vals.name is not None else &#39;z&#39;
        def_kwargs = dict()
        def_kwargs[&#39;trace_kwargs&#39;] = dict(
            hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                          f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                          f&#34;{z_name}: %{{z}}&lt;br&gt;&#34; +
                          &#34;value: %{value}&lt;extra&gt;&lt;/extra&gt;&#34;
        )
        def_kwargs[scene_name] = dict(
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name,
            zaxis_title=z_level_vals.name
        )
        def_kwargs[&#39;scene_name&#39;] = scene_name
        kwargs = merge_dicts(def_kwargs, kwargs)

        contains_nan = False
        if slider_level is None:
            # No grouping
            v = self.unstack_to_array(levels=(x_level, y_level, z_level))
            if fillna is not None:
                v = np.nan_to_num(v, nan=fillna)
            if np.isnan(v).any():
                contains_nan = True
            volume = plotting.Volume(
                data=v,
                x_labels=x_labels,
                y_labels=y_labels,
                z_labels=z_labels,
                fig=fig,
                **kwargs
            )
            if return_fig:
                fig = volume.fig
            else:
                fig = volume
        else:
            # Requires grouping
            # See https://plotly.com/python/sliders/
            if not return_fig:
                raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
            _slider_labels = []
            for i, (name, group) in enumerate(self._obj.groupby(level=slider_level)):
                if slider_labels is not None:
                    name = slider_labels[i]
                _slider_labels.append(name)
                v = group.vbt.unstack_to_array(levels=(x_level, y_level, z_level))
                if fillna is not None:
                    v = np.nan_to_num(v, nan=fillna)
                if np.isnan(v).any():
                    contains_nan = True
                _kwargs = merge_dicts(dict(
                    trace_kwargs=dict(
                        name=str(name) if name is not None else None,
                        visible=False
                    )
                ), kwargs)
                default_size = fig is None and &#39;height&#39; not in _kwargs
                fig = plotting.Volume(
                    data=v,
                    x_labels=x_labels,
                    y_labels=y_labels,
                    z_labels=z_labels,
                    fig=fig,
                    **_kwargs
                ).fig
                if default_size:
                    fig.layout[&#39;height&#39;] += 100  # slider takes up space
            fig.data[active].visible = True
            steps = []
            for i in range(len(fig.data)):
                step = dict(
                    method=&#34;update&#34;,
                    args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                    label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
                )
                step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
                steps.append(step)
            prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
                if self.wrapper.index.names[slider_level] is not None else None
            sliders = [dict(
                active=active,
                currentvalue={&#34;prefix&#34;: prefix},
                pad={&#34;t&#34;: 50},
                steps=steps
            )]
            fig.update_layout(
                sliders=sliders
            )

        if contains_nan:
            warnings.warn(&#34;Data contains NaNs. Use `fillna` argument or &#34;
                          &#34;`show` method in case of visualization issues.&#34;, stacklevel=2)
        return fig

    def qqplot(self,
               sparams: tp.Union[tp.Iterable, tuple, None] = (),
               dist: str = &#39;norm&#39;,
               plot_line: bool = True,
               line_shape_kwargs: tp.KwargsLike = None,
               xref: str = &#39;x&#39;,
               yref: str = &#39;y&#39;,
               fig: tp.Optional[tp.BaseFigure] = None,
               **kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot probability plot using `scipy.stats.probplot`.

        `**kwargs` are passed to `GenericAccessor.scatterplot`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
        ```

        ![](/vectorbt/docs/img/sr_qqplot.svg)
        &#34;&#34;&#34;
        qq = stats.probplot(self._obj, sparams=sparams, dist=dist)
        fig = pd.Series(qq[0][1], index=qq[0][0]).vbt.scatterplot(fig=fig, **kwargs)

        if plot_line:
            if line_shape_kwargs is None:
                line_shape_kwargs = {}
            x = np.array([qq[0][0][0], qq[0][0][-1]])
            y = qq[1][1] + qq[1][0] * x
            fig.add_shape(**merge_dicts(dict(
                type=&#34;line&#34;,
                xref=xref,
                yref=yref,
                x0=x[0],
                y0=y[0],
                x1=x[1],
                y1=y[1],
                line=dict(
                    color=&#39;red&#39;
                )
            ), line_shape_kwargs))

        return fig</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseSRAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseSRAccessor">BaseSRAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></li>
</ul>
<h3 class="section-subtitle">Subclasses</h3>
<ul class="hlist">
<li><a title="vectorbt.returns.accessors.ReturnsSRAccessor" href="../returns/accessors.html#vectorbt.returns.accessors.ReturnsSRAccessor">ReturnsSRAccessor</a></li>
<li><a title="vectorbt.root_accessors.Vbt_SRAccessor" href="../root_accessors.html#vectorbt.root_accessors.Vbt_SRAccessor">Vbt_SRAccessor</a></li>
<li><a title="vectorbt.signals.accessors.SignalsSRAccessor" href="../signals/accessors.html#vectorbt.signals.accessors.SignalsSRAccessor">SignalsSRAccessor</a></li>
</ul>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.heatmap"><code class="name flex">
<span>def <span class="ident">heatmap</span></span>(<span>self, x_level=None, y_level=None, symmetric=False, sort=True, x_labels=None, y_labels=None, slider_level=None, active=0, slider_labels=None, return_fig=True, fig=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a heatmap figure based on object's multi-index and values.</p>
<p>If index is not a multi-index, converts Series into a DataFrame and calls <code><a title="vectorbt.generic.accessors.GenericDFAccessor.heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.heatmap">GenericDFAccessor.heatmap()</a></code>.</p>
<p>If multi-index contains more than two levels or you want them in specific order,
pass <code>x_level</code> and <code>y_level</code>, each (<code>int</code> if index or <code>str</code> if name) corresponding
to an axis of the heatmap. Optionally, pass <code>slider_level</code> to use a level as a slider.</p>
<p>Creates <code><a title="vectorbt.generic.plotting.Heatmap" href="plotting.html#vectorbt.generic.plotting.Heatmap">Heatmap</a></code> and returns the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
...     (1, 1),
...     (2, 2),
...     (3, 3)
... ])
&gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
&gt;&gt;&gt; sr
1  1    0
2  2    1
3  3    2
dtype: int64

&gt;&gt;&gt; sr.vbt.heatmap()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/sr_heatmap.svg"></p>
<p>Using one level as a slider:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
...     (1, 1, 1),
...     (1, 2, 2),
...     (1, 3, 3),
...     (2, 3, 3),
...     (2, 2, 2),
...     (2, 1, 1)
... ])
&gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
&gt;&gt;&gt; sr
1  1  1    0
   2  2    1
   3  3    2
2  3  3    3
   2  2    4
   1  1    5
dtype: int64

&gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/sr_heatmap_slider.gif"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatmap(self,
            x_level: tp.Optional[tp.Level] = None,
            y_level: tp.Optional[tp.Level] = None,
            symmetric: bool = False,
            sort: bool = True,
            x_labels: tp.Optional[tp.Labels] = None,
            y_labels: tp.Optional[tp.Labels] = None,
            slider_level: tp.Optional[tp.Level] = None,
            active: int = 0,
            slider_labels: tp.Optional[tp.Labels] = None,
            return_fig: bool = True,
            fig: tp.Optional[tp.BaseFigure] = None,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Create a heatmap figure based on object&#39;s multi-index and values.

    If index is not a multi-index, converts Series into a DataFrame and calls `GenericDFAccessor.heatmap`.

    If multi-index contains more than two levels or you want them in specific order,
    pass `x_level` and `y_level`, each (`int` if index or `str` if name) corresponding
    to an axis of the heatmap. Optionally, pass `slider_level` to use a level as a slider.

    Creates `vectorbt.generic.plotting.Heatmap` and returns the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
    ...     (1, 1),
    ...     (2, 2),
    ...     (3, 3)
    ... ])
    &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
    &gt;&gt;&gt; sr
    1  1    0
    2  2    1
    3  3    2
    dtype: int64

    &gt;&gt;&gt; sr.vbt.heatmap()
    ```

    ![](/vectorbt/docs/img/sr_heatmap.svg)

    Using one level as a slider:

    ```python-repl
    &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
    ...     (1, 1, 1),
    ...     (1, 2, 2),
    ...     (1, 3, 3),
    ...     (2, 3, 3),
    ...     (2, 2, 2),
    ...     (2, 1, 1)
    ... ])
    &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
    &gt;&gt;&gt; sr
    1  1  1    0
       2  2    1
       3  3    2
    2  3  3    3
       2  2    4
       1  1    5
    dtype: int64

    &gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
    ```

    ![](/vectorbt/docs/img/sr_heatmap_slider.gif)
    &#34;&#34;&#34;
    if not isinstance(self.wrapper.index, pd.MultiIndex):
        return self._obj.to_frame().vbt.heatmap(
            x_labels=x_labels, y_labels=y_labels,
            return_fig=return_fig, fig=fig, **kwargs)

    (x_level, y_level), (slider_level,) = index_fns.pick_levels(
        self.wrapper.index,
        required_levels=(x_level, y_level),
        optional_levels=(slider_level,)
    )

    x_level_vals = self.wrapper.index.get_level_values(x_level)
    y_level_vals = self.wrapper.index.get_level_values(y_level)
    x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
    y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
    kwargs = merge_dicts(dict(
        trace_kwargs=dict(
            hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                          f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                          &#34;value: %{z}&lt;extra&gt;&lt;/extra&gt;&#34;
        ),
        xaxis_title=x_level_vals.name,
        yaxis_title=y_level_vals.name
    ), kwargs)

    if slider_level is None:
        # No grouping
        df = self.unstack_to_df(
            index_levels=y_level, column_levels=x_level,
            symmetric=symmetric, sort=sort
        )
        return df.vbt.heatmap(x_labels=x_labels, y_labels=y_labels, fig=fig, return_fig=return_fig, **kwargs)

    # Requires grouping
    # See https://plotly.com/python/sliders/
    if not return_fig:
        raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
    _slider_labels = []
    for i, (name, group) in enumerate(self._obj.groupby(level=slider_level)):
        if slider_labels is not None:
            name = slider_labels[i]
        _slider_labels.append(name)
        df = group.vbt.unstack_to_df(
            index_levels=y_level, column_levels=x_level,
            symmetric=symmetric, sort=sort
        )
        if x_labels is None:
            x_labels = df.columns
        if y_labels is None:
            y_labels = df.index
        _kwargs = merge_dicts(dict(
            trace_kwargs=dict(
                name=str(name) if name is not None else None,
                visible=False
            ),
        ), kwargs)
        default_size = fig is None and &#39;height&#39; not in _kwargs
        fig = plotting.Heatmap(
            data=df.vbt.to_2d_array(),
            x_labels=x_labels,
            y_labels=y_labels,
            fig=fig,
            **_kwargs
        ).fig
        if default_size:
            fig.layout[&#39;height&#39;] += 100  # slider takes up space
    fig.data[active].visible = True
    steps = []
    for i in range(len(fig.data)):
        step = dict(
            method=&#34;update&#34;,
            args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
            label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
        )
        step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
        steps.append(step)
    prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
        if self.wrapper.index.names[slider_level] is not None else None
    sliders = [dict(
        active=active,
        currentvalue={&#34;prefix&#34;: prefix},
        pad={&#34;t&#34;: 50},
        steps=steps
    )]
    fig.update_layout(
        sliders=sliders
    )
    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.overlay_with_heatmap"><code class="name flex">
<span>def <span class="ident">overlay_with_heatmap</span></span>(<span>self, other, trace_kwargs=None, heatmap_kwargs=None, add_trace_kwargs=None, fig=None, **layout_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot Series as a line and overlays it with a heatmap.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Second array. Will broadcast.</dd>
<dt><strong><code>trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code>.</dd>
<dt><strong><code>heatmap_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code><a title="vectorbt.generic.accessors.GenericDFAccessor.heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.heatmap">GenericDFAccessor.heatmap()</a></code>.</dd>
<dt><strong><code>add_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>add_trace</code>.</dd>
<dt><strong><code>fig</code></strong> :&ensp;<code>Figure</code> or <code>FigureWidget</code></dt>
<dd>Figure to add traces to.</dd>
<dt><strong><code>**layout_kwargs</code></strong></dt>
<dd>Keyword arguments for layout.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df['a'].vbt.overlay_with_heatmap(df['b'])
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/sr_overlay_with_heatmap.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def overlay_with_heatmap(self,
                         other: tp.ArrayLike,
                         trace_kwargs: tp.KwargsLike = None,
                         heatmap_kwargs: tp.KwargsLike = None,
                         add_trace_kwargs: tp.KwargsLike = None,
                         fig: tp.Optional[tp.BaseFigure] = None,
                         **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
    &#34;&#34;&#34;Plot Series as a line and overlays it with a heatmap.

    Args:
        other (array_like): Second array. Will broadcast.
        trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
        heatmap_kwargs (dict): Keyword arguments passed to `GenericDFAccessor.heatmap`.
        add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
        fig (Figure or FigureWidget): Figure to add traces to.
        **layout_kwargs: Keyword arguments for layout.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df[&#39;a&#39;].vbt.overlay_with_heatmap(df[&#39;b&#39;])
    ```

    ![](/vectorbt/docs/img/sr_overlay_with_heatmap.svg)
    &#34;&#34;&#34;
    from vectorbt._settings import settings
    plotting_cfg = settings[&#39;plotting&#39;]

    if trace_kwargs is None:
        trace_kwargs = {}
    if heatmap_kwargs is None:
        heatmap_kwargs = {}
    if add_trace_kwargs is None:
        add_trace_kwargs = {}

    obj, other = reshape_fns.broadcast(self._obj, other, columns_from=&#39;keep&#39;)
    checks.assert_type(other, pd.Series)
    if fig is None:
        fig = make_subplots(specs=[[{&#34;secondary_y&#34;: True}]])
        if &#39;width&#39; in plotting_cfg[&#39;layout&#39;]:
            fig.update_layout(width=plotting_cfg[&#39;layout&#39;][&#39;width&#39;] + 100)
    fig.update_layout(**layout_kwargs)

    other.vbt.ts_heatmap(**heatmap_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
    self.plot(
        trace_kwargs=merge_dicts(dict(line=dict(color=plotting_cfg[&#39;color_schema&#39;][&#39;blue&#39;])), trace_kwargs),
        add_trace_kwargs=merge_dicts(dict(secondary_y=True), add_trace_kwargs),
        fig=fig
    )
    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.plot_against"><code class="name flex">
<span>def <span class="ident">plot_against</span></span>(<span>self, other, trace_kwargs=None, other_trace_kwargs=None, pos_trace_kwargs=None, neg_trace_kwargs=None, hidden_trace_kwargs=None, add_trace_kwargs=None, fig=None, **layout_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot Series as a line against another line.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Second array. Will broadcast.</dd>
<dt><strong><code>trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code>.</dd>
<dt><strong><code>other_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>
<p>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for <code>other</code>.</p>
<p>Set to 'hidden' to hide.</p>
</dd>
<dt><strong><code>pos_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for positive line.</dd>
<dt><strong><code>neg_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for negative line.</dd>
<dt><strong><code>hidden_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for hidden lines.</dd>
<dt><strong><code>add_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>add_trace</code>.</dd>
<dt><strong><code>fig</code></strong> :&ensp;<code>Figure</code> or <code>FigureWidget</code></dt>
<dd>Figure to add traces to.</dd>
<dt><strong><code>**layout_kwargs</code></strong></dt>
<dd>Keyword arguments for layout.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df['a'].vbt.plot_against(df['b'])
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/sr_plot_against.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_against(self,
                 other: tp.ArrayLike,
                 trace_kwargs: tp.KwargsLike = None,
                 other_trace_kwargs: tp.Union[str, tp.KwargsLike] = None,
                 pos_trace_kwargs: tp.KwargsLike = None,
                 neg_trace_kwargs: tp.KwargsLike = None,
                 hidden_trace_kwargs: tp.KwargsLike = None,
                 add_trace_kwargs: tp.KwargsLike = None,
                 fig: tp.Optional[tp.BaseFigure] = None,
                 **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
    &#34;&#34;&#34;Plot Series as a line against another line.

    Args:
        other (array_like): Second array. Will broadcast.
        trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
        other_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for `other`.

            Set to &#39;hidden&#39; to hide.
        pos_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for positive line.
        neg_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for negative line.
        hidden_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for hidden lines.
        add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
        fig (Figure or FigureWidget): Figure to add traces to.
        **layout_kwargs: Keyword arguments for layout.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df[&#39;a&#39;].vbt.plot_against(df[&#39;b&#39;])
    ```

    ![](/vectorbt/docs/img/sr_plot_against.svg)
    &#34;&#34;&#34;
    if trace_kwargs is None:
        trace_kwargs = {}
    if other_trace_kwargs is None:
        other_trace_kwargs = {}
    if pos_trace_kwargs is None:
        pos_trace_kwargs = {}
    if neg_trace_kwargs is None:
        neg_trace_kwargs = {}
    if hidden_trace_kwargs is None:
        hidden_trace_kwargs = {}
    obj, other = reshape_fns.broadcast(self._obj, other, columns_from=&#39;keep&#39;)
    checks.assert_type(other, pd.Series)
    if fig is None:
        fig = make_figure()
    fig.update_layout(**layout_kwargs)

    # TODO: Using masks feels hacky
    pos_mask = self._obj &gt; other
    if pos_mask.any():
        # Fill positive area
        pos_obj = self._obj.copy()
        pos_obj[~pos_mask] = other[~pos_mask]
        other.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None,
            ), hidden_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )
        pos_obj.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                fillcolor=&#39;rgba(0, 128, 0, 0.3)&#39;,
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0,
                fill=&#39;tonexty&#39;,
                connectgaps=False,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            ), pos_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )
    neg_mask = self._obj &lt; other
    if neg_mask.any():
        # Fill negative area
        neg_obj = self._obj.copy()
        neg_obj[~neg_mask] = other[~neg_mask]
        other.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            ), hidden_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )
        neg_obj.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                fillcolor=&#39;rgba(255, 0, 0, 0.3)&#39;,
                opacity=0,
                fill=&#39;tonexty&#39;,
                connectgaps=False,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            ), neg_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )

    # Plot main traces
    self.plot(trace_kwargs=trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
    if other_trace_kwargs == &#39;hidden&#39;:
        other_trace_kwargs = dict(
            line=dict(
                color=&#39;rgba(0, 0, 0, 0)&#39;,
                width=0
            ),
            opacity=0.,
            hoverinfo=&#39;skip&#39;,
            showlegend=False,
            name=None
        )
    other.vbt.plot(trace_kwargs=other_trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.qqplot"><code class="name flex">
<span>def <span class="ident">qqplot</span></span>(<span>self, sparams=(), dist='norm', plot_line=True, line_shape_kwargs=None, xref='x', yref='y', fig=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot probability plot using <code>scipy.stats.probplot</code>.</p>
<p><code>**kwargs</code> are passed to <code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">GenericAccessor.scatterplot()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/sr_qqplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def qqplot(self,
           sparams: tp.Union[tp.Iterable, tuple, None] = (),
           dist: str = &#39;norm&#39;,
           plot_line: bool = True,
           line_shape_kwargs: tp.KwargsLike = None,
           xref: str = &#39;x&#39;,
           yref: str = &#39;y&#39;,
           fig: tp.Optional[tp.BaseFigure] = None,
           **kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
    &#34;&#34;&#34;Plot probability plot using `scipy.stats.probplot`.

    `**kwargs` are passed to `GenericAccessor.scatterplot`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
    ```

    ![](/vectorbt/docs/img/sr_qqplot.svg)
    &#34;&#34;&#34;
    qq = stats.probplot(self._obj, sparams=sparams, dist=dist)
    fig = pd.Series(qq[0][1], index=qq[0][0]).vbt.scatterplot(fig=fig, **kwargs)

    if plot_line:
        if line_shape_kwargs is None:
            line_shape_kwargs = {}
        x = np.array([qq[0][0][0], qq[0][0][-1]])
        y = qq[1][1] + qq[1][0] * x
        fig.add_shape(**merge_dicts(dict(
            type=&#34;line&#34;,
            xref=xref,
            yref=yref,
            x0=x[0],
            y0=y[0],
            x1=x[1],
            y1=y[1],
            line=dict(
                color=&#39;red&#39;
            )
        ), line_shape_kwargs))

    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.ts_heatmap"><code class="name flex">
<span>def <span class="ident">ts_heatmap</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Heatmap of time-series data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ts_heatmap(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
    return self._obj.to_frame().vbt.ts_heatmap(**kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.volume"><code class="name flex">
<span>def <span class="ident">volume</span></span>(<span>self, x_level=None, y_level=None, z_level=None, x_labels=None, y_labels=None, z_labels=None, slider_level=None, slider_labels=None, active=0, scene_name='scene', fillna=None, fig=None, return_fig=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a 3D volume figure based on object's multi-index and values.</p>
<p>If multi-index contains more than three levels or you want them in specific order, pass
<code>x_level</code>, <code>y_level</code>, and <code>z_level</code>, each (<code>int</code> if index or <code>str</code> if name) corresponding
to an axis of the volume. Optionally, pass <code>slider_level</code> to use a level as a slider.</p>
<p>Creates <code><a title="vectorbt.generic.plotting.Volume" href="plotting.html#vectorbt.generic.plotting.Volume">Volume</a></code> and returns the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
...     (1, 1, 1),
...     (2, 2, 2),
...     (3, 3, 3)
... ])
&gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
&gt;&gt;&gt; sr
1  1  1    0
2  2  2    1
3  3  3    2
dtype: int64

&gt;&gt;&gt; sr.vbt.volume().show()
</code></pre>
<p><img alt="" src="/vectorbt/docs/img/sr_volume.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def volume(self,
           x_level: tp.Optional[tp.Level] = None,
           y_level: tp.Optional[tp.Level] = None,
           z_level: tp.Optional[tp.Level] = None,
           x_labels: tp.Optional[tp.Labels] = None,
           y_labels: tp.Optional[tp.Labels] = None,
           z_labels: tp.Optional[tp.Labels] = None,
           slider_level: tp.Optional[tp.Level] = None,
           slider_labels: tp.Optional[tp.Labels] = None,
           active: int = 0,
           scene_name: str = &#39;scene&#39;,
           fillna: tp.Optional[tp.Number] = None,
           fig: tp.Optional[tp.BaseFigure] = None,
           return_fig: bool = True,
           **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Volume]:  # pragma: no cover
    &#34;&#34;&#34;Create a 3D volume figure based on object&#39;s multi-index and values.

    If multi-index contains more than three levels or you want them in specific order, pass
    `x_level`, `y_level`, and `z_level`, each (`int` if index or `str` if name) corresponding
    to an axis of the volume. Optionally, pass `slider_level` to use a level as a slider.

    Creates `vectorbt.generic.plotting.Volume` and returns the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
    ...     (1, 1, 1),
    ...     (2, 2, 2),
    ...     (3, 3, 3)
    ... ])
    &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
    &gt;&gt;&gt; sr
    1  1  1    0
    2  2  2    1
    3  3  3    2
    dtype: int64

    &gt;&gt;&gt; sr.vbt.volume().show()
    ```

    ![](/vectorbt/docs/img/sr_volume.svg)
    &#34;&#34;&#34;
    (x_level, y_level, z_level), (slider_level,) = index_fns.pick_levels(
        self.wrapper.index,
        required_levels=(x_level, y_level, z_level),
        optional_levels=(slider_level,)
    )

    x_level_vals = self.wrapper.index.get_level_values(x_level)
    y_level_vals = self.wrapper.index.get_level_values(y_level)
    z_level_vals = self.wrapper.index.get_level_values(z_level)
    # Labels are just unique level values
    if x_labels is None:
        x_labels = np.unique(x_level_vals)
    if y_labels is None:
        y_labels = np.unique(y_level_vals)
    if z_labels is None:
        z_labels = np.unique(z_level_vals)

    x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
    y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
    z_name = z_level_vals.name if z_level_vals.name is not None else &#39;z&#39;
    def_kwargs = dict()
    def_kwargs[&#39;trace_kwargs&#39;] = dict(
        hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                      f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                      f&#34;{z_name}: %{{z}}&lt;br&gt;&#34; +
                      &#34;value: %{value}&lt;extra&gt;&lt;/extra&gt;&#34;
    )
    def_kwargs[scene_name] = dict(
        xaxis_title=x_level_vals.name,
        yaxis_title=y_level_vals.name,
        zaxis_title=z_level_vals.name
    )
    def_kwargs[&#39;scene_name&#39;] = scene_name
    kwargs = merge_dicts(def_kwargs, kwargs)

    contains_nan = False
    if slider_level is None:
        # No grouping
        v = self.unstack_to_array(levels=(x_level, y_level, z_level))
        if fillna is not None:
            v = np.nan_to_num(v, nan=fillna)
        if np.isnan(v).any():
            contains_nan = True
        volume = plotting.Volume(
            data=v,
            x_labels=x_labels,
            y_labels=y_labels,
            z_labels=z_labels,
            fig=fig,
            **kwargs
        )
        if return_fig:
            fig = volume.fig
        else:
            fig = volume
    else:
        # Requires grouping
        # See https://plotly.com/python/sliders/
        if not return_fig:
            raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
        _slider_labels = []
        for i, (name, group) in enumerate(self._obj.groupby(level=slider_level)):
            if slider_labels is not None:
                name = slider_labels[i]
            _slider_labels.append(name)
            v = group.vbt.unstack_to_array(levels=(x_level, y_level, z_level))
            if fillna is not None:
                v = np.nan_to_num(v, nan=fillna)
            if np.isnan(v).any():
                contains_nan = True
            _kwargs = merge_dicts(dict(
                trace_kwargs=dict(
                    name=str(name) if name is not None else None,
                    visible=False
                )
            ), kwargs)
            default_size = fig is None and &#39;height&#39; not in _kwargs
            fig = plotting.Volume(
                data=v,
                x_labels=x_labels,
                y_labels=y_labels,
                z_labels=z_labels,
                fig=fig,
                **_kwargs
            ).fig
            if default_size:
                fig.layout[&#39;height&#39;] += 100  # slider takes up space
        fig.data[active].visible = True
        steps = []
        for i in range(len(fig.data)):
            step = dict(
                method=&#34;update&#34;,
                args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
            )
            step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
            steps.append(step)
        prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
            if self.wrapper.index.names[slider_level] is not None else None
        sliders = [dict(
            active=active,
            currentvalue={&#34;prefix&#34;: prefix},
            pad={&#34;t&#34;: 50},
            steps=steps
        )]
        fig.update_layout(
            sliders=sliders
        )

    if contains_nan:
        warnings.warn(&#34;Data contains NaNs. Use `fillna` argument or &#34;
                      &#34;`show` method in case of visualization issues.&#34;, stacklevel=2)
    return fig</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.align_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.align_to">align_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply">apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_along_axis" href="#vectorbt.generic.accessors.GenericAccessor.apply_along_axis">apply_along_axis</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_and_concat">apply_and_concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce" href="#vectorbt.generic.accessors.GenericAccessor.apply_and_reduce">apply_and_reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_on_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_on_index">apply_on_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.applymap" href="#vectorbt.generic.accessors.GenericAccessor.applymap">applymap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.barplot" href="#vectorbt.generic.accessors.GenericAccessor.barplot">barplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.binarize" href="#vectorbt.generic.accessors.GenericAccessor.binarize">binarize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.boxplot" href="#vectorbt.generic.accessors.GenericAccessor.boxplot">boxplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast">broadcast</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast_to">broadcast_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bshift" href="#vectorbt.generic.accessors.GenericAccessor.bshift">bshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.combine" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.combine">combine</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.concat">concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.count" href="#vectorbt.generic.accessors.GenericAccessor.count">count</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumprod" href="#vectorbt.generic.accessors.GenericAccessor.cumprod">cumprod</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumsum" href="#vectorbt.generic.accessors.GenericAccessor.cumsum">cumsum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.describe" href="#vectorbt.generic.accessors.GenericAccessor.describe">describe</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.diff" href="#vectorbt.generic.accessors.GenericAccessor.diff">diff</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdown" href="#vectorbt.generic.accessors.GenericAccessor.drawdown">drawdown</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.drawdowns">drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_duplicate_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels">drop_duplicate_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_levels">drop_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_redundant_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_redundant_levels">drop_redundant_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty">empty</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty_like" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty_like">empty_like</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_mean" href="#vectorbt.generic.accessors.GenericAccessor.ewm_mean">ewm_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_std" href="#vectorbt.generic.accessors.GenericAccessor.ewm_std">ewm_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_apply" href="#vectorbt.generic.accessors.GenericAccessor.expanding_apply">expanding_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_max" href="#vectorbt.generic.accessors.GenericAccessor.expanding_max">expanding_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_mean" href="#vectorbt.generic.accessors.GenericAccessor.expanding_mean">expanding_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_min" href="#vectorbt.generic.accessors.GenericAccessor.expanding_min">expanding_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_split" href="#vectorbt.generic.accessors.GenericAccessor.expanding_split">expanding_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_std" href="#vectorbt.generic.accessors.GenericAccessor.expanding_std">expanding_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ffill" href="#vectorbt.generic.accessors.GenericAccessor.ffill">ffill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fillna" href="#vectorbt.generic.accessors.GenericAccessor.fillna">fillna</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.filter" href="#vectorbt.generic.accessors.GenericAccessor.filter">filter</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.flatten_grouped" href="#vectorbt.generic.accessors.GenericAccessor.flatten_grouped">flatten_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fshift" href="#vectorbt.generic.accessors.GenericAccessor.fshift">fshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">get_drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.groupby_apply" href="#vectorbt.generic.accessors.GenericAccessor.groupby_apply">groupby_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.histplot" href="#vectorbt.generic.accessors.GenericAccessor.histplot">histplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmax" href="#vectorbt.generic.accessors.GenericAccessor.idxmax">idxmax</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmin" href="#vectorbt.generic.accessors.GenericAccessor.idxmin">idxmin</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.lineplot" href="#vectorbt.generic.accessors.GenericAccessor.lineplot">lineplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.make_symmetric" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.make_symmetric">make_symmetric</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.map_enum" href="#vectorbt.generic.accessors.GenericAccessor.map_enum">map_enum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.max" href="#vectorbt.generic.accessors.GenericAccessor.max">max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.maxabs_scale" href="#vectorbt.generic.accessors.GenericAccessor.maxabs_scale">maxabs_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mean" href="#vectorbt.generic.accessors.GenericAccessor.mean">mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.median" href="#vectorbt.generic.accessors.GenericAccessor.median">median</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.min" href="#vectorbt.generic.accessors.GenericAccessor.min">min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.minmax_scale" href="#vectorbt.generic.accessors.GenericAccessor.minmax_scale">minmax_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.normalize" href="#vectorbt.generic.accessors.GenericAccessor.normalize">normalize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pct_change" href="#vectorbt.generic.accessors.GenericAccessor.pct_change">pct_change</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">plot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.power_transform" href="#vectorbt.generic.accessors.GenericAccessor.power_transform">power_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.product" href="#vectorbt.generic.accessors.GenericAccessor.product">product</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.quantile_transform" href="#vectorbt.generic.accessors.GenericAccessor.quantile_transform">quantile_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.range_split" href="#vectorbt.generic.accessors.GenericAccessor.range_split">range_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.reduce" href="#vectorbt.generic.accessors.GenericAccessor.reduce">reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rename_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.rename_levels">rename_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.repeat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.repeat">repeat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resample_apply" href="#vectorbt.generic.accessors.GenericAccessor.resample_apply">resample_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.robust_scale" href="#vectorbt.generic.accessors.GenericAccessor.robust_scale">robust_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_apply" href="#vectorbt.generic.accessors.GenericAccessor.rolling_apply">rolling_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_max" href="#vectorbt.generic.accessors.GenericAccessor.rolling_max">rolling_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_mean" href="#vectorbt.generic.accessors.GenericAccessor.rolling_mean">rolling_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_min" href="#vectorbt.generic.accessors.GenericAccessor.rolling_min">rolling_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_split" href="#vectorbt.generic.accessors.GenericAccessor.rolling_split">rolling_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_std" href="#vectorbt.generic.accessors.GenericAccessor.rolling_std">rolling_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scale" href="#vectorbt.generic.accessors.GenericAccessor.scale">scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">scatterplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.select_levels">select_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.shuffle" href="#vectorbt.generic.accessors.GenericAccessor.shuffle">shuffle</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.squeeze_grouped" href="#vectorbt.generic.accessors.GenericAccessor.squeeze_grouped">squeeze_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stack_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.stack_index">stack_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.std" href="#vectorbt.generic.accessors.GenericAccessor.std">std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sum" href="#vectorbt.generic.accessors.GenericAccessor.sum">sum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.tile" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.tile">tile</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_1d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_1d_array">to_1d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_2d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_2d_array">to_2d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_mapped_array" href="#vectorbt.generic.accessors.GenericAccessor.to_mapped_array">to_mapped_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.transform" href="#vectorbt.generic.accessors.GenericAccessor.transform">transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_array">unstack_to_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_df" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_df">unstack_to_df</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.wrapper" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.wrapper">wrapper</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.zscore" href="#vectorbt.generic.accessors.GenericAccessor.zscore">zscore</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.TransformerT"><code class="flex name class">
<span>class <span class="ident">TransformerT</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for protocol classes. Protocol classes are defined as::</p>
<p>class Proto(Protocol):
def meth(self) -&gt; int:
&hellip;</p>
<p>Such classes are primarily used with static type checkers that recognize
structural subtyping (static duck-typing), for example::</p>
<p>class C:
def meth(self) -&gt; int:
return 0</p>
<p>def func(x: Proto) -&gt; int:
return x.meth()</p>
<p>func(C())
# Passes static type check</p>
<p>See PEP 544 for details. Protocol classes decorated with
@typing_extensions.runtime act as simple-minded runtime protocol that checks
only the presence of given attributes, ignoring their type signatures.</p>
<p>Protocol classes can be generic, they are defined as::</p>
<p>class GenProto(Protocol[T]):
def meth(self) -&gt; T:
&hellip;</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransformerT(tp.Protocol):
    def __init__(self, **kwargs) -&gt; None:
        ...

    def transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...

    def fit_transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li>typing_extensions.Protocol</li>
</ul>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.TransformerT.fit_transform"><code class="name flex">
<span>def <span class="ident">fit_transform</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_transform(self, *args, **kwargs) -&gt; tp.Array2d:
    ...</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.TransformerT.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, *args, **kwargs) -&gt; tp.Array2d:
    ...</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://github.com/polakowo/vectorbt">
<img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI1LjAuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkNhcGFfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiCgkgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDojRUYwMDAwO30KCS5zdDF7ZmlsbDojRkY5MDAwO30KCS5zdDJ7ZmlsbDojRkZERjAwO30KCS5zdDN7ZmlsbDojMjgyQzM0O30KPC9zdHlsZT4KPGc+Cgk8Zz4KCQk8Zz4KCQkJPHBvbHlnb24gY2xhc3M9InN0MCIgcG9pbnRzPSIxNTUuMywzMDAuMSAyODMuMSwwIDIwOCwwIDExMC44LDAgMzUuOCwwIDEuMiw0NTAuMiA3Ni4zLDQ1MC4yIAkJCSIvPgoJCTwvZz4KCTwvZz4KCTxnPgoJCTxnPgoJCQk8cG9seWdvbiBjbGFzcz0ic3QxIiBwb2ludHM9IjIzMC40LDMwMC4xIDM1OC4xLDAgMjgzLjEsMCAxODUuOCwwIDExMC44LDAgNzYuMyw0NTAuMiAxNTEuMyw0NTAuMiAJCQkiLz4KCQk8L2c+Cgk8L2c+Cgk8Zz4KCQk8Zz4KCQkJPHBvbHlnb24gY2xhc3M9InN0MiIgcG9pbnRzPSIzMDUuNCwzMDAuMSA0MzMuMSwwIDM1OC4xLDAgMzMxLjYsNjIuMyAyNjAuOCwwIDE4NS44LDAgMTUxLjMsNDUwLjIgMjI2LjQsNDUwLjIgCQkJIi8+CgkJPC9nPgoJPC9nPgoJPGc+CgkJPGc+CgkJCTxwb2x5Z29uIGNsYXNzPSJzdDMiIHBvaW50cz0iNTEwLjgsMCA0MzMuMSwwIDMwNS40LDMwMC4xIDMzOC40LDAgMjYwLjgsMCAyMjYuNCw0NTAuMiAzMDQsNDUwLjIgCQkJIi8+CgkJPC9nPgoJPC9nPgo8L2c+Cjwvc3ZnPgo="/>
vectorbt <span class="version">0.19.1</span></a>
</header>
<div class="search-container">
<input
id="search_input"
type="text"
placeholder="Search"
title="Search"
/>
</div>
<div class="scrollable-index">
<h1 class="index-caption">Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="vectorbt.generic" href="index.html">vectorbt.generic</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.add_transform_methods" href="#vectorbt.generic.accessors.add_transform_methods">add_transform_methods</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code></h4>
<ul class="two-column">
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_along_axis" href="#vectorbt.generic.accessors.GenericAccessor.apply_along_axis">apply_along_axis</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce" href="#vectorbt.generic.accessors.GenericAccessor.apply_and_reduce">apply_and_reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.applymap" href="#vectorbt.generic.accessors.GenericAccessor.applymap">applymap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.barplot" href="#vectorbt.generic.accessors.GenericAccessor.barplot">barplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.binarize" href="#vectorbt.generic.accessors.GenericAccessor.binarize">binarize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.boxplot" href="#vectorbt.generic.accessors.GenericAccessor.boxplot">boxplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bshift" href="#vectorbt.generic.accessors.GenericAccessor.bshift">bshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.count" href="#vectorbt.generic.accessors.GenericAccessor.count">count</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumprod" href="#vectorbt.generic.accessors.GenericAccessor.cumprod">cumprod</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumsum" href="#vectorbt.generic.accessors.GenericAccessor.cumsum">cumsum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.describe" href="#vectorbt.generic.accessors.GenericAccessor.describe">describe</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.diff" href="#vectorbt.generic.accessors.GenericAccessor.diff">diff</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdown" href="#vectorbt.generic.accessors.GenericAccessor.drawdown">drawdown</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.drawdowns">drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_mean" href="#vectorbt.generic.accessors.GenericAccessor.ewm_mean">ewm_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_std" href="#vectorbt.generic.accessors.GenericAccessor.ewm_std">ewm_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_apply" href="#vectorbt.generic.accessors.GenericAccessor.expanding_apply">expanding_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_max" href="#vectorbt.generic.accessors.GenericAccessor.expanding_max">expanding_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_mean" href="#vectorbt.generic.accessors.GenericAccessor.expanding_mean">expanding_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_min" href="#vectorbt.generic.accessors.GenericAccessor.expanding_min">expanding_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_split" href="#vectorbt.generic.accessors.GenericAccessor.expanding_split">expanding_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_std" href="#vectorbt.generic.accessors.GenericAccessor.expanding_std">expanding_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ffill" href="#vectorbt.generic.accessors.GenericAccessor.ffill">ffill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fillna" href="#vectorbt.generic.accessors.GenericAccessor.fillna">fillna</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.filter" href="#vectorbt.generic.accessors.GenericAccessor.filter">filter</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.flatten_grouped" href="#vectorbt.generic.accessors.GenericAccessor.flatten_grouped">flatten_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fshift" href="#vectorbt.generic.accessors.GenericAccessor.fshift">fshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">get_drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.groupby_apply" href="#vectorbt.generic.accessors.GenericAccessor.groupby_apply">groupby_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.histplot" href="#vectorbt.generic.accessors.GenericAccessor.histplot">histplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmax" href="#vectorbt.generic.accessors.GenericAccessor.idxmax">idxmax</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmin" href="#vectorbt.generic.accessors.GenericAccessor.idxmin">idxmin</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.lineplot" href="#vectorbt.generic.accessors.GenericAccessor.lineplot">lineplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.map_enum" href="#vectorbt.generic.accessors.GenericAccessor.map_enum">map_enum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.max" href="#vectorbt.generic.accessors.GenericAccessor.max">max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.maxabs_scale" href="#vectorbt.generic.accessors.GenericAccessor.maxabs_scale">maxabs_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mean" href="#vectorbt.generic.accessors.GenericAccessor.mean">mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.median" href="#vectorbt.generic.accessors.GenericAccessor.median">median</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.min" href="#vectorbt.generic.accessors.GenericAccessor.min">min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.minmax_scale" href="#vectorbt.generic.accessors.GenericAccessor.minmax_scale">minmax_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.normalize" href="#vectorbt.generic.accessors.GenericAccessor.normalize">normalize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pct_change" href="#vectorbt.generic.accessors.GenericAccessor.pct_change">pct_change</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">plot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.power_transform" href="#vectorbt.generic.accessors.GenericAccessor.power_transform">power_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.product" href="#vectorbt.generic.accessors.GenericAccessor.product">product</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.quantile_transform" href="#vectorbt.generic.accessors.GenericAccessor.quantile_transform">quantile_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.range_split" href="#vectorbt.generic.accessors.GenericAccessor.range_split">range_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.reduce" href="#vectorbt.generic.accessors.GenericAccessor.reduce">reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resample_apply" href="#vectorbt.generic.accessors.GenericAccessor.resample_apply">resample_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.robust_scale" href="#vectorbt.generic.accessors.GenericAccessor.robust_scale">robust_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_apply" href="#vectorbt.generic.accessors.GenericAccessor.rolling_apply">rolling_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_max" href="#vectorbt.generic.accessors.GenericAccessor.rolling_max">rolling_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_mean" href="#vectorbt.generic.accessors.GenericAccessor.rolling_mean">rolling_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_min" href="#vectorbt.generic.accessors.GenericAccessor.rolling_min">rolling_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_split" href="#vectorbt.generic.accessors.GenericAccessor.rolling_split">rolling_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_std" href="#vectorbt.generic.accessors.GenericAccessor.rolling_std">rolling_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scale" href="#vectorbt.generic.accessors.GenericAccessor.scale">scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">scatterplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.shuffle" href="#vectorbt.generic.accessors.GenericAccessor.shuffle">shuffle</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.squeeze_grouped" href="#vectorbt.generic.accessors.GenericAccessor.squeeze_grouped">squeeze_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.std" href="#vectorbt.generic.accessors.GenericAccessor.std">std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sum" href="#vectorbt.generic.accessors.GenericAccessor.sum">sum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_mapped_array" href="#vectorbt.generic.accessors.GenericAccessor.to_mapped_array">to_mapped_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.transform" href="#vectorbt.generic.accessors.GenericAccessor.transform">transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.zscore" href="#vectorbt.generic.accessors.GenericAccessor.zscore">zscore</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.GenericDFAccessor" href="#vectorbt.generic.accessors.GenericDFAccessor">GenericDFAccessor</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor.heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.heatmap">heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor.ts_heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.ts_heatmap">ts_heatmap</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.GenericSRAccessor" href="#vectorbt.generic.accessors.GenericSRAccessor">GenericSRAccessor</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.heatmap" href="#vectorbt.generic.accessors.GenericSRAccessor.heatmap">heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.overlay_with_heatmap" href="#vectorbt.generic.accessors.GenericSRAccessor.overlay_with_heatmap">overlay_with_heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.plot_against" href="#vectorbt.generic.accessors.GenericSRAccessor.plot_against">plot_against</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.qqplot" href="#vectorbt.generic.accessors.GenericSRAccessor.qqplot">qqplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.ts_heatmap" href="#vectorbt.generic.accessors.GenericSRAccessor.ts_heatmap">ts_heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.volume" href="#vectorbt.generic.accessors.GenericSRAccessor.volume">volume</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.TransformerT" href="#vectorbt.generic.accessors.TransformerT">TransformerT</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.TransformerT.fit_transform" href="#vectorbt.generic.accessors.TransformerT.fit_transform">fit_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.TransformerT.transform" href="#vectorbt.generic.accessors.TransformerT.transform">transform</a></code></li>
</ul>
</li>
</ul>
</li>
</nav>
</main>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript">
docsearch({
apiKey: 'ac97cfdd96a6e6fcdc67c570adaeaf94',
indexName: 'vectorbt',
inputSelector: '#search_input',
autocompleteOptions: {
autoWidth: false
},
debug: true // Set debug to true if you want to inspect the dropdown
});
</script>
<script src="https://buttons.github.io/buttons.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
<script>
// Turn off ESLint for this file because it's sent down to users as-is.
/* eslint-disable */
window.addEventListener('load', function() {
function button(label, ariaLabel, icon, className) {
const btn = document.createElement('button');
btn.classList.add('btnIcon', className);
btn.setAttribute('type', 'button');
btn.setAttribute('aria-label', ariaLabel);
btn.innerHTML =
'<div class="btnIcon__body">' +
icon +
'<strong class="btnIcon__label">' +
label +
'</strong>' +
'</div>';
return btn;
}
function addButtons(codeBlockSelector, btn) {
document.querySelectorAll(codeBlockSelector).forEach(function(code) {
code.parentNode.appendChild(btn.cloneNode(true));
});
}
const copyIcon =
'<svg width="12" height="12" viewBox="340 364 14 15" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M342 375.974h4v.998h-4v-.998zm5-5.987h-5v.998h5v-.998zm2 2.994v-1.995l-3 2.993 3 2.994v-1.996h5v-1.995h-5zm-4.5-.997H342v.998h2.5v-.997zm-2.5 2.993h2.5v-.998H342v.998zm9 .998h1v1.996c-.016.28-.11.514-.297.702-.187.187-.422.28-.703.296h-10c-.547 0-1-.452-1-.998v-10.976c0-.546.453-.998 1-.998h3c0-1.107.89-1.996 2-1.996 1.11 0 2 .89 2 1.996h3c.547 0 1 .452 1 .998v4.99h-1v-2.995h-10v8.98h10v-1.996zm-9-7.983h8c0-.544-.453-.996-1-.996h-1c-.547 0-1-.453-1-.998 0-.546-.453-.998-1-.998-.547 0-1 .452-1 .998 0 .545-.453.998-1 .998h-1c-.547 0-1 .452-1 .997z" fill-rule="evenodd"/></svg>';
addButtons(
'.hljs',
button('Copy', 'Copy code to clipboard', copyIcon, 'btnClipboard'),
);
const clipboard = new ClipboardJS('.btnClipboard', {
target: function(trigger) {
return trigger.parentNode.querySelector('code');
},
});
clipboard.on('success', function(event) {
event.clearSelection();
const textEl = event.trigger.querySelector('.btnIcon__label');
textEl.textContent = 'Copied';
setTimeout(function() {
textEl.textContent = 'Copy';
}, 2000);
});
});
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript">
docsearch({
apiKey: 'ac97cfdd96a6e6fcdc67c570adaeaf94',
indexName: 'vectorbt',
inputSelector: '#search_input',
autocompleteOptions: {
autoWidth: false
},
debug: true // Set debug to true if you want to inspect the dropdown
});
</script>
<script src="https://buttons.github.io/buttons.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
<script>
// Turn off ESLint for this file because it's sent down to users as-is.
/* eslint-disable */
window.addEventListener('load', function() {
function button(label, ariaLabel, icon, className) {
const btn = document.createElement('button');
btn.classList.add('btnIcon', className);
btn.setAttribute('type', 'button');
btn.setAttribute('aria-label', ariaLabel);
btn.innerHTML =
'<div class="btnIcon__body">' +
icon +
'<strong class="btnIcon__label">' +
label +
'</strong>' +
'</div>';
return btn;
}
function addButtons(codeBlockSelector, btn) {
document.querySelectorAll(codeBlockSelector).forEach(function(code) {
code.parentNode.appendChild(btn.cloneNode(true));
});
}
const copyIcon =
'<svg width="12" height="12" viewBox="340 364 14 15" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M342 375.974h4v.998h-4v-.998zm5-5.987h-5v.998h5v-.998zm2 2.994v-1.995l-3 2.993 3 2.994v-1.996h5v-1.995h-5zm-4.5-.997H342v.998h2.5v-.997zm-2.5 2.993h2.5v-.998H342v.998zm9 .998h1v1.996c-.016.28-.11.514-.297.702-.187.187-.422.28-.703.296h-10c-.547 0-1-.452-1-.998v-10.976c0-.546.453-.998 1-.998h3c0-1.107.89-1.996 2-1.996 1.11 0 2 .89 2 1.996h3c.547 0 1 .452 1 .998v4.99h-1v-2.995h-10v8.98h10v-1.996zm-9-7.983h8c0-.544-.453-.996-1-.996h-1c-.547 0-1-.453-1-.998 0-.546-.453-.998-1-.998-.547 0-1 .452-1 .998 0 .545-.453.998-1 .998h-1c-.547 0-1 .452-1 .997z" fill-rule="evenodd"/></svg>';
addButtons(
'.hljs',
button('Copy', 'Copy code to clipboard', copyIcon, 'btnClipboard'),
);
const clipboard = new ClipboardJS('.btnClipboard', {
target: function(trigger) {
return trigger.parentNode.querySelector('code');
},
});
clipboard.on('success', function(event) {
event.clearSelection();
const textEl = event.trigger.querySelector('.btnIcon__label');
textEl.textContent = 'Copied';
setTimeout(function() {
textEl.textContent = 'Copy';
}, 2000);
});
});
</script>
</body>
</html>