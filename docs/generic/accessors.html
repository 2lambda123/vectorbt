<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>vectorbt.generic.accessors API documentation</title>
<meta name="description" content="Custom pandas accessors for generic data â€¦" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-2/css/all.min.css" integrity="sha256-46r060N2LrChLLb5zowXQ72/iKKNiw/lAmygmHExk/o=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/styles/atom-one-dark.min.css" rel="stylesheet">
<style>:root{--highlight-color:#e82}body{line-height:1.5em}.version{font-weight:normal;font-style:italic;font-size:.75em;color:#8b949e}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar>*:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #eee;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}h2[id^="header-"]{margin-top:2em}.ident{color:#900}.headerlink{color:inherit}.headerlink:hover{color:inherit}pre code{background:#f8f8f8}.hljs{padding:1.25rem 1.5rem;border:1px solid #eee;border-radius:6px;background:#282c34 !important;color:#9da29e !important;word-break:normal}.hljs-keyword{color:#ff7b72 !important}.hljs-comment{color:#8b949e !important}.hljs-meta{color:#8b949e !important}.python{color:#c5c8c6 !important}code{background:#f2f2f1;padding:1px 4px;font-size:90%}h1 code{background:transparent}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{padding-bottom:.5em;border-bottom:1px solid #e82}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 1.5em}#header-classes+dl>dd{margin-bottom:3em}dd dd{margin-left:1em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name>span:first-child{white-space:nowrap}.name.class>span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-weight:400;font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary>*{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}.badge{display:inline-block;padding:0.25em 0.4em;font-size:75%;font-weight:700;line-height:1;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0.25rem;transition:color 0.15s ease-in-out,background-color 0.15s ease-in-out,border-color 0.15s ease-in-out,box-shadow 0.15s ease-in-out}@media (prefers-reduced-motion:reduce){.badge{transition:none}}a.badge:hover,a.badge:focus{text-decoration:none}.badge:empty{display:none}.btn .badge{position:relative;top:-1px}.badge-pill{padding-right:0.6em;padding-left:0.6em;border-radius:10rem}.badge-primary{color:#fff;background-color:#007bff}a.badge-primary:hover,a.badge-primary:focus{color:#fff;background-color:#0062cc}a.badge-primary:focus,a.badge-primary.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(0,123,255,0.5)}.badge-secondary{color:#fff;background-color:#6c757d}a.badge-secondary:hover,a.badge-secondary:focus{color:#fff;background-color:#545b62}a.badge-secondary:focus,a.badge-secondary.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(108,117,125,0.5)}.badge-success{color:#fff;background-color:#28a745}a.badge-success:hover,a.badge-success:focus{color:#fff;background-color:#1e7e34}a.badge-success:focus,a.badge-success.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(40,167,69,0.5)}.badge-info{color:#fff;background-color:#17a2b8}a.badge-info:hover,a.badge-info:focus{color:#fff;background-color:#117a8b}a.badge-info:focus,a.badge-info.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(23,162,184,0.5)}.badge-warning{color:#212529;background-color:#ffc107}a.badge-warning:hover,a.badge-warning:focus{color:#212529;background-color:#d39e00}a.badge-warning:focus,a.badge-warning.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(255,193,7,0.5)}.badge-danger{color:#fff;background-color:#dc3545}a.badge-danger:hover,a.badge-danger:focus{color:#fff;background-color:#bd2130}a.badge-danger:focus,a.badge-danger.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(220,53,69,0.5)}.badge-light{color:#212529;background-color:#f8f9fa}a.badge-light:hover,a.badge-light:focus{color:#212529;background-color:#dae0e5}a.badge-light:focus,a.badge-light.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(248,249,250,0.5)}.badge-dark{color:#fff;background-color:#343a40}a.badge-dark:hover,a.badge-dark:focus{color:#fff;background-color:#1d2124}a.badge-dark:focus,a.badge-dark.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(52,58,64,0.5)}.search-container{width:100%;margin-top:15px;margin-bottom:15px}#search_input{display:inline-block;width:100%;height:40px;padding:.375rem .75rem;font-size:1rem;line-height:1.5;color:white;background:#282c34 !important;border:none;border-radius:6px;border-bottom:1px solid #e82;outline:none}.algolia-autocomplete{width:100%;background:rgba(0,0,0,.2);border:none;border-radius:6px}.algolia-autocomplete input{display:none}.index-caption{color:white}#index a,#index h3,.toc a{color:white}#index a:hover,.toc a:hover{color:#e82}#sidebar{background:#393f4a}.toc ul ul,#index ul{padding-left:1.5em}.toc>ul>li{margin-top:.5em}pre{position:relative;background:#fafafa}pre .btnIcon{position:absolute;top:4px;z-index:2;cursor:pointer;border:1px solid transparent;padding:0;color:#383a42;background-color:transparent;height:30px;transition:all .25s ease-out}pre .btnIcon:hover{text-decoration:none}.btnIcon__body{align-items:center;display:flex;color:#abb2bf}.btnIcon svg{fill:currentColor;margin-right:.4em}.btnIcon__label{font-size:11px}.btnClipboard{right:10px}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{min-width:400px;height:100vh;overflow:visible;position:sticky;top:0}#content{width:100%;max-width:100ch;padding:3em 4em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.scrollable-index{overflow-y:scroll;height:calc(100vh - 250px)}.hljs{margin-left:-15px;margin-right:-15px}.source pre code{margin-left:0px;margin-right:0px}dd{margin:0 0 1em 3em}dd dd{margin-left:2em}.flex{display:flex !important}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4QLCS0J048"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-4QLCS0J048');
</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:white}.homelink:hover{color:#e82}.homelink img{max-width:100px;max-height:100px;margin:auto;margin-bottom:.3em}</style>
<link rel="apple-touch-icon" sizes="180x180" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon-16x16.png">
<link rel="manifest" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/site.webmanifest">
<link rel="icon" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#282c34">
<meta name="theme-color" content="#282c34">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>vectorbt.generic.accessors</code></h1>
</header>
<section id="section-intro">
<p>Custom pandas accessors for generic data.</p>
<p>Methods can be accessed as follows:</p>
<ul>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor" href="#vectorbt.generic.accessors.GenericSRAccessor">GenericSRAccessor</a></code> -&gt; <code>pd.Series.vbt.*</code></li>
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor" href="#vectorbt.generic.accessors.GenericDFAccessor">GenericDFAccessor</a></code> -&gt; <code>pd.DataFrame.vbt.*</code></li>
</ul>
<pre><code class="language-python-repl">&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import vectorbt as vbt

&gt;&gt;&gt; # vectorbt.generic.accessors.GenericAccessor.rolling_mean
&gt;&gt;&gt; pd.Series([1, 2, 3, 4]).vbt.rolling_mean(2)
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64
</code></pre>
<p>The accessors inherit <code><a title="vectorbt.base.accessors" href="../base/accessors.html">vectorbt.base.accessors</a></code> and are inherited by more
specialized accessors, such as <code><a title="vectorbt.signals.accessors" href="../signals/accessors.html">vectorbt.signals.accessors</a></code> and <code><a title="vectorbt.returns.accessors" href="../returns/accessors.html">vectorbt.returns.accessors</a></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Grouping is only supported by the methods that accept the <code>group_by</code> argument.</p>
<p>Accessors do not utilize caching.</p>
</div>
<p>Run for the examples below:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; import vectorbt as vbt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from numba import njit
&gt;&gt;&gt; from datetime import datetime, timedelta

&gt;&gt;&gt; df = pd.DataFrame({
...     'a': [1, 2, 3, 4, 5],
...     'b': [5, 4, 3, 2, 1],
...     'c': [1, 2, 3, 2, 1]
... }, index=pd.Index([
...     datetime(2020, 1, 1),
...     datetime(2020, 1, 2),
...     datetime(2020, 1, 3),
...     datetime(2020, 1, 4),
...     datetime(2020, 1, 5)
... ]))
&gt;&gt;&gt; df
            a  b  c
2020-01-01  1  5  1
2020-01-02  2  4  2
2020-01-03  3  3  3
2020-01-04  4  2  2
2020-01-05  5  1  1

&gt;&gt;&gt; index = [datetime(2020, 1, 1) + timedelta(days=i) for i in range(10)]
&gt;&gt;&gt; sr = pd.Series(np.arange(len(index)), index=index)
&gt;&gt;&gt; sr
2020-01-01    0
2020-01-02    1
2020-01-03    2
2020-01-04    3
2020-01-05    4
2020-01-06    5
2020-01-07    6
2020-01-08    7
2020-01-09    8
2020-01-10    9
dtype: int64
</code></pre>
<h2 id="stats">Stats</h2>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>See <code><a title="vectorbt.generic.stats_builder.StatsBuilderMixin.stats" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats">StatsBuilderMixin.stats()</a></code> and <code><a title="vectorbt.generic.accessors.GenericAccessor.metrics" href="#vectorbt.generic.accessors.GenericAccessor.metrics">GenericAccessor.metrics</a></code>.</p>
</div>
<pre><code class="language-python-repl">&gt;&gt;&gt; df2 = pd.DataFrame({
...     'a': [np.nan, 2, 3],
...     'b': [4, np.nan, 5],
...     'c': [6, 7, np.nan]
... }, index=['x', 'y', 'z'])

&gt;&gt;&gt; df2.vbt(freq='d').stats(column='a')
Start                      x
End                        z
Period       3 days 00:00:00
Count                      2
Mean                     2.5
Std                 0.707107
Min                      2.0
Median                   2.5
Max                      3.0
Min Index                  y
Max Index                  z
Name: a, dtype: object
</code></pre>
<h3 id="mapping">Mapping</h3>
<p>Mapping can be set both in <code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code> (preferred) and <code><a title="vectorbt.generic.accessors.GenericAccessor.stats" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats">StatsBuilderMixin.stats()</a></code>:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; mapping = {x: 'test_' + str(x) for x in pd.unique(df2.values.flatten())}
&gt;&gt;&gt; df2.vbt(freq='d', mapping=mapping).stats(column='a')
Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_4.0                  0
Value Counts: test_5.0                  0
Value Counts: test_6.0                  0
Value Counts: test_7.0                  0
Value Counts: test_nan                  1
Name: a, dtype: object

&gt;&gt;&gt; df2.vbt(freq='d').stats(column='a', settings=dict(mapping=mapping))
UserWarning: Changing the mapping will create a copy of this object.
Consider setting it upon object creation to re-use existing cache.

Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_4.0                  0
Value Counts: test_5.0                  0
Value Counts: test_6.0                  0
Value Counts: test_7.0                  0
Value Counts: test_nan                  1
Name: a, dtype: object
</code></pre>
<p>Selecting a column before calling <code>stats</code> will consider uniques from this column only:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df2['a'].vbt(freq='d', mapping=mapping).stats()
Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_nan                  1
Name: a, dtype: object
</code></pre>
<p>To include all keys from <code>mapping</code>, pass <code>incl_all_keys=True</code>:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df2['a'].vbt(freq='d', mapping=mapping).stats(settings=dict(incl_all_keys=True))
Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_4.0                  0
Value Counts: test_5.0                  0
Value Counts: test_6.0                  0
Value Counts: test_7.0                  0
Value Counts: test_nan                  1
Name: a, dtype: object
</code></pre>
<p><code>GenericAccessor.stats</code> also supports (re-)grouping:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; df2.vbt(freq='d').stats(column=0, group_by=[0, 0, 1])
Start                      x
End                        z
Period       3 days 00:00:00
Count                      4
Mean                     3.5
Std                 1.290994
Min                      2.0
Median                   3.5
Max                      5.0
Min Index                  y
Max Index                  z
Name: 0, dtype: object
</code></pre>
<pre><code>

## Plots

!!! hint
    See &lt;code&gt;&lt;a title=&quot;vectorbt.generic.plots_builder.PlotsBuilderMixin.plots&quot; href=&quot;plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.plots&quot;&gt;PlotsBuilderMixin.plots()&lt;/a&gt;&lt;/code&gt; and &lt;code&gt;&lt;a title=&quot;vectorbt.generic.accessors.GenericAccessor.subplots&quot; href=&quot;#vectorbt.generic.accessors.GenericAccessor.subplots&quot;&gt;GenericAccessor.subplots&lt;/a&gt;&lt;/code&gt;.

&lt;code&gt;&lt;a title=&quot;vectorbt.generic.accessors.GenericAccessor&quot; href=&quot;#vectorbt.generic.accessors.GenericAccessor&quot;&gt;GenericAccessor&lt;/a&gt;&lt;/code&gt; class has a single subplot based on &lt;code&gt;&lt;a title=&quot;vectorbt.generic.accessors.GenericAccessor.plot&quot; href=&quot;#vectorbt.generic.accessors.GenericAccessor.plot&quot;&gt;GenericAccessor.plot()&lt;/a&gt;&lt;/code&gt;:

```python-repl
&gt;&gt;&gt; df2.vbt.plots()
</code></pre>
<p><img alt="" src="/docs/img/generic_plots.svg"></p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright (c) 2021 Oleg Polakow. All rights reserved.
# This code is licensed under Apache 2.0 with Commons Clause license (see LICENSE.md for details)

&#34;&#34;&#34;Custom pandas accessors for generic data.

Methods can be accessed as follows:

* `GenericSRAccessor` -&gt; `pd.Series.vbt.*`
* `GenericDFAccessor` -&gt; `pd.DataFrame.vbt.*`

```python-repl
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; import vectorbt as vbt

&gt;&gt;&gt; # vectorbt.generic.accessors.GenericAccessor.rolling_mean
&gt;&gt;&gt; pd.Series([1, 2, 3, 4]).vbt.rolling_mean(2)
0    NaN
1    1.5
2    2.5
3    3.5
dtype: float64
```

The accessors inherit `vectorbt.base.accessors` and are inherited by more
specialized accessors, such as `vectorbt.signals.accessors` and `vectorbt.returns.accessors`.

!!! note
    Grouping is only supported by the methods that accept the `group_by` argument.

    Accessors do not utilize caching.

Run for the examples below:
    
```python-repl
&gt;&gt;&gt; import vectorbt as vbt
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from numba import njit
&gt;&gt;&gt; from datetime import datetime, timedelta

&gt;&gt;&gt; df = pd.DataFrame({
...     &#39;a&#39;: [1, 2, 3, 4, 5],
...     &#39;b&#39;: [5, 4, 3, 2, 1],
...     &#39;c&#39;: [1, 2, 3, 2, 1]
... }, index=pd.Index([
...     datetime(2020, 1, 1),
...     datetime(2020, 1, 2),
...     datetime(2020, 1, 3),
...     datetime(2020, 1, 4),
...     datetime(2020, 1, 5)
... ]))
&gt;&gt;&gt; df
            a  b  c
2020-01-01  1  5  1
2020-01-02  2  4  2
2020-01-03  3  3  3
2020-01-04  4  2  2
2020-01-05  5  1  1

&gt;&gt;&gt; index = [datetime(2020, 1, 1) + timedelta(days=i) for i in range(10)]
&gt;&gt;&gt; sr = pd.Series(np.arange(len(index)), index=index)
&gt;&gt;&gt; sr
2020-01-01    0
2020-01-02    1
2020-01-03    2
2020-01-04    3
2020-01-05    4
2020-01-06    5
2020-01-07    6
2020-01-08    7
2020-01-09    8
2020-01-10    9
dtype: int64
```

## Stats

!!! hint
    See `vectorbt.generic.stats_builder.StatsBuilderMixin.stats` and `GenericAccessor.metrics`.

```python-repl
&gt;&gt;&gt; df2 = pd.DataFrame({
...     &#39;a&#39;: [np.nan, 2, 3],
...     &#39;b&#39;: [4, np.nan, 5],
...     &#39;c&#39;: [6, 7, np.nan]
... }, index=[&#39;x&#39;, &#39;y&#39;, &#39;z&#39;])

&gt;&gt;&gt; df2.vbt(freq=&#39;d&#39;).stats(column=&#39;a&#39;)
Start                      x
End                        z
Period       3 days 00:00:00
Count                      2
Mean                     2.5
Std                 0.707107
Min                      2.0
Median                   2.5
Max                      3.0
Min Index                  y
Max Index                  z
Name: a, dtype: object
```

### Mapping

Mapping can be set both in `GenericAccessor` (preferred) and `GenericAccessor.stats`:

```python-repl
&gt;&gt;&gt; mapping = {x: &#39;test_&#39; + str(x) for x in pd.unique(df2.values.flatten())}
&gt;&gt;&gt; df2.vbt(freq=&#39;d&#39;, mapping=mapping).stats(column=&#39;a&#39;)
Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_4.0                  0
Value Counts: test_5.0                  0
Value Counts: test_6.0                  0
Value Counts: test_7.0                  0
Value Counts: test_nan                  1
Name: a, dtype: object

&gt;&gt;&gt; df2.vbt(freq=&#39;d&#39;).stats(column=&#39;a&#39;, settings=dict(mapping=mapping))
UserWarning: Changing the mapping will create a copy of this object.
Consider setting it upon object creation to re-use existing cache.

Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_4.0                  0
Value Counts: test_5.0                  0
Value Counts: test_6.0                  0
Value Counts: test_7.0                  0
Value Counts: test_nan                  1
Name: a, dtype: object
```

Selecting a column before calling `stats` will consider uniques from this column only:

```python-repl
&gt;&gt;&gt; df2[&#39;a&#39;].vbt(freq=&#39;d&#39;, mapping=mapping).stats()
Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_nan                  1
Name: a, dtype: object
```

To include all keys from `mapping`, pass `incl_all_keys=True`:

&gt;&gt;&gt; df2[&#39;a&#39;].vbt(freq=&#39;d&#39;, mapping=mapping).stats(settings=dict(incl_all_keys=True))
Start                                   x
End                                     z
Period                    3 days 00:00:00
Count                                   2
Value Counts: test_2.0                  1
Value Counts: test_3.0                  1
Value Counts: test_4.0                  0
Value Counts: test_5.0                  0
Value Counts: test_6.0                  0
Value Counts: test_7.0                  0
Value Counts: test_nan                  1
Name: a, dtype: object
```

`GenericAccessor.stats` also supports (re-)grouping:

```python-repl
&gt;&gt;&gt; df2.vbt(freq=&#39;d&#39;).stats(column=0, group_by=[0, 0, 1])
Start                      x
End                        z
Period       3 days 00:00:00
Count                      4
Mean                     3.5
Std                 1.290994
Min                      2.0
Median                   3.5
Max                      5.0
Min Index                  y
Max Index                  z
Name: 0, dtype: object
```

## Plots

!!! hint
    See `vectorbt.generic.plots_builder.PlotsBuilderMixin.plots` and `GenericAccessor.subplots`.

`GenericAccessor` class has a single subplot based on `GenericAccessor.plot`:

```python-repl
&gt;&gt;&gt; df2.vbt.plots()
```

![](/docs/img/generic_plots.svg)
&#34;&#34;&#34;

import numpy as np
import pandas as pd
from scipy import stats
from numba.typed import Dict
import warnings
from sklearn.utils.validation import check_is_fitted
from sklearn.exceptions import NotFittedError
from sklearn.preprocessing import (
    Binarizer,
    MinMaxScaler,
    MaxAbsScaler,
    Normalizer,
    RobustScaler,
    StandardScaler,
    QuantileTransformer,
    PowerTransformer
)

from vectorbt import _typing as tp
from vectorbt.utils import checks
from vectorbt.utils.config import Config, merge_dicts, resolve_dict
from vectorbt.utils.figure import make_figure, make_subplots
from vectorbt.utils.mapping import apply_mapping, to_mapping
from vectorbt.base import index_fns, reshape_fns
from vectorbt.base.accessors import BaseAccessor, BaseDFAccessor, BaseSRAccessor
from vectorbt.base.array_wrapper import ArrayWrapper, Wrapping
from vectorbt.generic import plotting, nb
from vectorbt.generic.ranges import Ranges
from vectorbt.generic.drawdowns import Drawdowns
from vectorbt.generic.splitters import SplitterT, RangeSplitter, RollingSplitter, ExpandingSplitter
from vectorbt.generic.stats_builder import StatsBuilderMixin
from vectorbt.generic.plots_builder import PlotsBuilderMixin
from vectorbt.generic.decorators import attach_nb_methods, attach_transform_methods
from vectorbt.records.mapped_array import MappedArray

try:  # pragma: no cover
    import bottleneck as bn

    nanmean = bn.nanmean
    nanstd = bn.nanstd
    nansum = bn.nansum
    nanmax = bn.nanmax
    nanmin = bn.nanmin
    nanmedian = bn.nanmedian
    nanargmax = bn.nanargmax
    nanargmin = bn.nanargmin
except ImportError:
    # slower numpy
    nanmean = np.nanmean
    nanstd = np.nanstd
    nansum = np.nansum
    nanmax = np.nanmax
    nanmin = np.nanmin
    nanmedian = np.nanmedian
    nanargmax = np.nanargmax
    nanargmin = np.nanargmin

__pdoc__ = {}


class MetaGenericAccessor(type(StatsBuilderMixin), type(PlotsBuilderMixin)):
    pass


GenericAccessorT = tp.TypeVar(&#34;GenericAccessorT&#34;, bound=&#34;GenericAccessor&#34;)
SplitOutputT = tp.Union[tp.MaybeTuple[tp.Tuple[tp.Frame, tp.Index]], tp.BaseFigure]


class TransformerT(tp.Protocol):
    def __init__(self, **kwargs) -&gt; None:
        ...

    def transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...

    def fit_transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...


nb_config = Config(
    {
        &#39;shuffle&#39;: dict(func=nb.shuffle_nb, path=&#39;vectorbt.generic.nb.shuffle_nb&#39;),
        &#39;fillna&#39;: dict(func=nb.fillna_nb, path=&#39;vectorbt.generic.nb.fillna_nb&#39;),
        &#39;bshift&#39;: dict(func=nb.bshift_nb, path=&#39;vectorbt.generic.nb.bshift_nb&#39;),
        &#39;fshift&#39;: dict(func=nb.fshift_nb, path=&#39;vectorbt.generic.nb.fshift_nb&#39;),
        &#39;diff&#39;: dict(func=nb.diff_nb, path=&#39;vectorbt.generic.nb.diff_nb&#39;),
        &#39;pct_change&#39;: dict(func=nb.pct_change_nb, path=&#39;vectorbt.generic.nb.pct_change_nb&#39;),
        &#39;bfill&#39;: dict(func=nb.bfill_nb, path=&#39;vectorbt.generic.nb.bfill_nb&#39;),
        &#39;ffill&#39;: dict(func=nb.ffill_nb, path=&#39;vectorbt.generic.nb.ffill_nb&#39;),
        &#39;cumsum&#39;: dict(func=nb.nancumsum_nb, path=&#39;vectorbt.generic.nb.nancumsum_nb&#39;),
        &#39;cumprod&#39;: dict(func=nb.nancumprod_nb, path=&#39;vectorbt.generic.nb.nancumprod_nb&#39;),
        &#39;rolling_min&#39;: dict(func=nb.rolling_min_nb, path=&#39;vectorbt.generic.nb.rolling_min_nb&#39;),
        &#39;rolling_max&#39;: dict(func=nb.rolling_max_nb, path=&#39;vectorbt.generic.nb.rolling_max_nb&#39;),
        &#39;rolling_mean&#39;: dict(func=nb.rolling_mean_nb, path=&#39;vectorbt.generic.nb.rolling_mean_nb&#39;),
        &#39;expanding_min&#39;: dict(func=nb.expanding_min_nb, path=&#39;vectorbt.generic.nb.expanding_min_nb&#39;),
        &#39;expanding_max&#39;: dict(func=nb.expanding_max_nb, path=&#39;vectorbt.generic.nb.expanding_max_nb&#39;),
        &#39;expanding_mean&#39;: dict(func=nb.expanding_mean_nb, path=&#39;vectorbt.generic.nb.expanding_mean_nb&#39;),
        &#39;product&#39;: dict(func=nb.nanprod_nb, is_reducing=True, path=&#39;vectorbt.generic.nb.nanprod_nb&#39;)
    },
    readonly=True,
    as_attrs=False
)
&#34;&#34;&#34;_&#34;&#34;&#34;

__pdoc__[&#39;nb_config&#39;] = f&#34;&#34;&#34;Config of Numba methods to be added to `GenericAccessor`.

```json
{nb_config.to_doc()}
```
&#34;&#34;&#34;

transform_config = Config(
    {
        &#39;binarize&#39;: dict(
            transformer=Binarizer,
            docstring=&#34;See `sklearn.preprocessing.Binarizer`.&#34;
        ),
        &#39;minmax_scale&#39;: dict(
            transformer=MinMaxScaler,
            docstring=&#34;See `sklearn.preprocessing.MinMaxScaler`.&#34;
        ),
        &#39;maxabs_scale&#39;: dict(
            transformer=MaxAbsScaler,
            docstring=&#34;See `sklearn.preprocessing.MaxAbsScaler`.&#34;
        ),
        &#39;normalize&#39;: dict(
            transformer=Normalizer,
            docstring=&#34;See `sklearn.preprocessing.Normalizer`.&#34;
        ),
        &#39;robust_scale&#39;: dict(
            transformer=RobustScaler,
            docstring=&#34;See `sklearn.preprocessing.RobustScaler`.&#34;
        ),
        &#39;scale&#39;: dict(
            transformer=StandardScaler,
            docstring=&#34;See `sklearn.preprocessing.StandardScaler`.&#34;
        ),
        &#39;quantile_transform&#39;: dict(
            transformer=QuantileTransformer,
            docstring=&#34;See `sklearn.preprocessing.QuantileTransformer`.&#34;
        ),
        &#39;power_transform&#39;: dict(
            transformer=PowerTransformer,
            docstring=&#34;See `sklearn.preprocessing.PowerTransformer`.&#34;
        )
    },
    readonly=True,
    as_attrs=False
)
&#34;&#34;&#34;_&#34;&#34;&#34;

__pdoc__[&#39;transform_config&#39;] = f&#34;&#34;&#34;Config of transform methods to be added to `GenericAccessor`.

```json
{transform_config.to_doc()}
```
&#34;&#34;&#34;


@attach_nb_methods(nb_config)
@attach_transform_methods(transform_config)
class GenericAccessor(BaseAccessor, StatsBuilderMixin, PlotsBuilderMixin, metaclass=MetaGenericAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For both, Series and DataFrames.

    Accessible through `pd.Series.vbt` and `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.SeriesFrame, mapping: tp.Optional[tp.MappingLike] = None, **kwargs) -&gt; None:
        BaseAccessor.__init__(self, obj, mapping=mapping, **kwargs)
        StatsBuilderMixin.__init__(self)
        PlotsBuilderMixin.__init__(self)

        if mapping is not None:
            if isinstance(mapping, str):
                if mapping.lower() == &#39;index&#39;:
                    mapping = self.wrapper.index
                elif mapping.lower() == &#39;columns&#39;:
                    mapping = self.wrapper.columns
            mapping = to_mapping(mapping)
        self._mapping = mapping

    @property
    def sr_accessor_cls(self) -&gt; tp.Type[&#34;GenericSRAccessor&#34;]:
        &#34;&#34;&#34;Accessor class for `pd.Series`.&#34;&#34;&#34;
        return GenericSRAccessor

    @property
    def df_accessor_cls(self) -&gt; tp.Type[&#34;GenericDFAccessor&#34;]:
        &#34;&#34;&#34;Accessor class for `pd.DataFrame`.&#34;&#34;&#34;
        return GenericDFAccessor

    @property
    def mapping(self) -&gt; tp.Optional[tp.Mapping]:
        &#34;&#34;&#34;Mapping.&#34;&#34;&#34;
        return self._mapping

    def apply_mapping(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.utils.mapping.apply_mapping`.&#34;&#34;&#34;
        return apply_mapping(self.obj, self.mapping, **kwargs)

    def rolling_std(self, window: int, minp: tp.Optional[int] = None, ddof: int = 1,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_std_nb`.&#34;&#34;&#34;
        out = nb.rolling_std_nb(self.to_2d_array(), window, minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def expanding_std(self, minp: tp.Optional[int] = 1, ddof: int = 1,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_std_nb`.&#34;&#34;&#34;
        out = nb.expanding_std_nb(self.to_2d_array(), minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def ewm_mean(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_mean_nb`.&#34;&#34;&#34;
        out = nb.ewm_mean_nb(self.to_2d_array(), span, minp=minp, adjust=adjust)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def ewm_std(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True, ddof: int = 1,
                wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_std_nb`.&#34;&#34;&#34;
        out = nb.ewm_std_nb(self.to_2d_array(), span, minp=minp, adjust=adjust, ddof=ddof)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def apply_along_axis(self, apply_func_nb: tp.Union[tp.ApplyFunc, tp.RowApplyFunc], *args, axis: int = 0,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Apply a function `apply_func_nb` along an axis.&#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if axis == 0:
            out = nb.apply_nb(self.to_2d_array(), apply_func_nb, *args)
        elif axis == 1:
            out = nb.row_apply_nb(self.to_2d_array(), apply_func_nb, *args)
        else:
            raise ValueError(&#34;Only axes 0 and 1 are supported&#34;)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def rolling_apply(self, window: int, apply_func_nb: tp.Union[tp.RollApplyFunc, nb.tp.RollMatrixApplyFunc],
                      *args, minp: tp.Optional[int] = None, on_matrix: bool = False,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_apply_nb` and
        `vectorbt.generic.nb.rolling_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
                      a    b         c
        2020-01-01  1.0  5.0  1.000000
        2020-01-02  1.5  4.5  1.500000
        2020-01-03  2.0  4.0  2.000000
        2020-01-04  3.0  3.0  2.333333
        2020-01-05  4.0  2.0  2.000000

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.777778  2.777778  2.777778
        2020-01-05  2.666667  2.666667  2.666667
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.rolling_matrix_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        else:
            out = nb.rolling_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def expanding_apply(self, apply_func_nb: tp.Union[tp.RollApplyFunc, nb.tp.RollMatrixApplyFunc],
                        *args, minp: tp.Optional[int] = 1, on_matrix: bool = False,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_apply_nb` and
        `vectorbt.generic.nb.expanding_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
                      a    b    c
        2020-01-01  1.0  5.0  1.0
        2020-01-02  1.5  4.5  1.5
        2020-01-03  2.0  4.0  2.0
        2020-01-04  2.5  3.5  2.0
        2020-01-05  3.0  3.0  1.8

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.666667  2.666667  2.666667
        2020-01-05  2.600000  2.600000  2.600000
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.expanding_matrix_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        else:
            out = nb.expanding_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def groupby_apply(self, by: tp.PandasGroupByLike,
                      apply_func_nb: tp.Union[tp.GroupByApplyFunc, tp.GroupByMatrixApplyFunc],
                      *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                      **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_matrix_apply_nb` for `on_matrix=True`.

        For `by`, see `pd.DataFrame.groupby`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
             a    b    c
        1  1.5  4.5  1.5
        2  3.5  2.5  2.5
        3  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
                  a         b         c
        1  2.500000  2.500000  2.500000
        2  2.833333  2.833333  2.833333
        3  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        regrouped = self.obj.groupby(by, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(regrouped.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_matrix_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        wrap_kwargs = merge_dicts(dict(name_or_index=list(regrouped.indices.keys())), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def resample_apply(self, freq: tp.PandasFrequencyLike,
                       apply_func_nb: tp.Union[tp.GroupByApplyFunc, tp.GroupByMatrixApplyFunc],
                       *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                       **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_matrix_apply_nb` for `on_matrix=True`.

        For `freq`, see `pd.DataFrame.resample`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_nb)
                      a    b    c
        2020-01-01  1.5  4.5  1.5
        2020-01-03  3.5  2.5  2.5
        2020-01-05  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.500000  2.500000  2.500000
        2020-01-03  2.833333  2.833333  2.833333
        2020-01-05  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        resampled = self.obj.resample(freq, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(resampled.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_matrix_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        out_obj = self.wrapper.wrap(out, group_by=False, index=list(resampled.indices.keys()))
        resampled_arr = np.full((resampled.ngroups, self.to_2d_array().shape[1]), np.nan)
        resampled_obj = self.wrapper.wrap(
            resampled_arr,
            index=resampled.asfreq().index,
            group_by=False,
            **merge_dicts({}, wrap_kwargs)
        )
        resampled_obj.loc[out_obj.index] = out_obj.values
        return resampled_obj

    def applymap(self, apply_func_nb: tp.ApplyMapFunc, *args,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.applymap_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
        &gt;&gt;&gt; df.vbt.applymap(multiply_nb)
                       a     b    c
        2020-01-01   1.0  25.0  1.0
        2020-01-02   4.0  16.0  4.0
        2020-01-03   9.0   9.0  9.0
        2020-01-04  16.0   4.0  4.0
        2020-01-05  25.0   1.0  1.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        out = nb.applymap_nb(self.to_2d_array(), apply_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def filter(self, filter_func_nb: tp.FilterFunc, *args,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.filter_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
        &gt;&gt;&gt; df.vbt.filter(greater_nb)
                      a    b    c
        2020-01-01  NaN  5.0  NaN
        2020-01-02  NaN  4.0  NaN
        2020-01-03  3.0  3.0  3.0
        2020-01-04  4.0  NaN  NaN
        2020-01-05  5.0  NaN  NaN
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(filter_func_nb)

        out = nb.filter_nb(self.to_2d_array(), filter_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def apply_and_reduce(self, apply_func_nb: tp.ApplyFunc, reduce_func_nb: tp.ReduceFunc,
                         apply_args: tp.Optional[tuple] = None, reduce_args: tp.Optional[tuple] = None,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;See `vectorbt.generic.nb.apply_and_reduce_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
        a    4.0
        b    4.0
        c    3.0
        dtype: float64
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)
        checks.assert_numba_func(reduce_func_nb)
        if apply_args is None:
            apply_args = ()
        if reduce_args is None:
            reduce_args = ()

        out = nb.apply_and_reduce_nb(self.to_2d_array(), apply_func_nb, apply_args, reduce_func_nb, reduce_args)
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;apply_and_reduce&#39;), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def reduce(self,
               reduce_func_nb: tp.Union[
                   tp.FlatGroupReduceFunc,
                   tp.FlatGroupReduceArrayFunc,
                   tp.GroupReduceFunc,
                   tp.GroupReduceArrayFunc,
                   tp.ReduceFunc,
                   tp.ReduceArrayFunc
               ],
               *args,
               returns_array: bool = False,
               returns_idx: bool = False,
               flatten: bool = False,
               order: str = &#39;C&#39;,
               to_index: bool = True,
               group_by: tp.GroupByLike = None,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeriesFrame[float]:
        &#34;&#34;&#34;Reduce by column.

        See `vectorbt.generic.nb.flat_reduce_grouped_to_array_nb` if grouped, `returns_array` is True and `flatten` is True.
        See `vectorbt.generic.nb.flat_reduce_grouped_nb` if grouped, `returns_array` is False and `flatten` is True.
        See `vectorbt.generic.nb.reduce_grouped_to_array_nb` if grouped, `returns_array` is True and `flatten` is False.
        See `vectorbt.generic.nb.reduce_grouped_nb` if grouped, `returns_array` is False and `flatten` is False.
        See `vectorbt.generic.nb.reduce_to_array_nb` if not grouped and `returns_array` is True.
        See `vectorbt.generic.nb.reduce_nb` if not grouped and `returns_array` is False.

        Set `returns_idx` to True if values returned by `reduce_func_nb` are indices/positions.
        Set `to_index` to False to return raw positions instead of labels.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.reduce(mean_nb)
        a    3.0
        b    3.0
        c    1.8
        dtype: float64

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True)
        a   2020-01-05
        b   2020-01-01
        c   2020-01-03
        dtype: datetime64[ns]

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True, to_index=False)
        a    4
        b    0
        c    2
        dtype: int64

        &gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, returns_array=True, wrap_kwargs=dict(name_or_index=[&#39;min&#39;, &#39;max&#39;]))
               a    b    c
        min  1.0  1.0  1.0
        max  5.0  5.0  3.0

        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
        group
        first     3.0
        second    1.8
        dtype: float64

        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;],
        ...     returns_array=True, group_by=group_by)
        group  first  second
        min      1.0     1.0
        max      5.0     3.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(reduce_func_nb)

        if self.wrapper.grouper.is_grouped(group_by=group_by):
            group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
            if flatten:
                checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])
                in_c_order = order.upper() == &#39;C&#39;
                if returns_array:
                    out = nb.flat_reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                else:
                    out = nb.flat_reduce_grouped_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                if returns_idx:
                    if in_c_order:
                        out //= group_lens  # flattened in C order
                    else:
                        out %= self.wrapper.shape[0]  # flattened in F order
            else:
                if returns_array:
                    out = nb.reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
                else:
                    out = nb.reduce_grouped_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
        else:
            if returns_array:
                out = nb.reduce_to_array_nb(
                    self.to_2d_array(), reduce_func_nb, *args)
            else:
                out = nb.reduce_nb(
                    self.to_2d_array(), reduce_func_nb, *args)

        # Perform post-processing
        wrap_kwargs = merge_dicts(dict(
            name_or_index=&#39;reduce&#39; if not returns_array else None,
            to_index=returns_idx and to_index,
            fillna=-1 if returns_idx else None,
            dtype=np.int_ if returns_idx else None
        ), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=group_by, **wrap_kwargs)

    def min(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;min&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.min_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmin = np.nanmin
        else:
            _nanmin = nanmin
        return self.wrapper.wrap_reduced(_nanmin(arr, axis=0), group_by=False, **wrap_kwargs)

    def max(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;max&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.max_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmax = np.nanmax
        else:
            _nanmax = nanmax
        return self.wrapper.wrap_reduced(_nanmax(arr, axis=0), group_by=False, **wrap_kwargs)

    def mean(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return mean of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;mean&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.mean_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmean = np.nanmean
        else:
            _nanmean = nanmean
        return self.wrapper.wrap_reduced(_nanmean(arr, axis=0), group_by=False, **wrap_kwargs)

    def median(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return median of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;median&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.median_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmedian = np.nanmedian
        else:
            _nanmedian = nanmedian
        return self.wrapper.wrap_reduced(_nanmedian(arr, axis=0), group_by=False, **wrap_kwargs)

    def std(self, ddof: int = 1, group_by: tp.GroupByLike = None,
            wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return standard deviation of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;std&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.std_reduce_nb, ddof, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanstd = np.nanstd
        else:
            _nanstd = nanstd
        return self.wrapper.wrap_reduced(_nanstd(arr, ddof=ddof, axis=0), group_by=False, **wrap_kwargs)

    def sum(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return sum of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;sum&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.sum_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nansum = np.nansum
        else:
            _nansum = nansum
        return self.wrapper.wrap_reduced(_nansum(arr, axis=0), group_by=False, **wrap_kwargs)

    def count(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return count of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;count&#39;, dtype=np.int_), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.count_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        return self.wrapper.wrap_reduced(np.sum(~np.isnan(self.to_2d_array()), axis=0), group_by=False, **wrap_kwargs)

    def idxmin(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmin&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmin_reduce_nb,
                group_by=group_by,
                flatten=True,
                returns_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmin(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def idxmax(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmax&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmax_reduce_nb,
                group_by=group_by,
                flatten=True,
                returns_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmax(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def describe(self, percentiles: tp.Optional[tp.ArrayLike] = None, ddof: int = 1,
                 group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.describe_reduce_nb`.

        For `percentiles`, see `pd.DataFrame.describe`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.describe()
                      a         b        c
        count  5.000000  5.000000  5.00000
        mean   3.000000  3.000000  1.80000
        std    1.581139  1.581139  0.83666
        min    1.000000  1.000000  1.00000
        25%    2.000000  2.000000  1.00000
        50%    3.000000  3.000000  2.00000
        75%    4.000000  4.000000  2.00000
        max    5.000000  5.000000  3.00000
        ```
        &#34;&#34;&#34;
        if percentiles is not None:
            percentiles = reshape_fns.to_1d_array(percentiles)
        else:
            percentiles = np.array([0.25, 0.5, 0.75])
        percentiles = percentiles.tolist()
        if 0.5 not in percentiles:
            percentiles.append(0.5)
        percentiles = np.unique(percentiles)
        perc_formatted = pd.io.formats.format.format_percentiles(percentiles)
        index = pd.Index([&#39;count&#39;, &#39;mean&#39;, &#39;std&#39;, &#39;min&#39;, *perc_formatted, &#39;max&#39;])
        wrap_kwargs = merge_dicts(dict(name_or_index=index), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.describe_reduce_nb, percentiles, ddof,
                group_by=group_by, flatten=True, returns_array=True,
                wrap_kwargs=wrap_kwargs)
        return self.reduce(
            nb.describe_reduce_nb, percentiles, ddof,
            returns_array=True, wrap_kwargs=wrap_kwargs)

    def value_counts(self,
                     normalize: bool = False,
                     sort_uniques: bool = True,
                     sort: bool = False,
                     ascending: bool = False,
                     dropna: bool = False,
                     group_by: tp.GroupByLike = None,
                     mapping: tp.Optional[tp.MappingLike] = None,
                     incl_all_keys: bool = False,
                     wrap_kwargs: tp.KwargsLike = None,
                     **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Return a Series/DataFrame containing counts of unique values.

        * Enable `normalize` flag to return the relative frequencies of the unique values.
        * Enable `sort_uniques` flag to sort uniques.
        * Enable `sort` flag to sort by frequencies.
        * Enable `ascending` flag to sort in ascending order.
        * Enable `dropna` flag to exclude counts of NaN.
        * Enable `incl_all_keys` to include all mapping keys, no only those that are present in the array.

        Mapping will be applied using `vectorbt.utils.mapping.apply_mapping` with `**kwargs`.&#34;&#34;&#34;
        if mapping is None:
            mapping = self.mapping
        if isinstance(mapping, str):
            if mapping.lower() == &#39;index&#39;:
                mapping = self.wrapper.index
            elif mapping.lower() == &#39;columns&#39;:
                mapping = self.wrapper.columns
            mapping = to_mapping(mapping)
        codes, uniques = pd.factorize(self.obj.values.flatten(), sort=False, na_sentinel=None)
        codes = codes.reshape(self.wrapper.shape_2d)
        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        value_counts = nb.value_counts_nb(codes, len(uniques), group_lens)
        if incl_all_keys and mapping is not None:
            missing_keys = []
            for x in mapping:
                if pd.isnull(x) and pd.isnull(uniques).any():
                    continue
                if x not in uniques:
                    missing_keys.append(x)
            value_counts = np.vstack((value_counts, np.full((len(missing_keys), value_counts.shape[1]), 0)))
            uniques = np.concatenate((uniques, np.array(missing_keys)))
        nan_mask = np.isnan(uniques)
        if dropna:
            value_counts = value_counts[~nan_mask]
            uniques = uniques[~nan_mask]
        if sort_uniques:
            new_indices = uniques.argsort()
            value_counts = value_counts[new_indices]
            uniques = uniques[new_indices]
        value_counts_sum = value_counts.sum(axis=1)
        if normalize:
            value_counts = value_counts / value_counts_sum.sum()
        if sort:
            if ascending:
                new_indices = value_counts_sum.argsort()
            else:
                new_indices = (-value_counts_sum).argsort()
            value_counts = value_counts[new_indices]
            uniques = uniques[new_indices]
        value_counts_pd = self.wrapper.wrap(
            value_counts,
            index=uniques,
            group_by=group_by,
            **merge_dicts({}, wrap_kwargs)
        )
        if mapping is not None:
            value_counts_pd.index = apply_mapping(value_counts_pd.index, mapping, **kwargs)
        return value_counts_pd

    # ############# Resolution ############# #

    def resolve_self(self: GenericAccessorT,
                     cond_kwargs: tp.KwargsLike = None,
                     custom_arg_names: tp.Optional[tp.Set[str]] = None,
                     impacts_caching: bool = True,
                     silence_warnings: bool = False) -&gt; GenericAccessorT:
        &#34;&#34;&#34;Resolve self.

        See `vectorbt.base.array_wrapper.Wrapping.resolve_self`.

        Creates a copy of this instance `mapping` is different in `cond_kwargs`.&#34;&#34;&#34;
        if cond_kwargs is None:
            cond_kwargs = {}
        if custom_arg_names is None:
            custom_arg_names = set()

        reself = Wrapping.resolve_self(
            self,
            cond_kwargs=cond_kwargs,
            custom_arg_names=custom_arg_names,
            impacts_caching=impacts_caching,
            silence_warnings=silence_warnings
        )
        if &#39;mapping&#39; in cond_kwargs:
            self_copy = reself.replace(mapping=cond_kwargs[&#39;mapping&#39;])

            if not checks.is_deep_equal(self_copy.mapping, reself.mapping):
                if not silence_warnings:
                    warnings.warn(f&#34;Changing the mapping will create a copy of this object. &#34;
                                  f&#34;Consider setting it upon object creation to re-use existing cache.&#34;, stacklevel=2)
                for alias in reself.self_aliases:
                    if alias not in custom_arg_names:
                        cond_kwargs[alias] = self_copy
                cond_kwargs[&#39;mapping&#39;] = self_copy.mapping
                if impacts_caching:
                    cond_kwargs[&#39;use_caching&#39;] = False
                return self_copy
        return reself

    # ############# Stats ############# #

    @property
    def stats_defaults(self) -&gt; tp.Kwargs:
        &#34;&#34;&#34;Defaults for `GenericAccessor.stats`.

        Merges `vectorbt.generic.stats_builder.StatsBuilderMixin.stats_defaults` and
        `generic.stats` from `vectorbt._settings.settings`.&#34;&#34;&#34;
        from vectorbt._settings import settings
        generic_stats_cfg = settings[&#39;generic&#39;][&#39;stats&#39;]

        return merge_dicts(
            StatsBuilderMixin.stats_defaults.__get__(self),
            generic_stats_cfg
        )

    _metrics: tp.ClassVar[Config] = Config(
        dict(
            start=dict(
                title=&#39;Start&#39;,
                calc_func=lambda self: self.wrapper.index[0],
                agg_func=None,
                tags=&#39;wrapper&#39;
            ),
            end=dict(
                title=&#39;End&#39;,
                calc_func=lambda self: self.wrapper.index[-1],
                agg_func=None,
                tags=&#39;wrapper&#39;
            ),
            period=dict(
                title=&#39;Period&#39;,
                calc_func=lambda self: len(self.wrapper.index),
                apply_to_timedelta=True,
                agg_func=None,
                tags=&#39;wrapper&#39;
            ),
            count=dict(
                title=&#39;Count&#39;,
                calc_func=&#39;count&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            mean=dict(
                title=&#39;Mean&#39;,
                calc_func=&#39;mean&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            std=dict(
                title=&#39;Std&#39;,
                calc_func=&#39;std&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            min=dict(
                title=&#39;Min&#39;,
                calc_func=&#39;min&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            median=dict(
                title=&#39;Median&#39;,
                calc_func=&#39;median&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            max=dict(
                title=&#39;Max&#39;,
                calc_func=&#39;max&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            idx_min=dict(
                title=&#39;Min Index&#39;,
                calc_func=&#39;idxmin&#39;,
                agg_func=None,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;index&#39;]
            ),
            idx_max=dict(
                title=&#39;Max Index&#39;,
                calc_func=&#39;idxmax&#39;,
                agg_func=None,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;index&#39;]
            ),
            value_counts=dict(
                title=&#39;Value Counts&#39;,
                calc_func=lambda value_counts: reshape_fns.to_dict(value_counts, orient=&#39;index_series&#39;),
                resolve_value_counts=True,
                check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;value_counts&#39;]
            )
        ),
        copy_kwargs=dict(copy_mode=&#39;deep&#39;)
    )

    @property
    def metrics(self) -&gt; Config:
        return self._metrics

    # ############# Conversion ############# #

    def drawdown(self, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Drawdown series.&#34;&#34;&#34;
        out = self.to_2d_array() / nb.expanding_max_nb(self.to_2d_array()) - 1
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    @property
    def ranges(self) -&gt; Ranges:
        &#34;&#34;&#34;`GenericAccessor.get_ranges` with default arguments.&#34;&#34;&#34;
        return self.get_ranges()

    def get_ranges(self, wrapper_kwargs: tp.KwargsLike = None, **kwargs) -&gt; Ranges:
        &#34;&#34;&#34;Generate range records.

        See `vectorbt.generic.ranges.Ranges`.&#34;&#34;&#34;
        wrapper_kwargs = merge_dicts(self.wrapper.config, wrapper_kwargs)
        return Ranges.from_ts(self.obj, wrapper_kwargs=wrapper_kwargs, **kwargs)

    @property
    def drawdowns(self) -&gt; Drawdowns:
        &#34;&#34;&#34;`GenericAccessor.get_drawdowns` with default arguments.&#34;&#34;&#34;
        return self.get_drawdowns()

    def get_drawdowns(self, wrapper_kwargs: tp.KwargsLike = None, **kwargs) -&gt; Drawdowns:
        &#34;&#34;&#34;Generate drawdown records.

        See `vectorbt.generic.drawdowns.Drawdowns`.&#34;&#34;&#34;
        wrapper_kwargs = merge_dicts(self.wrapper.config, wrapper_kwargs)
        return Drawdowns.from_ts(self.obj, wrapper_kwargs=wrapper_kwargs, **kwargs)

    def to_mapped(self,
                  dropna: bool = True,
                  dtype: tp.Optional[tp.DTypeLike] = None,
                  group_by: tp.GroupByLike = None,
                  **kwargs) -&gt; MappedArray:
        &#34;&#34;&#34;Convert this object into an instance of `vectorbt.records.mapped_array.MappedArray`.&#34;&#34;&#34;
        mapped_arr = self.to_2d_array().flatten(order=&#39;F&#39;)
        col_arr = np.repeat(np.arange(self.wrapper.shape_2d[1]), self.wrapper.shape_2d[0])
        idx_arr = np.tile(np.arange(self.wrapper.shape_2d[0]), self.wrapper.shape_2d[1])
        if dropna and np.isnan(mapped_arr).any():
            not_nan_mask = ~np.isnan(mapped_arr)
            mapped_arr = mapped_arr[not_nan_mask]
            col_arr = col_arr[not_nan_mask]
            idx_arr = idx_arr[not_nan_mask]
        return MappedArray(
            self.wrapper,
            np.asarray(mapped_arr, dtype=dtype),
            col_arr,
            idx_arr=idx_arr,
            **kwargs
        ).regroup(group_by)

    def to_returns(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Get returns of this object.&#34;&#34;&#34;
        return self.obj.vbt.returns.from_value(self.obj, **kwargs).obj

    # ############# Transformation ############# #

    def transform(self, transformer: TransformerT, wrap_kwargs: tp.KwargsLike = None, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Transform using a transformer.

        A transformer can be any class instance that has `transform` and `fit_transform` methods,
        ideally subclassing `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`.

        Will fit `transformer` if not fitted.

        `**kwargs` are passed to the `transform` or `fit_transform` method.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

        &gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
                      a    b    c
        2020-01-01 -1.0  1.0 -1.0
        2020-01-02 -0.5  0.5  0.0
        2020-01-03  0.0  0.0  1.0
        2020-01-04  0.5 -0.5  0.0
        2020-01-05  1.0 -1.0 -1.0

        &gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
        &gt;&gt;&gt; df.vbt.transform(fitted_scaler)
                      a    b    c
        2020-01-01 -2.0  2.0 -2.0
        2020-01-02 -1.0  1.0 -1.0
        2020-01-03  0.0  0.0  0.0
        2020-01-04  1.0 -1.0 -1.0
        2020-01-05  2.0 -2.0 -2.0
        ```&#34;&#34;&#34;
        is_fitted = True
        try:
            check_is_fitted(transformer)
        except NotFittedError:
            is_fitted = False
        if not is_fitted:
            result = transformer.fit_transform(self.to_2d_array(), **kwargs)
        else:
            result = transformer.transform(self.to_2d_array(), **kwargs)
        return self.wrapper.wrap(result, group_by=False, **merge_dicts({}, wrap_kwargs))

    def zscore(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Compute z-score using `sklearn.preprocessing.StandardScaler`.&#34;&#34;&#34;
        return self.scale(with_mean=True, with_std=True, **kwargs)

    def rebase(self, base: float, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Rebase all series to a given intial base.

        This makes comparing/plotting different series together easier.
        Will forward and backward fill NaN values.&#34;&#34;&#34;
        result = nb.bfill_nb(nb.ffill_nb(self.to_2d_array()))
        result = result / result[0] * base
        return self.wrapper.wrap(result, group_by=False, **merge_dicts({}, wrap_kwargs))

    # ############# Splitting ############# #

    def split(self, splitter: SplitterT, stack_kwargs: tp.KwargsLike = None, keys: tp.Optional[tp.IndexLike] = None,
              plot: bool = False, trace_names: tp.TraceNames = None, heatmap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using a splitter.

        Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.

        A splitter can be any class instance that has `split` method, ideally subclassing
        `sklearn.model_selection.BaseCrossValidator` or `vectorbt.generic.splitters.BaseSplitter`.

        `heatmap_kwargs` are passed to `vectorbt.generic.plotting.Heatmap` if `plot` is True,
        can be a dictionary or a list per set, for example, to set trace name for each set (&#39;train&#39;, &#39;test&#39;, etc.).

        `**kwargs` are passed to the `split` method.

        !!! note
            The datetime-like format of the index will be lost as result of this operation.
            Make sure to store the index metadata such as frequency information beforehand.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

        &gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
        &gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

        &gt;&gt;&gt; train_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          3.0  3.0  3
        4          NaN  4.0  4
        5          NaN  5.0  5
        6          NaN  NaN  6
        7          NaN  NaN  7
        &gt;&gt;&gt; train_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]
        &gt;&gt;&gt; test_df
        split_idx  0  1  2
        0          4  6  8
        1          5  7  9
        &gt;&gt;&gt; test_indexes
        [DatetimeIndex([&#39;2020-01-05&#39;, &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-09&#39;, &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=[&#39;train&#39;, &#39;test&#39;])
        ```

        ![](/docs/img/split_plot.svg)
        &#34;&#34;&#34;
        total_range_sr = pd.Series(np.arange(len(self.wrapper.index)), index=self.wrapper.index)
        set_ranges = list(splitter.split(total_range_sr, **kwargs))
        if len(set_ranges) == 0:
            raise ValueError(&#34;No splits were generated&#34;)
        idxs_by_split_and_set = list(zip(*set_ranges))

        results = []
        if keys is not None:
            if not isinstance(keys, pd.Index):
                keys = pd.Index(keys)
        for idxs_by_split in idxs_by_split_and_set:
            split_dfs = []
            split_indexes = []
            for split_idx, idxs in enumerate(idxs_by_split):
                split_dfs.append(self.obj.iloc[idxs].reset_index(drop=True))
                if keys is not None:
                    split_name = keys[split_idx]
                else:
                    split_name = &#39;split_&#39; + str(split_idx)
                split_indexes.append(pd.Index(self.wrapper.index[idxs], name=split_name))
            set_df = pd.concat(split_dfs, axis=1).reset_index(drop=True)
            if keys is not None:
                split_columns = keys
            else:
                split_columns = pd.Index(np.arange(len(split_indexes)), name=&#39;split_idx&#39;)
            split_columns = index_fns.repeat_index(split_columns, len(self.wrapper.columns))
            if stack_kwargs is None:
                stack_kwargs = {}
            set_df = set_df.vbt.stack_index(split_columns, **stack_kwargs)
            results.append((set_df, split_indexes))

        if plot:  # pragma: no cover
            if trace_names is None:
                trace_names = list(range(len(results)))
            if isinstance(trace_names, str):
                trace_names = [trace_names]
            nan_df = pd.DataFrame(np.nan, columns=pd.RangeIndex(stop=len(results[0][1])), index=self.wrapper.index)
            fig = None
            for i, (_, split_indexes) in enumerate(results):
                heatmap_df = nan_df.copy()
                for j in range(len(split_indexes)):
                    heatmap_df.loc[split_indexes[j], j] = i
                _heatmap_kwargs = resolve_dict(heatmap_kwargs, i=i)
                fig = heatmap_df.vbt.ts_heatmap(fig=fig, **merge_dicts(
                    dict(
                        trace_kwargs=dict(
                            showscale=False,
                            name=str(trace_names[i]),
                            showlegend=True
                        )
                    ),
                    _heatmap_kwargs
                ))
                if fig.layout.colorway is not None:
                    colorway = fig.layout.colorway
                else:
                    colorway = fig.layout.template.layout.colorway
                if &#39;colorscale&#39; not in _heatmap_kwargs:
                    fig.data[-1].update(colorscale=[colorway[i], colorway[i]])
            return fig

        if len(results) == 1:
            return results[0]
        return tuple(results)

    def range_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RangeSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  5
        1          1  6
        2          2  7
        3          3  8
        4          4  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
        &gt;&gt;&gt; range_df
        split_idx  0  1  2  3  4  5  6
        0          0  1  2  3  4  5  6
        1          1  2  3  4  5  6  7
        2          2  3  4  5  6  7  8
        3          3  4  5  6  7  8  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;),
         DatetimeIndex([&#39;2020-01-04&#39;, ..., &#39;2020-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_3&#39;),
         DatetimeIndex([&#39;2020-01-05&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_4&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-09&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_5&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_6&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  2
        1          1  3
        2          2  4
        3          3  5
        4          4  6
        5          5  7
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
        &gt;&gt;&gt; range_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          NaN  3.0  3
        4          NaN  NaN  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-03&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
        ...     start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;]),
        ...     end_idxs=pd.Index([&#39;2020-01-04&#39;, &#39;2020-01-05&#39;])
        ... )
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  1
        1          1  2
        2          2  3
        3          3  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

         &gt;&gt;&gt; sr.vbt.range_split(
         ...    start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;, &#39;2020-01-01&#39;]),
         ...    end_idxs=pd.Index([&#39;2020-01-08&#39;, &#39;2020-01-04&#39;, &#39;2020-01-07&#39;]),
         ...    plot=True
         ... )
        ```

        ![](/docs/img/range_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RangeSplitter(), **kwargs)

    def rolling_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RollingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx  0  1  2  3  4  5
        0          0  1  2  3  4  5
        1          1  2  3  4  5  6
        2          2  3  4  5  6  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5
        0          3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5
        0          4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/docs/img/rolling_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RollingSplitter(), **kwargs)

    def expanding_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.ExpandingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
        ...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx    0    1    2    3    4    5    6  7
        0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
        1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
        2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
        3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
        4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
        5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
        6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
        7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          1  2  3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          2  3  4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.expanding_split(
        ...     set_lens=(1, 1), min_len=3, left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/docs/img/expanding_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(ExpandingSplitter(), **kwargs)

    # ############# Plotting ############# #

    def plot(self,
             trace_names: tp.TraceNames = None,
             x_labels: tp.Optional[tp.Labels] = None,
             return_fig: bool = True,
             **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Scatter` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.plot()
        ```

        ![](/docs/img/df_plot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        scatter = plotting.Scatter(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return scatter.fig
        return scatter

    def lineplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;lines&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.lineplot()
        ```

        ![](/docs/img/df_lineplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;lines&#39;)), kwargs))

    def scatterplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;markers&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.scatterplot()
        ```

        ![](/docs/img/df_scatterplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;markers&#39;)), kwargs))

    def barplot(self,
                trace_names: tp.TraceNames = None,
                x_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Bar]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Bar` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.barplot()
        ```

        ![](/docs/img/df_barplot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        bar = plotting.Bar(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return bar.fig
        return bar

    def histplot(self,
                 trace_names: tp.TraceNames = None,
                 group_by: tp.GroupByLike = None,
                 return_fig: bool = True,
                 **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Histogram]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Histogram` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.histplot()
        ```

        ![](/docs/img/df_histplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.histplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        hist = plotting.Histogram(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return hist.fig
        return hist

    def boxplot(self,
                trace_names: tp.TraceNames = None,
                group_by: tp.GroupByLike = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Box]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Box` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.boxplot()
        ```

        ![](/docs/img/df_boxplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.boxplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        box = plotting.Box(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return box.fig
        return box

    @property
    def plots_defaults(self) -&gt; tp.Kwargs:
        &#34;&#34;&#34;Defaults for `GenericAccessor.plots`.

        Merges `vectorbt.generic.plots_builder.PlotsBuilderMixin.plots_defaults` and
        `generic.plots` from `vectorbt._settings.settings`.&#34;&#34;&#34;
        from vectorbt._settings import settings
        generic_plots_cfg = settings[&#39;generic&#39;][&#39;plots&#39;]

        return merge_dicts(
            PlotsBuilderMixin.plots_defaults.__get__(self),
            generic_plots_cfg
        )

    _subplots: tp.ClassVar[Config] = Config(
        dict(
            plot=dict(
                check_is_not_grouped=True,
                plot_func=&#39;plot&#39;,
                pass_trace_names=False,
                tags=&#39;generic&#39;
            )
        ),
        copy_kwargs=dict(copy_mode=&#39;deep&#39;)
    )

    @property
    def subplots(self) -&gt; Config:
        return self._subplots


GenericAccessor.override_metrics_doc(__pdoc__)
GenericAccessor.override_subplots_doc(__pdoc__)


class GenericSRAccessor(GenericAccessor, BaseSRAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For Series only.

    Accessible through `pd.Series.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Series, mapping: tp.Optional[tp.MappingLike] = None, **kwargs) -&gt; None:
        BaseSRAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, mapping=mapping, **kwargs)

    def squeeze_grouped(self,
                        squeeze_func_nb: tp.GroupSqueezeFunc, *args,
                        group_by: tp.GroupByLike = None,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Squeeze each group of elements into a single element.

        Based on `vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped`.&#34;&#34;&#34;
        obj_frame = self.obj.to_frame().transpose()
        squeezed = obj_frame.vbt.squeeze_grouped(squeeze_func_nb, *args, group_by=group_by).iloc[0]
        wrap_kwargs = merge_dicts(dict(name_or_index=self.wrapper.name), wrap_kwargs)
        return ArrayWrapper.from_obj(obj_frame).wrap_reduced(squeezed, group_by=group_by, **wrap_kwargs)

    def flatten_grouped(self,
                        group_by: tp.GroupByLike = None,
                        order: str = &#39;C&#39;,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Flatten each group of elements.

        Based on `vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped`.&#34;&#34;&#34;
        obj_frame = self.obj.to_frame().transpose()
        return obj_frame.vbt.flatten_grouped(group_by=group_by, order=order, wrap_kwargs=wrap_kwargs)

    def plot_against(self,
                     other: tp.ArrayLike,
                     trace_kwargs: tp.KwargsLike = None,
                     other_trace_kwargs: tp.Union[str, tp.KwargsLike] = None,
                     pos_trace_kwargs: tp.KwargsLike = None,
                     neg_trace_kwargs: tp.KwargsLike = None,
                     hidden_trace_kwargs: tp.KwargsLike = None,
                     add_trace_kwargs: tp.KwargsLike = None,
                     fig: tp.Optional[tp.BaseFigure] = None,
                     **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line against another line.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            other_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for `other`.

                Set to &#39;hidden&#39; to hide.
            pos_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for positive line.
            neg_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for negative line.
            hidden_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for hidden lines.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.plot_against(df[&#39;b&#39;])
        ```

        ![](/docs/img/sr_plot_against.svg)
        &#34;&#34;&#34;
        if trace_kwargs is None:
            trace_kwargs = {}
        if other_trace_kwargs is None:
            other_trace_kwargs = {}
        if pos_trace_kwargs is None:
            pos_trace_kwargs = {}
        if neg_trace_kwargs is None:
            neg_trace_kwargs = {}
        if hidden_trace_kwargs is None:
            hidden_trace_kwargs = {}
        obj, other = reshape_fns.broadcast(self.obj, other, columns_from=&#39;keep&#39;)
        checks.assert_instance_of(other, pd.Series)
        if fig is None:
            fig = make_figure()
        fig.update_layout(**layout_kwargs)

        # TODO: Using masks feels hacky
        pos_mask = self.obj &gt; other
        if pos_mask.any():
            # Fill positive area
            pos_obj = self.obj.copy()
            pos_obj[~pos_mask] = other[~pos_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None,
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            pos_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    fillcolor=&#39;rgba(0, 128, 0, 0.3)&#39;,
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), pos_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
        neg_mask = self.obj &lt; other
        if neg_mask.any():
            # Fill negative area
            neg_obj = self.obj.copy()
            neg_obj[~neg_mask] = other[~neg_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            neg_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    fillcolor=&#39;rgba(255, 0, 0, 0.3)&#39;,
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), neg_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )

        # Plot main traces
        self.plot(trace_kwargs=trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        if other_trace_kwargs == &#39;hidden&#39;:
            other_trace_kwargs = dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0.,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            )
        other.vbt.plot(trace_kwargs=other_trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        return fig

    def overlay_with_heatmap(self,
                             other: tp.ArrayLike,
                             trace_kwargs: tp.KwargsLike = None,
                             heatmap_kwargs: tp.KwargsLike = None,
                             add_trace_kwargs: tp.KwargsLike = None,
                             fig: tp.Optional[tp.BaseFigure] = None,
                             **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line and overlays it with a heatmap.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            heatmap_kwargs (dict): Keyword arguments passed to `GenericDFAccessor.heatmap`.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.overlay_with_heatmap(df[&#39;b&#39;])
        ```

        ![](/docs/img/sr_overlay_with_heatmap.svg)
        &#34;&#34;&#34;
        from vectorbt._settings import settings
        plotting_cfg = settings[&#39;plotting&#39;]

        if trace_kwargs is None:
            trace_kwargs = {}
        if heatmap_kwargs is None:
            heatmap_kwargs = {}
        if add_trace_kwargs is None:
            add_trace_kwargs = {}

        obj, other = reshape_fns.broadcast(self.obj, other, columns_from=&#39;keep&#39;)
        checks.assert_instance_of(other, pd.Series)
        if fig is None:
            fig = make_subplots(specs=[[{&#34;secondary_y&#34;: True}]])
            if &#39;width&#39; in plotting_cfg[&#39;layout&#39;]:
                fig.update_layout(width=plotting_cfg[&#39;layout&#39;][&#39;width&#39;] + 100)
        fig.update_layout(**layout_kwargs)

        other.vbt.ts_heatmap(**heatmap_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        self.plot(
            trace_kwargs=merge_dicts(dict(line=dict(color=plotting_cfg[&#39;color_schema&#39;][&#39;blue&#39;])), trace_kwargs),
            add_trace_kwargs=merge_dicts(dict(secondary_y=True), add_trace_kwargs),
            fig=fig
        )
        return fig

    def heatmap(self,
                x_level: tp.Optional[tp.Level] = None,
                y_level: tp.Optional[tp.Level] = None,
                symmetric: bool = False,
                sort: bool = True,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                slider_level: tp.Optional[tp.Level] = None,
                active: int = 0,
                slider_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                fig: tp.Optional[tp.BaseFigure] = None,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create a heatmap figure based on object&#39;s multi-index and values.

        If index is not a multi-index, converts Series into a DataFrame and calls `GenericDFAccessor.heatmap`.

        If multi-index contains more than two levels or you want them in specific order,
        pass `x_level` and `y_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the heatmap. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Heatmap` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1),
        ...     (2, 2),
        ...     (3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1    0
        2  2    1
        3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap()
        ```

        ![](/docs/img/sr_heatmap.svg)

        Using one level as a slider:

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (1, 2, 2),
        ...     (1, 3, 3),
        ...     (2, 3, 3),
        ...     (2, 2, 2),
        ...     (2, 1, 1)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
           2  2    1
           3  3    2
        2  3  3    3
           2  2    4
           1  1    5
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
        ```

        ![](/docs/img/sr_heatmap_slider.gif)
        &#34;&#34;&#34;
        if not isinstance(self.wrapper.index, pd.MultiIndex):
            return self.obj.to_frame().vbt.heatmap(
                x_labels=x_labels, y_labels=y_labels,
                return_fig=return_fig, fig=fig, **kwargs)

        (x_level, y_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        kwargs = merge_dicts(dict(
            trace_kwargs=dict(
                hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                              f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                              &#34;value: %{z}&lt;extra&gt;&lt;/extra&gt;&#34;
            ),
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name
        ), kwargs)

        if slider_level is None:
            # No grouping
            df = self.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            return df.vbt.heatmap(x_labels=x_labels, y_labels=y_labels, fig=fig, return_fig=return_fig, **kwargs)

        # Requires grouping
        # See https://plotly.com/python/sliders/
        if not return_fig:
            raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
        _slider_labels = []
        for i, (name, group) in enumerate(self.obj.groupby(level=slider_level)):
            if slider_labels is not None:
                name = slider_labels[i]
            _slider_labels.append(name)
            df = group.vbt.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            if x_labels is None:
                x_labels = df.columns
            if y_labels is None:
                y_labels = df.index
            _kwargs = merge_dicts(dict(
                trace_kwargs=dict(
                    name=str(name) if name is not None else None,
                    visible=False
                ),
            ), kwargs)
            default_size = fig is None and &#39;height&#39; not in _kwargs
            fig = plotting.Heatmap(
                data=reshape_fns.to_2d_array(df),
                x_labels=x_labels,
                y_labels=y_labels,
                fig=fig,
                **_kwargs
            ).fig
            if default_size:
                fig.layout[&#39;height&#39;] += 100  # slider takes up space
        fig.data[active].visible = True
        steps = []
        for i in range(len(fig.data)):
            step = dict(
                method=&#34;update&#34;,
                args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
            )
            step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
            steps.append(step)
        prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
            if self.wrapper.index.names[slider_level] is not None else None
        sliders = [dict(
            active=active,
            currentvalue={&#34;prefix&#34;: prefix},
            pad={&#34;t&#34;: 50},
            steps=steps
        )]
        fig.update_layout(
            sliders=sliders
        )
        return fig

    def ts_heatmap(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self.obj.to_frame().vbt.ts_heatmap(**kwargs)

    def volume(self,
               x_level: tp.Optional[tp.Level] = None,
               y_level: tp.Optional[tp.Level] = None,
               z_level: tp.Optional[tp.Level] = None,
               x_labels: tp.Optional[tp.Labels] = None,
               y_labels: tp.Optional[tp.Labels] = None,
               z_labels: tp.Optional[tp.Labels] = None,
               slider_level: tp.Optional[tp.Level] = None,
               slider_labels: tp.Optional[tp.Labels] = None,
               active: int = 0,
               scene_name: str = &#39;scene&#39;,
               fillna: tp.Optional[tp.Number] = None,
               fig: tp.Optional[tp.BaseFigure] = None,
               return_fig: bool = True,
               **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Volume]:  # pragma: no cover
        &#34;&#34;&#34;Create a 3D volume figure based on object&#39;s multi-index and values.

        If multi-index contains more than three levels or you want them in specific order, pass
        `x_level`, `y_level`, and `z_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the volume. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Volume` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (2, 2, 2),
        ...     (3, 3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
        2  2  2    1
        3  3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.volume().show()
        ```

        ![](/docs/img/sr_volume.svg)
        &#34;&#34;&#34;
        (x_level, y_level, z_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level, z_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        z_level_vals = self.wrapper.index.get_level_values(z_level)
        # Labels are just unique level values
        if x_labels is None:
            x_labels = np.unique(x_level_vals)
        if y_labels is None:
            y_labels = np.unique(y_level_vals)
        if z_labels is None:
            z_labels = np.unique(z_level_vals)

        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        z_name = z_level_vals.name if z_level_vals.name is not None else &#39;z&#39;
        def_kwargs = dict()
        def_kwargs[&#39;trace_kwargs&#39;] = dict(
            hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                          f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                          f&#34;{z_name}: %{{z}}&lt;br&gt;&#34; +
                          &#34;value: %{value}&lt;extra&gt;&lt;/extra&gt;&#34;
        )
        def_kwargs[scene_name] = dict(
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name,
            zaxis_title=z_level_vals.name
        )
        def_kwargs[&#39;scene_name&#39;] = scene_name
        kwargs = merge_dicts(def_kwargs, kwargs)

        contains_nan = False
        if slider_level is None:
            # No grouping
            v = self.unstack_to_array(levels=(x_level, y_level, z_level))
            if fillna is not None:
                v = np.nan_to_num(v, nan=fillna)
            if np.isnan(v).any():
                contains_nan = True
            volume = plotting.Volume(
                data=v,
                x_labels=x_labels,
                y_labels=y_labels,
                z_labels=z_labels,
                fig=fig,
                **kwargs
            )
            if return_fig:
                fig = volume.fig
            else:
                fig = volume
        else:
            # Requires grouping
            # See https://plotly.com/python/sliders/
            if not return_fig:
                raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
            _slider_labels = []
            for i, (name, group) in enumerate(self.obj.groupby(level=slider_level)):
                if slider_labels is not None:
                    name = slider_labels[i]
                _slider_labels.append(name)
                v = group.vbt.unstack_to_array(levels=(x_level, y_level, z_level))
                if fillna is not None:
                    v = np.nan_to_num(v, nan=fillna)
                if np.isnan(v).any():
                    contains_nan = True
                _kwargs = merge_dicts(dict(
                    trace_kwargs=dict(
                        name=str(name) if name is not None else None,
                        visible=False
                    )
                ), kwargs)
                default_size = fig is None and &#39;height&#39; not in _kwargs
                fig = plotting.Volume(
                    data=v,
                    x_labels=x_labels,
                    y_labels=y_labels,
                    z_labels=z_labels,
                    fig=fig,
                    **_kwargs
                ).fig
                if default_size:
                    fig.layout[&#39;height&#39;] += 100  # slider takes up space
            fig.data[active].visible = True
            steps = []
            for i in range(len(fig.data)):
                step = dict(
                    method=&#34;update&#34;,
                    args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                    label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
                )
                step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
                steps.append(step)
            prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
                if self.wrapper.index.names[slider_level] is not None else None
            sliders = [dict(
                active=active,
                currentvalue={&#34;prefix&#34;: prefix},
                pad={&#34;t&#34;: 50},
                steps=steps
            )]
            fig.update_layout(
                sliders=sliders
            )

        if contains_nan:
            warnings.warn(&#34;Data contains NaNs. Use `fillna` argument or &#34;
                          &#34;`show` method in case of visualization issues.&#34;, stacklevel=2)
        return fig

    def qqplot(self,
               sparams: tp.Union[tp.Iterable, tuple, None] = (),
               dist: str = &#39;norm&#39;,
               plot_line: bool = True,
               line_shape_kwargs: tp.KwargsLike = None,
               xref: str = &#39;x&#39;,
               yref: str = &#39;y&#39;,
               fig: tp.Optional[tp.BaseFigure] = None,
               **kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot probability plot using `scipy.stats.probplot`.

        `**kwargs` are passed to `GenericAccessor.scatterplot`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
        ```

        ![](/docs/img/sr_qqplot.svg)
        &#34;&#34;&#34;
        qq = stats.probplot(self.obj, sparams=sparams, dist=dist)
        fig = pd.Series(qq[0][1], index=qq[0][0]).vbt.scatterplot(fig=fig, **kwargs)

        if plot_line:
            if line_shape_kwargs is None:
                line_shape_kwargs = {}
            x = np.array([qq[0][0][0], qq[0][0][-1]])
            y = qq[1][1] + qq[1][0] * x
            fig.add_shape(**merge_dicts(dict(
                type=&#34;line&#34;,
                xref=xref,
                yref=yref,
                x0=x[0],
                y0=y[0],
                x1=x[1],
                y1=y[1],
                line=dict(
                    color=&#39;red&#39;
                )
            ), line_shape_kwargs))

        return fig


class GenericDFAccessor(GenericAccessor, BaseDFAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For DataFrames only.

    Accessible through `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Frame, mapping: tp.Optional[tp.MappingLike] = None, **kwargs) -&gt; None:
        BaseDFAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, mapping=mapping, **kwargs)

    def squeeze_grouped(self,
                        squeeze_func_nb: tp.GroupSqueezeFunc, *args,
                        group_by: tp.GroupByLike = None,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Squeeze each group of columns into a single column.

        See `vectorbt.generic.nb.squeeze_grouped_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; mean_squeeze_nb = njit(lambda i, group, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.squeeze_grouped(mean_squeeze_nb, group_by=group_by)
        group       first  second
        2020-01-01    3.0     1.0
        2020-01-02    3.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    3.0     2.0
        2020-01-05    3.0     1.0
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_numba_func(squeeze_func_nb)

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        out = nb.squeeze_grouped_nb(self.to_2d_array(), group_lens, squeeze_func_nb, *args)
        return self.wrapper.wrap(out, group_by=group_by, **merge_dicts({}, wrap_kwargs))

    def flatten_grouped(self,
                        group_by: tp.GroupByLike = None,
                        order: str = &#39;C&#39;,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Flatten each group of columns.

        See `vectorbt.generic.nb.flatten_grouped_nb`.
        If all groups have the same length, see `vectorbt.generic.nb.flatten_uniform_grouped_nb`.

        !!! warning
            Make sure that the distribution of group lengths is close to uniform, otherwise
            groups with less columns will be filled with NaN and needlessly occupy memory.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;C&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    2.0     2.0
        2020-01-02    4.0     NaN
        2020-01-03    3.0     3.0
        2020-01-03    3.0     NaN
        2020-01-04    4.0     2.0
        2020-01-04    2.0     NaN
        2020-01-05    5.0     1.0
        2020-01-05    1.0     NaN

        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;F&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-02    2.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    4.0     2.0
        2020-01-05    5.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    4.0     NaN
        2020-01-03    3.0     NaN
        2020-01-04    2.0     NaN
        2020-01-05    1.0     NaN
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        if np.all(group_lens == group_lens.item(0)):
            func = nb.flatten_uniform_grouped_nb
        else:
            func = nb.flatten_grouped_nb
        if order.upper() == &#39;C&#39;:
            out = func(self.to_2d_array(), group_lens, True)
            new_index = index_fns.repeat_index(self.wrapper.index, np.max(group_lens))
        else:
            out = func(self.to_2d_array(), group_lens, False)
            new_index = index_fns.tile_index(self.wrapper.index, np.max(group_lens))
        wrap_kwargs = merge_dicts(dict(index=new_index), wrap_kwargs)
        return self.wrapper.wrap(out, group_by=group_by, **wrap_kwargs)

    def heatmap(self,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Heatmap` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df = pd.DataFrame([
        ...     [0, np.nan, np.nan],
        ...     [np.nan, 1, np.nan],
        ...     [np.nan, np.nan, 2]
        ... ])
        &gt;&gt;&gt; df.vbt.heatmap()
        ```

        ![](/docs/img/df_heatmap.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.columns
        if y_labels is None:
            y_labels = self.wrapper.index
        heatmap = plotting.Heatmap(
            data=self.to_2d_array(),
            x_labels=x_labels,
            y_labels=y_labels,
            **kwargs
        )
        if return_fig:
            return heatmap.fig
        return heatmap

    def ts_heatmap(self, is_y_category: bool = True,
                   **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self.obj.transpose().iloc[::-1].vbt.heatmap(is_y_category=is_y_category, **kwargs)</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="vectorbt.generic.accessors.nb_config"><code class="name">var <span class="ident parent-name">nb_config</span></code></dt>
<dd>
<div class="desc"><p>Config of Numba methods to be added to <code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code>.</p>
<pre><code class="language-json">Config({
    &quot;shuffle&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function shuffle_nb at 0x7f6c0c200730&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.shuffle_nb&quot;
    },
    &quot;fillna&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function fillna_nb at 0x7f6c0c1fd7b8&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.fillna_nb&quot;
    },
    &quot;bshift&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function bshift_nb at 0x7f6c0c1fdd08&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.bshift_nb&quot;
    },
    &quot;fshift&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function fshift_nb at 0x7f6c0c1fe2f0&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.fshift_nb&quot;
    },
    &quot;diff&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function diff_nb at 0x7f6c0c1fe840&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.diff_nb&quot;
    },
    &quot;pct_change&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function pct_change_nb at 0x7f6c0c1fed90&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.pct_change_nb&quot;
    },
    &quot;bfill&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function bfill_nb at 0x7f6c0c1f9378&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.bfill_nb&quot;
    },
    &quot;ffill&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function ffill_nb at 0x7f6c0c1f98c8&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.ffill_nb&quot;
    },
    &quot;cumsum&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function nancumsum_nb at 0x7f6c0c1f9e18&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.nancumsum_nb&quot;
    },
    &quot;cumprod&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function nancumprod_nb at 0x7f6c0c213158&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.nancumprod_nb&quot;
    },
    &quot;rolling_min&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function rolling_min_nb at 0x7f6c0c21bc80&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.rolling_min_nb&quot;
    },
    &quot;rolling_max&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function rolling_max_nb at 0x7f6c0c225268&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.rolling_max_nb&quot;
    },
    &quot;rolling_mean&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function rolling_mean_nb at 0x7f6c0c2257b8&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.rolling_mean_nb&quot;
    },
    &quot;expanding_min&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function expanding_min_nb at 0x7f6c0c22dd90&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.expanding_min_nb&quot;
    },
    &quot;expanding_max&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function expanding_max_nb at 0x7f6c0c234378&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.expanding_max_nb&quot;
    },
    &quot;expanding_mean&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function expanding_mean_nb at 0x7f6c0c2348c8&gt;)&quot;,
        &quot;path&quot;: &quot;vectorbt.generic.nb.expanding_mean_nb&quot;
    },
    &quot;product&quot;: {
        &quot;func&quot;: &quot;CPUDispatcher(&lt;function nanprod_nb at 0x7f6c0c1f9b70&gt;)&quot;,
        &quot;is_reducing&quot;: true,
        &quot;path&quot;: &quot;vectorbt.generic.nb.nanprod_nb&quot;
    }
})
</code></pre></div>
</dd>
<dt id="vectorbt.generic.accessors.transform_config"><code class="name">var <span class="ident parent-name">transform_config</span></code></dt>
<dd>
<div class="desc"><p>Config of transform methods to be added to <code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code>.</p>
<pre><code class="language-json">Config({
    &quot;binarize&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.Binarizer'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.Binarizer`.&quot;
    },
    &quot;minmax_scale&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.MinMaxScaler'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.MinMaxScaler`.&quot;
    },
    &quot;maxabs_scale&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.MaxAbsScaler'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.MaxAbsScaler`.&quot;
    },
    &quot;normalize&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.Normalizer'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.Normalizer`.&quot;
    },
    &quot;robust_scale&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.RobustScaler'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.RobustScaler`.&quot;
    },
    &quot;scale&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.StandardScaler'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.StandardScaler`.&quot;
    },
    &quot;quantile_transform&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.QuantileTransformer'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.QuantileTransformer`.&quot;
    },
    &quot;power_transform&quot;: {
        &quot;transformer&quot;: &quot;&lt;class 'sklearn.preprocessing._data.PowerTransformer'&gt;&quot;,
        &quot;docstring&quot;: &quot;See `sklearn.preprocessing.PowerTransformer`.&quot;
    }
})
</code></pre></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor"><code class="flex name class">
<span>class <span class="ident parent-name">GenericAccessor</span></span>
(<span class="params">obj, mapping=None, **kwargs</span>)
</code></dt>
<dd>
<div class="desc"><p>Accessor on top of data of any type. For both, Series and DataFrames.</p>
<p>Accessible through <code>pd.Series.vbt</code> and <code>pd.DataFrame.vbt</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenericAccessor(BaseAccessor, StatsBuilderMixin, PlotsBuilderMixin, metaclass=MetaGenericAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For both, Series and DataFrames.

    Accessible through `pd.Series.vbt` and `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.SeriesFrame, mapping: tp.Optional[tp.MappingLike] = None, **kwargs) -&gt; None:
        BaseAccessor.__init__(self, obj, mapping=mapping, **kwargs)
        StatsBuilderMixin.__init__(self)
        PlotsBuilderMixin.__init__(self)

        if mapping is not None:
            if isinstance(mapping, str):
                if mapping.lower() == &#39;index&#39;:
                    mapping = self.wrapper.index
                elif mapping.lower() == &#39;columns&#39;:
                    mapping = self.wrapper.columns
            mapping = to_mapping(mapping)
        self._mapping = mapping

    @property
    def sr_accessor_cls(self) -&gt; tp.Type[&#34;GenericSRAccessor&#34;]:
        &#34;&#34;&#34;Accessor class for `pd.Series`.&#34;&#34;&#34;
        return GenericSRAccessor

    @property
    def df_accessor_cls(self) -&gt; tp.Type[&#34;GenericDFAccessor&#34;]:
        &#34;&#34;&#34;Accessor class for `pd.DataFrame`.&#34;&#34;&#34;
        return GenericDFAccessor

    @property
    def mapping(self) -&gt; tp.Optional[tp.Mapping]:
        &#34;&#34;&#34;Mapping.&#34;&#34;&#34;
        return self._mapping

    def apply_mapping(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.utils.mapping.apply_mapping`.&#34;&#34;&#34;
        return apply_mapping(self.obj, self.mapping, **kwargs)

    def rolling_std(self, window: int, minp: tp.Optional[int] = None, ddof: int = 1,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_std_nb`.&#34;&#34;&#34;
        out = nb.rolling_std_nb(self.to_2d_array(), window, minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def expanding_std(self, minp: tp.Optional[int] = 1, ddof: int = 1,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_std_nb`.&#34;&#34;&#34;
        out = nb.expanding_std_nb(self.to_2d_array(), minp=minp, ddof=ddof)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def ewm_mean(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_mean_nb`.&#34;&#34;&#34;
        out = nb.ewm_mean_nb(self.to_2d_array(), span, minp=minp, adjust=adjust)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def ewm_std(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True, ddof: int = 1,
                wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
        &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_std_nb`.&#34;&#34;&#34;
        out = nb.ewm_std_nb(self.to_2d_array(), span, minp=minp, adjust=adjust, ddof=ddof)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def apply_along_axis(self, apply_func_nb: tp.Union[tp.ApplyFunc, tp.RowApplyFunc], *args, axis: int = 0,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Apply a function `apply_func_nb` along an axis.&#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if axis == 0:
            out = nb.apply_nb(self.to_2d_array(), apply_func_nb, *args)
        elif axis == 1:
            out = nb.row_apply_nb(self.to_2d_array(), apply_func_nb, *args)
        else:
            raise ValueError(&#34;Only axes 0 and 1 are supported&#34;)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def rolling_apply(self, window: int, apply_func_nb: tp.Union[tp.RollApplyFunc, nb.tp.RollMatrixApplyFunc],
                      *args, minp: tp.Optional[int] = None, on_matrix: bool = False,
                      wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_apply_nb` and
        `vectorbt.generic.nb.rolling_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
                      a    b         c
        2020-01-01  1.0  5.0  1.000000
        2020-01-02  1.5  4.5  1.500000
        2020-01-03  2.0  4.0  2.000000
        2020-01-04  3.0  3.0  2.333333
        2020-01-05  4.0  2.0  2.000000

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.777778  2.777778  2.777778
        2020-01-05  2.666667  2.666667  2.666667
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.rolling_matrix_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        else:
            out = nb.rolling_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def expanding_apply(self, apply_func_nb: tp.Union[tp.RollApplyFunc, nb.tp.RollMatrixApplyFunc],
                        *args, minp: tp.Optional[int] = 1, on_matrix: bool = False,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_apply_nb` and
        `vectorbt.generic.nb.expanding_matrix_apply_nb` for `on_matrix=True`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
                      a    b    c
        2020-01-01  1.0  5.0  1.0
        2020-01-02  1.5  4.5  1.5
        2020-01-03  2.0  4.0  2.0
        2020-01-04  2.5  3.5  2.0
        2020-01-05  3.0  3.0  1.8

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.333333  2.333333  2.333333
        2020-01-02  2.500000  2.500000  2.500000
        2020-01-03  2.666667  2.666667  2.666667
        2020-01-04  2.666667  2.666667  2.666667
        2020-01-05  2.600000  2.600000  2.600000
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        if on_matrix:
            out = nb.expanding_matrix_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        else:
            out = nb.expanding_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def groupby_apply(self, by: tp.PandasGroupByLike,
                      apply_func_nb: tp.Union[tp.GroupByApplyFunc, tp.GroupByMatrixApplyFunc],
                      *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                      **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_matrix_apply_nb` for `on_matrix=True`.

        For `by`, see `pd.DataFrame.groupby`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
             a    b    c
        1  1.5  4.5  1.5
        2  3.5  2.5  2.5
        3  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
                  a         b         c
        1  2.500000  2.500000  2.500000
        2  2.833333  2.833333  2.833333
        3  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        regrouped = self.obj.groupby(by, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(regrouped.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_matrix_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        wrap_kwargs = merge_dicts(dict(name_or_index=list(regrouped.indices.keys())), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def resample_apply(self, freq: tp.PandasFrequencyLike,
                       apply_func_nb: tp.Union[tp.GroupByApplyFunc, tp.GroupByMatrixApplyFunc],
                       *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                       **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
        `vectorbt.generic.nb.groupby_matrix_apply_nb` for `on_matrix=True`.

        For `freq`, see `pd.DataFrame.resample`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_nb)
                      a    b    c
        2020-01-01  1.5  4.5  1.5
        2020-01-03  3.5  2.5  2.5
        2020-01-05  5.0  1.0  1.0

        &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_matrix_nb, on_matrix=True)
                           a         b         c
        2020-01-01  2.500000  2.500000  2.500000
        2020-01-03  2.833333  2.833333  2.833333
        2020-01-05  2.333333  2.333333  2.333333
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        resampled = self.obj.resample(freq, axis=0, **kwargs)
        groups = Dict()
        for i, (k, v) in enumerate(resampled.indices.items()):
            groups[i] = np.asarray(v)
        if on_matrix:
            out = nb.groupby_matrix_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        else:
            out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
        out_obj = self.wrapper.wrap(out, group_by=False, index=list(resampled.indices.keys()))
        resampled_arr = np.full((resampled.ngroups, self.to_2d_array().shape[1]), np.nan)
        resampled_obj = self.wrapper.wrap(
            resampled_arr,
            index=resampled.asfreq().index,
            group_by=False,
            **merge_dicts({}, wrap_kwargs)
        )
        resampled_obj.loc[out_obj.index] = out_obj.values
        return resampled_obj

    def applymap(self, apply_func_nb: tp.ApplyMapFunc, *args,
                 wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.applymap_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
        &gt;&gt;&gt; df.vbt.applymap(multiply_nb)
                       a     b    c
        2020-01-01   1.0  25.0  1.0
        2020-01-02   4.0  16.0  4.0
        2020-01-03   9.0   9.0  9.0
        2020-01-04  16.0   4.0  4.0
        2020-01-05  25.0   1.0  1.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)

        out = nb.applymap_nb(self.to_2d_array(), apply_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def filter(self, filter_func_nb: tp.FilterFunc, *args,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.filter_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
        &gt;&gt;&gt; df.vbt.filter(greater_nb)
                      a    b    c
        2020-01-01  NaN  5.0  NaN
        2020-01-02  NaN  4.0  NaN
        2020-01-03  3.0  3.0  3.0
        2020-01-04  4.0  NaN  NaN
        2020-01-05  5.0  NaN  NaN
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(filter_func_nb)

        out = nb.filter_nb(self.to_2d_array(), filter_func_nb, *args)
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    def apply_and_reduce(self, apply_func_nb: tp.ApplyFunc, reduce_func_nb: tp.ReduceFunc,
                         apply_args: tp.Optional[tuple] = None, reduce_args: tp.Optional[tuple] = None,
                         wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;See `vectorbt.generic.nb.apply_and_reduce_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
        a    4.0
        b    4.0
        c    3.0
        dtype: float64
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(apply_func_nb)
        checks.assert_numba_func(reduce_func_nb)
        if apply_args is None:
            apply_args = ()
        if reduce_args is None:
            reduce_args = ()

        out = nb.apply_and_reduce_nb(self.to_2d_array(), apply_func_nb, apply_args, reduce_func_nb, reduce_args)
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;apply_and_reduce&#39;), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def reduce(self,
               reduce_func_nb: tp.Union[
                   tp.FlatGroupReduceFunc,
                   tp.FlatGroupReduceArrayFunc,
                   tp.GroupReduceFunc,
                   tp.GroupReduceArrayFunc,
                   tp.ReduceFunc,
                   tp.ReduceArrayFunc
               ],
               *args,
               returns_array: bool = False,
               returns_idx: bool = False,
               flatten: bool = False,
               order: str = &#39;C&#39;,
               to_index: bool = True,
               group_by: tp.GroupByLike = None,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeriesFrame[float]:
        &#34;&#34;&#34;Reduce by column.

        See `vectorbt.generic.nb.flat_reduce_grouped_to_array_nb` if grouped, `returns_array` is True and `flatten` is True.
        See `vectorbt.generic.nb.flat_reduce_grouped_nb` if grouped, `returns_array` is False and `flatten` is True.
        See `vectorbt.generic.nb.reduce_grouped_to_array_nb` if grouped, `returns_array` is True and `flatten` is False.
        See `vectorbt.generic.nb.reduce_grouped_nb` if grouped, `returns_array` is False and `flatten` is False.
        See `vectorbt.generic.nb.reduce_to_array_nb` if not grouped and `returns_array` is True.
        See `vectorbt.generic.nb.reduce_nb` if not grouped and `returns_array` is False.

        Set `returns_idx` to True if values returned by `reduce_func_nb` are indices/positions.
        Set `to_index` to False to return raw positions instead of labels.

        ## Example

        ```python-repl
        &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.reduce(mean_nb)
        a    3.0
        b    3.0
        c    1.8
        dtype: float64

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True)
        a   2020-01-05
        b   2020-01-01
        c   2020-01-03
        dtype: datetime64[ns]

        &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
        &gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True, to_index=False)
        a    4
        b    0
        c    2
        dtype: int64

        &gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, returns_array=True, wrap_kwargs=dict(name_or_index=[&#39;min&#39;, &#39;max&#39;]))
               a    b    c
        min  1.0  1.0  1.0
        max  5.0  5.0  3.0

        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
        group
        first     3.0
        second    1.8
        dtype: float64

        &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;],
        ...     returns_array=True, group_by=group_by)
        group  first  second
        min      1.0     1.0
        max      5.0     3.0
        ```
        &#34;&#34;&#34;
        checks.assert_numba_func(reduce_func_nb)

        if self.wrapper.grouper.is_grouped(group_by=group_by):
            group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
            if flatten:
                checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])
                in_c_order = order.upper() == &#39;C&#39;
                if returns_array:
                    out = nb.flat_reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                else:
                    out = nb.flat_reduce_grouped_nb(
                        self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
                if returns_idx:
                    if in_c_order:
                        out //= group_lens  # flattened in C order
                    else:
                        out %= self.wrapper.shape[0]  # flattened in F order
            else:
                if returns_array:
                    out = nb.reduce_grouped_to_array_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
                else:
                    out = nb.reduce_grouped_nb(
                        self.to_2d_array(), group_lens, reduce_func_nb, *args)
        else:
            if returns_array:
                out = nb.reduce_to_array_nb(
                    self.to_2d_array(), reduce_func_nb, *args)
            else:
                out = nb.reduce_nb(
                    self.to_2d_array(), reduce_func_nb, *args)

        # Perform post-processing
        wrap_kwargs = merge_dicts(dict(
            name_or_index=&#39;reduce&#39; if not returns_array else None,
            to_index=returns_idx and to_index,
            fillna=-1 if returns_idx else None,
            dtype=np.int_ if returns_idx else None
        ), wrap_kwargs)
        return self.wrapper.wrap_reduced(out, group_by=group_by, **wrap_kwargs)

    def min(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;min&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.min_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmin = np.nanmin
        else:
            _nanmin = nanmin
        return self.wrapper.wrap_reduced(_nanmin(arr, axis=0), group_by=False, **wrap_kwargs)

    def max(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;max&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.max_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmax = np.nanmax
        else:
            _nanmax = nanmax
        return self.wrapper.wrap_reduced(_nanmax(arr, axis=0), group_by=False, **wrap_kwargs)

    def mean(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return mean of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;mean&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.mean_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmean = np.nanmean
        else:
            _nanmean = nanmean
        return self.wrapper.wrap_reduced(_nanmean(arr, axis=0), group_by=False, **wrap_kwargs)

    def median(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return median of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;median&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.median_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanmedian = np.nanmedian
        else:
            _nanmedian = nanmedian
        return self.wrapper.wrap_reduced(_nanmedian(arr, axis=0), group_by=False, **wrap_kwargs)

    def std(self, ddof: int = 1, group_by: tp.GroupByLike = None,
            wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return standard deviation of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;std&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.std_reduce_nb, ddof, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nanstd = np.nanstd
        else:
            _nanstd = nanstd
        return self.wrapper.wrap_reduced(_nanstd(arr, ddof=ddof, axis=0), group_by=False, **wrap_kwargs)

    def sum(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return sum of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;sum&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.sum_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        arr = self.to_2d_array()
        if arr.dtype != int and arr.dtype != float:
            # bottleneck can&#39;t consume other than that
            _nansum = np.nansum
        else:
            _nansum = nansum
        return self.wrapper.wrap_reduced(_nansum(arr, axis=0), group_by=False, **wrap_kwargs)

    def count(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return count of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;count&#39;, dtype=np.int_), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(nb.count_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

        return self.wrapper.wrap_reduced(np.sum(~np.isnan(self.to_2d_array()), axis=0), group_by=False, **wrap_kwargs)

    def idxmin(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of min of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmin&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmin_reduce_nb,
                group_by=group_by,
                flatten=True,
                returns_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmin(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def idxmax(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
               wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Return labeled index of max of non-NaN elements.&#34;&#34;&#34;
        wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmax&#39;), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.argmax_reduce_nb,
                group_by=group_by,
                flatten=True,
                returns_idx=True,
                order=order,
                wrap_kwargs=wrap_kwargs
            )

        obj = self.to_2d_array()
        out = np.full(obj.shape[1], np.nan, dtype=object)
        nan_mask = np.all(np.isnan(obj), axis=0)
        out[~nan_mask] = self.wrapper.index[nanargmax(obj[:, ~nan_mask], axis=0)]
        return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)

    def describe(self, percentiles: tp.Optional[tp.ArrayLike] = None, ddof: int = 1,
                 group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;See `vectorbt.generic.nb.describe_reduce_nb`.

        For `percentiles`, see `pd.DataFrame.describe`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.describe()
                      a         b        c
        count  5.000000  5.000000  5.00000
        mean   3.000000  3.000000  1.80000
        std    1.581139  1.581139  0.83666
        min    1.000000  1.000000  1.00000
        25%    2.000000  2.000000  1.00000
        50%    3.000000  3.000000  2.00000
        75%    4.000000  4.000000  2.00000
        max    5.000000  5.000000  3.00000
        ```
        &#34;&#34;&#34;
        if percentiles is not None:
            percentiles = reshape_fns.to_1d_array(percentiles)
        else:
            percentiles = np.array([0.25, 0.5, 0.75])
        percentiles = percentiles.tolist()
        if 0.5 not in percentiles:
            percentiles.append(0.5)
        percentiles = np.unique(percentiles)
        perc_formatted = pd.io.formats.format.format_percentiles(percentiles)
        index = pd.Index([&#39;count&#39;, &#39;mean&#39;, &#39;std&#39;, &#39;min&#39;, *perc_formatted, &#39;max&#39;])
        wrap_kwargs = merge_dicts(dict(name_or_index=index), wrap_kwargs)
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.reduce(
                nb.describe_reduce_nb, percentiles, ddof,
                group_by=group_by, flatten=True, returns_array=True,
                wrap_kwargs=wrap_kwargs)
        return self.reduce(
            nb.describe_reduce_nb, percentiles, ddof,
            returns_array=True, wrap_kwargs=wrap_kwargs)

    def value_counts(self,
                     normalize: bool = False,
                     sort_uniques: bool = True,
                     sort: bool = False,
                     ascending: bool = False,
                     dropna: bool = False,
                     group_by: tp.GroupByLike = None,
                     mapping: tp.Optional[tp.MappingLike] = None,
                     incl_all_keys: bool = False,
                     wrap_kwargs: tp.KwargsLike = None,
                     **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Return a Series/DataFrame containing counts of unique values.

        * Enable `normalize` flag to return the relative frequencies of the unique values.
        * Enable `sort_uniques` flag to sort uniques.
        * Enable `sort` flag to sort by frequencies.
        * Enable `ascending` flag to sort in ascending order.
        * Enable `dropna` flag to exclude counts of NaN.
        * Enable `incl_all_keys` to include all mapping keys, no only those that are present in the array.

        Mapping will be applied using `vectorbt.utils.mapping.apply_mapping` with `**kwargs`.&#34;&#34;&#34;
        if mapping is None:
            mapping = self.mapping
        if isinstance(mapping, str):
            if mapping.lower() == &#39;index&#39;:
                mapping = self.wrapper.index
            elif mapping.lower() == &#39;columns&#39;:
                mapping = self.wrapper.columns
            mapping = to_mapping(mapping)
        codes, uniques = pd.factorize(self.obj.values.flatten(), sort=False, na_sentinel=None)
        codes = codes.reshape(self.wrapper.shape_2d)
        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        value_counts = nb.value_counts_nb(codes, len(uniques), group_lens)
        if incl_all_keys and mapping is not None:
            missing_keys = []
            for x in mapping:
                if pd.isnull(x) and pd.isnull(uniques).any():
                    continue
                if x not in uniques:
                    missing_keys.append(x)
            value_counts = np.vstack((value_counts, np.full((len(missing_keys), value_counts.shape[1]), 0)))
            uniques = np.concatenate((uniques, np.array(missing_keys)))
        nan_mask = np.isnan(uniques)
        if dropna:
            value_counts = value_counts[~nan_mask]
            uniques = uniques[~nan_mask]
        if sort_uniques:
            new_indices = uniques.argsort()
            value_counts = value_counts[new_indices]
            uniques = uniques[new_indices]
        value_counts_sum = value_counts.sum(axis=1)
        if normalize:
            value_counts = value_counts / value_counts_sum.sum()
        if sort:
            if ascending:
                new_indices = value_counts_sum.argsort()
            else:
                new_indices = (-value_counts_sum).argsort()
            value_counts = value_counts[new_indices]
            uniques = uniques[new_indices]
        value_counts_pd = self.wrapper.wrap(
            value_counts,
            index=uniques,
            group_by=group_by,
            **merge_dicts({}, wrap_kwargs)
        )
        if mapping is not None:
            value_counts_pd.index = apply_mapping(value_counts_pd.index, mapping, **kwargs)
        return value_counts_pd

    # ############# Resolution ############# #

    def resolve_self(self: GenericAccessorT,
                     cond_kwargs: tp.KwargsLike = None,
                     custom_arg_names: tp.Optional[tp.Set[str]] = None,
                     impacts_caching: bool = True,
                     silence_warnings: bool = False) -&gt; GenericAccessorT:
        &#34;&#34;&#34;Resolve self.

        See `vectorbt.base.array_wrapper.Wrapping.resolve_self`.

        Creates a copy of this instance `mapping` is different in `cond_kwargs`.&#34;&#34;&#34;
        if cond_kwargs is None:
            cond_kwargs = {}
        if custom_arg_names is None:
            custom_arg_names = set()

        reself = Wrapping.resolve_self(
            self,
            cond_kwargs=cond_kwargs,
            custom_arg_names=custom_arg_names,
            impacts_caching=impacts_caching,
            silence_warnings=silence_warnings
        )
        if &#39;mapping&#39; in cond_kwargs:
            self_copy = reself.replace(mapping=cond_kwargs[&#39;mapping&#39;])

            if not checks.is_deep_equal(self_copy.mapping, reself.mapping):
                if not silence_warnings:
                    warnings.warn(f&#34;Changing the mapping will create a copy of this object. &#34;
                                  f&#34;Consider setting it upon object creation to re-use existing cache.&#34;, stacklevel=2)
                for alias in reself.self_aliases:
                    if alias not in custom_arg_names:
                        cond_kwargs[alias] = self_copy
                cond_kwargs[&#39;mapping&#39;] = self_copy.mapping
                if impacts_caching:
                    cond_kwargs[&#39;use_caching&#39;] = False
                return self_copy
        return reself

    # ############# Stats ############# #

    @property
    def stats_defaults(self) -&gt; tp.Kwargs:
        &#34;&#34;&#34;Defaults for `GenericAccessor.stats`.

        Merges `vectorbt.generic.stats_builder.StatsBuilderMixin.stats_defaults` and
        `generic.stats` from `vectorbt._settings.settings`.&#34;&#34;&#34;
        from vectorbt._settings import settings
        generic_stats_cfg = settings[&#39;generic&#39;][&#39;stats&#39;]

        return merge_dicts(
            StatsBuilderMixin.stats_defaults.__get__(self),
            generic_stats_cfg
        )

    _metrics: tp.ClassVar[Config] = Config(
        dict(
            start=dict(
                title=&#39;Start&#39;,
                calc_func=lambda self: self.wrapper.index[0],
                agg_func=None,
                tags=&#39;wrapper&#39;
            ),
            end=dict(
                title=&#39;End&#39;,
                calc_func=lambda self: self.wrapper.index[-1],
                agg_func=None,
                tags=&#39;wrapper&#39;
            ),
            period=dict(
                title=&#39;Period&#39;,
                calc_func=lambda self: len(self.wrapper.index),
                apply_to_timedelta=True,
                agg_func=None,
                tags=&#39;wrapper&#39;
            ),
            count=dict(
                title=&#39;Count&#39;,
                calc_func=&#39;count&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            mean=dict(
                title=&#39;Mean&#39;,
                calc_func=&#39;mean&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            std=dict(
                title=&#39;Std&#39;,
                calc_func=&#39;std&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            min=dict(
                title=&#39;Min&#39;,
                calc_func=&#39;min&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            median=dict(
                title=&#39;Median&#39;,
                calc_func=&#39;median&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            max=dict(
                title=&#39;Max&#39;,
                calc_func=&#39;max&#39;,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;describe&#39;]
            ),
            idx_min=dict(
                title=&#39;Min Index&#39;,
                calc_func=&#39;idxmin&#39;,
                agg_func=None,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;index&#39;]
            ),
            idx_max=dict(
                title=&#39;Max Index&#39;,
                calc_func=&#39;idxmax&#39;,
                agg_func=None,
                inv_check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;index&#39;]
            ),
            value_counts=dict(
                title=&#39;Value Counts&#39;,
                calc_func=lambda value_counts: reshape_fns.to_dict(value_counts, orient=&#39;index_series&#39;),
                resolve_value_counts=True,
                check_has_mapping=True,
                tags=[&#39;generic&#39;, &#39;value_counts&#39;]
            )
        ),
        copy_kwargs=dict(copy_mode=&#39;deep&#39;)
    )

    @property
    def metrics(self) -&gt; Config:
        return self._metrics

    # ############# Conversion ############# #

    def drawdown(self, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Drawdown series.&#34;&#34;&#34;
        out = self.to_2d_array() / nb.expanding_max_nb(self.to_2d_array()) - 1
        return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))

    @property
    def ranges(self) -&gt; Ranges:
        &#34;&#34;&#34;`GenericAccessor.get_ranges` with default arguments.&#34;&#34;&#34;
        return self.get_ranges()

    def get_ranges(self, wrapper_kwargs: tp.KwargsLike = None, **kwargs) -&gt; Ranges:
        &#34;&#34;&#34;Generate range records.

        See `vectorbt.generic.ranges.Ranges`.&#34;&#34;&#34;
        wrapper_kwargs = merge_dicts(self.wrapper.config, wrapper_kwargs)
        return Ranges.from_ts(self.obj, wrapper_kwargs=wrapper_kwargs, **kwargs)

    @property
    def drawdowns(self) -&gt; Drawdowns:
        &#34;&#34;&#34;`GenericAccessor.get_drawdowns` with default arguments.&#34;&#34;&#34;
        return self.get_drawdowns()

    def get_drawdowns(self, wrapper_kwargs: tp.KwargsLike = None, **kwargs) -&gt; Drawdowns:
        &#34;&#34;&#34;Generate drawdown records.

        See `vectorbt.generic.drawdowns.Drawdowns`.&#34;&#34;&#34;
        wrapper_kwargs = merge_dicts(self.wrapper.config, wrapper_kwargs)
        return Drawdowns.from_ts(self.obj, wrapper_kwargs=wrapper_kwargs, **kwargs)

    def to_mapped(self,
                  dropna: bool = True,
                  dtype: tp.Optional[tp.DTypeLike] = None,
                  group_by: tp.GroupByLike = None,
                  **kwargs) -&gt; MappedArray:
        &#34;&#34;&#34;Convert this object into an instance of `vectorbt.records.mapped_array.MappedArray`.&#34;&#34;&#34;
        mapped_arr = self.to_2d_array().flatten(order=&#39;F&#39;)
        col_arr = np.repeat(np.arange(self.wrapper.shape_2d[1]), self.wrapper.shape_2d[0])
        idx_arr = np.tile(np.arange(self.wrapper.shape_2d[0]), self.wrapper.shape_2d[1])
        if dropna and np.isnan(mapped_arr).any():
            not_nan_mask = ~np.isnan(mapped_arr)
            mapped_arr = mapped_arr[not_nan_mask]
            col_arr = col_arr[not_nan_mask]
            idx_arr = idx_arr[not_nan_mask]
        return MappedArray(
            self.wrapper,
            np.asarray(mapped_arr, dtype=dtype),
            col_arr,
            idx_arr=idx_arr,
            **kwargs
        ).regroup(group_by)

    def to_returns(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Get returns of this object.&#34;&#34;&#34;
        return self.obj.vbt.returns.from_value(self.obj, **kwargs).obj

    # ############# Transformation ############# #

    def transform(self, transformer: TransformerT, wrap_kwargs: tp.KwargsLike = None, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Transform using a transformer.

        A transformer can be any class instance that has `transform` and `fit_transform` methods,
        ideally subclassing `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`.

        Will fit `transformer` if not fitted.

        `**kwargs` are passed to the `transform` or `fit_transform` method.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

        &gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
                      a    b    c
        2020-01-01 -1.0  1.0 -1.0
        2020-01-02 -0.5  0.5  0.0
        2020-01-03  0.0  0.0  1.0
        2020-01-04  0.5 -0.5  0.0
        2020-01-05  1.0 -1.0 -1.0

        &gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
        &gt;&gt;&gt; df.vbt.transform(fitted_scaler)
                      a    b    c
        2020-01-01 -2.0  2.0 -2.0
        2020-01-02 -1.0  1.0 -1.0
        2020-01-03  0.0  0.0  0.0
        2020-01-04  1.0 -1.0 -1.0
        2020-01-05  2.0 -2.0 -2.0
        ```&#34;&#34;&#34;
        is_fitted = True
        try:
            check_is_fitted(transformer)
        except NotFittedError:
            is_fitted = False
        if not is_fitted:
            result = transformer.fit_transform(self.to_2d_array(), **kwargs)
        else:
            result = transformer.transform(self.to_2d_array(), **kwargs)
        return self.wrapper.wrap(result, group_by=False, **merge_dicts({}, wrap_kwargs))

    def zscore(self, **kwargs) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Compute z-score using `sklearn.preprocessing.StandardScaler`.&#34;&#34;&#34;
        return self.scale(with_mean=True, with_std=True, **kwargs)

    def rebase(self, base: float, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Rebase all series to a given intial base.

        This makes comparing/plotting different series together easier.
        Will forward and backward fill NaN values.&#34;&#34;&#34;
        result = nb.bfill_nb(nb.ffill_nb(self.to_2d_array()))
        result = result / result[0] * base
        return self.wrapper.wrap(result, group_by=False, **merge_dicts({}, wrap_kwargs))

    # ############# Splitting ############# #

    def split(self, splitter: SplitterT, stack_kwargs: tp.KwargsLike = None, keys: tp.Optional[tp.IndexLike] = None,
              plot: bool = False, trace_names: tp.TraceNames = None, heatmap_kwargs: tp.KwargsLike = None,
              **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using a splitter.

        Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.

        A splitter can be any class instance that has `split` method, ideally subclassing
        `sklearn.model_selection.BaseCrossValidator` or `vectorbt.generic.splitters.BaseSplitter`.

        `heatmap_kwargs` are passed to `vectorbt.generic.plotting.Heatmap` if `plot` is True,
        can be a dictionary or a list per set, for example, to set trace name for each set (&#39;train&#39;, &#39;test&#39;, etc.).

        `**kwargs` are passed to the `split` method.

        !!! note
            The datetime-like format of the index will be lost as result of this operation.
            Make sure to store the index metadata such as frequency information beforehand.

        ## Example

        ```python-repl
        &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

        &gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
        &gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

        &gt;&gt;&gt; train_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          3.0  3.0  3
        4          NaN  4.0  4
        5          NaN  5.0  5
        6          NaN  NaN  6
        7          NaN  NaN  7
        &gt;&gt;&gt; train_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]
        &gt;&gt;&gt; test_df
        split_idx  0  1  2
        0          4  6  8
        1          5  7  9
        &gt;&gt;&gt; test_indexes
        [DatetimeIndex([&#39;2020-01-05&#39;, &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-09&#39;, &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=[&#39;train&#39;, &#39;test&#39;])
        ```

        ![](/docs/img/split_plot.svg)
        &#34;&#34;&#34;
        total_range_sr = pd.Series(np.arange(len(self.wrapper.index)), index=self.wrapper.index)
        set_ranges = list(splitter.split(total_range_sr, **kwargs))
        if len(set_ranges) == 0:
            raise ValueError(&#34;No splits were generated&#34;)
        idxs_by_split_and_set = list(zip(*set_ranges))

        results = []
        if keys is not None:
            if not isinstance(keys, pd.Index):
                keys = pd.Index(keys)
        for idxs_by_split in idxs_by_split_and_set:
            split_dfs = []
            split_indexes = []
            for split_idx, idxs in enumerate(idxs_by_split):
                split_dfs.append(self.obj.iloc[idxs].reset_index(drop=True))
                if keys is not None:
                    split_name = keys[split_idx]
                else:
                    split_name = &#39;split_&#39; + str(split_idx)
                split_indexes.append(pd.Index(self.wrapper.index[idxs], name=split_name))
            set_df = pd.concat(split_dfs, axis=1).reset_index(drop=True)
            if keys is not None:
                split_columns = keys
            else:
                split_columns = pd.Index(np.arange(len(split_indexes)), name=&#39;split_idx&#39;)
            split_columns = index_fns.repeat_index(split_columns, len(self.wrapper.columns))
            if stack_kwargs is None:
                stack_kwargs = {}
            set_df = set_df.vbt.stack_index(split_columns, **stack_kwargs)
            results.append((set_df, split_indexes))

        if plot:  # pragma: no cover
            if trace_names is None:
                trace_names = list(range(len(results)))
            if isinstance(trace_names, str):
                trace_names = [trace_names]
            nan_df = pd.DataFrame(np.nan, columns=pd.RangeIndex(stop=len(results[0][1])), index=self.wrapper.index)
            fig = None
            for i, (_, split_indexes) in enumerate(results):
                heatmap_df = nan_df.copy()
                for j in range(len(split_indexes)):
                    heatmap_df.loc[split_indexes[j], j] = i
                _heatmap_kwargs = resolve_dict(heatmap_kwargs, i=i)
                fig = heatmap_df.vbt.ts_heatmap(fig=fig, **merge_dicts(
                    dict(
                        trace_kwargs=dict(
                            showscale=False,
                            name=str(trace_names[i]),
                            showlegend=True
                        )
                    ),
                    _heatmap_kwargs
                ))
                if fig.layout.colorway is not None:
                    colorway = fig.layout.colorway
                else:
                    colorway = fig.layout.template.layout.colorway
                if &#39;colorscale&#39; not in _heatmap_kwargs:
                    fig.data[-1].update(colorscale=[colorway[i], colorway[i]])
            return fig

        if len(results) == 1:
            return results[0]
        return tuple(results)

    def range_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RangeSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  5
        1          1  6
        2          2  7
        3          3  8
        4          4  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
        &gt;&gt;&gt; range_df
        split_idx  0  1  2  3  4  5  6
        0          0  1  2  3  4  5  6
        1          1  2  3  4  5  6  7
        2          2  3  4  5  6  7  8
        3          3  4  5  6  7  8  9
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;),
         DatetimeIndex([&#39;2020-01-04&#39;, ..., &#39;2020-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_3&#39;),
         DatetimeIndex([&#39;2020-01-05&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_4&#39;),
         DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-09&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_5&#39;),
         DatetimeIndex([&#39;2020-01-07&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_6&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  2
        1          1  3
        2          2  4
        3          3  5
        4          4  6
        5          5  7
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
        &gt;&gt;&gt; range_df
        split_idx    0    1  2
        0          0.0  0.0  0
        1          1.0  1.0  1
        2          2.0  2.0  2
        3          NaN  3.0  3
        4          NaN  NaN  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-03&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
         DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

        &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
        ...     start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;]),
        ...     end_idxs=pd.Index([&#39;2020-01-04&#39;, &#39;2020-01-05&#39;])
        ... )
        &gt;&gt;&gt; range_df
        split_idx  0  1
        0          0  1
        1          1  2
        2          2  3
        3          3  4
        &gt;&gt;&gt; range_indexes
        [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
         DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

         &gt;&gt;&gt; sr.vbt.range_split(
         ...    start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;, &#39;2020-01-01&#39;]),
         ...    end_idxs=pd.Index([&#39;2020-01-08&#39;, &#39;2020-01-04&#39;, &#39;2020-01-07&#39;]),
         ...    plot=True
         ... )
        ```

        ![](/docs/img/range_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RangeSplitter(), **kwargs)

    def rolling_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RollingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx  0  1  2  3  4  5
        0          0  1  2  3  4  5
        1          1  2  3  4  5  6
        2          2  3  4  5  6  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5
        0          3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5
        0          4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.rolling_split(
        ...     window_len=5, set_lens=(1, 1), left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/docs/img/rolling_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(RollingSplitter(), **kwargs)

    def expanding_split(self, **kwargs) -&gt; SplitOutputT:
        &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.ExpandingSplitter`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
        ...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
        &gt;&gt;&gt; train_set[0]
        split_idx    0    1    2    3    4    5    6  7
        0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
        1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
        2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
        3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
        4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
        5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
        6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
        7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
        &gt;&gt;&gt; valid_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          1  2  3  4  5  6  7  8
        &gt;&gt;&gt; test_set[0]
        split_idx  0  1  2  3  4  5  6  7
        0          2  3  4  5  6  7  8  9

        &gt;&gt;&gt; sr.vbt.expanding_split(
        ...     set_lens=(1, 1), min_len=3, left_to_right=False,
        ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
        ```

        ![](/docs/img/expanding_split_plot.svg)
        &#34;&#34;&#34;
        return self.split(ExpandingSplitter(), **kwargs)

    # ############# Plotting ############# #

    def plot(self,
             trace_names: tp.TraceNames = None,
             x_labels: tp.Optional[tp.Labels] = None,
             return_fig: bool = True,
             **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Scatter` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.plot()
        ```

        ![](/docs/img/df_plot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        scatter = plotting.Scatter(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return scatter.fig
        return scatter

    def lineplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;lines&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.lineplot()
        ```

        ![](/docs/img/df_lineplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;lines&#39;)), kwargs))

    def scatterplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
        &#34;&#34;&#34;`GenericAccessor.plot` with &#39;markers&#39; mode.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.scatterplot()
        ```

        ![](/docs/img/df_scatterplot.svg)
        &#34;&#34;&#34;
        return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;markers&#39;)), kwargs))

    def barplot(self,
                trace_names: tp.TraceNames = None,
                x_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Bar]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Bar` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.barplot()
        ```

        ![](/docs/img/df_barplot.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.index
        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        bar = plotting.Bar(
            data=self.to_2d_array(),
            trace_names=trace_names,
            x_labels=x_labels,
            **kwargs
        )
        if return_fig:
            return bar.fig
        return bar

    def histplot(self,
                 trace_names: tp.TraceNames = None,
                 group_by: tp.GroupByLike = None,
                 return_fig: bool = True,
                 **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Histogram]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Histogram` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.histplot()
        ```

        ![](/docs/img/df_histplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.histplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        hist = plotting.Histogram(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return hist.fig
        return hist

    def boxplot(self,
                trace_names: tp.TraceNames = None,
                group_by: tp.GroupByLike = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Box]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Box` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df.vbt.boxplot()
        ```

        ![](/docs/img/df_boxplot.svg)
        &#34;&#34;&#34;
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            return self.flatten_grouped(group_by=group_by).vbt.boxplot(trace_names=trace_names, **kwargs)

        if trace_names is None:
            if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
                trace_names = self.wrapper.columns
        box = plotting.Box(
            data=self.to_2d_array(),
            trace_names=trace_names,
            **kwargs
        )
        if return_fig:
            return box.fig
        return box

    @property
    def plots_defaults(self) -&gt; tp.Kwargs:
        &#34;&#34;&#34;Defaults for `GenericAccessor.plots`.

        Merges `vectorbt.generic.plots_builder.PlotsBuilderMixin.plots_defaults` and
        `generic.plots` from `vectorbt._settings.settings`.&#34;&#34;&#34;
        from vectorbt._settings import settings
        generic_plots_cfg = settings[&#39;generic&#39;][&#39;plots&#39;]

        return merge_dicts(
            PlotsBuilderMixin.plots_defaults.__get__(self),
            generic_plots_cfg
        )

    _subplots: tp.ClassVar[Config] = Config(
        dict(
            plot=dict(
                check_is_not_grouped=True,
                plot_func=&#39;plot&#39;,
                pass_trace_names=False,
                tags=&#39;generic&#39;
            )
        ),
        copy_kwargs=dict(copy_mode=&#39;deep&#39;)
    )

    @property
    def subplots(self) -&gt; Config:
        return self._subplots</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></li>
<li><a title="vectorbt.base.array_wrapper.Wrapping" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping">Wrapping</a></li>
<li><a title="vectorbt.utils.config.Configured" href="../utils/config.html#vectorbt.utils.config.Configured">Configured</a></li>
<li><a title="vectorbt.utils.config.Pickleable" href="../utils/config.html#vectorbt.utils.config.Pickleable">Pickleable</a></li>
<li><a title="vectorbt.utils.docs.Documented" href="../utils/docs.html#vectorbt.utils.docs.Documented">Documented</a></li>
<li><a title="vectorbt.base.indexing.PandasIndexer" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer">PandasIndexer</a></li>
<li><a title="vectorbt.base.indexing.IndexingBase" href="../base/indexing.html#vectorbt.base.indexing.IndexingBase">IndexingBase</a></li>
<li><a title="vectorbt.utils.attr.AttrResolver" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver">AttrResolver</a></li>
<li><a title="vectorbt.generic.stats_builder.StatsBuilderMixin" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin">StatsBuilderMixin</a></li>
<li><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin">PlotsBuilderMixin</a></li>
</ul>
<h3 class="section-subtitle">Subclasses</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.accessors.GenericDFAccessor" href="#vectorbt.generic.accessors.GenericDFAccessor">GenericDFAccessor</a></li>
<li><a title="vectorbt.generic.accessors.GenericSRAccessor" href="#vectorbt.generic.accessors.GenericSRAccessor">GenericSRAccessor</a></li>
<li><a title="vectorbt.returns.accessors.ReturnsAccessor" href="../returns/accessors.html#vectorbt.returns.accessors.ReturnsAccessor">ReturnsAccessor</a></li>
<li><a title="vectorbt.signals.accessors.SignalsAccessor" href="../signals/accessors.html#vectorbt.signals.accessors.SignalsAccessor">SignalsAccessor</a></li>
</ul>
<h3 class="section-subtitle">Class variables</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor.metrics"><code class="name">var <span class="ident child-name">metrics</span></code></dt>
<dd>
<div class="desc"><p>Metrics supported by <code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code>.</p>
<pre><code class="language-json">Config({
    &quot;start&quot;: {
        &quot;title&quot;: &quot;Start&quot;,
        &quot;calc_func&quot;: &quot;&lt;function GenericAccessor.&lt;lambda&gt; at 0x7f6bfb238730&gt;&quot;,
        &quot;agg_func&quot;: null,
        &quot;tags&quot;: &quot;wrapper&quot;
    },
    &quot;end&quot;: {
        &quot;title&quot;: &quot;End&quot;,
        &quot;calc_func&quot;: &quot;&lt;function GenericAccessor.&lt;lambda&gt; at 0x7f6bfb2387b8&gt;&quot;,
        &quot;agg_func&quot;: null,
        &quot;tags&quot;: &quot;wrapper&quot;
    },
    &quot;period&quot;: {
        &quot;title&quot;: &quot;Period&quot;,
        &quot;calc_func&quot;: &quot;&lt;function GenericAccessor.&lt;lambda&gt; at 0x7f6bfb238840&gt;&quot;,
        &quot;apply_to_timedelta&quot;: true,
        &quot;agg_func&quot;: null,
        &quot;tags&quot;: &quot;wrapper&quot;
    },
    &quot;count&quot;: {
        &quot;title&quot;: &quot;Count&quot;,
        &quot;calc_func&quot;: &quot;count&quot;,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;describe&quot;
        ]
    },
    &quot;mean&quot;: {
        &quot;title&quot;: &quot;Mean&quot;,
        &quot;calc_func&quot;: &quot;mean&quot;,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;describe&quot;
        ]
    },
    &quot;std&quot;: {
        &quot;title&quot;: &quot;Std&quot;,
        &quot;calc_func&quot;: &quot;std&quot;,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;describe&quot;
        ]
    },
    &quot;min&quot;: {
        &quot;title&quot;: &quot;Min&quot;,
        &quot;calc_func&quot;: &quot;min&quot;,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;describe&quot;
        ]
    },
    &quot;median&quot;: {
        &quot;title&quot;: &quot;Median&quot;,
        &quot;calc_func&quot;: &quot;median&quot;,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;describe&quot;
        ]
    },
    &quot;max&quot;: {
        &quot;title&quot;: &quot;Max&quot;,
        &quot;calc_func&quot;: &quot;max&quot;,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;describe&quot;
        ]
    },
    &quot;idx_min&quot;: {
        &quot;title&quot;: &quot;Min Index&quot;,
        &quot;calc_func&quot;: &quot;idxmin&quot;,
        &quot;agg_func&quot;: null,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;index&quot;
        ]
    },
    &quot;idx_max&quot;: {
        &quot;title&quot;: &quot;Max Index&quot;,
        &quot;calc_func&quot;: &quot;idxmax&quot;,
        &quot;agg_func&quot;: null,
        &quot;inv_check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;index&quot;
        ]
    },
    &quot;value_counts&quot;: {
        &quot;title&quot;: &quot;Value Counts&quot;,
        &quot;calc_func&quot;: &quot;&lt;function GenericAccessor.&lt;lambda&gt; at 0x7f6bfb2388c8&gt;&quot;,
        &quot;resolve_value_counts&quot;: true,
        &quot;check_has_mapping&quot;: true,
        &quot;tags&quot;: [
            &quot;generic&quot;,
            &quot;value_counts&quot;
        ]
    }
})
</code></pre>
<p>Returns <code>GenericAccessor._metrics</code>, which gets (deep) copied upon creation of each instance.
Thus, changing this config won't affect the class.</p>
<p>To change metrics, you can either change the config in-place, override this property,
or overwrite the instance variable <code>GenericAccessor._metrics</code>.</p></div>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.subplots"><code class="name">var <span class="ident child-name">subplots</span></code></dt>
<dd>
<div class="desc"><p>Subplots supported by <code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code>.</p>
<pre><code class="language-json">Config({
    &quot;plot&quot;: {
        &quot;check_is_not_grouped&quot;: true,
        &quot;plot_func&quot;: &quot;plot&quot;,
        &quot;pass_trace_names&quot;: false,
        &quot;tags&quot;: &quot;generic&quot;
    }
})
</code></pre>
<p>Returns <code>GenericAccessor._subplots</code>, which gets (deep) copied upon creation of each instance.
Thus, changing this config won't affect the class.</p>
<p>To change subplots, you can either change the config in-place, override this property,
or overwrite the instance variable <code>GenericAccessor._subplots</code>.</p></div>
</dd>
</dl>
<h3 class="section-subtitle">Instance variables</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor.drawdowns"><code class="name">var <span class="ident child-name">drawdowns</span></code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">GenericAccessor.get_drawdowns()</a></code> with default arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def drawdowns(self) -&gt; Drawdowns:
    &#34;&#34;&#34;`GenericAccessor.get_drawdowns` with default arguments.&#34;&#34;&#34;
    return self.get_drawdowns()</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.mapping"><code class="name">var <span class="ident child-name">mapping</span></code></dt>
<dd>
<div class="desc"><p>Mapping.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def mapping(self) -&gt; tp.Optional[tp.Mapping]:
    &#34;&#34;&#34;Mapping.&#34;&#34;&#34;
    return self._mapping</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.plots_defaults"><code class="name">var <span class="ident child-name">plots_defaults</span></code></dt>
<dd>
<div class="desc"><p>Defaults for <code><a title="vectorbt.generic.accessors.GenericAccessor.plots" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.plots">PlotsBuilderMixin.plots()</a></code>.</p>
<p>Merges <code><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin.plots_defaults" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.plots_defaults">PlotsBuilderMixin.plots_defaults</a></code> and
<code>generic.plots</code> from <code><a title="vectorbt._settings.settings" href="../_settings.html#vectorbt._settings.settings">settings</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def plots_defaults(self) -&gt; tp.Kwargs:
    &#34;&#34;&#34;Defaults for `GenericAccessor.plots`.

    Merges `vectorbt.generic.plots_builder.PlotsBuilderMixin.plots_defaults` and
    `generic.plots` from `vectorbt._settings.settings`.&#34;&#34;&#34;
    from vectorbt._settings import settings
    generic_plots_cfg = settings[&#39;generic&#39;][&#39;plots&#39;]

    return merge_dicts(
        PlotsBuilderMixin.plots_defaults.__get__(self),
        generic_plots_cfg
    )</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ranges"><code class="name">var <span class="ident child-name">ranges</span></code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.get_ranges" href="#vectorbt.generic.accessors.GenericAccessor.get_ranges">GenericAccessor.get_ranges()</a></code> with default arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def ranges(self) -&gt; Ranges:
    &#34;&#34;&#34;`GenericAccessor.get_ranges` with default arguments.&#34;&#34;&#34;
    return self.get_ranges()</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.stats_defaults"><code class="name">var <span class="ident child-name">stats_defaults</span></code></dt>
<dd>
<div class="desc"><p>Defaults for <code><a title="vectorbt.generic.accessors.GenericAccessor.stats" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats">StatsBuilderMixin.stats()</a></code>.</p>
<p>Merges <code><a title="vectorbt.generic.stats_builder.StatsBuilderMixin.stats_defaults" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats_defaults">StatsBuilderMixin.stats_defaults</a></code> and
<code>generic.stats</code> from <code><a title="vectorbt._settings.settings" href="../_settings.html#vectorbt._settings.settings">settings</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def stats_defaults(self) -&gt; tp.Kwargs:
    &#34;&#34;&#34;Defaults for `GenericAccessor.stats`.

    Merges `vectorbt.generic.stats_builder.StatsBuilderMixin.stats_defaults` and
    `generic.stats` from `vectorbt._settings.settings`.&#34;&#34;&#34;
    from vectorbt._settings import settings
    generic_stats_cfg = settings[&#39;generic&#39;][&#39;stats&#39;]

    return merge_dicts(
        StatsBuilderMixin.stats_defaults.__get__(self),
        generic_stats_cfg
    )</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericAccessor.apply_along_axis"><code class="name flex">
<span>def <span class="ident child-name">apply_along_axis</span></span>(<span class="params">self, apply_func_nb, *args, axis=0, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Apply a function <code>apply_func_nb</code> along an axis.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_along_axis(self, apply_func_nb: tp.Union[tp.ApplyFunc, tp.RowApplyFunc], *args, axis: int = 0,
                     wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Apply a function `apply_func_nb` along an axis.&#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    if axis == 0:
        out = nb.apply_nb(self.to_2d_array(), apply_func_nb, *args)
    elif axis == 1:
        out = nb.row_apply_nb(self.to_2d_array(), apply_func_nb, *args)
    else:
        raise ValueError(&#34;Only axes 0 and 1 are supported&#34;)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce"><code class="name flex">
<span>def <span class="ident child-name">apply_and_reduce</span></span>(<span class="params">self, apply_func_nb, reduce_func_nb, apply_args=None, reduce_args=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.apply_and_reduce_nb" href="nb.html#vectorbt.generic.nb.apply_and_reduce_nb">apply_and_reduce_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
&gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
a    4.0
b    4.0
c    3.0
dtype: float64
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_and_reduce(self, apply_func_nb: tp.ApplyFunc, reduce_func_nb: tp.ReduceFunc,
                     apply_args: tp.Optional[tuple] = None, reduce_args: tp.Optional[tuple] = None,
                     wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;See `vectorbt.generic.nb.apply_and_reduce_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; greater_nb = njit(lambda col, a: a[a &gt; 2])
    &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.apply_and_reduce(greater_nb, mean_nb)
    a    4.0
    b    4.0
    c    3.0
    dtype: float64
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)
    checks.assert_numba_func(reduce_func_nb)
    if apply_args is None:
        apply_args = ()
    if reduce_args is None:
        reduce_args = ()

    out = nb.apply_and_reduce_nb(self.to_2d_array(), apply_func_nb, apply_args, reduce_func_nb, reduce_args)
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;apply_and_reduce&#39;), wrap_kwargs)
    return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.apply_mapping"><code class="name flex">
<span>def <span class="ident child-name">apply_mapping</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.utils.mapping.apply_mapping" href="../utils/mapping.html#vectorbt.utils.mapping.apply_mapping">apply_mapping()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_mapping(self, **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.utils.mapping.apply_mapping`.&#34;&#34;&#34;
    return apply_mapping(self.obj, self.mapping, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.applymap"><code class="name flex">
<span>def <span class="ident child-name">applymap</span></span>(<span class="params">self, apply_func_nb, *args, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.applymap_nb" href="nb.html#vectorbt.generic.nb.applymap_nb">applymap_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
&gt;&gt;&gt; df.vbt.applymap(multiply_nb)
               a     b    c
2020-01-01   1.0  25.0  1.0
2020-01-02   4.0  16.0  4.0
2020-01-03   9.0   9.0  9.0
2020-01-04  16.0   4.0  4.0
2020-01-05  25.0   1.0  1.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def applymap(self, apply_func_nb: tp.ApplyMapFunc, *args,
             wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.applymap_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; multiply_nb = njit(lambda i, col, a: a ** 2)
    &gt;&gt;&gt; df.vbt.applymap(multiply_nb)
                   a     b    c
    2020-01-01   1.0  25.0  1.0
    2020-01-02   4.0  16.0  4.0
    2020-01-03   9.0   9.0  9.0
    2020-01-04  16.0   4.0  4.0
    2020-01-05  25.0   1.0  1.0
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    out = nb.applymap_nb(self.to_2d_array(), apply_func_nb, *args)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.barplot"><code class="name flex">
<span>def <span class="ident child-name">barplot</span></span>(<span class="params">self, trace_names=None, x_labels=None, return_fig=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Bar" href="plotting.html#vectorbt.generic.plotting.Bar">Bar</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.barplot()
</code></pre>
<p><img alt="" src="/docs/img/df_barplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def barplot(self,
            trace_names: tp.TraceNames = None,
            x_labels: tp.Optional[tp.Labels] = None,
            return_fig: bool = True,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Bar]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Bar` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.barplot()
    ```

    ![](/docs/img/df_barplot.svg)
    &#34;&#34;&#34;
    if x_labels is None:
        x_labels = self.wrapper.index
    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    bar = plotting.Bar(
        data=self.to_2d_array(),
        trace_names=trace_names,
        x_labels=x_labels,
        **kwargs
    )
    if return_fig:
        return bar.fig
    return bar</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.bfill"><code class="name flex">
<span>def <span class="ident child-name">bfill</span></span>(<span class="params">self, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.bfill_nb" href="nb.html#vectorbt.generic.nb.bfill_nb">bfill_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.binarize"><code class="name flex">
<span>def <span class="ident child-name">binarize</span></span>(<span class="params">self, *, threshold=0.0, copy=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.Binarizer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.boxplot"><code class="name flex">
<span>def <span class="ident child-name">boxplot</span></span>(<span class="params">self, trace_names=None, group_by=None, return_fig=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Box" href="plotting.html#vectorbt.generic.plotting.Box">Box</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.boxplot()
</code></pre>
<p><img alt="" src="/docs/img/df_boxplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def boxplot(self,
            trace_names: tp.TraceNames = None,
            group_by: tp.GroupByLike = None,
            return_fig: bool = True,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Box]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Box` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.boxplot()
    ```

    ![](/docs/img/df_boxplot.svg)
    &#34;&#34;&#34;
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.flatten_grouped(group_by=group_by).vbt.boxplot(trace_names=trace_names, **kwargs)

    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    box = plotting.Box(
        data=self.to_2d_array(),
        trace_names=trace_names,
        **kwargs
    )
    if return_fig:
        return box.fig
    return box</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.bshift"><code class="name flex">
<span>def <span class="ident child-name">bshift</span></span>(<span class="params">self, n=1, fill_value=nan, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.bshift_nb" href="nb.html#vectorbt.generic.nb.bshift_nb">bshift_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.count"><code class="name flex">
<span>def <span class="ident child-name">count</span></span>(<span class="params">self, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return count of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return count of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;count&#39;, dtype=np.int_), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.count_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    return self.wrapper.wrap_reduced(np.sum(~np.isnan(self.to_2d_array()), axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.cumprod"><code class="name flex">
<span>def <span class="ident child-name">cumprod</span></span>(<span class="params">self, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.nancumprod_nb" href="nb.html#vectorbt.generic.nb.nancumprod_nb">nancumprod_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.cumsum"><code class="name flex">
<span>def <span class="ident child-name">cumsum</span></span>(<span class="params">self, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.nancumsum_nb" href="nb.html#vectorbt.generic.nb.nancumsum_nb">nancumsum_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.describe"><code class="name flex">
<span>def <span class="ident child-name">describe</span></span>(<span class="params">self, percentiles=None, ddof=1, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.describe_reduce_nb" href="nb.html#vectorbt.generic.nb.describe_reduce_nb">describe_reduce_nb()</a></code>.</p>
<p>For <code>percentiles</code>, see <code>pd.DataFrame.describe</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.describe()
              a         b        c
count  5.000000  5.000000  5.00000
mean   3.000000  3.000000  1.80000
std    1.581139  1.581139  0.83666
min    1.000000  1.000000  1.00000
25%    2.000000  2.000000  1.00000
50%    3.000000  3.000000  2.00000
75%    4.000000  4.000000  2.00000
max    5.000000  5.000000  3.00000
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def describe(self, percentiles: tp.Optional[tp.ArrayLike] = None, ddof: int = 1,
             group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.describe_reduce_nb`.

    For `percentiles`, see `pd.DataFrame.describe`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.describe()
                  a         b        c
    count  5.000000  5.000000  5.00000
    mean   3.000000  3.000000  1.80000
    std    1.581139  1.581139  0.83666
    min    1.000000  1.000000  1.00000
    25%    2.000000  2.000000  1.00000
    50%    3.000000  3.000000  2.00000
    75%    4.000000  4.000000  2.00000
    max    5.000000  5.000000  3.00000
    ```
    &#34;&#34;&#34;
    if percentiles is not None:
        percentiles = reshape_fns.to_1d_array(percentiles)
    else:
        percentiles = np.array([0.25, 0.5, 0.75])
    percentiles = percentiles.tolist()
    if 0.5 not in percentiles:
        percentiles.append(0.5)
    percentiles = np.unique(percentiles)
    perc_formatted = pd.io.formats.format.format_percentiles(percentiles)
    index = pd.Index([&#39;count&#39;, &#39;mean&#39;, &#39;std&#39;, &#39;min&#39;, *perc_formatted, &#39;max&#39;])
    wrap_kwargs = merge_dicts(dict(name_or_index=index), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.describe_reduce_nb, percentiles, ddof,
            group_by=group_by, flatten=True, returns_array=True,
            wrap_kwargs=wrap_kwargs)
    return self.reduce(
        nb.describe_reduce_nb, percentiles, ddof,
        returns_array=True, wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.diff"><code class="name flex">
<span>def <span class="ident child-name">diff</span></span>(<span class="params">self, n=1, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.diff_nb" href="nb.html#vectorbt.generic.nb.diff_nb">diff_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.drawdown"><code class="name flex">
<span>def <span class="ident child-name">drawdown</span></span>(<span class="params">self, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Drawdown series.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drawdown(self, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Drawdown series.&#34;&#34;&#34;
    out = self.to_2d_array() / nb.expanding_max_nb(self.to_2d_array()) - 1
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ewm_mean"><code class="name flex">
<span>def <span class="ident child-name">ewm_mean</span></span>(<span class="params">self, span, minp=0, adjust=True, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.ewm_mean_nb" href="nb.html#vectorbt.generic.nb.ewm_mean_nb">ewm_mean_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ewm_mean(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True,
             wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_mean_nb`.&#34;&#34;&#34;
    out = nb.ewm_mean_nb(self.to_2d_array(), span, minp=minp, adjust=adjust)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ewm_std"><code class="name flex">
<span>def <span class="ident child-name">ewm_std</span></span>(<span class="params">self, span, minp=0, adjust=True, ddof=1, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.ewm_std_nb" href="nb.html#vectorbt.generic.nb.ewm_std_nb">ewm_std_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ewm_std(self, span: int, minp: tp.Optional[int] = 0, adjust: bool = True, ddof: int = 1,
            wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.ewm_std_nb`.&#34;&#34;&#34;
    out = nb.ewm_std_nb(self.to_2d_array(), span, minp=minp, adjust=adjust, ddof=ddof)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_apply"><code class="name flex">
<span>def <span class="ident child-name">expanding_apply</span></span>(<span class="params">self, apply_func_nb, *args, minp=1, on_matrix=False, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_apply_nb" href="nb.html#vectorbt.generic.nb.expanding_apply_nb">expanding_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.expanding_matrix_apply_nb" href="nb.html#vectorbt.generic.nb.expanding_matrix_apply_nb">expanding_matrix_apply_nb()</a></code> for <code>on_matrix=True</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
              a    b    c
2020-01-01  1.0  5.0  1.0
2020-01-02  1.5  4.5  1.5
2020-01-03  2.0  4.0  2.0
2020-01-04  2.5  3.5  2.0
2020-01-05  3.0  3.0  1.8

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                   a         b         c
2020-01-01  2.333333  2.333333  2.333333
2020-01-02  2.500000  2.500000  2.500000
2020-01-03  2.666667  2.666667  2.666667
2020-01-04  2.666667  2.666667  2.666667
2020-01-05  2.600000  2.600000  2.600000
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expanding_apply(self, apply_func_nb: tp.Union[tp.RollApplyFunc, nb.tp.RollMatrixApplyFunc],
                    *args, minp: tp.Optional[int] = 1, on_matrix: bool = False,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_apply_nb` and
    `vectorbt.generic.nb.expanding_matrix_apply_nb` for `on_matrix=True`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.expanding_apply(mean_nb)
                  a    b    c
    2020-01-01  1.0  5.0  1.0
    2020-01-02  1.5  4.5  1.5
    2020-01-03  2.0  4.0  2.0
    2020-01-04  2.5  3.5  2.0
    2020-01-05  3.0  3.0  1.8

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.expanding_apply(mean_matrix_nb, on_matrix=True)
                       a         b         c
    2020-01-01  2.333333  2.333333  2.333333
    2020-01-02  2.500000  2.500000  2.500000
    2020-01-03  2.666667  2.666667  2.666667
    2020-01-04  2.666667  2.666667  2.666667
    2020-01-05  2.600000  2.600000  2.600000
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    if on_matrix:
        out = nb.expanding_matrix_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
    else:
        out = nb.expanding_apply_nb(self.to_2d_array(), minp, apply_func_nb, *args)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_max"><code class="name flex">
<span>def <span class="ident child-name">expanding_max</span></span>(<span class="params">self, minp=1, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_max_nb" href="nb.html#vectorbt.generic.nb.expanding_max_nb">expanding_max_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_mean"><code class="name flex">
<span>def <span class="ident child-name">expanding_mean</span></span>(<span class="params">self, minp=1, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_mean_nb" href="nb.html#vectorbt.generic.nb.expanding_mean_nb">expanding_mean_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_min"><code class="name flex">
<span>def <span class="ident child-name">expanding_min</span></span>(<span class="params">self, minp=1, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_min_nb" href="nb.html#vectorbt.generic.nb.expanding_min_nb">expanding_min_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_split"><code class="name flex">
<span>def <span class="ident child-name">expanding_split</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Split using <code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">GenericAccessor.split()</a></code> on <code><a title="vectorbt.generic.splitters.ExpandingSplitter" href="splitters.html#vectorbt.generic.splitters.ExpandingSplitter">ExpandingSplitter</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
&gt;&gt;&gt; train_set[0]
split_idx    0    1    2    3    4    5    6  7
0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
&gt;&gt;&gt; valid_set[0]
split_idx  0  1  2  3  4  5  6  7
0          1  2  3  4  5  6  7  8
&gt;&gt;&gt; test_set[0]
split_idx  0  1  2  3  4  5  6  7
0          2  3  4  5  6  7  8  9

&gt;&gt;&gt; sr.vbt.expanding_split(
...     set_lens=(1, 1), min_len=3, left_to_right=False,
...     plot=True, trace_names=['train', 'valid', 'test'])
</code></pre>
<p><img alt="" src="/docs/img/expanding_split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expanding_split(self, **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.ExpandingSplitter`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.expanding_split(
    ...     n=5, set_lens=(1, 1), min_len=3, left_to_right=False)
    &gt;&gt;&gt; train_set[0]
    split_idx    0    1    2    3    4    5    6  7
    0          0.0  0.0  0.0  0.0  0.0  0.0  0.0  0
    1          NaN  1.0  1.0  1.0  1.0  1.0  1.0  1
    2          NaN  NaN  2.0  2.0  2.0  2.0  2.0  2
    3          NaN  NaN  NaN  3.0  3.0  3.0  3.0  3
    4          NaN  NaN  NaN  NaN  4.0  4.0  4.0  4
    5          NaN  NaN  NaN  NaN  NaN  5.0  5.0  5
    6          NaN  NaN  NaN  NaN  NaN  NaN  6.0  6
    7          NaN  NaN  NaN  NaN  NaN  NaN  NaN  7
    &gt;&gt;&gt; valid_set[0]
    split_idx  0  1  2  3  4  5  6  7
    0          1  2  3  4  5  6  7  8
    &gt;&gt;&gt; test_set[0]
    split_idx  0  1  2  3  4  5  6  7
    0          2  3  4  5  6  7  8  9

    &gt;&gt;&gt; sr.vbt.expanding_split(
    ...     set_lens=(1, 1), min_len=3, left_to_right=False,
    ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
    ```

    ![](/docs/img/expanding_split_plot.svg)
    &#34;&#34;&#34;
    return self.split(ExpandingSplitter(), **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.expanding_std"><code class="name flex">
<span>def <span class="ident child-name">expanding_std</span></span>(<span class="params">self, minp=1, ddof=1, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.expanding_std_nb" href="nb.html#vectorbt.generic.nb.expanding_std_nb">expanding_std_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def expanding_std(self, minp: tp.Optional[int] = 1, ddof: int = 1,
                  wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.expanding_std_nb`.&#34;&#34;&#34;
    out = nb.expanding_std_nb(self.to_2d_array(), minp=minp, ddof=ddof)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.ffill"><code class="name flex">
<span>def <span class="ident child-name">ffill</span></span>(<span class="params">self, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.ffill_nb" href="nb.html#vectorbt.generic.nb.ffill_nb">ffill_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.fillna"><code class="name flex">
<span>def <span class="ident child-name">fillna</span></span>(<span class="params">self, value, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.fillna_nb" href="nb.html#vectorbt.generic.nb.fillna_nb">fillna_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.filter"><code class="name flex">
<span>def <span class="ident child-name">filter</span></span>(<span class="params">self, filter_func_nb, *args, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.filter_nb" href="nb.html#vectorbt.generic.nb.filter_nb">filter_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
&gt;&gt;&gt; df.vbt.filter(greater_nb)
              a    b    c
2020-01-01  NaN  5.0  NaN
2020-01-02  NaN  4.0  NaN
2020-01-03  3.0  3.0  3.0
2020-01-04  4.0  NaN  NaN
2020-01-05  5.0  NaN  NaN
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, filter_func_nb: tp.FilterFunc, *args,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.filter_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; greater_nb = njit(lambda i, col, a: a &gt; 2)
    &gt;&gt;&gt; df.vbt.filter(greater_nb)
                  a    b    c
    2020-01-01  NaN  5.0  NaN
    2020-01-02  NaN  4.0  NaN
    2020-01-03  3.0  3.0  3.0
    2020-01-04  4.0  NaN  NaN
    2020-01-05  5.0  NaN  NaN
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(filter_func_nb)

    out = nb.filter_nb(self.to_2d_array(), filter_func_nb, *args)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.fshift"><code class="name flex">
<span>def <span class="ident child-name">fshift</span></span>(<span class="params">self, n=1, fill_value=nan, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.fshift_nb" href="nb.html#vectorbt.generic.nb.fshift_nb">fshift_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.get_drawdowns"><code class="name flex">
<span>def <span class="ident child-name">get_drawdowns</span></span>(<span class="params">self, wrapper_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Generate drawdown records.</p>
<p>See <code><a title="vectorbt.generic.drawdowns.Drawdowns" href="drawdowns.html#vectorbt.generic.drawdowns.Drawdowns">Drawdowns</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_drawdowns(self, wrapper_kwargs: tp.KwargsLike = None, **kwargs) -&gt; Drawdowns:
    &#34;&#34;&#34;Generate drawdown records.

    See `vectorbt.generic.drawdowns.Drawdowns`.&#34;&#34;&#34;
    wrapper_kwargs = merge_dicts(self.wrapper.config, wrapper_kwargs)
    return Drawdowns.from_ts(self.obj, wrapper_kwargs=wrapper_kwargs, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.get_ranges"><code class="name flex">
<span>def <span class="ident child-name">get_ranges</span></span>(<span class="params">self, wrapper_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Generate range records.</p>
<p>See <code><a title="vectorbt.generic.ranges.Ranges" href="ranges.html#vectorbt.generic.ranges.Ranges">Ranges</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_ranges(self, wrapper_kwargs: tp.KwargsLike = None, **kwargs) -&gt; Ranges:
    &#34;&#34;&#34;Generate range records.

    See `vectorbt.generic.ranges.Ranges`.&#34;&#34;&#34;
    wrapper_kwargs = merge_dicts(self.wrapper.config, wrapper_kwargs)
    return Ranges.from_ts(self.obj, wrapper_kwargs=wrapper_kwargs, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.groupby_apply"><code class="name flex">
<span>def <span class="ident child-name">groupby_apply</span></span>(<span class="params">self, by, apply_func_nb, *args, on_matrix=False, wrap_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.groupby_apply_nb" href="nb.html#vectorbt.generic.nb.groupby_apply_nb">groupby_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.groupby_matrix_apply_nb" href="nb.html#vectorbt.generic.nb.groupby_matrix_apply_nb">groupby_matrix_apply_nb()</a></code> for <code>on_matrix=True</code>.</p>
<p>For <code>by</code>, see <code>pd.DataFrame.groupby</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
     a    b    c
1  1.5  4.5  1.5
2  3.5  2.5  2.5
3  5.0  1.0  1.0

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
          a         b         c
1  2.500000  2.500000  2.500000
2  2.833333  2.833333  2.833333
3  2.333333  2.333333  2.333333
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupby_apply(self, by: tp.PandasGroupByLike,
                  apply_func_nb: tp.Union[tp.GroupByApplyFunc, tp.GroupByMatrixApplyFunc],
                  *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                  **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
    `vectorbt.generic.nb.groupby_matrix_apply_nb` for `on_matrix=True`.

    For `by`, see `pd.DataFrame.groupby`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_nb)
         a    b    c
    1  1.5  4.5  1.5
    2  3.5  2.5  2.5
    3  5.0  1.0  1.0

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.groupby_apply([1, 1, 2, 2, 3], mean_matrix_nb, on_matrix=True)
              a         b         c
    1  2.500000  2.500000  2.500000
    2  2.833333  2.833333  2.833333
    3  2.333333  2.333333  2.333333
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    regrouped = self.obj.groupby(by, axis=0, **kwargs)
    groups = Dict()
    for i, (k, v) in enumerate(regrouped.indices.items()):
        groups[i] = np.asarray(v)
    if on_matrix:
        out = nb.groupby_matrix_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    else:
        out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    wrap_kwargs = merge_dicts(dict(name_or_index=list(regrouped.indices.keys())), wrap_kwargs)
    return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.histplot"><code class="name flex">
<span>def <span class="ident child-name">histplot</span></span>(<span class="params">self, trace_names=None, group_by=None, return_fig=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Histogram" href="plotting.html#vectorbt.generic.plotting.Histogram">Histogram</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.histplot()
</code></pre>
<p><img alt="" src="/docs/img/df_histplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def histplot(self,
             trace_names: tp.TraceNames = None,
             group_by: tp.GroupByLike = None,
             return_fig: bool = True,
             **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Histogram]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Histogram` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.histplot()
    ```

    ![](/docs/img/df_histplot.svg)
    &#34;&#34;&#34;
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.flatten_grouped(group_by=group_by).vbt.histplot(trace_names=trace_names, **kwargs)

    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    hist = plotting.Histogram(
        data=self.to_2d_array(),
        trace_names=trace_names,
        **kwargs
    )
    if return_fig:
        return hist.fig
    return hist</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.idxmax"><code class="name flex">
<span>def <span class="ident child-name">idxmax</span></span>(<span class="params">self, group_by=None, order='C', wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return labeled index of max of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def idxmax(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return labeled index of max of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmax&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.argmax_reduce_nb,
            group_by=group_by,
            flatten=True,
            returns_idx=True,
            order=order,
            wrap_kwargs=wrap_kwargs
        )

    obj = self.to_2d_array()
    out = np.full(obj.shape[1], np.nan, dtype=object)
    nan_mask = np.all(np.isnan(obj), axis=0)
    out[~nan_mask] = self.wrapper.index[nanargmax(obj[:, ~nan_mask], axis=0)]
    return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.idxmin"><code class="name flex">
<span>def <span class="ident child-name">idxmin</span></span>(<span class="params">self, group_by=None, order='C', wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return labeled index of min of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def idxmin(self, group_by: tp.GroupByLike = None, order: str = &#39;C&#39;,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return labeled index of min of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;idxmin&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.argmin_reduce_nb,
            group_by=group_by,
            flatten=True,
            returns_idx=True,
            order=order,
            wrap_kwargs=wrap_kwargs
        )

    obj = self.to_2d_array()
    out = np.full(obj.shape[1], np.nan, dtype=object)
    nan_mask = np.all(np.isnan(obj), axis=0)
    out[~nan_mask] = self.wrapper.index[nanargmin(obj[:, ~nan_mask], axis=0)]
    return self.wrapper.wrap_reduced(out, group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.lineplot"><code class="name flex">
<span>def <span class="ident child-name">lineplot</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">GenericAccessor.plot()</a></code> with 'lines' mode.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.lineplot()
</code></pre>
<p><img alt="" src="/docs/img/df_lineplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lineplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
    &#34;&#34;&#34;`GenericAccessor.plot` with &#39;lines&#39; mode.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.lineplot()
    ```

    ![](/docs/img/df_lineplot.svg)
    &#34;&#34;&#34;
    return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;lines&#39;)), kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.max"><code class="name flex">
<span>def <span class="ident child-name">max</span></span>(<span class="params">self, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return max of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return max of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;max&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.max_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmax = np.nanmax
    else:
        _nanmax = nanmax
    return self.wrapper.wrap_reduced(_nanmax(arr, axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.maxabs_scale"><code class="name flex">
<span>def <span class="ident child-name">maxabs_scale</span></span>(<span class="params">self, *, copy=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.MaxAbsScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.mean"><code class="name flex">
<span>def <span class="ident child-name">mean</span></span>(<span class="params">self, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return mean of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return mean of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;mean&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(
            nb.mean_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmean = np.nanmean
    else:
        _nanmean = nanmean
    return self.wrapper.wrap_reduced(_nanmean(arr, axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.median"><code class="name flex">
<span>def <span class="ident child-name">median</span></span>(<span class="params">self, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return median of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def median(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return median of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;median&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.median_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmedian = np.nanmedian
    else:
        _nanmedian = nanmedian
    return self.wrapper.wrap_reduced(_nanmedian(arr, axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.min"><code class="name flex">
<span>def <span class="ident child-name">min</span></span>(<span class="params">self, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return min of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return min of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;min&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.min_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanmin = np.nanmin
    else:
        _nanmin = nanmin
    return self.wrapper.wrap_reduced(_nanmin(arr, axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.minmax_scale"><code class="name flex">
<span>def <span class="ident child-name">minmax_scale</span></span>(<span class="params">self, feature_range=(0, 1), *, copy=True, clip=False, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.MinMaxScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.normalize"><code class="name flex">
<span>def <span class="ident child-name">normalize</span></span>(<span class="params">self, norm='l2', *, copy=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.Normalizer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.pct_change"><code class="name flex">
<span>def <span class="ident child-name">pct_change</span></span>(<span class="params">self, n=1, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.pct_change_nb" href="nb.html#vectorbt.generic.nb.pct_change_nb">pct_change_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.plot"><code class="name flex">
<span>def <span class="ident child-name">plot</span></span>(<span class="params">self, trace_names=None, x_labels=None, return_fig=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Scatter" href="plotting.html#vectorbt.generic.plotting.Scatter">Scatter</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.plot()
</code></pre>
<p><img alt="" src="/docs/img/df_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self,
         trace_names: tp.TraceNames = None,
         x_labels: tp.Optional[tp.Labels] = None,
         return_fig: bool = True,
         **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Scatter` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.plot()
    ```

    ![](/docs/img/df_plot.svg)
    &#34;&#34;&#34;
    if x_labels is None:
        x_labels = self.wrapper.index
    if trace_names is None:
        if self.is_frame() or (self.is_series() and self.wrapper.name is not None):
            trace_names = self.wrapper.columns
    scatter = plotting.Scatter(
        data=self.to_2d_array(),
        trace_names=trace_names,
        x_labels=x_labels,
        **kwargs
    )
    if return_fig:
        return scatter.fig
    return scatter</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.power_transform"><code class="name flex">
<span>def <span class="ident child-name">power_transform</span></span>(<span class="params">self, method='yeo-johnson', *, standardize=True, copy=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.PowerTransformer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.product"><code class="name flex">
<span>def <span class="ident child-name">product</span></span>(<span class="params">self, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.nanprod_nb" href="nb.html#vectorbt.generic.nb.nanprod_nb">nanprod_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.quantile_transform"><code class="name flex">
<span>def <span class="ident child-name">quantile_transform</span></span>(<span class="params">self, *, n_quantiles=1000, output_distribution='uniform', ignore_implicit_zeros=False, subsample=100000, random_state=None, copy=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.QuantileTransformer</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.range_split"><code class="name flex">
<span>def <span class="ident child-name">range_split</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Split using <code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">GenericAccessor.split()</a></code> on <code><a title="vectorbt.generic.splitters.RangeSplitter" href="splitters.html#vectorbt.generic.splitters.RangeSplitter">RangeSplitter</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
&gt;&gt;&gt; range_df
split_idx  0  1
0          0  5
1          1  6
2          2  7
3          3  8
4          4  9
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-06', ..., '2020-01-10'], dtype='datetime64[ns]', name='split_1')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
&gt;&gt;&gt; range_df
split_idx  0  1  2  3  4  5  6
0          0  1  2  3  4  5  6
1          1  2  3  4  5  6  7
2          2  3  4  5  6  7  8
3          3  4  5  6  7  8  9
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-02', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-03', ..., '2020-01-06'], dtype='datetime64[ns]', name='split_2'),
 DatetimeIndex(['2020-01-04', ..., '2020-01-07'], dtype='datetime64[ns]', name='split_3'),
 DatetimeIndex(['2020-01-05', ..., '2020-01-08'], dtype='datetime64[ns]', name='split_4'),
 DatetimeIndex(['2020-01-06', ..., '2020-01-09'], dtype='datetime64[ns]', name='split_5'),
 DatetimeIndex(['2020-01-07', ..., '2020-01-10'], dtype='datetime64[ns]', name='split_6')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
&gt;&gt;&gt; range_df
split_idx  0  1
0          0  2
1          1  3
2          2  4
3          3  5
4          4  6
5          5  7
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-06'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-03', ..., '2020-01-08'], dtype='datetime64[ns]', name='split_1')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
&gt;&gt;&gt; range_df
split_idx    0    1  2
0          0.0  0.0  0
1          1.0  1.0  1
2          2.0  2.0  2
3          NaN  3.0  3
4          NaN  NaN  4
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-03'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_2')]

&gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
...     start_idxs=pd.Index(['2020-01-01', '2020-01-02']),
...     end_idxs=pd.Index(['2020-01-04', '2020-01-05'])
... )
&gt;&gt;&gt; range_df
split_idx  0  1
0          0  1
1          1  2
2          2  3
3          3  4
&gt;&gt;&gt; range_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-02', ..., '2020-01-05'], dtype='datetime64[ns]', name='split_1')]

 &gt;&gt;&gt; sr.vbt.range_split(
 ...    start_idxs=pd.Index(['2020-01-01', '2020-01-02', '2020-01-01']),
 ...    end_idxs=pd.Index(['2020-01-08', '2020-01-04', '2020-01-07']),
 ...    plot=True
 ... )
</code></pre>
<p><img alt="" src="/docs/img/range_split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def range_split(self, **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RangeSplitter`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(n=2)
    &gt;&gt;&gt; range_df
    split_idx  0  1
    0          0  5
    1          1  6
    2          2  7
    3          3  8
    4          4  9
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(range_len=4)
    &gt;&gt;&gt; range_df
    split_idx  0  1  2  3  4  5  6
    0          0  1  2  3  4  5  6
    1          1  2  3  4  5  6  7
    2          2  3  4  5  6  7  8
    3          3  4  5  6  7  8  9
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;),
     DatetimeIndex([&#39;2020-01-04&#39;, ..., &#39;2020-01-07&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_3&#39;),
     DatetimeIndex([&#39;2020-01-05&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_4&#39;),
     DatetimeIndex([&#39;2020-01-06&#39;, ..., &#39;2020-01-09&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_5&#39;),
     DatetimeIndex([&#39;2020-01-07&#39;, ..., &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_6&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0, 2], end_idxs=[5, 7])
    &gt;&gt;&gt; range_df
    split_idx  0  1
    0          0  2
    1          1  3
    2          2  4
    3          3  5
    4          4  6
    5          5  7
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-03&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(start_idxs=[0], end_idxs=[2, 3, 4])
    &gt;&gt;&gt; range_df
    split_idx    0    1  2
    0          0.0  0.0  0
    1          1.0  1.0  1
    2          2.0  2.0  2
    3          NaN  3.0  3
    4          NaN  NaN  4
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-03&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

    &gt;&gt;&gt; range_df, range_indexes = sr.vbt.range_split(
    ...     start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;]),
    ...     end_idxs=pd.Index([&#39;2020-01-04&#39;, &#39;2020-01-05&#39;])
    ... )
    &gt;&gt;&gt; range_df
    split_idx  0  1
    0          0  1
    1          1  2
    2          2  3
    3          3  4
    &gt;&gt;&gt; range_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-02&#39;, ..., &#39;2020-01-05&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;)]

     &gt;&gt;&gt; sr.vbt.range_split(
     ...    start_idxs=pd.Index([&#39;2020-01-01&#39;, &#39;2020-01-02&#39;, &#39;2020-01-01&#39;]),
     ...    end_idxs=pd.Index([&#39;2020-01-08&#39;, &#39;2020-01-04&#39;, &#39;2020-01-07&#39;]),
     ...    plot=True
     ... )
    ```

    ![](/docs/img/range_split_plot.svg)
    &#34;&#34;&#34;
    return self.split(RangeSplitter(), **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rebase"><code class="name flex">
<span>def <span class="ident child-name">rebase</span></span>(<span class="params">self, base, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Rebase all series to a given intial base.</p>
<p>This makes comparing/plotting different series together easier.
Will forward and backward fill NaN values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rebase(self, base: float, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Rebase all series to a given intial base.

    This makes comparing/plotting different series together easier.
    Will forward and backward fill NaN values.&#34;&#34;&#34;
    result = nb.bfill_nb(nb.ffill_nb(self.to_2d_array()))
    result = result / result[0] * base
    return self.wrapper.wrap(result, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.reduce"><code class="name flex">
<span>def <span class="ident child-name">reduce</span></span>(<span class="params">self, reduce_func_nb, *args, returns_array=False, returns_idx=False, flatten=False, order='C', to_index=True, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce by column.</p>
<p>See <code><a title="vectorbt.generic.nb.flat_reduce_grouped_to_array_nb" href="nb.html#vectorbt.generic.nb.flat_reduce_grouped_to_array_nb">flat_reduce_grouped_to_array_nb()</a></code> if grouped, <code>returns_array</code> is True and <code>flatten</code> is True.
See <code><a title="vectorbt.generic.nb.flat_reduce_grouped_nb" href="nb.html#vectorbt.generic.nb.flat_reduce_grouped_nb">flat_reduce_grouped_nb()</a></code> if grouped, <code>returns_array</code> is False and <code>flatten</code> is True.
See <code><a title="vectorbt.generic.nb.reduce_grouped_to_array_nb" href="nb.html#vectorbt.generic.nb.reduce_grouped_to_array_nb">reduce_grouped_to_array_nb()</a></code> if grouped, <code>returns_array</code> is True and <code>flatten</code> is False.
See <code><a title="vectorbt.generic.nb.reduce_grouped_nb" href="nb.html#vectorbt.generic.nb.reduce_grouped_nb">reduce_grouped_nb()</a></code> if grouped, <code>returns_array</code> is False and <code>flatten</code> is False.
See <code><a title="vectorbt.generic.nb.reduce_to_array_nb" href="nb.html#vectorbt.generic.nb.reduce_to_array_nb">reduce_to_array_nb()</a></code> if not grouped and <code>returns_array</code> is True.
See <code><a title="vectorbt.generic.nb.reduce_nb" href="nb.html#vectorbt.generic.nb.reduce_nb">reduce_nb()</a></code> if not grouped and <code>returns_array</code> is False.</p>
<p>Set <code>returns_idx</code> to True if values returned by <code>reduce_func_nb</code> are indices/positions.
Set <code>to_index</code> to False to return raw positions instead of labels.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.reduce(mean_nb)
a    3.0
b    3.0
c    1.8
dtype: float64

&gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
&gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True)
a   2020-01-05
b   2020-01-01
c   2020-01-03
dtype: datetime64[ns]

&gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
&gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True, to_index=False)
a    4
b    0
c    2
dtype: int64

&gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
&gt;&gt;&gt; df.vbt.reduce(min_max_nb, returns_array=True, wrap_kwargs=dict(name_or_index=['min', 'max']))
       a    b    c
min  1.0  1.0  1.0
max  5.0  5.0  3.0

&gt;&gt;&gt; group_by = pd.Series(['first', 'first', 'second'], name='group')
&gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
group
first     3.0
second    1.8
dtype: float64

&gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=['min', 'max'],
...     returns_array=True, group_by=group_by)
group  first  second
min      1.0     1.0
max      5.0     3.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reduce(self,
           reduce_func_nb: tp.Union[
               tp.FlatGroupReduceFunc,
               tp.FlatGroupReduceArrayFunc,
               tp.GroupReduceFunc,
               tp.GroupReduceArrayFunc,
               tp.ReduceFunc,
               tp.ReduceArrayFunc
           ],
           *args,
           returns_array: bool = False,
           returns_idx: bool = False,
           flatten: bool = False,
           order: str = &#39;C&#39;,
           to_index: bool = True,
           group_by: tp.GroupByLike = None,
           wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeriesFrame[float]:
    &#34;&#34;&#34;Reduce by column.

    See `vectorbt.generic.nb.flat_reduce_grouped_to_array_nb` if grouped, `returns_array` is True and `flatten` is True.
    See `vectorbt.generic.nb.flat_reduce_grouped_nb` if grouped, `returns_array` is False and `flatten` is True.
    See `vectorbt.generic.nb.reduce_grouped_to_array_nb` if grouped, `returns_array` is True and `flatten` is False.
    See `vectorbt.generic.nb.reduce_grouped_nb` if grouped, `returns_array` is False and `flatten` is False.
    See `vectorbt.generic.nb.reduce_to_array_nb` if not grouped and `returns_array` is True.
    See `vectorbt.generic.nb.reduce_nb` if not grouped and `returns_array` is False.

    Set `returns_idx` to True if values returned by `reduce_func_nb` are indices/positions.
    Set `to_index` to False to return raw positions instead of labels.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.reduce(mean_nb)
    a    3.0
    b    3.0
    c    1.8
    dtype: float64

    &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
    &gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True)
    a   2020-01-05
    b   2020-01-01
    c   2020-01-03
    dtype: datetime64[ns]

    &gt;&gt;&gt; argmax_nb = njit(lambda col, a: np.argmax(a))
    &gt;&gt;&gt; df.vbt.reduce(argmax_nb, returns_idx=True, to_index=False)
    a    4
    b    0
    c    2
    dtype: int64

    &gt;&gt;&gt; min_max_nb = njit(lambda col, a: np.array([np.nanmin(a), np.nanmax(a)]))
    &gt;&gt;&gt; df.vbt.reduce(min_max_nb, returns_array=True, wrap_kwargs=dict(name_or_index=[&#39;min&#39;, &#39;max&#39;]))
           a    b    c
    min  1.0  1.0  1.0
    max  5.0  5.0  3.0

    &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
    &gt;&gt;&gt; df.vbt.reduce(mean_nb, group_by=group_by)
    group
    first     3.0
    second    1.8
    dtype: float64

    &gt;&gt;&gt; df.vbt.reduce(min_max_nb, name_or_index=[&#39;min&#39;, &#39;max&#39;],
    ...     returns_array=True, group_by=group_by)
    group  first  second
    min      1.0     1.0
    max      5.0     3.0
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(reduce_func_nb)

    if self.wrapper.grouper.is_grouped(group_by=group_by):
        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        if flatten:
            checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])
            in_c_order = order.upper() == &#39;C&#39;
            if returns_array:
                out = nb.flat_reduce_grouped_to_array_nb(
                    self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
            else:
                out = nb.flat_reduce_grouped_nb(
                    self.to_2d_array(), group_lens, in_c_order, reduce_func_nb, *args)
            if returns_idx:
                if in_c_order:
                    out //= group_lens  # flattened in C order
                else:
                    out %= self.wrapper.shape[0]  # flattened in F order
        else:
            if returns_array:
                out = nb.reduce_grouped_to_array_nb(
                    self.to_2d_array(), group_lens, reduce_func_nb, *args)
            else:
                out = nb.reduce_grouped_nb(
                    self.to_2d_array(), group_lens, reduce_func_nb, *args)
    else:
        if returns_array:
            out = nb.reduce_to_array_nb(
                self.to_2d_array(), reduce_func_nb, *args)
        else:
            out = nb.reduce_nb(
                self.to_2d_array(), reduce_func_nb, *args)

    # Perform post-processing
    wrap_kwargs = merge_dicts(dict(
        name_or_index=&#39;reduce&#39; if not returns_array else None,
        to_index=returns_idx and to_index,
        fillna=-1 if returns_idx else None,
        dtype=np.int_ if returns_idx else None
    ), wrap_kwargs)
    return self.wrapper.wrap_reduced(out, group_by=group_by, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.resample_apply"><code class="name flex">
<span>def <span class="ident child-name">resample_apply</span></span>(<span class="params">self, freq, apply_func_nb, *args, on_matrix=False, wrap_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.groupby_apply_nb" href="nb.html#vectorbt.generic.nb.groupby_apply_nb">groupby_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.groupby_matrix_apply_nb" href="nb.html#vectorbt.generic.nb.groupby_matrix_apply_nb">groupby_matrix_apply_nb()</a></code> for <code>on_matrix=True</code>.</p>
<p>For <code>freq</code>, see <code>pd.DataFrame.resample</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.resample_apply('2d', mean_nb)
              a    b    c
2020-01-01  1.5  4.5  1.5
2020-01-03  3.5  2.5  2.5
2020-01-05  5.0  1.0  1.0

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.resample_apply('2d', mean_matrix_nb, on_matrix=True)
                   a         b         c
2020-01-01  2.500000  2.500000  2.500000
2020-01-03  2.833333  2.833333  2.833333
2020-01-05  2.333333  2.333333  2.333333
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resample_apply(self, freq: tp.PandasFrequencyLike,
                   apply_func_nb: tp.Union[tp.GroupByApplyFunc, tp.GroupByMatrixApplyFunc],
                   *args, on_matrix: bool = False, wrap_kwargs: tp.KwargsLike = None,
                   **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.groupby_apply_nb` and
    `vectorbt.generic.nb.groupby_matrix_apply_nb` for `on_matrix=True`.

    For `freq`, see `pd.DataFrame.resample`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_nb)
                  a    b    c
    2020-01-01  1.5  4.5  1.5
    2020-01-03  3.5  2.5  2.5
    2020-01-05  5.0  1.0  1.0

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.resample_apply(&#39;2d&#39;, mean_matrix_nb, on_matrix=True)
                       a         b         c
    2020-01-01  2.500000  2.500000  2.500000
    2020-01-03  2.833333  2.833333  2.833333
    2020-01-05  2.333333  2.333333  2.333333
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    resampled = self.obj.resample(freq, axis=0, **kwargs)
    groups = Dict()
    for i, (k, v) in enumerate(resampled.indices.items()):
        groups[i] = np.asarray(v)
    if on_matrix:
        out = nb.groupby_matrix_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    else:
        out = nb.groupby_apply_nb(self.to_2d_array(), groups, apply_func_nb, *args)
    out_obj = self.wrapper.wrap(out, group_by=False, index=list(resampled.indices.keys()))
    resampled_arr = np.full((resampled.ngroups, self.to_2d_array().shape[1]), np.nan)
    resampled_obj = self.wrapper.wrap(
        resampled_arr,
        index=resampled.asfreq().index,
        group_by=False,
        **merge_dicts({}, wrap_kwargs)
    )
    resampled_obj.loc[out_obj.index] = out_obj.values
    return resampled_obj</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.resolve_self"><code class="name flex">
<span>def <span class="ident child-name">resolve_self</span></span>(<span class="params">self, cond_kwargs=None, custom_arg_names=None, impacts_caching=True, silence_warnings=False)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Resolve self.</p>
<p>See <code><a title="vectorbt.base.array_wrapper.Wrapping.resolve_self" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.resolve_self">Wrapping.resolve_self()</a></code>.</p>
<p>Creates a copy of this instance <code>mapping</code> is different in <code>cond_kwargs</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resolve_self(self: GenericAccessorT,
                 cond_kwargs: tp.KwargsLike = None,
                 custom_arg_names: tp.Optional[tp.Set[str]] = None,
                 impacts_caching: bool = True,
                 silence_warnings: bool = False) -&gt; GenericAccessorT:
    &#34;&#34;&#34;Resolve self.

    See `vectorbt.base.array_wrapper.Wrapping.resolve_self`.

    Creates a copy of this instance `mapping` is different in `cond_kwargs`.&#34;&#34;&#34;
    if cond_kwargs is None:
        cond_kwargs = {}
    if custom_arg_names is None:
        custom_arg_names = set()

    reself = Wrapping.resolve_self(
        self,
        cond_kwargs=cond_kwargs,
        custom_arg_names=custom_arg_names,
        impacts_caching=impacts_caching,
        silence_warnings=silence_warnings
    )
    if &#39;mapping&#39; in cond_kwargs:
        self_copy = reself.replace(mapping=cond_kwargs[&#39;mapping&#39;])

        if not checks.is_deep_equal(self_copy.mapping, reself.mapping):
            if not silence_warnings:
                warnings.warn(f&#34;Changing the mapping will create a copy of this object. &#34;
                              f&#34;Consider setting it upon object creation to re-use existing cache.&#34;, stacklevel=2)
            for alias in reself.self_aliases:
                if alias not in custom_arg_names:
                    cond_kwargs[alias] = self_copy
            cond_kwargs[&#39;mapping&#39;] = self_copy.mapping
            if impacts_caching:
                cond_kwargs[&#39;use_caching&#39;] = False
            return self_copy
    return reself</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.robust_scale"><code class="name flex">
<span>def <span class="ident child-name">robust_scale</span></span>(<span class="params">self, *, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True, unit_variance=False, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.RobustScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_apply"><code class="name flex">
<span>def <span class="ident child-name">rolling_apply</span></span>(<span class="params">self, window, apply_func_nb, *args, minp=None, on_matrix=False, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_apply_nb" href="nb.html#vectorbt.generic.nb.rolling_apply_nb">rolling_apply_nb()</a></code> and
<code><a title="vectorbt.generic.nb.rolling_matrix_apply_nb" href="nb.html#vectorbt.generic.nb.rolling_matrix_apply_nb">rolling_matrix_apply_nb()</a></code> for <code>on_matrix=True</code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
              a    b         c
2020-01-01  1.0  5.0  1.000000
2020-01-02  1.5  4.5  1.500000
2020-01-03  2.0  4.0  2.000000
2020-01-04  3.0  3.0  2.333333
2020-01-05  4.0  2.0  2.000000

&gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                   a         b         c
2020-01-01  2.333333  2.333333  2.333333
2020-01-02  2.500000  2.500000  2.500000
2020-01-03  2.666667  2.666667  2.666667
2020-01-04  2.777778  2.777778  2.777778
2020-01-05  2.666667  2.666667  2.666667
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rolling_apply(self, window: int, apply_func_nb: tp.Union[tp.RollApplyFunc, nb.tp.RollMatrixApplyFunc],
                  *args, minp: tp.Optional[int] = None, on_matrix: bool = False,
                  wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_apply_nb` and
    `vectorbt.generic.nb.rolling_matrix_apply_nb` for `on_matrix=True`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; mean_nb = njit(lambda i, col, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_nb)
                  a    b         c
    2020-01-01  1.0  5.0  1.000000
    2020-01-02  1.5  4.5  1.500000
    2020-01-03  2.0  4.0  2.000000
    2020-01-04  3.0  3.0  2.333333
    2020-01-05  4.0  2.0  2.000000

    &gt;&gt;&gt; mean_matrix_nb = njit(lambda i, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.rolling_apply(3, mean_matrix_nb, on_matrix=True)
                       a         b         c
    2020-01-01  2.333333  2.333333  2.333333
    2020-01-02  2.500000  2.500000  2.500000
    2020-01-03  2.666667  2.666667  2.666667
    2020-01-04  2.777778  2.777778  2.777778
    2020-01-05  2.666667  2.666667  2.666667
    ```
    &#34;&#34;&#34;
    checks.assert_numba_func(apply_func_nb)

    if on_matrix:
        out = nb.rolling_matrix_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
    else:
        out = nb.rolling_apply_nb(self.to_2d_array(), window, minp, apply_func_nb, *args)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_max"><code class="name flex">
<span>def <span class="ident child-name">rolling_max</span></span>(<span class="params">self, window, minp=None, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_max_nb" href="nb.html#vectorbt.generic.nb.rolling_max_nb">rolling_max_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_mean"><code class="name flex">
<span>def <span class="ident child-name">rolling_mean</span></span>(<span class="params">self, window, minp=None, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_mean_nb" href="nb.html#vectorbt.generic.nb.rolling_mean_nb">rolling_mean_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_min"><code class="name flex">
<span>def <span class="ident child-name">rolling_min</span></span>(<span class="params">self, window, minp=None, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_min_nb" href="nb.html#vectorbt.generic.nb.rolling_min_nb">rolling_min_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_split"><code class="name flex">
<span>def <span class="ident child-name">rolling_split</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Split using <code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">GenericAccessor.split()</a></code> on <code><a title="vectorbt.generic.splitters.RollingSplitter" href="splitters.html#vectorbt.generic.splitters.RollingSplitter">RollingSplitter</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
...     window_len=5, set_lens=(1, 1), left_to_right=False)
&gt;&gt;&gt; train_set[0]
split_idx  0  1  2  3  4  5
0          0  1  2  3  4  5
1          1  2  3  4  5  6
2          2  3  4  5  6  7
&gt;&gt;&gt; valid_set[0]
split_idx  0  1  2  3  4  5
0          3  4  5  6  7  8
&gt;&gt;&gt; test_set[0]
split_idx  0  1  2  3  4  5
0          4  5  6  7  8  9

&gt;&gt;&gt; sr.vbt.rolling_split(
...     window_len=5, set_lens=(1, 1), left_to_right=False,
...     plot=True, trace_names=['train', 'valid', 'test'])
</code></pre>
<p><img alt="" src="/docs/img/rolling_split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rolling_split(self, **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using `GenericAccessor.split` on `vectorbt.generic.splitters.RollingSplitter`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; train_set, valid_set, test_set = sr.vbt.rolling_split(
    ...     window_len=5, set_lens=(1, 1), left_to_right=False)
    &gt;&gt;&gt; train_set[0]
    split_idx  0  1  2  3  4  5
    0          0  1  2  3  4  5
    1          1  2  3  4  5  6
    2          2  3  4  5  6  7
    &gt;&gt;&gt; valid_set[0]
    split_idx  0  1  2  3  4  5
    0          3  4  5  6  7  8
    &gt;&gt;&gt; test_set[0]
    split_idx  0  1  2  3  4  5
    0          4  5  6  7  8  9

    &gt;&gt;&gt; sr.vbt.rolling_split(
    ...     window_len=5, set_lens=(1, 1), left_to_right=False,
    ...     plot=True, trace_names=[&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;])
    ```

    ![](/docs/img/rolling_split_plot.svg)
    &#34;&#34;&#34;
    return self.split(RollingSplitter(), **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.rolling_std"><code class="name flex">
<span>def <span class="ident child-name">rolling_std</span></span>(<span class="params">self, window, minp=None, ddof=1, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.rolling_std_nb" href="nb.html#vectorbt.generic.nb.rolling_std_nb">rolling_std_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rolling_std(self, window: int, minp: tp.Optional[int] = None, ddof: int = 1,
                wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:  # pragma: no cover
    &#34;&#34;&#34;See `vectorbt.generic.nb.rolling_std_nb`.&#34;&#34;&#34;
    out = nb.rolling_std_nb(self.to_2d_array(), window, minp=minp, ddof=ddof)
    return self.wrapper.wrap(out, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.scale"><code class="name flex">
<span>def <span class="ident child-name">scale</span></span>(<span class="params">self, *, copy=True, with_mean=True, with_std=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code>sklearn.preprocessing.StandardScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               _target_name: str = target_name,
               _transformer: tp.Union[tp.Type[TransformerT], TransformerT] = transformer,
               **kwargs) -&gt; tp.SeriesFrame:
    if inspect.isclass(_transformer):
        arg_names = get_func_arg_names(_transformer.__init__)
        transformer_kwargs = dict()
        for arg_name in arg_names:
            if arg_name in kwargs:
                transformer_kwargs[arg_name] = kwargs.pop(arg_name)
        return self.transform(_transformer(**transformer_kwargs), **kwargs)
    return self.transform(_transformer, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.scatterplot"><code class="name flex">
<span>def <span class="ident child-name">scatterplot</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">GenericAccessor.plot()</a></code> with 'markers' mode.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df.vbt.scatterplot()
</code></pre>
<p><img alt="" src="/docs/img/df_scatterplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scatterplot(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Scatter]:  # pragma: no cover
    &#34;&#34;&#34;`GenericAccessor.plot` with &#39;markers&#39; mode.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df.vbt.scatterplot()
    ```

    ![](/docs/img/df_scatterplot.svg)
    &#34;&#34;&#34;
    return self.plot(**merge_dicts(dict(trace_kwargs=dict(mode=&#39;markers&#39;)), kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.shuffle"><code class="name flex">
<span>def <span class="ident child-name">shuffle</span></span>(<span class="params">self, seed=None, *, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>See <code><a title="vectorbt.generic.nb.shuffle_nb" href="nb.html#vectorbt.generic.nb.shuffle_nb">shuffle_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_method(self,
               *args,
               _target_name: str = target_name,
               _func: tp.Callable = func,
               _is_reducing: bool = is_reducing,
               _default_wrap_kwargs: tp.KwargsLike = default_wrap_kwargs,
               wrap_kwargs: tp.KwargsLike = None,
               **kwargs) -&gt; tp.SeriesFrame:
    args = (self.to_2d_array(),) + args
    inspect.signature(_func).bind(*args, **kwargs)

    a = _func(*args, **kwargs)
    wrap_kwargs = merge_dicts(_default_wrap_kwargs, wrap_kwargs)
    if _is_reducing:
        return self.wrapper.wrap_reduced(a, **wrap_kwargs)
    return self.wrapper.wrap(a, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.split"><code class="name flex">
<span>def <span class="ident child-name">split</span></span>(<span class="params">self, splitter, stack_kwargs=None, keys=None, plot=False, trace_names=None, heatmap_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Split using a splitter.</p>
<p>Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.</p>
<p>A splitter can be any class instance that has <code>split</code> method, ideally subclassing
<code>sklearn.model_selection.BaseCrossValidator</code> or <code><a title="vectorbt.generic.splitters.BaseSplitter" href="splitters.html#vectorbt.generic.splitters.BaseSplitter">BaseSplitter</a></code>.</p>
<p><code>heatmap_kwargs</code> are passed to <code><a title="vectorbt.generic.plotting.Heatmap" href="plotting.html#vectorbt.generic.plotting.Heatmap">Heatmap</a></code> if <code>plot</code> is True,
can be a dictionary or a list per set, for example, to set trace name for each set ('train', 'test', etc.).</p>
<p><code>**kwargs</code> are passed to the <code>split</code> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The datetime-like format of the index will be lost as result of this operation.
Make sure to store the index metadata such as frequency information beforehand.</p>
</div>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

&gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
&gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

&gt;&gt;&gt; train_df
split_idx    0    1  2
0          0.0  0.0  0
1          1.0  1.0  1
2          2.0  2.0  2
3          3.0  3.0  3
4          NaN  4.0  4
5          NaN  5.0  5
6          NaN  NaN  6
7          NaN  NaN  7
&gt;&gt;&gt; train_indexes
[DatetimeIndex(['2020-01-01', ..., '2020-01-04'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-06'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-01', ..., '2020-01-08'], dtype='datetime64[ns]', name='split_2')]
&gt;&gt;&gt; test_df
split_idx  0  1  2
0          4  6  8
1          5  7  9
&gt;&gt;&gt; test_indexes
[DatetimeIndex(['2020-01-05', '2020-01-06'], dtype='datetime64[ns]', name='split_0'),
 DatetimeIndex(['2020-01-07', '2020-01-08'], dtype='datetime64[ns]', name='split_1'),
 DatetimeIndex(['2020-01-09', '2020-01-10'], dtype='datetime64[ns]', name='split_2')]

&gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=['train', 'test'])
</code></pre>
<p><img alt="" src="/docs/img/split_plot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split(self, splitter: SplitterT, stack_kwargs: tp.KwargsLike = None, keys: tp.Optional[tp.IndexLike] = None,
          plot: bool = False, trace_names: tp.TraceNames = None, heatmap_kwargs: tp.KwargsLike = None,
          **kwargs) -&gt; SplitOutputT:
    &#34;&#34;&#34;Split using a splitter.

    Returns a tuple of tuples, each corresponding to a set and composed of a dataframe and split indexes.

    A splitter can be any class instance that has `split` method, ideally subclassing
    `sklearn.model_selection.BaseCrossValidator` or `vectorbt.generic.splitters.BaseSplitter`.

    `heatmap_kwargs` are passed to `vectorbt.generic.plotting.Heatmap` if `plot` is True,
    can be a dictionary or a list per set, for example, to set trace name for each set (&#39;train&#39;, &#39;test&#39;, etc.).

    `**kwargs` are passed to the `split` method.

    !!! note
        The datetime-like format of the index will be lost as result of this operation.
        Make sure to store the index metadata such as frequency information beforehand.

    ## Example

    ```python-repl
    &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit

    &gt;&gt;&gt; splitter = TimeSeriesSplit(n_splits=3)
    &gt;&gt;&gt; (train_df, train_indexes), (test_df, test_indexes) = sr.vbt.split(splitter)

    &gt;&gt;&gt; train_df
    split_idx    0    1  2
    0          0.0  0.0  0
    1          1.0  1.0  1
    2          2.0  2.0  2
    3          3.0  3.0  3
    4          NaN  4.0  4
    5          NaN  5.0  5
    6          NaN  NaN  6
    7          NaN  NaN  7
    &gt;&gt;&gt; train_indexes
    [DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-04&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-01&#39;, ..., &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]
    &gt;&gt;&gt; test_df
    split_idx  0  1  2
    0          4  6  8
    1          5  7  9
    &gt;&gt;&gt; test_indexes
    [DatetimeIndex([&#39;2020-01-05&#39;, &#39;2020-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_0&#39;),
     DatetimeIndex([&#39;2020-01-07&#39;, &#39;2020-01-08&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_1&#39;),
     DatetimeIndex([&#39;2020-01-09&#39;, &#39;2020-01-10&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;split_2&#39;)]

    &gt;&gt;&gt; sr.vbt.split(splitter, plot=True, trace_names=[&#39;train&#39;, &#39;test&#39;])
    ```

    ![](/docs/img/split_plot.svg)
    &#34;&#34;&#34;
    total_range_sr = pd.Series(np.arange(len(self.wrapper.index)), index=self.wrapper.index)
    set_ranges = list(splitter.split(total_range_sr, **kwargs))
    if len(set_ranges) == 0:
        raise ValueError(&#34;No splits were generated&#34;)
    idxs_by_split_and_set = list(zip(*set_ranges))

    results = []
    if keys is not None:
        if not isinstance(keys, pd.Index):
            keys = pd.Index(keys)
    for idxs_by_split in idxs_by_split_and_set:
        split_dfs = []
        split_indexes = []
        for split_idx, idxs in enumerate(idxs_by_split):
            split_dfs.append(self.obj.iloc[idxs].reset_index(drop=True))
            if keys is not None:
                split_name = keys[split_idx]
            else:
                split_name = &#39;split_&#39; + str(split_idx)
            split_indexes.append(pd.Index(self.wrapper.index[idxs], name=split_name))
        set_df = pd.concat(split_dfs, axis=1).reset_index(drop=True)
        if keys is not None:
            split_columns = keys
        else:
            split_columns = pd.Index(np.arange(len(split_indexes)), name=&#39;split_idx&#39;)
        split_columns = index_fns.repeat_index(split_columns, len(self.wrapper.columns))
        if stack_kwargs is None:
            stack_kwargs = {}
        set_df = set_df.vbt.stack_index(split_columns, **stack_kwargs)
        results.append((set_df, split_indexes))

    if plot:  # pragma: no cover
        if trace_names is None:
            trace_names = list(range(len(results)))
        if isinstance(trace_names, str):
            trace_names = [trace_names]
        nan_df = pd.DataFrame(np.nan, columns=pd.RangeIndex(stop=len(results[0][1])), index=self.wrapper.index)
        fig = None
        for i, (_, split_indexes) in enumerate(results):
            heatmap_df = nan_df.copy()
            for j in range(len(split_indexes)):
                heatmap_df.loc[split_indexes[j], j] = i
            _heatmap_kwargs = resolve_dict(heatmap_kwargs, i=i)
            fig = heatmap_df.vbt.ts_heatmap(fig=fig, **merge_dicts(
                dict(
                    trace_kwargs=dict(
                        showscale=False,
                        name=str(trace_names[i]),
                        showlegend=True
                    )
                ),
                _heatmap_kwargs
            ))
            if fig.layout.colorway is not None:
                colorway = fig.layout.colorway
            else:
                colorway = fig.layout.template.layout.colorway
            if &#39;colorscale&#39; not in _heatmap_kwargs:
                fig.data[-1].update(colorscale=[colorway[i], colorway[i]])
        return fig

    if len(results) == 1:
        return results[0]
    return tuple(results)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.std"><code class="name flex">
<span>def <span class="ident child-name">std</span></span>(<span class="params">self, ddof=1, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return standard deviation of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self, ddof: int = 1, group_by: tp.GroupByLike = None,
        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return standard deviation of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;std&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.std_reduce_nb, ddof, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nanstd = np.nanstd
    else:
        _nanstd = nanstd
    return self.wrapper.wrap_reduced(_nanstd(arr, ddof=ddof, axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.sum"><code class="name flex">
<span>def <span class="ident child-name">sum</span></span>(<span class="params">self, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return sum of non-NaN elements.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self, group_by: tp.GroupByLike = None, wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Return sum of non-NaN elements.&#34;&#34;&#34;
    wrap_kwargs = merge_dicts(dict(name_or_index=&#39;sum&#39;), wrap_kwargs)
    if self.wrapper.grouper.is_grouped(group_by=group_by):
        return self.reduce(nb.sum_reduce_nb, group_by=group_by, flatten=True, wrap_kwargs=wrap_kwargs)

    arr = self.to_2d_array()
    if arr.dtype != int and arr.dtype != float:
        # bottleneck can&#39;t consume other than that
        _nansum = np.nansum
    else:
        _nansum = nansum
    return self.wrapper.wrap_reduced(_nansum(arr, axis=0), group_by=False, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.to_mapped"><code class="name flex">
<span>def <span class="ident child-name">to_mapped</span></span>(<span class="params">self, dropna=True, dtype=None, group_by=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Convert this object into an instance of <code><a title="vectorbt.records.mapped_array.MappedArray" href="../records/mapped_array.html#vectorbt.records.mapped_array.MappedArray">MappedArray</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_mapped(self,
              dropna: bool = True,
              dtype: tp.Optional[tp.DTypeLike] = None,
              group_by: tp.GroupByLike = None,
              **kwargs) -&gt; MappedArray:
    &#34;&#34;&#34;Convert this object into an instance of `vectorbt.records.mapped_array.MappedArray`.&#34;&#34;&#34;
    mapped_arr = self.to_2d_array().flatten(order=&#39;F&#39;)
    col_arr = np.repeat(np.arange(self.wrapper.shape_2d[1]), self.wrapper.shape_2d[0])
    idx_arr = np.tile(np.arange(self.wrapper.shape_2d[0]), self.wrapper.shape_2d[1])
    if dropna and np.isnan(mapped_arr).any():
        not_nan_mask = ~np.isnan(mapped_arr)
        mapped_arr = mapped_arr[not_nan_mask]
        col_arr = col_arr[not_nan_mask]
        idx_arr = idx_arr[not_nan_mask]
    return MappedArray(
        self.wrapper,
        np.asarray(mapped_arr, dtype=dtype),
        col_arr,
        idx_arr=idx_arr,
        **kwargs
    ).regroup(group_by)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.to_returns"><code class="name flex">
<span>def <span class="ident child-name">to_returns</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Get returns of this object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_returns(self, **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Get returns of this object.&#34;&#34;&#34;
    return self.obj.vbt.returns.from_value(self.obj, **kwargs).obj</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.transform"><code class="name flex">
<span>def <span class="ident child-name">transform</span></span>(<span class="params">self, transformer, wrap_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Transform using a transformer.</p>
<p>A transformer can be any class instance that has <code>transform</code> and <code>fit_transform</code> methods,
ideally subclassing <code>sklearn.base.TransformerMixin</code> and <code>sklearn.base.BaseEstimator</code>.</p>
<p>Will fit <code>transformer</code> if not fitted.</p>
<p><code>**kwargs</code> are passed to the <code>transform</code> or <code>fit_transform</code> method.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

&gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
              a    b    c
2020-01-01 -1.0  1.0 -1.0
2020-01-02 -0.5  0.5  0.0
2020-01-03  0.0  0.0  1.0
2020-01-04  0.5 -0.5  0.0
2020-01-05  1.0 -1.0 -1.0

&gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
&gt;&gt;&gt; df.vbt.transform(fitted_scaler)
              a    b    c
2020-01-01 -2.0  2.0 -2.0
2020-01-02 -1.0  1.0 -1.0
2020-01-03  0.0  0.0  0.0
2020-01-04  1.0 -1.0 -1.0
2020-01-05  2.0 -2.0 -2.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, transformer: TransformerT, wrap_kwargs: tp.KwargsLike = None, **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Transform using a transformer.

    A transformer can be any class instance that has `transform` and `fit_transform` methods,
    ideally subclassing `sklearn.base.TransformerMixin` and `sklearn.base.BaseEstimator`.

    Will fit `transformer` if not fitted.

    `**kwargs` are passed to the `transform` or `fit_transform` method.

    ## Example

    ```python-repl
    &gt;&gt;&gt; from sklearn.preprocessing import MinMaxScaler

    &gt;&gt;&gt; df.vbt.transform(MinMaxScaler((-1, 1)))
                  a    b    c
    2020-01-01 -1.0  1.0 -1.0
    2020-01-02 -0.5  0.5  0.0
    2020-01-03  0.0  0.0  1.0
    2020-01-04  0.5 -0.5  0.0
    2020-01-05  1.0 -1.0 -1.0

    &gt;&gt;&gt; fitted_scaler = MinMaxScaler((-1, 1)).fit(np.array([[2], [4]]))
    &gt;&gt;&gt; df.vbt.transform(fitted_scaler)
                  a    b    c
    2020-01-01 -2.0  2.0 -2.0
    2020-01-02 -1.0  1.0 -1.0
    2020-01-03  0.0  0.0  0.0
    2020-01-04  1.0 -1.0 -1.0
    2020-01-05  2.0 -2.0 -2.0
    ```&#34;&#34;&#34;
    is_fitted = True
    try:
        check_is_fitted(transformer)
    except NotFittedError:
        is_fitted = False
    if not is_fitted:
        result = transformer.fit_transform(self.to_2d_array(), **kwargs)
    else:
        result = transformer.transform(self.to_2d_array(), **kwargs)
    return self.wrapper.wrap(result, group_by=False, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.value_counts"><code class="name flex">
<span>def <span class="ident child-name">value_counts</span></span>(<span class="params">self, normalize=False, sort_uniques=True, sort=False, ascending=False, dropna=False, group_by=None, mapping=None, incl_all_keys=False, wrap_kwargs=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return a Series/DataFrame containing counts of unique values.</p>
<ul>
<li>Enable <code>normalize</code> flag to return the relative frequencies of the unique values.</li>
<li>Enable <code>sort_uniques</code> flag to sort uniques.</li>
<li>Enable <code>sort</code> flag to sort by frequencies.</li>
<li>Enable <code>ascending</code> flag to sort in ascending order.</li>
<li>Enable <code>dropna</code> flag to exclude counts of NaN.</li>
<li>Enable <code>incl_all_keys</code> to include all mapping keys, no only those that are present in the array.</li>
</ul>
<p>Mapping will be applied using <code><a title="vectorbt.utils.mapping.apply_mapping" href="../utils/mapping.html#vectorbt.utils.mapping.apply_mapping">apply_mapping()</a></code> with <code>**kwargs</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def value_counts(self,
                 normalize: bool = False,
                 sort_uniques: bool = True,
                 sort: bool = False,
                 ascending: bool = False,
                 dropna: bool = False,
                 group_by: tp.GroupByLike = None,
                 mapping: tp.Optional[tp.MappingLike] = None,
                 incl_all_keys: bool = False,
                 wrap_kwargs: tp.KwargsLike = None,
                 **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Return a Series/DataFrame containing counts of unique values.

    * Enable `normalize` flag to return the relative frequencies of the unique values.
    * Enable `sort_uniques` flag to sort uniques.
    * Enable `sort` flag to sort by frequencies.
    * Enable `ascending` flag to sort in ascending order.
    * Enable `dropna` flag to exclude counts of NaN.
    * Enable `incl_all_keys` to include all mapping keys, no only those that are present in the array.

    Mapping will be applied using `vectorbt.utils.mapping.apply_mapping` with `**kwargs`.&#34;&#34;&#34;
    if mapping is None:
        mapping = self.mapping
    if isinstance(mapping, str):
        if mapping.lower() == &#39;index&#39;:
            mapping = self.wrapper.index
        elif mapping.lower() == &#39;columns&#39;:
            mapping = self.wrapper.columns
        mapping = to_mapping(mapping)
    codes, uniques = pd.factorize(self.obj.values.flatten(), sort=False, na_sentinel=None)
    codes = codes.reshape(self.wrapper.shape_2d)
    group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
    value_counts = nb.value_counts_nb(codes, len(uniques), group_lens)
    if incl_all_keys and mapping is not None:
        missing_keys = []
        for x in mapping:
            if pd.isnull(x) and pd.isnull(uniques).any():
                continue
            if x not in uniques:
                missing_keys.append(x)
        value_counts = np.vstack((value_counts, np.full((len(missing_keys), value_counts.shape[1]), 0)))
        uniques = np.concatenate((uniques, np.array(missing_keys)))
    nan_mask = np.isnan(uniques)
    if dropna:
        value_counts = value_counts[~nan_mask]
        uniques = uniques[~nan_mask]
    if sort_uniques:
        new_indices = uniques.argsort()
        value_counts = value_counts[new_indices]
        uniques = uniques[new_indices]
    value_counts_sum = value_counts.sum(axis=1)
    if normalize:
        value_counts = value_counts / value_counts_sum.sum()
    if sort:
        if ascending:
            new_indices = value_counts_sum.argsort()
        else:
            new_indices = (-value_counts_sum).argsort()
        value_counts = value_counts[new_indices]
        uniques = uniques[new_indices]
    value_counts_pd = self.wrapper.wrap(
        value_counts,
        index=uniques,
        group_by=group_by,
        **merge_dicts({}, wrap_kwargs)
    )
    if mapping is not None:
        value_counts_pd.index = apply_mapping(value_counts_pd.index, mapping, **kwargs)
    return value_counts_pd</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericAccessor.zscore"><code class="name flex">
<span>def <span class="ident child-name">zscore</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Compute z-score using <code>sklearn.preprocessing.StandardScaler</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def zscore(self, **kwargs) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Compute z-score using `sklearn.preprocessing.StandardScaler`.&#34;&#34;&#34;
    return self.scale(with_mean=True, with_std=True, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.base.accessors.BaseAccessor.align_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.align_to">align_to</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.apply" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply">apply</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.apply_and_concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_and_concat">apply_and_concat</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.apply_on_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_on_index">apply_on_index</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.broadcast" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast">broadcast</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.broadcast_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast_to">broadcast_to</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.combine" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.combine">combine</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.concat">concat</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.config" href="../utils/config.html#vectorbt.utils.config.Configured.config">config</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.copy" href="../utils/config.html#vectorbt.utils.config.Configured.copy">copy</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.deep_getattr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.deep_getattr">deep_getattr</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.df_accessor_cls" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.df_accessor_cls">df_accessor_cls</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels">drop_duplicate_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.drop_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_levels">drop_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.drop_redundant_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_redundant_levels">drop_redundant_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.dumps" href="../utils/config.html#vectorbt.utils.config.Pickleable.dumps">dumps</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.empty" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty">empty</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.empty_like" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty_like">empty_like</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.iloc" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.iloc">iloc</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.indexing_func" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.indexing_func">indexing_func</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.indexing_kwargs" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.indexing_kwargs">indexing_kwargs</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.load" href="../utils/config.html#vectorbt.utils.config.Pickleable.load">load</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.loads" href="../utils/config.html#vectorbt.utils.config.Pickleable.loads">loads</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.loc" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.loc">loc</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.make_symmetric" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.make_symmetric">make_symmetric</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.obj" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.obj">obj</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.post_resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.post_resolve_attr">post_resolve_attr</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.pre_resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.pre_resolve_attr">pre_resolve_attr</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.regroup" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.regroup">regroup</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.rename_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.rename_levels">rename_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.repeat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.repeat">repeat</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.replace" href="../utils/config.html#vectorbt.utils.config.Configured.replace">replace</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.resolve_attr">resolve_attr</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.save" href="../utils/config.html#vectorbt.utils.config.Pickleable.save">save</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.select_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.select_levels">select_levels</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.select_one" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.select_one">select_one</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.select_one_from_obj" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.select_one_from_obj">select_one_from_obj</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.self_aliases" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.self_aliases">self_aliases</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.sr_accessor_cls" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.sr_accessor_cls">sr_accessor_cls</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.stack_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.stack_index">stack_index</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.tile" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.tile">tile</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.to_1d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_1d_array">to_1d_array</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.to_2d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_2d_array">to_2d_array</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.to_dict" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_dict">to_dict</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.to_doc" href="../utils/docs.html#vectorbt.utils.docs.Documented.to_doc">to_doc</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.unstack_to_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_array">unstack_to_array</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.unstack_to_df" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_df">unstack_to_df</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.update_config" href="../utils/config.html#vectorbt.utils.config.Configured.update_config">update_config</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.wrapper" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.wrapper">wrapper</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.writeable_attrs" href="../utils/config.html#vectorbt.utils.config.Configured.writeable_attrs">writeable_attrs</a></code></li>
<li><code><a title="vectorbt.base.accessors.BaseAccessor.xs" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.xs">xs</a></code></li>
</ul>
</li>
<li><code><b><a title="vectorbt.generic.stats_builder.StatsBuilderMixin" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin">StatsBuilderMixin</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.stats_builder.StatsBuilderMixin.build_metrics_doc" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.build_metrics_doc">build_metrics_doc</a></code></li>
<li><code><a title="vectorbt.generic.stats_builder.StatsBuilderMixin.override_metrics_doc" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.override_metrics_doc">override_metrics_doc</a></code></li>
<li><code><a title="vectorbt.generic.stats_builder.StatsBuilderMixin.stats" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats">stats</a></code></li>
</ul>
</li>
<li><code><b><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin">PlotsBuilderMixin</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin.build_subplots_doc" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.build_subplots_doc">build_subplots_doc</a></code></li>
<li><code><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin.override_subplots_doc" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.override_subplots_doc">override_subplots_doc</a></code></li>
<li><code><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin.plots" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.plots">plots</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.GenericDFAccessor"><code class="flex name class">
<span>class <span class="ident parent-name">GenericDFAccessor</span></span>
(<span class="params">obj, mapping=None, **kwargs</span>)
</code></dt>
<dd>
<div class="desc"><p>Accessor on top of data of any type. For DataFrames only.</p>
<p>Accessible through <code>pd.DataFrame.vbt</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenericDFAccessor(GenericAccessor, BaseDFAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For DataFrames only.

    Accessible through `pd.DataFrame.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Frame, mapping: tp.Optional[tp.MappingLike] = None, **kwargs) -&gt; None:
        BaseDFAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, mapping=mapping, **kwargs)

    def squeeze_grouped(self,
                        squeeze_func_nb: tp.GroupSqueezeFunc, *args,
                        group_by: tp.GroupByLike = None,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Squeeze each group of columns into a single column.

        See `vectorbt.generic.nb.squeeze_grouped_nb`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; mean_squeeze_nb = njit(lambda i, group, a: np.nanmean(a))
        &gt;&gt;&gt; df.vbt.squeeze_grouped(mean_squeeze_nb, group_by=group_by)
        group       first  second
        2020-01-01    3.0     1.0
        2020-01-02    3.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    3.0     2.0
        2020-01-05    3.0     1.0
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_numba_func(squeeze_func_nb)

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        out = nb.squeeze_grouped_nb(self.to_2d_array(), group_lens, squeeze_func_nb, *args)
        return self.wrapper.wrap(out, group_by=group_by, **merge_dicts({}, wrap_kwargs))

    def flatten_grouped(self,
                        group_by: tp.GroupByLike = None,
                        order: str = &#39;C&#39;,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
        &#34;&#34;&#34;Flatten each group of columns.

        See `vectorbt.generic.nb.flatten_grouped_nb`.
        If all groups have the same length, see `vectorbt.generic.nb.flatten_uniform_grouped_nb`.

        !!! warning
            Make sure that the distribution of group lengths is close to uniform, otherwise
            groups with less columns will be filled with NaN and needlessly occupy memory.

        ## Example

        ```python-repl
        &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;C&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    2.0     2.0
        2020-01-02    4.0     NaN
        2020-01-03    3.0     3.0
        2020-01-03    3.0     NaN
        2020-01-04    4.0     2.0
        2020-01-04    2.0     NaN
        2020-01-05    5.0     1.0
        2020-01-05    1.0     NaN

        &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;F&#39;)
        group       first  second
        2020-01-01    1.0     1.0
        2020-01-02    2.0     2.0
        2020-01-03    3.0     3.0
        2020-01-04    4.0     2.0
        2020-01-05    5.0     1.0
        2020-01-01    5.0     NaN
        2020-01-02    4.0     NaN
        2020-01-03    3.0     NaN
        2020-01-04    2.0     NaN
        2020-01-05    1.0     NaN
        ```
        &#34;&#34;&#34;
        if not self.wrapper.grouper.is_grouped(group_by=group_by):
            raise ValueError(&#34;Grouping required&#34;)
        checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])

        group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
        if np.all(group_lens == group_lens.item(0)):
            func = nb.flatten_uniform_grouped_nb
        else:
            func = nb.flatten_grouped_nb
        if order.upper() == &#39;C&#39;:
            out = func(self.to_2d_array(), group_lens, True)
            new_index = index_fns.repeat_index(self.wrapper.index, np.max(group_lens))
        else:
            out = func(self.to_2d_array(), group_lens, False)
            new_index = index_fns.tile_index(self.wrapper.index, np.max(group_lens))
        wrap_kwargs = merge_dicts(dict(index=new_index), wrap_kwargs)
        return self.wrapper.wrap(out, group_by=group_by, **wrap_kwargs)

    def heatmap(self,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create `vectorbt.generic.plotting.Heatmap` and return the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df = pd.DataFrame([
        ...     [0, np.nan, np.nan],
        ...     [np.nan, 1, np.nan],
        ...     [np.nan, np.nan, 2]
        ... ])
        &gt;&gt;&gt; df.vbt.heatmap()
        ```

        ![](/docs/img/df_heatmap.svg)
        &#34;&#34;&#34;
        if x_labels is None:
            x_labels = self.wrapper.columns
        if y_labels is None:
            y_labels = self.wrapper.index
        heatmap = plotting.Heatmap(
            data=self.to_2d_array(),
            x_labels=x_labels,
            y_labels=y_labels,
            **kwargs
        )
        if return_fig:
            return heatmap.fig
        return heatmap

    def ts_heatmap(self, is_y_category: bool = True,
                   **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self.obj.transpose().iloc[::-1].vbt.heatmap(is_y_category=is_y_category, **kwargs)</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseDFAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseDFAccessor">BaseDFAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></li>
<li><a title="vectorbt.base.array_wrapper.Wrapping" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping">Wrapping</a></li>
<li><a title="vectorbt.utils.config.Configured" href="../utils/config.html#vectorbt.utils.config.Configured">Configured</a></li>
<li><a title="vectorbt.utils.config.Pickleable" href="../utils/config.html#vectorbt.utils.config.Pickleable">Pickleable</a></li>
<li><a title="vectorbt.utils.docs.Documented" href="../utils/docs.html#vectorbt.utils.docs.Documented">Documented</a></li>
<li><a title="vectorbt.base.indexing.PandasIndexer" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer">PandasIndexer</a></li>
<li><a title="vectorbt.base.indexing.IndexingBase" href="../base/indexing.html#vectorbt.base.indexing.IndexingBase">IndexingBase</a></li>
<li><a title="vectorbt.utils.attr.AttrResolver" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver">AttrResolver</a></li>
<li><a title="vectorbt.generic.stats_builder.StatsBuilderMixin" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin">StatsBuilderMixin</a></li>
<li><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin">PlotsBuilderMixin</a></li>
</ul>
<h3 class="section-subtitle">Subclasses</h3>
<ul class="hlist">
<li><a title="vectorbt.ohlcv_accessors.OHLCVDFAccessor" href="../ohlcv_accessors.html#vectorbt.ohlcv_accessors.OHLCVDFAccessor">OHLCVDFAccessor</a></li>
<li><a title="vectorbt.returns.accessors.ReturnsDFAccessor" href="../returns/accessors.html#vectorbt.returns.accessors.ReturnsDFAccessor">ReturnsDFAccessor</a></li>
<li><a title="vectorbt.root_accessors.Vbt_DFAccessor" href="../root_accessors.html#vectorbt.root_accessors.Vbt_DFAccessor">Vbt_DFAccessor</a></li>
<li><a title="vectorbt.signals.accessors.SignalsDFAccessor" href="../signals/accessors.html#vectorbt.signals.accessors.SignalsDFAccessor">SignalsDFAccessor</a></li>
</ul>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped"><code class="name flex">
<span>def <span class="ident child-name">flatten_grouped</span></span>(<span class="params">self, group_by=None, order='C', wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Flatten each group of columns.</p>
<p>See <code><a title="vectorbt.generic.nb.flatten_grouped_nb" href="nb.html#vectorbt.generic.nb.flatten_grouped_nb">flatten_grouped_nb()</a></code>.
If all groups have the same length, see <code><a title="vectorbt.generic.nb.flatten_uniform_grouped_nb" href="nb.html#vectorbt.generic.nb.flatten_uniform_grouped_nb">flatten_uniform_grouped_nb()</a></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Make sure that the distribution of group lengths is close to uniform, otherwise
groups with less columns will be filled with NaN and needlessly occupy memory.</p>
</div>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; group_by = pd.Series(['first', 'first', 'second'], name='group')
&gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order='C')
group       first  second
2020-01-01    1.0     1.0
2020-01-01    5.0     NaN
2020-01-02    2.0     2.0
2020-01-02    4.0     NaN
2020-01-03    3.0     3.0
2020-01-03    3.0     NaN
2020-01-04    4.0     2.0
2020-01-04    2.0     NaN
2020-01-05    5.0     1.0
2020-01-05    1.0     NaN

&gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order='F')
group       first  second
2020-01-01    1.0     1.0
2020-01-02    2.0     2.0
2020-01-03    3.0     3.0
2020-01-04    4.0     2.0
2020-01-05    5.0     1.0
2020-01-01    5.0     NaN
2020-01-02    4.0     NaN
2020-01-03    3.0     NaN
2020-01-04    2.0     NaN
2020-01-05    1.0     NaN
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flatten_grouped(self,
                    group_by: tp.GroupByLike = None,
                    order: str = &#39;C&#39;,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Flatten each group of columns.

    See `vectorbt.generic.nb.flatten_grouped_nb`.
    If all groups have the same length, see `vectorbt.generic.nb.flatten_uniform_grouped_nb`.

    !!! warning
        Make sure that the distribution of group lengths is close to uniform, otherwise
        groups with less columns will be filled with NaN and needlessly occupy memory.

    ## Example

    ```python-repl
    &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
    &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;C&#39;)
    group       first  second
    2020-01-01    1.0     1.0
    2020-01-01    5.0     NaN
    2020-01-02    2.0     2.0
    2020-01-02    4.0     NaN
    2020-01-03    3.0     3.0
    2020-01-03    3.0     NaN
    2020-01-04    4.0     2.0
    2020-01-04    2.0     NaN
    2020-01-05    5.0     1.0
    2020-01-05    1.0     NaN

    &gt;&gt;&gt; df.vbt.flatten_grouped(group_by=group_by, order=&#39;F&#39;)
    group       first  second
    2020-01-01    1.0     1.0
    2020-01-02    2.0     2.0
    2020-01-03    3.0     3.0
    2020-01-04    4.0     2.0
    2020-01-05    5.0     1.0
    2020-01-01    5.0     NaN
    2020-01-02    4.0     NaN
    2020-01-03    3.0     NaN
    2020-01-04    2.0     NaN
    2020-01-05    1.0     NaN
    ```
    &#34;&#34;&#34;
    if not self.wrapper.grouper.is_grouped(group_by=group_by):
        raise ValueError(&#34;Grouping required&#34;)
    checks.assert_in(order.upper(), [&#39;C&#39;, &#39;F&#39;])

    group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
    if np.all(group_lens == group_lens.item(0)):
        func = nb.flatten_uniform_grouped_nb
    else:
        func = nb.flatten_grouped_nb
    if order.upper() == &#39;C&#39;:
        out = func(self.to_2d_array(), group_lens, True)
        new_index = index_fns.repeat_index(self.wrapper.index, np.max(group_lens))
    else:
        out = func(self.to_2d_array(), group_lens, False)
        new_index = index_fns.tile_index(self.wrapper.index, np.max(group_lens))
    wrap_kwargs = merge_dicts(dict(index=new_index), wrap_kwargs)
    return self.wrapper.wrap(out, group_by=group_by, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericDFAccessor.heatmap"><code class="name flex">
<span>def <span class="ident child-name">heatmap</span></span>(<span class="params">self, x_labels=None, y_labels=None, return_fig=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create <code><a title="vectorbt.generic.plotting.Heatmap" href="plotting.html#vectorbt.generic.plotting.Heatmap">Heatmap</a></code> and return the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df = pd.DataFrame([
...     [0, np.nan, np.nan],
...     [np.nan, 1, np.nan],
...     [np.nan, np.nan, 2]
... ])
&gt;&gt;&gt; df.vbt.heatmap()
</code></pre>
<p><img alt="" src="/docs/img/df_heatmap.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatmap(self,
            x_labels: tp.Optional[tp.Labels] = None,
            y_labels: tp.Optional[tp.Labels] = None,
            return_fig: bool = True,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Create `vectorbt.generic.plotting.Heatmap` and return the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df = pd.DataFrame([
    ...     [0, np.nan, np.nan],
    ...     [np.nan, 1, np.nan],
    ...     [np.nan, np.nan, 2]
    ... ])
    &gt;&gt;&gt; df.vbt.heatmap()
    ```

    ![](/docs/img/df_heatmap.svg)
    &#34;&#34;&#34;
    if x_labels is None:
        x_labels = self.wrapper.columns
    if y_labels is None:
        y_labels = self.wrapper.index
    heatmap = plotting.Heatmap(
        data=self.to_2d_array(),
        x_labels=x_labels,
        y_labels=y_labels,
        **kwargs
    )
    if return_fig:
        return heatmap.fig
    return heatmap</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped"><code class="name flex">
<span>def <span class="ident child-name">squeeze_grouped</span></span>(<span class="params">self, squeeze_func_nb, *args, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Squeeze each group of columns into a single column.</p>
<p>See <code><a title="vectorbt.generic.nb.squeeze_grouped_nb" href="nb.html#vectorbt.generic.nb.squeeze_grouped_nb">squeeze_grouped_nb()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; group_by = pd.Series(['first', 'first', 'second'], name='group')
&gt;&gt;&gt; mean_squeeze_nb = njit(lambda i, group, a: np.nanmean(a))
&gt;&gt;&gt; df.vbt.squeeze_grouped(mean_squeeze_nb, group_by=group_by)
group       first  second
2020-01-01    3.0     1.0
2020-01-02    3.0     2.0
2020-01-03    3.0     3.0
2020-01-04    3.0     2.0
2020-01-05    3.0     1.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squeeze_grouped(self,
                    squeeze_func_nb: tp.GroupSqueezeFunc, *args,
                    group_by: tp.GroupByLike = None,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.SeriesFrame:
    &#34;&#34;&#34;Squeeze each group of columns into a single column.

    See `vectorbt.generic.nb.squeeze_grouped_nb`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; group_by = pd.Series([&#39;first&#39;, &#39;first&#39;, &#39;second&#39;], name=&#39;group&#39;)
    &gt;&gt;&gt; mean_squeeze_nb = njit(lambda i, group, a: np.nanmean(a))
    &gt;&gt;&gt; df.vbt.squeeze_grouped(mean_squeeze_nb, group_by=group_by)
    group       first  second
    2020-01-01    3.0     1.0
    2020-01-02    3.0     2.0
    2020-01-03    3.0     3.0
    2020-01-04    3.0     2.0
    2020-01-05    3.0     1.0
    ```
    &#34;&#34;&#34;
    if not self.wrapper.grouper.is_grouped(group_by=group_by):
        raise ValueError(&#34;Grouping required&#34;)
    checks.assert_numba_func(squeeze_func_nb)

    group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
    out = nb.squeeze_grouped_nb(self.to_2d_array(), group_lens, squeeze_func_nb, *args)
    return self.wrapper.wrap(out, group_by=group_by, **merge_dicts({}, wrap_kwargs))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericDFAccessor.ts_heatmap"><code class="name flex">
<span>def <span class="ident child-name">ts_heatmap</span></span>(<span class="params">self, is_y_category=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Heatmap of time-series data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ts_heatmap(self, is_y_category: bool = True,
               **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
    return self.obj.transpose().iloc[::-1].vbt.heatmap(is_y_category=is_y_category, **kwargs)</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.align_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.align_to">align_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply">apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_along_axis" href="#vectorbt.generic.accessors.GenericAccessor.apply_along_axis">apply_along_axis</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_and_concat">apply_and_concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce" href="#vectorbt.generic.accessors.GenericAccessor.apply_and_reduce">apply_and_reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_mapping" href="#vectorbt.generic.accessors.GenericAccessor.apply_mapping">apply_mapping</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_on_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_on_index">apply_on_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.applymap" href="#vectorbt.generic.accessors.GenericAccessor.applymap">applymap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.barplot" href="#vectorbt.generic.accessors.GenericAccessor.barplot">barplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bfill" href="#vectorbt.generic.accessors.GenericAccessor.bfill">bfill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.binarize" href="#vectorbt.generic.accessors.GenericAccessor.binarize">binarize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.boxplot" href="#vectorbt.generic.accessors.GenericAccessor.boxplot">boxplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast">broadcast</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast_to">broadcast_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bshift" href="#vectorbt.generic.accessors.GenericAccessor.bshift">bshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.build_metrics_doc" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.build_metrics_doc">build_metrics_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.build_subplots_doc" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.build_subplots_doc">build_subplots_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.combine" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.combine">combine</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.concat">concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.config" href="../utils/config.html#vectorbt.utils.config.Configured.config">config</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.copy" href="../utils/config.html#vectorbt.utils.config.Configured.copy">copy</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.count" href="#vectorbt.generic.accessors.GenericAccessor.count">count</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumprod" href="#vectorbt.generic.accessors.GenericAccessor.cumprod">cumprod</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumsum" href="#vectorbt.generic.accessors.GenericAccessor.cumsum">cumsum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.deep_getattr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.deep_getattr">deep_getattr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.describe" href="#vectorbt.generic.accessors.GenericAccessor.describe">describe</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.df_accessor_cls" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.df_accessor_cls">df_accessor_cls</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.diff" href="#vectorbt.generic.accessors.GenericAccessor.diff">diff</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdown" href="#vectorbt.generic.accessors.GenericAccessor.drawdown">drawdown</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.drawdowns">drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_duplicate_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels">drop_duplicate_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_levels">drop_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_redundant_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_redundant_levels">drop_redundant_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.dumps" href="../utils/config.html#vectorbt.utils.config.Pickleable.dumps">dumps</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty">empty</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty_like" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty_like">empty_like</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_mean" href="#vectorbt.generic.accessors.GenericAccessor.ewm_mean">ewm_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_std" href="#vectorbt.generic.accessors.GenericAccessor.ewm_std">ewm_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_apply" href="#vectorbt.generic.accessors.GenericAccessor.expanding_apply">expanding_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_max" href="#vectorbt.generic.accessors.GenericAccessor.expanding_max">expanding_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_mean" href="#vectorbt.generic.accessors.GenericAccessor.expanding_mean">expanding_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_min" href="#vectorbt.generic.accessors.GenericAccessor.expanding_min">expanding_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_split" href="#vectorbt.generic.accessors.GenericAccessor.expanding_split">expanding_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_std" href="#vectorbt.generic.accessors.GenericAccessor.expanding_std">expanding_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ffill" href="#vectorbt.generic.accessors.GenericAccessor.ffill">ffill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fillna" href="#vectorbt.generic.accessors.GenericAccessor.fillna">fillna</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.filter" href="#vectorbt.generic.accessors.GenericAccessor.filter">filter</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fshift" href="#vectorbt.generic.accessors.GenericAccessor.fshift">fshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">get_drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_ranges" href="#vectorbt.generic.accessors.GenericAccessor.get_ranges">get_ranges</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.groupby_apply" href="#vectorbt.generic.accessors.GenericAccessor.groupby_apply">groupby_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.histplot" href="#vectorbt.generic.accessors.GenericAccessor.histplot">histplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmax" href="#vectorbt.generic.accessors.GenericAccessor.idxmax">idxmax</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmin" href="#vectorbt.generic.accessors.GenericAccessor.idxmin">idxmin</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.iloc" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.iloc">iloc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.indexing_func" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.indexing_func">indexing_func</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.indexing_kwargs" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.indexing_kwargs">indexing_kwargs</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.lineplot" href="#vectorbt.generic.accessors.GenericAccessor.lineplot">lineplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.load" href="../utils/config.html#vectorbt.utils.config.Pickleable.load">load</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.loads" href="../utils/config.html#vectorbt.utils.config.Pickleable.loads">loads</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.loc" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.loc">loc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.make_symmetric" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.make_symmetric">make_symmetric</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mapping" href="#vectorbt.generic.accessors.GenericAccessor.mapping">mapping</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.max" href="#vectorbt.generic.accessors.GenericAccessor.max">max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.maxabs_scale" href="#vectorbt.generic.accessors.GenericAccessor.maxabs_scale">maxabs_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mean" href="#vectorbt.generic.accessors.GenericAccessor.mean">mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.median" href="#vectorbt.generic.accessors.GenericAccessor.median">median</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.min" href="#vectorbt.generic.accessors.GenericAccessor.min">min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.minmax_scale" href="#vectorbt.generic.accessors.GenericAccessor.minmax_scale">minmax_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.normalize" href="#vectorbt.generic.accessors.GenericAccessor.normalize">normalize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.obj" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.obj">obj</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.override_metrics_doc" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.override_metrics_doc">override_metrics_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.override_subplots_doc" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.override_subplots_doc">override_subplots_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pct_change" href="#vectorbt.generic.accessors.GenericAccessor.pct_change">pct_change</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">plot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plots" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.plots">plots</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plots_defaults" href="#vectorbt.generic.accessors.GenericAccessor.plots_defaults">plots_defaults</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.post_resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.post_resolve_attr">post_resolve_attr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.power_transform" href="#vectorbt.generic.accessors.GenericAccessor.power_transform">power_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pre_resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.pre_resolve_attr">pre_resolve_attr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.product" href="#vectorbt.generic.accessors.GenericAccessor.product">product</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.quantile_transform" href="#vectorbt.generic.accessors.GenericAccessor.quantile_transform">quantile_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.range_split" href="#vectorbt.generic.accessors.GenericAccessor.range_split">range_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ranges" href="#vectorbt.generic.accessors.GenericAccessor.ranges">ranges</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rebase" href="#vectorbt.generic.accessors.GenericAccessor.rebase">rebase</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.reduce" href="#vectorbt.generic.accessors.GenericAccessor.reduce">reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.regroup" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.regroup">regroup</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rename_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.rename_levels">rename_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.repeat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.repeat">repeat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.replace" href="../utils/config.html#vectorbt.utils.config.Configured.replace">replace</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resample_apply" href="#vectorbt.generic.accessors.GenericAccessor.resample_apply">resample_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.resolve_attr">resolve_attr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resolve_self" href="#vectorbt.generic.accessors.GenericAccessor.resolve_self">resolve_self</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.robust_scale" href="#vectorbt.generic.accessors.GenericAccessor.robust_scale">robust_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_apply" href="#vectorbt.generic.accessors.GenericAccessor.rolling_apply">rolling_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_max" href="#vectorbt.generic.accessors.GenericAccessor.rolling_max">rolling_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_mean" href="#vectorbt.generic.accessors.GenericAccessor.rolling_mean">rolling_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_min" href="#vectorbt.generic.accessors.GenericAccessor.rolling_min">rolling_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_split" href="#vectorbt.generic.accessors.GenericAccessor.rolling_split">rolling_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_std" href="#vectorbt.generic.accessors.GenericAccessor.rolling_std">rolling_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.save" href="../utils/config.html#vectorbt.utils.config.Pickleable.save">save</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scale" href="#vectorbt.generic.accessors.GenericAccessor.scale">scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">scatterplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.select_levels">select_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_one" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.select_one">select_one</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_one_from_obj" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.select_one_from_obj">select_one_from_obj</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.self_aliases" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.self_aliases">self_aliases</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.shuffle" href="#vectorbt.generic.accessors.GenericAccessor.shuffle">shuffle</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sr_accessor_cls" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.sr_accessor_cls">sr_accessor_cls</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stack_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.stack_index">stack_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stats" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats">stats</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stats_defaults" href="#vectorbt.generic.accessors.GenericAccessor.stats_defaults">stats_defaults</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.std" href="#vectorbt.generic.accessors.GenericAccessor.std">std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sum" href="#vectorbt.generic.accessors.GenericAccessor.sum">sum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.tile" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.tile">tile</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_1d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_1d_array">to_1d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_2d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_2d_array">to_2d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_dict" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_dict">to_dict</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_doc" href="../utils/docs.html#vectorbt.utils.docs.Documented.to_doc">to_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_mapped" href="#vectorbt.generic.accessors.GenericAccessor.to_mapped">to_mapped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_returns" href="#vectorbt.generic.accessors.GenericAccessor.to_returns">to_returns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.transform" href="#vectorbt.generic.accessors.GenericAccessor.transform">transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_array">unstack_to_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_df" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_df">unstack_to_df</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.update_config" href="../utils/config.html#vectorbt.utils.config.Configured.update_config">update_config</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.value_counts" href="#vectorbt.generic.accessors.GenericAccessor.value_counts">value_counts</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.wrapper" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.wrapper">wrapper</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.writeable_attrs" href="../utils/config.html#vectorbt.utils.config.Configured.writeable_attrs">writeable_attrs</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.xs" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.xs">xs</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.zscore" href="#vectorbt.generic.accessors.GenericAccessor.zscore">zscore</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor"><code class="flex name class">
<span>class <span class="ident parent-name">GenericSRAccessor</span></span>
(<span class="params">obj, mapping=None, **kwargs</span>)
</code></dt>
<dd>
<div class="desc"><p>Accessor on top of data of any type. For Series only.</p>
<p>Accessible through <code>pd.Series.vbt</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GenericSRAccessor(GenericAccessor, BaseSRAccessor):
    &#34;&#34;&#34;Accessor on top of data of any type. For Series only.

    Accessible through `pd.Series.vbt`.&#34;&#34;&#34;

    def __init__(self, obj: tp.Series, mapping: tp.Optional[tp.MappingLike] = None, **kwargs) -&gt; None:
        BaseSRAccessor.__init__(self, obj, **kwargs)
        GenericAccessor.__init__(self, obj, mapping=mapping, **kwargs)

    def squeeze_grouped(self,
                        squeeze_func_nb: tp.GroupSqueezeFunc, *args,
                        group_by: tp.GroupByLike = None,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Squeeze each group of elements into a single element.

        Based on `vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped`.&#34;&#34;&#34;
        obj_frame = self.obj.to_frame().transpose()
        squeezed = obj_frame.vbt.squeeze_grouped(squeeze_func_nb, *args, group_by=group_by).iloc[0]
        wrap_kwargs = merge_dicts(dict(name_or_index=self.wrapper.name), wrap_kwargs)
        return ArrayWrapper.from_obj(obj_frame).wrap_reduced(squeezed, group_by=group_by, **wrap_kwargs)

    def flatten_grouped(self,
                        group_by: tp.GroupByLike = None,
                        order: str = &#39;C&#39;,
                        wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
        &#34;&#34;&#34;Flatten each group of elements.

        Based on `vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped`.&#34;&#34;&#34;
        obj_frame = self.obj.to_frame().transpose()
        return obj_frame.vbt.flatten_grouped(group_by=group_by, order=order, wrap_kwargs=wrap_kwargs)

    def plot_against(self,
                     other: tp.ArrayLike,
                     trace_kwargs: tp.KwargsLike = None,
                     other_trace_kwargs: tp.Union[str, tp.KwargsLike] = None,
                     pos_trace_kwargs: tp.KwargsLike = None,
                     neg_trace_kwargs: tp.KwargsLike = None,
                     hidden_trace_kwargs: tp.KwargsLike = None,
                     add_trace_kwargs: tp.KwargsLike = None,
                     fig: tp.Optional[tp.BaseFigure] = None,
                     **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line against another line.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            other_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for `other`.

                Set to &#39;hidden&#39; to hide.
            pos_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for positive line.
            neg_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for negative line.
            hidden_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for hidden lines.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.plot_against(df[&#39;b&#39;])
        ```

        ![](/docs/img/sr_plot_against.svg)
        &#34;&#34;&#34;
        if trace_kwargs is None:
            trace_kwargs = {}
        if other_trace_kwargs is None:
            other_trace_kwargs = {}
        if pos_trace_kwargs is None:
            pos_trace_kwargs = {}
        if neg_trace_kwargs is None:
            neg_trace_kwargs = {}
        if hidden_trace_kwargs is None:
            hidden_trace_kwargs = {}
        obj, other = reshape_fns.broadcast(self.obj, other, columns_from=&#39;keep&#39;)
        checks.assert_instance_of(other, pd.Series)
        if fig is None:
            fig = make_figure()
        fig.update_layout(**layout_kwargs)

        # TODO: Using masks feels hacky
        pos_mask = self.obj &gt; other
        if pos_mask.any():
            # Fill positive area
            pos_obj = self.obj.copy()
            pos_obj[~pos_mask] = other[~pos_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None,
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            pos_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    fillcolor=&#39;rgba(0, 128, 0, 0.3)&#39;,
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), pos_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
        neg_mask = self.obj &lt; other
        if neg_mask.any():
            # Fill negative area
            neg_obj = self.obj.copy()
            neg_obj[~neg_mask] = other[~neg_mask]
            other.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    opacity=0,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), hidden_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )
            neg_obj.vbt.plot(
                trace_kwargs=merge_dicts(dict(
                    line=dict(
                        color=&#39;rgba(0, 0, 0, 0)&#39;,
                        width=0
                    ),
                    fillcolor=&#39;rgba(255, 0, 0, 0.3)&#39;,
                    opacity=0,
                    fill=&#39;tonexty&#39;,
                    connectgaps=False,
                    hoverinfo=&#39;skip&#39;,
                    showlegend=False,
                    name=None
                ), neg_trace_kwargs),
                add_trace_kwargs=add_trace_kwargs,
                fig=fig
            )

        # Plot main traces
        self.plot(trace_kwargs=trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        if other_trace_kwargs == &#39;hidden&#39;:
            other_trace_kwargs = dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0.,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            )
        other.vbt.plot(trace_kwargs=other_trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        return fig

    def overlay_with_heatmap(self,
                             other: tp.ArrayLike,
                             trace_kwargs: tp.KwargsLike = None,
                             heatmap_kwargs: tp.KwargsLike = None,
                             add_trace_kwargs: tp.KwargsLike = None,
                             fig: tp.Optional[tp.BaseFigure] = None,
                             **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot Series as a line and overlays it with a heatmap.

        Args:
            other (array_like): Second array. Will broadcast.
            trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
            heatmap_kwargs (dict): Keyword arguments passed to `GenericDFAccessor.heatmap`.
            add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
            fig (Figure or FigureWidget): Figure to add traces to.
            **layout_kwargs: Keyword arguments for layout.

        ## Example

        ```python-repl
        &gt;&gt;&gt; df[&#39;a&#39;].vbt.overlay_with_heatmap(df[&#39;b&#39;])
        ```

        ![](/docs/img/sr_overlay_with_heatmap.svg)
        &#34;&#34;&#34;
        from vectorbt._settings import settings
        plotting_cfg = settings[&#39;plotting&#39;]

        if trace_kwargs is None:
            trace_kwargs = {}
        if heatmap_kwargs is None:
            heatmap_kwargs = {}
        if add_trace_kwargs is None:
            add_trace_kwargs = {}

        obj, other = reshape_fns.broadcast(self.obj, other, columns_from=&#39;keep&#39;)
        checks.assert_instance_of(other, pd.Series)
        if fig is None:
            fig = make_subplots(specs=[[{&#34;secondary_y&#34;: True}]])
            if &#39;width&#39; in plotting_cfg[&#39;layout&#39;]:
                fig.update_layout(width=plotting_cfg[&#39;layout&#39;][&#39;width&#39;] + 100)
        fig.update_layout(**layout_kwargs)

        other.vbt.ts_heatmap(**heatmap_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
        self.plot(
            trace_kwargs=merge_dicts(dict(line=dict(color=plotting_cfg[&#39;color_schema&#39;][&#39;blue&#39;])), trace_kwargs),
            add_trace_kwargs=merge_dicts(dict(secondary_y=True), add_trace_kwargs),
            fig=fig
        )
        return fig

    def heatmap(self,
                x_level: tp.Optional[tp.Level] = None,
                y_level: tp.Optional[tp.Level] = None,
                symmetric: bool = False,
                sort: bool = True,
                x_labels: tp.Optional[tp.Labels] = None,
                y_labels: tp.Optional[tp.Labels] = None,
                slider_level: tp.Optional[tp.Level] = None,
                active: int = 0,
                slider_labels: tp.Optional[tp.Labels] = None,
                return_fig: bool = True,
                fig: tp.Optional[tp.BaseFigure] = None,
                **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Create a heatmap figure based on object&#39;s multi-index and values.

        If index is not a multi-index, converts Series into a DataFrame and calls `GenericDFAccessor.heatmap`.

        If multi-index contains more than two levels or you want them in specific order,
        pass `x_level` and `y_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the heatmap. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Heatmap` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1),
        ...     (2, 2),
        ...     (3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1    0
        2  2    1
        3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap()
        ```

        ![](/docs/img/sr_heatmap.svg)

        Using one level as a slider:

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (1, 2, 2),
        ...     (1, 3, 3),
        ...     (2, 3, 3),
        ...     (2, 2, 2),
        ...     (2, 1, 1)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
           2  2    1
           3  3    2
        2  3  3    3
           2  2    4
           1  1    5
        dtype: int64

        &gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
        ```

        ![](/docs/img/sr_heatmap_slider.gif)
        &#34;&#34;&#34;
        if not isinstance(self.wrapper.index, pd.MultiIndex):
            return self.obj.to_frame().vbt.heatmap(
                x_labels=x_labels, y_labels=y_labels,
                return_fig=return_fig, fig=fig, **kwargs)

        (x_level, y_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        kwargs = merge_dicts(dict(
            trace_kwargs=dict(
                hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                              f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                              &#34;value: %{z}&lt;extra&gt;&lt;/extra&gt;&#34;
            ),
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name
        ), kwargs)

        if slider_level is None:
            # No grouping
            df = self.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            return df.vbt.heatmap(x_labels=x_labels, y_labels=y_labels, fig=fig, return_fig=return_fig, **kwargs)

        # Requires grouping
        # See https://plotly.com/python/sliders/
        if not return_fig:
            raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
        _slider_labels = []
        for i, (name, group) in enumerate(self.obj.groupby(level=slider_level)):
            if slider_labels is not None:
                name = slider_labels[i]
            _slider_labels.append(name)
            df = group.vbt.unstack_to_df(
                index_levels=y_level, column_levels=x_level,
                symmetric=symmetric, sort=sort
            )
            if x_labels is None:
                x_labels = df.columns
            if y_labels is None:
                y_labels = df.index
            _kwargs = merge_dicts(dict(
                trace_kwargs=dict(
                    name=str(name) if name is not None else None,
                    visible=False
                ),
            ), kwargs)
            default_size = fig is None and &#39;height&#39; not in _kwargs
            fig = plotting.Heatmap(
                data=reshape_fns.to_2d_array(df),
                x_labels=x_labels,
                y_labels=y_labels,
                fig=fig,
                **_kwargs
            ).fig
            if default_size:
                fig.layout[&#39;height&#39;] += 100  # slider takes up space
        fig.data[active].visible = True
        steps = []
        for i in range(len(fig.data)):
            step = dict(
                method=&#34;update&#34;,
                args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
            )
            step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
            steps.append(step)
        prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
            if self.wrapper.index.names[slider_level] is not None else None
        sliders = [dict(
            active=active,
            currentvalue={&#34;prefix&#34;: prefix},
            pad={&#34;t&#34;: 50},
            steps=steps
        )]
        fig.update_layout(
            sliders=sliders
        )
        return fig

    def ts_heatmap(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
        &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
        return self.obj.to_frame().vbt.ts_heatmap(**kwargs)

    def volume(self,
               x_level: tp.Optional[tp.Level] = None,
               y_level: tp.Optional[tp.Level] = None,
               z_level: tp.Optional[tp.Level] = None,
               x_labels: tp.Optional[tp.Labels] = None,
               y_labels: tp.Optional[tp.Labels] = None,
               z_labels: tp.Optional[tp.Labels] = None,
               slider_level: tp.Optional[tp.Level] = None,
               slider_labels: tp.Optional[tp.Labels] = None,
               active: int = 0,
               scene_name: str = &#39;scene&#39;,
               fillna: tp.Optional[tp.Number] = None,
               fig: tp.Optional[tp.BaseFigure] = None,
               return_fig: bool = True,
               **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Volume]:  # pragma: no cover
        &#34;&#34;&#34;Create a 3D volume figure based on object&#39;s multi-index and values.

        If multi-index contains more than three levels or you want them in specific order, pass
        `x_level`, `y_level`, and `z_level`, each (`int` if index or `str` if name) corresponding
        to an axis of the volume. Optionally, pass `slider_level` to use a level as a slider.

        Creates `vectorbt.generic.plotting.Volume` and returns the figure.

        ## Example

        ```python-repl
        &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
        ...     (1, 1, 1),
        ...     (2, 2, 2),
        ...     (3, 3, 3)
        ... ])
        &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
        &gt;&gt;&gt; sr
        1  1  1    0
        2  2  2    1
        3  3  3    2
        dtype: int64

        &gt;&gt;&gt; sr.vbt.volume().show()
        ```

        ![](/docs/img/sr_volume.svg)
        &#34;&#34;&#34;
        (x_level, y_level, z_level), (slider_level,) = index_fns.pick_levels(
            self.wrapper.index,
            required_levels=(x_level, y_level, z_level),
            optional_levels=(slider_level,)
        )

        x_level_vals = self.wrapper.index.get_level_values(x_level)
        y_level_vals = self.wrapper.index.get_level_values(y_level)
        z_level_vals = self.wrapper.index.get_level_values(z_level)
        # Labels are just unique level values
        if x_labels is None:
            x_labels = np.unique(x_level_vals)
        if y_labels is None:
            y_labels = np.unique(y_level_vals)
        if z_labels is None:
            z_labels = np.unique(z_level_vals)

        x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
        y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
        z_name = z_level_vals.name if z_level_vals.name is not None else &#39;z&#39;
        def_kwargs = dict()
        def_kwargs[&#39;trace_kwargs&#39;] = dict(
            hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                          f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                          f&#34;{z_name}: %{{z}}&lt;br&gt;&#34; +
                          &#34;value: %{value}&lt;extra&gt;&lt;/extra&gt;&#34;
        )
        def_kwargs[scene_name] = dict(
            xaxis_title=x_level_vals.name,
            yaxis_title=y_level_vals.name,
            zaxis_title=z_level_vals.name
        )
        def_kwargs[&#39;scene_name&#39;] = scene_name
        kwargs = merge_dicts(def_kwargs, kwargs)

        contains_nan = False
        if slider_level is None:
            # No grouping
            v = self.unstack_to_array(levels=(x_level, y_level, z_level))
            if fillna is not None:
                v = np.nan_to_num(v, nan=fillna)
            if np.isnan(v).any():
                contains_nan = True
            volume = plotting.Volume(
                data=v,
                x_labels=x_labels,
                y_labels=y_labels,
                z_labels=z_labels,
                fig=fig,
                **kwargs
            )
            if return_fig:
                fig = volume.fig
            else:
                fig = volume
        else:
            # Requires grouping
            # See https://plotly.com/python/sliders/
            if not return_fig:
                raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
            _slider_labels = []
            for i, (name, group) in enumerate(self.obj.groupby(level=slider_level)):
                if slider_labels is not None:
                    name = slider_labels[i]
                _slider_labels.append(name)
                v = group.vbt.unstack_to_array(levels=(x_level, y_level, z_level))
                if fillna is not None:
                    v = np.nan_to_num(v, nan=fillna)
                if np.isnan(v).any():
                    contains_nan = True
                _kwargs = merge_dicts(dict(
                    trace_kwargs=dict(
                        name=str(name) if name is not None else None,
                        visible=False
                    )
                ), kwargs)
                default_size = fig is None and &#39;height&#39; not in _kwargs
                fig = plotting.Volume(
                    data=v,
                    x_labels=x_labels,
                    y_labels=y_labels,
                    z_labels=z_labels,
                    fig=fig,
                    **_kwargs
                ).fig
                if default_size:
                    fig.layout[&#39;height&#39;] += 100  # slider takes up space
            fig.data[active].visible = True
            steps = []
            for i in range(len(fig.data)):
                step = dict(
                    method=&#34;update&#34;,
                    args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                    label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
                )
                step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
                steps.append(step)
            prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
                if self.wrapper.index.names[slider_level] is not None else None
            sliders = [dict(
                active=active,
                currentvalue={&#34;prefix&#34;: prefix},
                pad={&#34;t&#34;: 50},
                steps=steps
            )]
            fig.update_layout(
                sliders=sliders
            )

        if contains_nan:
            warnings.warn(&#34;Data contains NaNs. Use `fillna` argument or &#34;
                          &#34;`show` method in case of visualization issues.&#34;, stacklevel=2)
        return fig

    def qqplot(self,
               sparams: tp.Union[tp.Iterable, tuple, None] = (),
               dist: str = &#39;norm&#39;,
               plot_line: bool = True,
               line_shape_kwargs: tp.KwargsLike = None,
               xref: str = &#39;x&#39;,
               yref: str = &#39;y&#39;,
               fig: tp.Optional[tp.BaseFigure] = None,
               **kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
        &#34;&#34;&#34;Plot probability plot using `scipy.stats.probplot`.

        `**kwargs` are passed to `GenericAccessor.scatterplot`.

        ## Example

        ```python-repl
        &gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
        ```

        ![](/docs/img/sr_qqplot.svg)
        &#34;&#34;&#34;
        qq = stats.probplot(self.obj, sparams=sparams, dist=dist)
        fig = pd.Series(qq[0][1], index=qq[0][0]).vbt.scatterplot(fig=fig, **kwargs)

        if plot_line:
            if line_shape_kwargs is None:
                line_shape_kwargs = {}
            x = np.array([qq[0][0][0], qq[0][0][-1]])
            y = qq[1][1] + qq[1][0] * x
            fig.add_shape(**merge_dicts(dict(
                type=&#34;line&#34;,
                xref=xref,
                yref=yref,
                x0=x[0],
                y0=y[0],
                x1=x[1],
                y1=y[1],
                line=dict(
                    color=&#39;red&#39;
                )
            ), line_shape_kwargs))

        return fig</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseSRAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseSRAccessor">BaseSRAccessor</a></li>
<li><a title="vectorbt.base.accessors.BaseAccessor" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor">BaseAccessor</a></li>
<li><a title="vectorbt.base.array_wrapper.Wrapping" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping">Wrapping</a></li>
<li><a title="vectorbt.utils.config.Configured" href="../utils/config.html#vectorbt.utils.config.Configured">Configured</a></li>
<li><a title="vectorbt.utils.config.Pickleable" href="../utils/config.html#vectorbt.utils.config.Pickleable">Pickleable</a></li>
<li><a title="vectorbt.utils.docs.Documented" href="../utils/docs.html#vectorbt.utils.docs.Documented">Documented</a></li>
<li><a title="vectorbt.base.indexing.PandasIndexer" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer">PandasIndexer</a></li>
<li><a title="vectorbt.base.indexing.IndexingBase" href="../base/indexing.html#vectorbt.base.indexing.IndexingBase">IndexingBase</a></li>
<li><a title="vectorbt.utils.attr.AttrResolver" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver">AttrResolver</a></li>
<li><a title="vectorbt.generic.stats_builder.StatsBuilderMixin" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin">StatsBuilderMixin</a></li>
<li><a title="vectorbt.generic.plots_builder.PlotsBuilderMixin" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin">PlotsBuilderMixin</a></li>
</ul>
<h3 class="section-subtitle">Subclasses</h3>
<ul class="hlist">
<li><a title="vectorbt.returns.accessors.ReturnsSRAccessor" href="../returns/accessors.html#vectorbt.returns.accessors.ReturnsSRAccessor">ReturnsSRAccessor</a></li>
<li><a title="vectorbt.root_accessors.Vbt_SRAccessor" href="../root_accessors.html#vectorbt.root_accessors.Vbt_SRAccessor">Vbt_SRAccessor</a></li>
<li><a title="vectorbt.signals.accessors.SignalsSRAccessor" href="../signals/accessors.html#vectorbt.signals.accessors.SignalsSRAccessor">SignalsSRAccessor</a></li>
</ul>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.flatten_grouped"><code class="name flex">
<span>def <span class="ident child-name">flatten_grouped</span></span>(<span class="params">self, group_by=None, order='C', wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Flatten each group of elements.</p>
<p>Based on <code><a title="vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped" href="#vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped">GenericDFAccessor.flatten_grouped()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flatten_grouped(self,
                    group_by: tp.GroupByLike = None,
                    order: str = &#39;C&#39;,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Flatten each group of elements.

    Based on `vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped`.&#34;&#34;&#34;
    obj_frame = self.obj.to_frame().transpose()
    return obj_frame.vbt.flatten_grouped(group_by=group_by, order=order, wrap_kwargs=wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.heatmap"><code class="name flex">
<span>def <span class="ident child-name">heatmap</span></span>(<span class="params">self, x_level=None, y_level=None, symmetric=False, sort=True, x_labels=None, y_labels=None, slider_level=None, active=0, slider_labels=None, return_fig=True, fig=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create a heatmap figure based on object's multi-index and values.</p>
<p>If index is not a multi-index, converts Series into a DataFrame and calls <code><a title="vectorbt.generic.accessors.GenericDFAccessor.heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.heatmap">GenericDFAccessor.heatmap()</a></code>.</p>
<p>If multi-index contains more than two levels or you want them in specific order,
pass <code>x_level</code> and <code>y_level</code>, each (<code>int</code> if index or <code>str</code> if name) corresponding
to an axis of the heatmap. Optionally, pass <code>slider_level</code> to use a level as a slider.</p>
<p>Creates <code><a title="vectorbt.generic.plotting.Heatmap" href="plotting.html#vectorbt.generic.plotting.Heatmap">Heatmap</a></code> and returns the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
...     (1, 1),
...     (2, 2),
...     (3, 3)
... ])
&gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
&gt;&gt;&gt; sr
1  1    0
2  2    1
3  3    2
dtype: int64

&gt;&gt;&gt; sr.vbt.heatmap()
</code></pre>
<p><img alt="" src="/docs/img/sr_heatmap.svg"></p>
<p>Using one level as a slider:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
...     (1, 1, 1),
...     (1, 2, 2),
...     (1, 3, 3),
...     (2, 3, 3),
...     (2, 2, 2),
...     (2, 1, 1)
... ])
&gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
&gt;&gt;&gt; sr
1  1  1    0
   2  2    1
   3  3    2
2  3  3    3
   2  2    4
   1  1    5
dtype: int64

&gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
</code></pre>
<p><img alt="" src="/docs/img/sr_heatmap_slider.gif"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatmap(self,
            x_level: tp.Optional[tp.Level] = None,
            y_level: tp.Optional[tp.Level] = None,
            symmetric: bool = False,
            sort: bool = True,
            x_labels: tp.Optional[tp.Labels] = None,
            y_labels: tp.Optional[tp.Labels] = None,
            slider_level: tp.Optional[tp.Level] = None,
            active: int = 0,
            slider_labels: tp.Optional[tp.Labels] = None,
            return_fig: bool = True,
            fig: tp.Optional[tp.BaseFigure] = None,
            **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Create a heatmap figure based on object&#39;s multi-index and values.

    If index is not a multi-index, converts Series into a DataFrame and calls `GenericDFAccessor.heatmap`.

    If multi-index contains more than two levels or you want them in specific order,
    pass `x_level` and `y_level`, each (`int` if index or `str` if name) corresponding
    to an axis of the heatmap. Optionally, pass `slider_level` to use a level as a slider.

    Creates `vectorbt.generic.plotting.Heatmap` and returns the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
    ...     (1, 1),
    ...     (2, 2),
    ...     (3, 3)
    ... ])
    &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
    &gt;&gt;&gt; sr
    1  1    0
    2  2    1
    3  3    2
    dtype: int64

    &gt;&gt;&gt; sr.vbt.heatmap()
    ```

    ![](/docs/img/sr_heatmap.svg)

    Using one level as a slider:

    ```python-repl
    &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
    ...     (1, 1, 1),
    ...     (1, 2, 2),
    ...     (1, 3, 3),
    ...     (2, 3, 3),
    ...     (2, 2, 2),
    ...     (2, 1, 1)
    ... ])
    &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
    &gt;&gt;&gt; sr
    1  1  1    0
       2  2    1
       3  3    2
    2  3  3    3
       2  2    4
       1  1    5
    dtype: int64

    &gt;&gt;&gt; sr.vbt.heatmap(slider_level=0)
    ```

    ![](/docs/img/sr_heatmap_slider.gif)
    &#34;&#34;&#34;
    if not isinstance(self.wrapper.index, pd.MultiIndex):
        return self.obj.to_frame().vbt.heatmap(
            x_labels=x_labels, y_labels=y_labels,
            return_fig=return_fig, fig=fig, **kwargs)

    (x_level, y_level), (slider_level,) = index_fns.pick_levels(
        self.wrapper.index,
        required_levels=(x_level, y_level),
        optional_levels=(slider_level,)
    )

    x_level_vals = self.wrapper.index.get_level_values(x_level)
    y_level_vals = self.wrapper.index.get_level_values(y_level)
    x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
    y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
    kwargs = merge_dicts(dict(
        trace_kwargs=dict(
            hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                          f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                          &#34;value: %{z}&lt;extra&gt;&lt;/extra&gt;&#34;
        ),
        xaxis_title=x_level_vals.name,
        yaxis_title=y_level_vals.name
    ), kwargs)

    if slider_level is None:
        # No grouping
        df = self.unstack_to_df(
            index_levels=y_level, column_levels=x_level,
            symmetric=symmetric, sort=sort
        )
        return df.vbt.heatmap(x_labels=x_labels, y_labels=y_labels, fig=fig, return_fig=return_fig, **kwargs)

    # Requires grouping
    # See https://plotly.com/python/sliders/
    if not return_fig:
        raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
    _slider_labels = []
    for i, (name, group) in enumerate(self.obj.groupby(level=slider_level)):
        if slider_labels is not None:
            name = slider_labels[i]
        _slider_labels.append(name)
        df = group.vbt.unstack_to_df(
            index_levels=y_level, column_levels=x_level,
            symmetric=symmetric, sort=sort
        )
        if x_labels is None:
            x_labels = df.columns
        if y_labels is None:
            y_labels = df.index
        _kwargs = merge_dicts(dict(
            trace_kwargs=dict(
                name=str(name) if name is not None else None,
                visible=False
            ),
        ), kwargs)
        default_size = fig is None and &#39;height&#39; not in _kwargs
        fig = plotting.Heatmap(
            data=reshape_fns.to_2d_array(df),
            x_labels=x_labels,
            y_labels=y_labels,
            fig=fig,
            **_kwargs
        ).fig
        if default_size:
            fig.layout[&#39;height&#39;] += 100  # slider takes up space
    fig.data[active].visible = True
    steps = []
    for i in range(len(fig.data)):
        step = dict(
            method=&#34;update&#34;,
            args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
            label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
        )
        step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
        steps.append(step)
    prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
        if self.wrapper.index.names[slider_level] is not None else None
    sliders = [dict(
        active=active,
        currentvalue={&#34;prefix&#34;: prefix},
        pad={&#34;t&#34;: 50},
        steps=steps
    )]
    fig.update_layout(
        sliders=sliders
    )
    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.overlay_with_heatmap"><code class="name flex">
<span>def <span class="ident child-name">overlay_with_heatmap</span></span>(<span class="params">self, other, trace_kwargs=None, heatmap_kwargs=None, add_trace_kwargs=None, fig=None, **layout_kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Plot Series as a line and overlays it with a heatmap.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Second array. Will broadcast.</dd>
<dt><strong><code>trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code>.</dd>
<dt><strong><code>heatmap_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code><a title="vectorbt.generic.accessors.GenericDFAccessor.heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.heatmap">GenericDFAccessor.heatmap()</a></code>.</dd>
<dt><strong><code>add_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>add_trace</code>.</dd>
<dt><strong><code>fig</code></strong> :&ensp;<code>Figure</code> or <code>FigureWidget</code></dt>
<dd>Figure to add traces to.</dd>
<dt><strong><code>**layout_kwargs</code></strong></dt>
<dd>Keyword arguments for layout.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df['a'].vbt.overlay_with_heatmap(df['b'])
</code></pre>
<p><img alt="" src="/docs/img/sr_overlay_with_heatmap.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def overlay_with_heatmap(self,
                         other: tp.ArrayLike,
                         trace_kwargs: tp.KwargsLike = None,
                         heatmap_kwargs: tp.KwargsLike = None,
                         add_trace_kwargs: tp.KwargsLike = None,
                         fig: tp.Optional[tp.BaseFigure] = None,
                         **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
    &#34;&#34;&#34;Plot Series as a line and overlays it with a heatmap.

    Args:
        other (array_like): Second array. Will broadcast.
        trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
        heatmap_kwargs (dict): Keyword arguments passed to `GenericDFAccessor.heatmap`.
        add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
        fig (Figure or FigureWidget): Figure to add traces to.
        **layout_kwargs: Keyword arguments for layout.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df[&#39;a&#39;].vbt.overlay_with_heatmap(df[&#39;b&#39;])
    ```

    ![](/docs/img/sr_overlay_with_heatmap.svg)
    &#34;&#34;&#34;
    from vectorbt._settings import settings
    plotting_cfg = settings[&#39;plotting&#39;]

    if trace_kwargs is None:
        trace_kwargs = {}
    if heatmap_kwargs is None:
        heatmap_kwargs = {}
    if add_trace_kwargs is None:
        add_trace_kwargs = {}

    obj, other = reshape_fns.broadcast(self.obj, other, columns_from=&#39;keep&#39;)
    checks.assert_instance_of(other, pd.Series)
    if fig is None:
        fig = make_subplots(specs=[[{&#34;secondary_y&#34;: True}]])
        if &#39;width&#39; in plotting_cfg[&#39;layout&#39;]:
            fig.update_layout(width=plotting_cfg[&#39;layout&#39;][&#39;width&#39;] + 100)
    fig.update_layout(**layout_kwargs)

    other.vbt.ts_heatmap(**heatmap_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
    self.plot(
        trace_kwargs=merge_dicts(dict(line=dict(color=plotting_cfg[&#39;color_schema&#39;][&#39;blue&#39;])), trace_kwargs),
        add_trace_kwargs=merge_dicts(dict(secondary_y=True), add_trace_kwargs),
        fig=fig
    )
    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.plot_against"><code class="name flex">
<span>def <span class="ident child-name">plot_against</span></span>(<span class="params">self, other, trace_kwargs=None, other_trace_kwargs=None, pos_trace_kwargs=None, neg_trace_kwargs=None, hidden_trace_kwargs=None, add_trace_kwargs=None, fig=None, **layout_kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Plot Series as a line against another line.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Second array. Will broadcast.</dd>
<dt><strong><code>trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code>.</dd>
<dt><strong><code>other_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>
<p>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for <code>other</code>.</p>
<p>Set to 'hidden' to hide.</p>
</dd>
<dt><strong><code>pos_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for positive line.</dd>
<dt><strong><code>neg_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for negative line.</dd>
<dt><strong><code>hidden_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>plotly.graph_objects.Scatter</code> for hidden lines.</dd>
<dt><strong><code>add_trace_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to <code>add_trace</code>.</dd>
<dt><strong><code>fig</code></strong> :&ensp;<code>Figure</code> or <code>FigureWidget</code></dt>
<dd>Figure to add traces to.</dd>
<dt><strong><code>**layout_kwargs</code></strong></dt>
<dd>Keyword arguments for layout.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; df['a'].vbt.plot_against(df['b'])
</code></pre>
<p><img alt="" src="/docs/img/sr_plot_against.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_against(self,
                 other: tp.ArrayLike,
                 trace_kwargs: tp.KwargsLike = None,
                 other_trace_kwargs: tp.Union[str, tp.KwargsLike] = None,
                 pos_trace_kwargs: tp.KwargsLike = None,
                 neg_trace_kwargs: tp.KwargsLike = None,
                 hidden_trace_kwargs: tp.KwargsLike = None,
                 add_trace_kwargs: tp.KwargsLike = None,
                 fig: tp.Optional[tp.BaseFigure] = None,
                 **layout_kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
    &#34;&#34;&#34;Plot Series as a line against another line.

    Args:
        other (array_like): Second array. Will broadcast.
        trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter`.
        other_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for `other`.

            Set to &#39;hidden&#39; to hide.
        pos_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for positive line.
        neg_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for negative line.
        hidden_trace_kwargs (dict): Keyword arguments passed to `plotly.graph_objects.Scatter` for hidden lines.
        add_trace_kwargs (dict): Keyword arguments passed to `add_trace`.
        fig (Figure or FigureWidget): Figure to add traces to.
        **layout_kwargs: Keyword arguments for layout.

    ## Example

    ```python-repl
    &gt;&gt;&gt; df[&#39;a&#39;].vbt.plot_against(df[&#39;b&#39;])
    ```

    ![](/docs/img/sr_plot_against.svg)
    &#34;&#34;&#34;
    if trace_kwargs is None:
        trace_kwargs = {}
    if other_trace_kwargs is None:
        other_trace_kwargs = {}
    if pos_trace_kwargs is None:
        pos_trace_kwargs = {}
    if neg_trace_kwargs is None:
        neg_trace_kwargs = {}
    if hidden_trace_kwargs is None:
        hidden_trace_kwargs = {}
    obj, other = reshape_fns.broadcast(self.obj, other, columns_from=&#39;keep&#39;)
    checks.assert_instance_of(other, pd.Series)
    if fig is None:
        fig = make_figure()
    fig.update_layout(**layout_kwargs)

    # TODO: Using masks feels hacky
    pos_mask = self.obj &gt; other
    if pos_mask.any():
        # Fill positive area
        pos_obj = self.obj.copy()
        pos_obj[~pos_mask] = other[~pos_mask]
        other.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None,
            ), hidden_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )
        pos_obj.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                fillcolor=&#39;rgba(0, 128, 0, 0.3)&#39;,
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0,
                fill=&#39;tonexty&#39;,
                connectgaps=False,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            ), pos_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )
    neg_mask = self.obj &lt; other
    if neg_mask.any():
        # Fill negative area
        neg_obj = self.obj.copy()
        neg_obj[~neg_mask] = other[~neg_mask]
        other.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                opacity=0,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            ), hidden_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )
        neg_obj.vbt.plot(
            trace_kwargs=merge_dicts(dict(
                line=dict(
                    color=&#39;rgba(0, 0, 0, 0)&#39;,
                    width=0
                ),
                fillcolor=&#39;rgba(255, 0, 0, 0.3)&#39;,
                opacity=0,
                fill=&#39;tonexty&#39;,
                connectgaps=False,
                hoverinfo=&#39;skip&#39;,
                showlegend=False,
                name=None
            ), neg_trace_kwargs),
            add_trace_kwargs=add_trace_kwargs,
            fig=fig
        )

    # Plot main traces
    self.plot(trace_kwargs=trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
    if other_trace_kwargs == &#39;hidden&#39;:
        other_trace_kwargs = dict(
            line=dict(
                color=&#39;rgba(0, 0, 0, 0)&#39;,
                width=0
            ),
            opacity=0.,
            hoverinfo=&#39;skip&#39;,
            showlegend=False,
            name=None
        )
    other.vbt.plot(trace_kwargs=other_trace_kwargs, add_trace_kwargs=add_trace_kwargs, fig=fig)
    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.qqplot"><code class="name flex">
<span>def <span class="ident child-name">qqplot</span></span>(<span class="params">self, sparams=(), dist='norm', plot_line=True, line_shape_kwargs=None, xref='x', yref='y', fig=None, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Plot probability plot using <code>scipy.stats.probplot</code>.</p>
<p><code>**kwargs</code> are passed to <code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">GenericAccessor.scatterplot()</a></code>.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
</code></pre>
<p><img alt="" src="/docs/img/sr_qqplot.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def qqplot(self,
           sparams: tp.Union[tp.Iterable, tuple, None] = (),
           dist: str = &#39;norm&#39;,
           plot_line: bool = True,
           line_shape_kwargs: tp.KwargsLike = None,
           xref: str = &#39;x&#39;,
           yref: str = &#39;y&#39;,
           fig: tp.Optional[tp.BaseFigure] = None,
           **kwargs) -&gt; tp.BaseFigure:  # pragma: no cover
    &#34;&#34;&#34;Plot probability plot using `scipy.stats.probplot`.

    `**kwargs` are passed to `GenericAccessor.scatterplot`.

    ## Example

    ```python-repl
    &gt;&gt;&gt; pd.Series(np.random.standard_normal(100)).vbt.qqplot()
    ```

    ![](/docs/img/sr_qqplot.svg)
    &#34;&#34;&#34;
    qq = stats.probplot(self.obj, sparams=sparams, dist=dist)
    fig = pd.Series(qq[0][1], index=qq[0][0]).vbt.scatterplot(fig=fig, **kwargs)

    if plot_line:
        if line_shape_kwargs is None:
            line_shape_kwargs = {}
        x = np.array([qq[0][0][0], qq[0][0][-1]])
        y = qq[1][1] + qq[1][0] * x
        fig.add_shape(**merge_dicts(dict(
            type=&#34;line&#34;,
            xref=xref,
            yref=yref,
            x0=x[0],
            y0=y[0],
            x1=x[1],
            y1=y[1],
            line=dict(
                color=&#39;red&#39;
            )
        ), line_shape_kwargs))

    return fig</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.squeeze_grouped"><code class="name flex">
<span>def <span class="ident child-name">squeeze_grouped</span></span>(<span class="params">self, squeeze_func_nb, *args, group_by=None, wrap_kwargs=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Squeeze each group of elements into a single element.</p>
<p>Based on <code><a title="vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped" href="#vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped">GenericDFAccessor.squeeze_grouped()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squeeze_grouped(self,
                    squeeze_func_nb: tp.GroupSqueezeFunc, *args,
                    group_by: tp.GroupByLike = None,
                    wrap_kwargs: tp.KwargsLike = None) -&gt; tp.MaybeSeries:
    &#34;&#34;&#34;Squeeze each group of elements into a single element.

    Based on `vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped`.&#34;&#34;&#34;
    obj_frame = self.obj.to_frame().transpose()
    squeezed = obj_frame.vbt.squeeze_grouped(squeeze_func_nb, *args, group_by=group_by).iloc[0]
    wrap_kwargs = merge_dicts(dict(name_or_index=self.wrapper.name), wrap_kwargs)
    return ArrayWrapper.from_obj(obj_frame).wrap_reduced(squeezed, group_by=group_by, **wrap_kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.ts_heatmap"><code class="name flex">
<span>def <span class="ident child-name">ts_heatmap</span></span>(<span class="params">self, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Heatmap of time-series data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ts_heatmap(self, **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Heatmap]:  # pragma: no cover
    &#34;&#34;&#34;Heatmap of time-series data.&#34;&#34;&#34;
    return self.obj.to_frame().vbt.ts_heatmap(**kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.GenericSRAccessor.volume"><code class="name flex">
<span>def <span class="ident child-name">volume</span></span>(<span class="params">self, x_level=None, y_level=None, z_level=None, x_labels=None, y_labels=None, z_labels=None, slider_level=None, slider_labels=None, active=0, scene_name='scene', fillna=None, fig=None, return_fig=True, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Create a 3D volume figure based on object's multi-index and values.</p>
<p>If multi-index contains more than three levels or you want them in specific order, pass
<code>x_level</code>, <code>y_level</code>, and <code>z_level</code>, each (<code>int</code> if index or <code>str</code> if name) corresponding
to an axis of the volume. Optionally, pass <code>slider_level</code> to use a level as a slider.</p>
<p>Creates <code><a title="vectorbt.generic.plotting.Volume" href="plotting.html#vectorbt.generic.plotting.Volume">Volume</a></code> and returns the figure.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
...     (1, 1, 1),
...     (2, 2, 2),
...     (3, 3, 3)
... ])
&gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
&gt;&gt;&gt; sr
1  1  1    0
2  2  2    1
3  3  3    2
dtype: int64

&gt;&gt;&gt; sr.vbt.volume().show()
</code></pre>
<p><img alt="" src="/docs/img/sr_volume.svg"></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def volume(self,
           x_level: tp.Optional[tp.Level] = None,
           y_level: tp.Optional[tp.Level] = None,
           z_level: tp.Optional[tp.Level] = None,
           x_labels: tp.Optional[tp.Labels] = None,
           y_labels: tp.Optional[tp.Labels] = None,
           z_labels: tp.Optional[tp.Labels] = None,
           slider_level: tp.Optional[tp.Level] = None,
           slider_labels: tp.Optional[tp.Labels] = None,
           active: int = 0,
           scene_name: str = &#39;scene&#39;,
           fillna: tp.Optional[tp.Number] = None,
           fig: tp.Optional[tp.BaseFigure] = None,
           return_fig: bool = True,
           **kwargs) -&gt; tp.Union[tp.BaseFigure, plotting.Volume]:  # pragma: no cover
    &#34;&#34;&#34;Create a 3D volume figure based on object&#39;s multi-index and values.

    If multi-index contains more than three levels or you want them in specific order, pass
    `x_level`, `y_level`, and `z_level`, each (`int` if index or `str` if name) corresponding
    to an axis of the volume. Optionally, pass `slider_level` to use a level as a slider.

    Creates `vectorbt.generic.plotting.Volume` and returns the figure.

    ## Example

    ```python-repl
    &gt;&gt;&gt; multi_index = pd.MultiIndex.from_tuples([
    ...     (1, 1, 1),
    ...     (2, 2, 2),
    ...     (3, 3, 3)
    ... ])
    &gt;&gt;&gt; sr = pd.Series(np.arange(len(multi_index)), index=multi_index)
    &gt;&gt;&gt; sr
    1  1  1    0
    2  2  2    1
    3  3  3    2
    dtype: int64

    &gt;&gt;&gt; sr.vbt.volume().show()
    ```

    ![](/docs/img/sr_volume.svg)
    &#34;&#34;&#34;
    (x_level, y_level, z_level), (slider_level,) = index_fns.pick_levels(
        self.wrapper.index,
        required_levels=(x_level, y_level, z_level),
        optional_levels=(slider_level,)
    )

    x_level_vals = self.wrapper.index.get_level_values(x_level)
    y_level_vals = self.wrapper.index.get_level_values(y_level)
    z_level_vals = self.wrapper.index.get_level_values(z_level)
    # Labels are just unique level values
    if x_labels is None:
        x_labels = np.unique(x_level_vals)
    if y_labels is None:
        y_labels = np.unique(y_level_vals)
    if z_labels is None:
        z_labels = np.unique(z_level_vals)

    x_name = x_level_vals.name if x_level_vals.name is not None else &#39;x&#39;
    y_name = y_level_vals.name if y_level_vals.name is not None else &#39;y&#39;
    z_name = z_level_vals.name if z_level_vals.name is not None else &#39;z&#39;
    def_kwargs = dict()
    def_kwargs[&#39;trace_kwargs&#39;] = dict(
        hovertemplate=f&#34;{x_name}: %{{x}}&lt;br&gt;&#34; +
                      f&#34;{y_name}: %{{y}}&lt;br&gt;&#34; +
                      f&#34;{z_name}: %{{z}}&lt;br&gt;&#34; +
                      &#34;value: %{value}&lt;extra&gt;&lt;/extra&gt;&#34;
    )
    def_kwargs[scene_name] = dict(
        xaxis_title=x_level_vals.name,
        yaxis_title=y_level_vals.name,
        zaxis_title=z_level_vals.name
    )
    def_kwargs[&#39;scene_name&#39;] = scene_name
    kwargs = merge_dicts(def_kwargs, kwargs)

    contains_nan = False
    if slider_level is None:
        # No grouping
        v = self.unstack_to_array(levels=(x_level, y_level, z_level))
        if fillna is not None:
            v = np.nan_to_num(v, nan=fillna)
        if np.isnan(v).any():
            contains_nan = True
        volume = plotting.Volume(
            data=v,
            x_labels=x_labels,
            y_labels=y_labels,
            z_labels=z_labels,
            fig=fig,
            **kwargs
        )
        if return_fig:
            fig = volume.fig
        else:
            fig = volume
    else:
        # Requires grouping
        # See https://plotly.com/python/sliders/
        if not return_fig:
            raise ValueError(&#34;Cannot use return_fig=False and slider_level simultaneously&#34;)
        _slider_labels = []
        for i, (name, group) in enumerate(self.obj.groupby(level=slider_level)):
            if slider_labels is not None:
                name = slider_labels[i]
            _slider_labels.append(name)
            v = group.vbt.unstack_to_array(levels=(x_level, y_level, z_level))
            if fillna is not None:
                v = np.nan_to_num(v, nan=fillna)
            if np.isnan(v).any():
                contains_nan = True
            _kwargs = merge_dicts(dict(
                trace_kwargs=dict(
                    name=str(name) if name is not None else None,
                    visible=False
                )
            ), kwargs)
            default_size = fig is None and &#39;height&#39; not in _kwargs
            fig = plotting.Volume(
                data=v,
                x_labels=x_labels,
                y_labels=y_labels,
                z_labels=z_labels,
                fig=fig,
                **_kwargs
            ).fig
            if default_size:
                fig.layout[&#39;height&#39;] += 100  # slider takes up space
        fig.data[active].visible = True
        steps = []
        for i in range(len(fig.data)):
            step = dict(
                method=&#34;update&#34;,
                args=[{&#34;visible&#34;: [False] * len(fig.data)}, {}],
                label=str(_slider_labels[i]) if _slider_labels[i] is not None else None
            )
            step[&#34;args&#34;][0][&#34;visible&#34;][i] = True
            steps.append(step)
        prefix = f&#39;{self.wrapper.index.names[slider_level]}: &#39; \
            if self.wrapper.index.names[slider_level] is not None else None
        sliders = [dict(
            active=active,
            currentvalue={&#34;prefix&#34;: prefix},
            pad={&#34;t&#34;: 50},
            steps=steps
        )]
        fig.update_layout(
            sliders=sliders
        )

    if contains_nan:
        warnings.warn(&#34;Data contains NaNs. Use `fillna` argument or &#34;
                      &#34;`show` method in case of visualization issues.&#34;, stacklevel=2)
    return fig</code></pre>
</details>
</dd>
</dl>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.align_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.align_to">align_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply">apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_along_axis" href="#vectorbt.generic.accessors.GenericAccessor.apply_along_axis">apply_along_axis</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_and_concat">apply_and_concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce" href="#vectorbt.generic.accessors.GenericAccessor.apply_and_reduce">apply_and_reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_mapping" href="#vectorbt.generic.accessors.GenericAccessor.apply_mapping">apply_mapping</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_on_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.apply_on_index">apply_on_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.applymap" href="#vectorbt.generic.accessors.GenericAccessor.applymap">applymap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.barplot" href="#vectorbt.generic.accessors.GenericAccessor.barplot">barplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bfill" href="#vectorbt.generic.accessors.GenericAccessor.bfill">bfill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.binarize" href="#vectorbt.generic.accessors.GenericAccessor.binarize">binarize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.boxplot" href="#vectorbt.generic.accessors.GenericAccessor.boxplot">boxplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast">broadcast</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.broadcast_to" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.broadcast_to">broadcast_to</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bshift" href="#vectorbt.generic.accessors.GenericAccessor.bshift">bshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.build_metrics_doc" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.build_metrics_doc">build_metrics_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.build_subplots_doc" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.build_subplots_doc">build_subplots_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.combine" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.combine">combine</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.concat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.concat">concat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.config" href="../utils/config.html#vectorbt.utils.config.Configured.config">config</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.copy" href="../utils/config.html#vectorbt.utils.config.Configured.copy">copy</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.count" href="#vectorbt.generic.accessors.GenericAccessor.count">count</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumprod" href="#vectorbt.generic.accessors.GenericAccessor.cumprod">cumprod</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumsum" href="#vectorbt.generic.accessors.GenericAccessor.cumsum">cumsum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.deep_getattr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.deep_getattr">deep_getattr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.describe" href="#vectorbt.generic.accessors.GenericAccessor.describe">describe</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.df_accessor_cls" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.df_accessor_cls">df_accessor_cls</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.diff" href="#vectorbt.generic.accessors.GenericAccessor.diff">diff</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdown" href="#vectorbt.generic.accessors.GenericAccessor.drawdown">drawdown</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.drawdowns">drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_duplicate_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_duplicate_levels">drop_duplicate_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_levels">drop_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drop_redundant_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.drop_redundant_levels">drop_redundant_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.dumps" href="../utils/config.html#vectorbt.utils.config.Pickleable.dumps">dumps</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty">empty</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.empty_like" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.empty_like">empty_like</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_mean" href="#vectorbt.generic.accessors.GenericAccessor.ewm_mean">ewm_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_std" href="#vectorbt.generic.accessors.GenericAccessor.ewm_std">ewm_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_apply" href="#vectorbt.generic.accessors.GenericAccessor.expanding_apply">expanding_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_max" href="#vectorbt.generic.accessors.GenericAccessor.expanding_max">expanding_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_mean" href="#vectorbt.generic.accessors.GenericAccessor.expanding_mean">expanding_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_min" href="#vectorbt.generic.accessors.GenericAccessor.expanding_min">expanding_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_split" href="#vectorbt.generic.accessors.GenericAccessor.expanding_split">expanding_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_std" href="#vectorbt.generic.accessors.GenericAccessor.expanding_std">expanding_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ffill" href="#vectorbt.generic.accessors.GenericAccessor.ffill">ffill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fillna" href="#vectorbt.generic.accessors.GenericAccessor.fillna">fillna</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.filter" href="#vectorbt.generic.accessors.GenericAccessor.filter">filter</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fshift" href="#vectorbt.generic.accessors.GenericAccessor.fshift">fshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">get_drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_ranges" href="#vectorbt.generic.accessors.GenericAccessor.get_ranges">get_ranges</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.groupby_apply" href="#vectorbt.generic.accessors.GenericAccessor.groupby_apply">groupby_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.histplot" href="#vectorbt.generic.accessors.GenericAccessor.histplot">histplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmax" href="#vectorbt.generic.accessors.GenericAccessor.idxmax">idxmax</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmin" href="#vectorbt.generic.accessors.GenericAccessor.idxmin">idxmin</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.iloc" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.iloc">iloc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.indexing_func" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.indexing_func">indexing_func</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.indexing_kwargs" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.indexing_kwargs">indexing_kwargs</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.lineplot" href="#vectorbt.generic.accessors.GenericAccessor.lineplot">lineplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.load" href="../utils/config.html#vectorbt.utils.config.Pickleable.load">load</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.loads" href="../utils/config.html#vectorbt.utils.config.Pickleable.loads">loads</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.loc" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.loc">loc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.make_symmetric" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.make_symmetric">make_symmetric</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mapping" href="#vectorbt.generic.accessors.GenericAccessor.mapping">mapping</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.max" href="#vectorbt.generic.accessors.GenericAccessor.max">max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.maxabs_scale" href="#vectorbt.generic.accessors.GenericAccessor.maxabs_scale">maxabs_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mean" href="#vectorbt.generic.accessors.GenericAccessor.mean">mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.median" href="#vectorbt.generic.accessors.GenericAccessor.median">median</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.min" href="#vectorbt.generic.accessors.GenericAccessor.min">min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.minmax_scale" href="#vectorbt.generic.accessors.GenericAccessor.minmax_scale">minmax_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.normalize" href="#vectorbt.generic.accessors.GenericAccessor.normalize">normalize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.obj" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.obj">obj</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.override_metrics_doc" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.override_metrics_doc">override_metrics_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.override_subplots_doc" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.override_subplots_doc">override_subplots_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pct_change" href="#vectorbt.generic.accessors.GenericAccessor.pct_change">pct_change</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">plot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plots" href="plots_builder.html#vectorbt.generic.plots_builder.PlotsBuilderMixin.plots">plots</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plots_defaults" href="#vectorbt.generic.accessors.GenericAccessor.plots_defaults">plots_defaults</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.post_resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.post_resolve_attr">post_resolve_attr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.power_transform" href="#vectorbt.generic.accessors.GenericAccessor.power_transform">power_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pre_resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.pre_resolve_attr">pre_resolve_attr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.product" href="#vectorbt.generic.accessors.GenericAccessor.product">product</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.quantile_transform" href="#vectorbt.generic.accessors.GenericAccessor.quantile_transform">quantile_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.range_split" href="#vectorbt.generic.accessors.GenericAccessor.range_split">range_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ranges" href="#vectorbt.generic.accessors.GenericAccessor.ranges">ranges</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rebase" href="#vectorbt.generic.accessors.GenericAccessor.rebase">rebase</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.reduce" href="#vectorbt.generic.accessors.GenericAccessor.reduce">reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.regroup" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.regroup">regroup</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rename_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.rename_levels">rename_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.repeat" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.repeat">repeat</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.replace" href="../utils/config.html#vectorbt.utils.config.Configured.replace">replace</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resample_apply" href="#vectorbt.generic.accessors.GenericAccessor.resample_apply">resample_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resolve_attr" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.resolve_attr">resolve_attr</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resolve_self" href="#vectorbt.generic.accessors.GenericAccessor.resolve_self">resolve_self</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.robust_scale" href="#vectorbt.generic.accessors.GenericAccessor.robust_scale">robust_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_apply" href="#vectorbt.generic.accessors.GenericAccessor.rolling_apply">rolling_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_max" href="#vectorbt.generic.accessors.GenericAccessor.rolling_max">rolling_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_mean" href="#vectorbt.generic.accessors.GenericAccessor.rolling_mean">rolling_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_min" href="#vectorbt.generic.accessors.GenericAccessor.rolling_min">rolling_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_split" href="#vectorbt.generic.accessors.GenericAccessor.rolling_split">rolling_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_std" href="#vectorbt.generic.accessors.GenericAccessor.rolling_std">rolling_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.save" href="../utils/config.html#vectorbt.utils.config.Pickleable.save">save</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scale" href="#vectorbt.generic.accessors.GenericAccessor.scale">scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">scatterplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_levels" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.select_levels">select_levels</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_one" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.select_one">select_one</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.select_one_from_obj" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.select_one_from_obj">select_one_from_obj</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.self_aliases" href="../utils/attr.html#vectorbt.utils.attr.AttrResolver.self_aliases">self_aliases</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.shuffle" href="#vectorbt.generic.accessors.GenericAccessor.shuffle">shuffle</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sr_accessor_cls" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.sr_accessor_cls">sr_accessor_cls</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stack_index" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.stack_index">stack_index</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stats" href="stats_builder.html#vectorbt.generic.stats_builder.StatsBuilderMixin.stats">stats</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stats_defaults" href="#vectorbt.generic.accessors.GenericAccessor.stats_defaults">stats_defaults</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.std" href="#vectorbt.generic.accessors.GenericAccessor.std">std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sum" href="#vectorbt.generic.accessors.GenericAccessor.sum">sum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.tile" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.tile">tile</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_1d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_1d_array">to_1d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_2d_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_2d_array">to_2d_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_dict" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.to_dict">to_dict</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_doc" href="../utils/docs.html#vectorbt.utils.docs.Documented.to_doc">to_doc</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_mapped" href="#vectorbt.generic.accessors.GenericAccessor.to_mapped">to_mapped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_returns" href="#vectorbt.generic.accessors.GenericAccessor.to_returns">to_returns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.transform" href="#vectorbt.generic.accessors.GenericAccessor.transform">transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_array" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_array">unstack_to_array</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.unstack_to_df" href="../base/accessors.html#vectorbt.base.accessors.BaseAccessor.unstack_to_df">unstack_to_df</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.update_config" href="../utils/config.html#vectorbt.utils.config.Configured.update_config">update_config</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.value_counts" href="#vectorbt.generic.accessors.GenericAccessor.value_counts">value_counts</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.wrapper" href="../base/array_wrapper.html#vectorbt.base.array_wrapper.Wrapping.wrapper">wrapper</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.writeable_attrs" href="../utils/config.html#vectorbt.utils.config.Configured.writeable_attrs">writeable_attrs</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.xs" href="../base/indexing.html#vectorbt.base.indexing.PandasIndexer.xs">xs</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.zscore" href="#vectorbt.generic.accessors.GenericAccessor.zscore">zscore</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.MetaGenericAccessor"><code class="flex name class">
<span>class <span class="ident parent-name">MetaGenericAccessor</span></span>
(<span class="params">*args, **kwargs</span>)
</code></dt>
<dd>
<div class="desc"><p>Meta class that exposes a read-only class property <code>StatsBuilderMixin.metrics</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MetaGenericAccessor(type(StatsBuilderMixin), type(PlotsBuilderMixin)):
    pass</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li><a title="vectorbt.generic.stats_builder.MetaStatsBuilderMixin" href="stats_builder.html#vectorbt.generic.stats_builder.MetaStatsBuilderMixin">MetaStatsBuilderMixin</a></li>
<li><a title="vectorbt.generic.plots_builder.MetaPlotsBuilderMixin" href="plots_builder.html#vectorbt.generic.plots_builder.MetaPlotsBuilderMixin">MetaPlotsBuilderMixin</a></li>
<li>builtins.type</li>
</ul>
<h3 class="section-subtitle">Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vectorbt.generic.stats_builder.MetaStatsBuilderMixin" href="stats_builder.html#vectorbt.generic.stats_builder.MetaStatsBuilderMixin">MetaStatsBuilderMixin</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.stats_builder.MetaStatsBuilderMixin.metrics" href="stats_builder.html#vectorbt.generic.stats_builder.MetaStatsBuilderMixin.metrics">metrics</a></code></li>
</ul>
</li>
<li><code><b><a title="vectorbt.generic.plots_builder.MetaPlotsBuilderMixin" href="plots_builder.html#vectorbt.generic.plots_builder.MetaPlotsBuilderMixin">MetaPlotsBuilderMixin</a></b></code>:
<ul class="hlist">
<li><code><a title="vectorbt.generic.plots_builder.MetaPlotsBuilderMixin.subplots" href="plots_builder.html#vectorbt.generic.plots_builder.MetaPlotsBuilderMixin.subplots">subplots</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vectorbt.generic.accessors.TransformerT"><code class="flex name class">
<span>class <span class="ident parent-name">TransformerT</span></span>
(<span class="params">*args, **kwargs</span>)
</code></dt>
<dd>
<div class="desc"><p>Base class for protocol classes. Protocol classes are defined as::</p>
<p>class Proto(Protocol):
def meth(self) -&gt; int:
&hellip;</p>
<p>Such classes are primarily used with static type checkers that recognize
structural subtyping (static duck-typing), for example::</p>
<p>class C:
def meth(self) -&gt; int:
return 0</p>
<p>def func(x: Proto) -&gt; int:
return x.meth()</p>
<p>func(C())
# Passes static type check</p>
<p>See PEP 544 for details. Protocol classes decorated with
@typing_extensions.runtime act as simple-minded runtime protocol that checks
only the presence of given attributes, ignoring their type signatures.</p>
<p>Protocol classes can be generic, they are defined as::</p>
<p>class GenProto(Protocol[T]):
def meth(self) -&gt; T:
&hellip;</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransformerT(tp.Protocol):
    def __init__(self, **kwargs) -&gt; None:
        ...

    def transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...

    def fit_transform(self, *args, **kwargs) -&gt; tp.Array2d:
        ...</code></pre>
</details>
<h3 class="section-subtitle">Ancestors</h3>
<ul class="hlist">
<li>typing_extensions.Protocol</li>
</ul>
<h3 class="section-subtitle">Methods</h3>
<dl>
<dt id="vectorbt.generic.accessors.TransformerT.fit_transform"><code class="name flex">
<span>def <span class="ident child-name">fit_transform</span></span>(<span class="params">self, *args, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_transform(self, *args, **kwargs) -&gt; tp.Array2d:
    ...</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.accessors.TransformerT.transform"><code class="name flex">
<span>def <span class="ident child-name">transform</span></span>(<span class="params">self, *args, **kwargs)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, *args, **kwargs) -&gt; tp.Array2d:
    ...</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://github.com/polakowo/vectorbt">
<img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI1LjAuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkNhcGFfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiCgkgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDojRUYwMDAwO30KCS5zdDF7ZmlsbDojRkY5MDAwO30KCS5zdDJ7ZmlsbDojRkZERjAwO30KCS5zdDN7ZmlsbDojMjgyQzM0O30KPC9zdHlsZT4KPGc+Cgk8Zz4KCQk8Zz4KCQkJPHBvbHlnb24gY2xhc3M9InN0MCIgcG9pbnRzPSIxNTUuMywzMDAuMSAyODMuMSwwIDIwOCwwIDExMC44LDAgMzUuOCwwIDEuMiw0NTAuMiA3Ni4zLDQ1MC4yIAkJCSIvPgoJCTwvZz4KCTwvZz4KCTxnPgoJCTxnPgoJCQk8cG9seWdvbiBjbGFzcz0ic3QxIiBwb2ludHM9IjIzMC40LDMwMC4xIDM1OC4xLDAgMjgzLjEsMCAxODUuOCwwIDExMC44LDAgNzYuMyw0NTAuMiAxNTEuMyw0NTAuMiAJCQkiLz4KCQk8L2c+Cgk8L2c+Cgk8Zz4KCQk8Zz4KCQkJPHBvbHlnb24gY2xhc3M9InN0MiIgcG9pbnRzPSIzMDUuNCwzMDAuMSA0MzMuMSwwIDM1OC4xLDAgMzMxLjYsNjIuMyAyNjAuOCwwIDE4NS44LDAgMTUxLjMsNDUwLjIgMjI2LjQsNDUwLjIgCQkJIi8+CgkJPC9nPgoJPC9nPgoJPGc+CgkJPGc+CgkJCTxwb2x5Z29uIGNsYXNzPSJzdDMiIHBvaW50cz0iNTEwLjgsMCA0MzMuMSwwIDMwNS40LDMwMC4xIDMzOC40LDAgMjYwLjgsMCAyMjYuNCw0NTAuMiAzMDQsNDUwLjIgCQkJIi8+CgkJPC9nPgoJPC9nPgo8L2c+Cjwvc3ZnPgo="/>
vectorbt <span class="version">0.21.0</span></a>
</header>
<div class="search-container">
<input
id="search_input"
type="text"
placeholder="Search"
title="Search"
/>
</div>
<div class="scrollable-index">
<h1 class="index-caption">Index</h1>
<div class="toc">
<ul>
<li><a href="#stats">Stats</a><ul>
<li><a href="#mapping">Mapping</a></li>
</ul>
</li>
<li><a href="#plots">Plots</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="vectorbt.generic" href="index.html">vectorbt.generic</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.nb_config" href="#vectorbt.generic.accessors.nb_config">nb_config</a></code></li>
<li><code><a title="vectorbt.generic.accessors.transform_config" href="#vectorbt.generic.accessors.transform_config">transform_config</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="vectorbt.generic.accessors.GenericAccessor" href="#vectorbt.generic.accessors.GenericAccessor">GenericAccessor</a></code></h4>
<ul class="two-column">
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_along_axis" href="#vectorbt.generic.accessors.GenericAccessor.apply_along_axis">apply_along_axis</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_and_reduce" href="#vectorbt.generic.accessors.GenericAccessor.apply_and_reduce">apply_and_reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.apply_mapping" href="#vectorbt.generic.accessors.GenericAccessor.apply_mapping">apply_mapping</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.applymap" href="#vectorbt.generic.accessors.GenericAccessor.applymap">applymap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.barplot" href="#vectorbt.generic.accessors.GenericAccessor.barplot">barplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bfill" href="#vectorbt.generic.accessors.GenericAccessor.bfill">bfill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.binarize" href="#vectorbt.generic.accessors.GenericAccessor.binarize">binarize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.boxplot" href="#vectorbt.generic.accessors.GenericAccessor.boxplot">boxplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.bshift" href="#vectorbt.generic.accessors.GenericAccessor.bshift">bshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.count" href="#vectorbt.generic.accessors.GenericAccessor.count">count</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumprod" href="#vectorbt.generic.accessors.GenericAccessor.cumprod">cumprod</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.cumsum" href="#vectorbt.generic.accessors.GenericAccessor.cumsum">cumsum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.describe" href="#vectorbt.generic.accessors.GenericAccessor.describe">describe</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.diff" href="#vectorbt.generic.accessors.GenericAccessor.diff">diff</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdown" href="#vectorbt.generic.accessors.GenericAccessor.drawdown">drawdown</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.drawdowns">drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_mean" href="#vectorbt.generic.accessors.GenericAccessor.ewm_mean">ewm_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ewm_std" href="#vectorbt.generic.accessors.GenericAccessor.ewm_std">ewm_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_apply" href="#vectorbt.generic.accessors.GenericAccessor.expanding_apply">expanding_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_max" href="#vectorbt.generic.accessors.GenericAccessor.expanding_max">expanding_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_mean" href="#vectorbt.generic.accessors.GenericAccessor.expanding_mean">expanding_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_min" href="#vectorbt.generic.accessors.GenericAccessor.expanding_min">expanding_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_split" href="#vectorbt.generic.accessors.GenericAccessor.expanding_split">expanding_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.expanding_std" href="#vectorbt.generic.accessors.GenericAccessor.expanding_std">expanding_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ffill" href="#vectorbt.generic.accessors.GenericAccessor.ffill">ffill</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fillna" href="#vectorbt.generic.accessors.GenericAccessor.fillna">fillna</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.filter" href="#vectorbt.generic.accessors.GenericAccessor.filter">filter</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.fshift" href="#vectorbt.generic.accessors.GenericAccessor.fshift">fshift</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_drawdowns" href="#vectorbt.generic.accessors.GenericAccessor.get_drawdowns">get_drawdowns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.get_ranges" href="#vectorbt.generic.accessors.GenericAccessor.get_ranges">get_ranges</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.groupby_apply" href="#vectorbt.generic.accessors.GenericAccessor.groupby_apply">groupby_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.histplot" href="#vectorbt.generic.accessors.GenericAccessor.histplot">histplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmax" href="#vectorbt.generic.accessors.GenericAccessor.idxmax">idxmax</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.idxmin" href="#vectorbt.generic.accessors.GenericAccessor.idxmin">idxmin</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.lineplot" href="#vectorbt.generic.accessors.GenericAccessor.lineplot">lineplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mapping" href="#vectorbt.generic.accessors.GenericAccessor.mapping">mapping</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.max" href="#vectorbt.generic.accessors.GenericAccessor.max">max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.maxabs_scale" href="#vectorbt.generic.accessors.GenericAccessor.maxabs_scale">maxabs_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.mean" href="#vectorbt.generic.accessors.GenericAccessor.mean">mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.median" href="#vectorbt.generic.accessors.GenericAccessor.median">median</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.metrics" href="#vectorbt.generic.accessors.GenericAccessor.metrics">metrics</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.min" href="#vectorbt.generic.accessors.GenericAccessor.min">min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.minmax_scale" href="#vectorbt.generic.accessors.GenericAccessor.minmax_scale">minmax_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.normalize" href="#vectorbt.generic.accessors.GenericAccessor.normalize">normalize</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.pct_change" href="#vectorbt.generic.accessors.GenericAccessor.pct_change">pct_change</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plot" href="#vectorbt.generic.accessors.GenericAccessor.plot">plot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.plots_defaults" href="#vectorbt.generic.accessors.GenericAccessor.plots_defaults">plots_defaults</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.power_transform" href="#vectorbt.generic.accessors.GenericAccessor.power_transform">power_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.product" href="#vectorbt.generic.accessors.GenericAccessor.product">product</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.quantile_transform" href="#vectorbt.generic.accessors.GenericAccessor.quantile_transform">quantile_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.range_split" href="#vectorbt.generic.accessors.GenericAccessor.range_split">range_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.ranges" href="#vectorbt.generic.accessors.GenericAccessor.ranges">ranges</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rebase" href="#vectorbt.generic.accessors.GenericAccessor.rebase">rebase</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.reduce" href="#vectorbt.generic.accessors.GenericAccessor.reduce">reduce</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resample_apply" href="#vectorbt.generic.accessors.GenericAccessor.resample_apply">resample_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.resolve_self" href="#vectorbt.generic.accessors.GenericAccessor.resolve_self">resolve_self</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.robust_scale" href="#vectorbt.generic.accessors.GenericAccessor.robust_scale">robust_scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_apply" href="#vectorbt.generic.accessors.GenericAccessor.rolling_apply">rolling_apply</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_max" href="#vectorbt.generic.accessors.GenericAccessor.rolling_max">rolling_max</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_mean" href="#vectorbt.generic.accessors.GenericAccessor.rolling_mean">rolling_mean</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_min" href="#vectorbt.generic.accessors.GenericAccessor.rolling_min">rolling_min</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_split" href="#vectorbt.generic.accessors.GenericAccessor.rolling_split">rolling_split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.rolling_std" href="#vectorbt.generic.accessors.GenericAccessor.rolling_std">rolling_std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scale" href="#vectorbt.generic.accessors.GenericAccessor.scale">scale</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.scatterplot" href="#vectorbt.generic.accessors.GenericAccessor.scatterplot">scatterplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.shuffle" href="#vectorbt.generic.accessors.GenericAccessor.shuffle">shuffle</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.split" href="#vectorbt.generic.accessors.GenericAccessor.split">split</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.stats_defaults" href="#vectorbt.generic.accessors.GenericAccessor.stats_defaults">stats_defaults</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.std" href="#vectorbt.generic.accessors.GenericAccessor.std">std</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.subplots" href="#vectorbt.generic.accessors.GenericAccessor.subplots">subplots</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.sum" href="#vectorbt.generic.accessors.GenericAccessor.sum">sum</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_mapped" href="#vectorbt.generic.accessors.GenericAccessor.to_mapped">to_mapped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.to_returns" href="#vectorbt.generic.accessors.GenericAccessor.to_returns">to_returns</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.transform" href="#vectorbt.generic.accessors.GenericAccessor.transform">transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.value_counts" href="#vectorbt.generic.accessors.GenericAccessor.value_counts">value_counts</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericAccessor.zscore" href="#vectorbt.generic.accessors.GenericAccessor.zscore">zscore</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.GenericDFAccessor" href="#vectorbt.generic.accessors.GenericDFAccessor">GenericDFAccessor</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped" href="#vectorbt.generic.accessors.GenericDFAccessor.flatten_grouped">flatten_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor.heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.heatmap">heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped" href="#vectorbt.generic.accessors.GenericDFAccessor.squeeze_grouped">squeeze_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericDFAccessor.ts_heatmap" href="#vectorbt.generic.accessors.GenericDFAccessor.ts_heatmap">ts_heatmap</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.GenericSRAccessor" href="#vectorbt.generic.accessors.GenericSRAccessor">GenericSRAccessor</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.flatten_grouped" href="#vectorbt.generic.accessors.GenericSRAccessor.flatten_grouped">flatten_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.heatmap" href="#vectorbt.generic.accessors.GenericSRAccessor.heatmap">heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.overlay_with_heatmap" href="#vectorbt.generic.accessors.GenericSRAccessor.overlay_with_heatmap">overlay_with_heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.plot_against" href="#vectorbt.generic.accessors.GenericSRAccessor.plot_against">plot_against</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.qqplot" href="#vectorbt.generic.accessors.GenericSRAccessor.qqplot">qqplot</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.squeeze_grouped" href="#vectorbt.generic.accessors.GenericSRAccessor.squeeze_grouped">squeeze_grouped</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.ts_heatmap" href="#vectorbt.generic.accessors.GenericSRAccessor.ts_heatmap">ts_heatmap</a></code></li>
<li><code><a title="vectorbt.generic.accessors.GenericSRAccessor.volume" href="#vectorbt.generic.accessors.GenericSRAccessor.volume">volume</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.MetaGenericAccessor" href="#vectorbt.generic.accessors.MetaGenericAccessor">MetaGenericAccessor</a></code></h4>
</li>
<li>
<h4><code><a title="vectorbt.generic.accessors.TransformerT" href="#vectorbt.generic.accessors.TransformerT">TransformerT</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.generic.accessors.TransformerT.fit_transform" href="#vectorbt.generic.accessors.TransformerT.fit_transform">fit_transform</a></code></li>
<li><code><a title="vectorbt.generic.accessors.TransformerT.transform" href="#vectorbt.generic.accessors.TransformerT.transform">transform</a></code></li>
</ul>
</li>
</ul>
</li>
</nav>
</main>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript">
docsearch({
apiKey: 'ac97cfdd96a6e6fcdc67c570adaeaf94',
indexName: 'vectorbt',
inputSelector: '#search_input',
autocompleteOptions: {
autoWidth: false
},
debug: true // Set debug to true if you want to inspect the dropdown
});
</script>
<script src="https://buttons.github.io/buttons.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
<script>
// Turn off ESLint for this file because it's sent down to users as-is.
/* eslint-disable */
window.addEventListener('load', function() {
function button(label, ariaLabel, icon, className) {
const btn = document.createElement('button');
btn.classList.add('btnIcon', className);
btn.setAttribute('type', 'button');
btn.setAttribute('aria-label', ariaLabel);
btn.innerHTML =
'<div class="btnIcon__body">' +
icon +
'<strong class="btnIcon__label">' +
label +
'</strong>' +
'</div>';
return btn;
}
function addButtons(codeBlockSelector, btn) {
document.querySelectorAll(codeBlockSelector).forEach(function(code) {
code.parentNode.appendChild(btn.cloneNode(true));
});
}
const copyIcon =
'<svg width="12" height="12" viewBox="340 364 14 15" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M342 375.974h4v.998h-4v-.998zm5-5.987h-5v.998h5v-.998zm2 2.994v-1.995l-3 2.993 3 2.994v-1.996h5v-1.995h-5zm-4.5-.997H342v.998h2.5v-.997zm-2.5 2.993h2.5v-.998H342v.998zm9 .998h1v1.996c-.016.28-.11.514-.297.702-.187.187-.422.28-.703.296h-10c-.547 0-1-.452-1-.998v-10.976c0-.546.453-.998 1-.998h3c0-1.107.89-1.996 2-1.996 1.11 0 2 .89 2 1.996h3c.547 0 1 .452 1 .998v4.99h-1v-2.995h-10v8.98h10v-1.996zm-9-7.983h8c0-.544-.453-.996-1-.996h-1c-.547 0-1-.453-1-.998 0-.546-.453-.998-1-.998-.547 0-1 .452-1 .998 0 .545-.453.998-1 .998h-1c-.547 0-1 .452-1 .997z" fill-rule="evenodd"/></svg>';
addButtons(
'.hljs',
button('Copy', 'Copy code to clipboard', copyIcon, 'btnClipboard'),
);
const clipboard = new ClipboardJS('.btnClipboard', {
target: function(trigger) {
return trigger.parentNode.querySelector('code');
},
});
clipboard.on('success', function(event) {
event.clearSelection();
const textEl = event.trigger.querySelector('.btnIcon__label');
textEl.textContent = 'Copied';
setTimeout(function() {
textEl.textContent = 'Copy';
}, 2000);
});
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous"></script>
<script>
$(document).ready(function() {
$("article dt[id], #section-intro [id]").each(function() {
const thisId = $(this).attr('id');
$(this).wrap('<a class="headerlink" href="#' + thisId + '">');
});
});
</script>
</body>
</html>