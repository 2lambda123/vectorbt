<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>vectorbt.generic.nb API documentation</title>
<meta name="description" content="Numba-compiled functions â€¦" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-2/css/all.min.css" integrity="sha256-46r060N2LrChLLb5zowXQ72/iKKNiw/lAmygmHExk/o=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/styles/atom-one-dark.min.css" rel="stylesheet">
<style>:root{--highlight-color:#e82}body{line-height:1.5em}.version{font-weight:normal;font-style:italic;font-size:.75em;color:#8b949e}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar>*:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #eee;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}h2[id^="header-"]{margin-top:2em}.ident{color:#900}.headerlink{color:inherit}.headerlink:hover{color:inherit}pre code{background:#f8f8f8}.hljs{padding:1.25rem 1.5rem;border:1px solid #eee;border-radius:6px;background:#282c34 !important;color:#9da29e !important;word-break:normal}.hljs-keyword{color:#ff7b72 !important}.hljs-comment{color:#8b949e !important}.hljs-meta{color:#8b949e !important}.python{color:#c5c8c6 !important}code{background:#f2f2f1;padding:1px 4px;font-size:90%}h1 code{background:transparent}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{padding-bottom:.5em;border-bottom:1px solid #e82}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 1.5em}#header-classes+dl>dd{margin-bottom:3em}dd dd{margin-left:1em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name>span:first-child{white-space:nowrap}.name.class>span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-weight:400;font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary>*{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}.badge{display:inline-block;padding:0.25em 0.4em;font-size:75%;font-weight:700;line-height:1;text-align:center;white-space:nowrap;vertical-align:baseline;border-radius:0.25rem;transition:color 0.15s ease-in-out,background-color 0.15s ease-in-out,border-color 0.15s ease-in-out,box-shadow 0.15s ease-in-out}@media (prefers-reduced-motion:reduce){.badge{transition:none}}a.badge:hover,a.badge:focus{text-decoration:none}.badge:empty{display:none}.btn .badge{position:relative;top:-1px}.badge-pill{padding-right:0.6em;padding-left:0.6em;border-radius:10rem}.badge-primary{color:#fff;background-color:#007bff}a.badge-primary:hover,a.badge-primary:focus{color:#fff;background-color:#0062cc}a.badge-primary:focus,a.badge-primary.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(0,123,255,0.5)}.badge-secondary{color:#fff;background-color:#6c757d}a.badge-secondary:hover,a.badge-secondary:focus{color:#fff;background-color:#545b62}a.badge-secondary:focus,a.badge-secondary.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(108,117,125,0.5)}.badge-success{color:#fff;background-color:#28a745}a.badge-success:hover,a.badge-success:focus{color:#fff;background-color:#1e7e34}a.badge-success:focus,a.badge-success.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(40,167,69,0.5)}.badge-info{color:#fff;background-color:#17a2b8}a.badge-info:hover,a.badge-info:focus{color:#fff;background-color:#117a8b}a.badge-info:focus,a.badge-info.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(23,162,184,0.5)}.badge-warning{color:#212529;background-color:#ffc107}a.badge-warning:hover,a.badge-warning:focus{color:#212529;background-color:#d39e00}a.badge-warning:focus,a.badge-warning.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(255,193,7,0.5)}.badge-danger{color:#fff;background-color:#dc3545}a.badge-danger:hover,a.badge-danger:focus{color:#fff;background-color:#bd2130}a.badge-danger:focus,a.badge-danger.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(220,53,69,0.5)}.badge-light{color:#212529;background-color:#f8f9fa}a.badge-light:hover,a.badge-light:focus{color:#212529;background-color:#dae0e5}a.badge-light:focus,a.badge-light.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(248,249,250,0.5)}.badge-dark{color:#fff;background-color:#343a40}a.badge-dark:hover,a.badge-dark:focus{color:#fff;background-color:#1d2124}a.badge-dark:focus,a.badge-dark.focus{outline:0;box-shadow:0 0 0 0.2rem rgba(52,58,64,0.5)}.search-container{width:100%;margin-top:15px;margin-bottom:15px}#search_input{display:inline-block;width:100%;height:40px;padding:.375rem .75rem;font-size:1rem;line-height:1.5;color:white;background:#282c34 !important;border:none;border-radius:6px;border-bottom:1px solid #e82;outline:none}.algolia-autocomplete{width:100%;background:rgba(0,0,0,.2);border:none;border-radius:6px}.algolia-autocomplete input{display:none}.index-caption{color:white}#index a,#index h3,.toc a{color:white}#index a:hover,.toc a:hover{color:#e82}#sidebar{background:#393f4a}.toc ul ul,#index ul{padding-left:1.5em}.toc>ul>li{margin-top:.5em}pre{position:relative;background:#fafafa}pre .btnIcon{position:absolute;top:4px;z-index:2;cursor:pointer;border:1px solid transparent;padding:0;color:#383a42;background-color:transparent;height:30px;transition:all .25s ease-out}pre .btnIcon:hover{text-decoration:none}.btnIcon__body{align-items:center;display:flex;color:#abb2bf}.btnIcon svg{fill:currentColor;margin-right:.4em}.btnIcon__label{font-size:11px}.btnClipboard{right:10px}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{min-width:400px;height:100vh;overflow:visible;position:sticky;top:0}#content{width:100%;max-width:100ch;padding:3em 4em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.scrollable-index{overflow-y:scroll;height:calc(100vh - 250px)}.hljs{margin-left:-15px;margin-right:-15px}.source pre code{margin-left:0px;margin-right:0px}dd{margin:0 0 1em 3em}dd dd{margin-left:2em}.flex{display:flex !important}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4QLCS0J048"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-4QLCS0J048');
</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:white}.homelink:hover{color:#e82}.homelink img{max-width:100px;max-height:100px;margin:auto;margin-bottom:.3em}</style>
<link rel="apple-touch-icon" sizes="180x180" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon-16x16.png">
<link rel="manifest" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/site.webmanifest">
<link rel="icon" href="https://raw.githubusercontent.com/polakowo/vectorbt/master/static/favicon/favicon.ico">
<meta name="msapplication-TileColor" content="#282c34">
<meta name="theme-color" content="#282c34">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>vectorbt.generic.nb</code></h1>
</header>
<section id="section-intro">
<p>Numba-compiled functions.</p>
<p>Provides an arsenal of Numba-compiled functions that are used by accessors
and in many other parts of the backtesting pipeline, such as technical indicators.
These only accept NumPy arrays and other Numba-compatible types.</p>
<p>The module can be accessed directly via <code>vbt.nb</code>.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import vectorbt as vbt

&gt;&gt;&gt; # vectorbt.generic.nb.rolling_mean_1d_nb
&gt;&gt;&gt; vbt.nb.rolling_mean_1d_nb(np.array([1, 2, 3, 4]), 2)
array([nan, 1.5, 2.5, 3.5])
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>vectorbt treats matrices as first-class citizens and expects input arrays to be
2-dim, unless function has suffix <code>_1d</code> or is meant to be input to another function.
Data is processed along index (axis 0).</p>
<p>Rolling functions with <code>minp=None</code> have <code>min_periods</code> set to the window size.</p>
<p>All functions passed as argument should be Numba-compiled.</p>
</div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright (c) 2021 Oleg Polakow. All rights reserved.
# This code is licensed under Apache 2.0 with Commons Clause license (see LICENSE.md for details)

&#34;&#34;&#34;Numba-compiled functions.

Provides an arsenal of Numba-compiled functions that are used by accessors
and in many other parts of the backtesting pipeline, such as technical indicators.
These only accept NumPy arrays and other Numba-compatible types.

The module can be accessed directly via `vbt.nb`.

```python-repl
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import vectorbt as vbt

&gt;&gt;&gt; # vectorbt.generic.nb.rolling_mean_1d_nb
&gt;&gt;&gt; vbt.nb.rolling_mean_1d_nb(np.array([1, 2, 3, 4]), 2)
array([nan, 1.5, 2.5, 3.5])
```

!!! note
    vectorbt treats matrices as first-class citizens and expects input arrays to be
    2-dim, unless function has suffix `_1d` or is meant to be input to another function. 
    Data is processed along index (axis 0).
    
    Rolling functions with `minp=None` have `min_periods` set to the window size.
    
    All functions passed as argument should be Numba-compiled.&#34;&#34;&#34;

import numpy as np
from numba import njit, generated_jit
from numba.np.numpy_support import as_dtype
from numba.typed import Dict
from numba.core.types import Omitted

from vectorbt import _typing as tp
from vectorbt.generic.enums import RangeStatus, DrawdownStatus, range_dt, drawdown_dt


@njit(cache=True)
def shuffle_1d_nb(a: tp.Array1d, seed: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Shuffle each column in `a`.

    Specify `seed` to make output deterministic.&#34;&#34;&#34;
    if seed is not None:
        np.random.seed(seed)
    return np.random.permutation(a)


@njit(cache=True)
def shuffle_nb(a: tp.Array2d, seed: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `shuffle_1d_nb`.&#34;&#34;&#34;
    if seed is not None:
        np.random.seed(seed)
    out = np.empty_like(a, dtype=a.dtype)

    for col in range(a.shape[1]):
        out[:, col] = np.random.permutation(a[:, col])
    return out


@generated_jit(nopython=True, cache=True)
def set_by_mask_1d_nb(a: tp.Array1d, mask: tp.Array1d, value: tp.Scalar) -&gt; tp.Array1d:
    &#34;&#34;&#34;Set each element to a value by boolean mask.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(value)
    else:
        a_dtype = a.dtype
        value_dtype = np.array(value).dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_1d_nb(a, mask, value):
        out = a.astype(dtype)
        out[mask] = value
        return out

    if not nb_enabled:
        return _set_by_mask_1d_nb(a, mask, value)

    return _set_by_mask_1d_nb


@generated_jit(nopython=True, cache=True)
def set_by_mask_nb(a: tp.Array2d, mask: tp.Array2d, value: tp.Scalar) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `set_by_mask_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(value)
    else:
        a_dtype = a.dtype
        value_dtype = np.array(value).dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_nb(a, mask, value):
        out = a.astype(dtype)
        for col in range(a.shape[1]):
            out[mask[:, col], col] = value
        return out

    if not nb_enabled:
        return _set_by_mask_nb(a, mask, value)

    return _set_by_mask_nb


@generated_jit(nopython=True, cache=True)
def set_by_mask_mult_1d_nb(a: tp.Array1d, mask: tp.Array1d, values: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Set each element in one array to the corresponding element in another by boolean mask.

    `values` should be of the same shape as in `a`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(values.dtype)
    else:
        a_dtype = a.dtype
        value_dtype = values.dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_mult_1d_nb(a, mask, values):
        out = a.astype(dtype)
        out[mask] = values[mask]
        return out

    if not nb_enabled:
        return _set_by_mask_mult_1d_nb(a, mask, values)

    return _set_by_mask_mult_1d_nb


@generated_jit(nopython=True, cache=True)
def set_by_mask_mult_nb(a: tp.Array2d, mask: tp.Array2d, values: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `set_by_mask_mult_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(values.dtype)
    else:
        a_dtype = a.dtype
        value_dtype = values.dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_mult_nb(a, mask, values):
        out = a.astype(dtype)
        for col in range(a.shape[1]):
            out[mask[:, col], col] = values[mask[:, col], col]
        return out

    if not nb_enabled:
        return _set_by_mask_mult_nb(a, mask, values)

    return _set_by_mask_mult_nb


@njit(cache=True)
def fillna_1d_nb(a: tp.Array1d, value: tp.Scalar) -&gt; tp.Array1d:
    &#34;&#34;&#34;Replace NaNs with value.

    Numba equivalent to `pd.Series(a).fillna(value)`.&#34;&#34;&#34;
    return set_by_mask_1d_nb(a, np.isnan(a), value)


@njit(cache=True)
def fillna_nb(a: tp.Array2d, value: tp.Scalar) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `fillna_1d_nb`.&#34;&#34;&#34;
    return set_by_mask_nb(a, np.isnan(a), value)


@generated_jit(nopython=True, cache=True)
def bshift_1d_nb(a: tp.Array1d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array1d:
    &#34;&#34;&#34;Shift backward by `n` positions.

    Numba equivalent to `pd.Series(a).shift(n)`.

    !!! warning
        This operation looks ahead.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _bshift_1d_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        out[-n:] = fill_value
        out[:-n] = a[n:]
        return out

    if not nb_enabled:
        return _bshift_1d_nb(a, n, fill_value)

    return _bshift_1d_nb


@generated_jit(nopython=True, cache=True)
def bshift_nb(a: tp.Array2d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `bshift_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _bshift_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = bshift_1d_nb(a[:, col], n=n, fill_value=fill_value)
        return out

    if not nb_enabled:
        return _bshift_nb(a, n, fill_value)

    return _bshift_nb


@generated_jit(nopython=True, cache=True)
def fshift_1d_nb(a: tp.Array1d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array1d:
    &#34;&#34;&#34;Shift forward by `n` positions.

    Numba equivalent to `pd.Series(a).shift(n)`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _fshift_1d_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        out[:n] = fill_value
        out[n:] = a[:-n]
        return out

    if not nb_enabled:
        return _fshift_1d_nb(a, n, fill_value)

    return _fshift_1d_nb


@generated_jit(nopython=True, cache=True)
def fshift_nb(a: tp.Array2d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `fshift_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _fshift_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = fshift_1d_nb(a[:, col], n=n, fill_value=fill_value)
        return out

    if not nb_enabled:
        return _fshift_nb(a, n, fill_value)

    return _fshift_nb


@njit(cache=True)
def diff_1d_nb(a: tp.Array1d, n: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the 1-th discrete difference.

    Numba equivalent to `pd.Series(a).diff()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    out[:n] = np.nan
    out[n:] = a[n:] - a[:-n]
    return out


@njit(cache=True)
def diff_nb(a: tp.Array2d, n: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `diff_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = diff_1d_nb(a[:, col], n=n)
    return out


@njit(cache=True)
def pct_change_1d_nb(a: tp.Array1d, n: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the percentage change.

    Numba equivalent to `pd.Series(a).pct_change()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    out[:n] = np.nan
    out[n:] = a[n:] / a[:-n] - 1
    return out


@njit(cache=True)
def pct_change_nb(a: tp.Array2d, n: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `pct_change_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = pct_change_1d_nb(a[:, col], n=n)
    return out


@njit(cache=True)
def bfill_1d_nb(a: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Fill NaNs by propagating first valid observation backward.

    Numba equivalent to `pd.Series(a).fillna(method=&#39;bfill&#39;)`.

    !!! warning
        This operation looks ahead.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    lastval = a[-1]
    for i in range(a.shape[0] - 1, -1, -1):
        if np.isnan(a[i]):
            out[i] = lastval
        else:
            lastval = out[i] = a[i]
    return out


@njit(cache=True)
def bfill_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `bfill_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    for col in range(a.shape[1]):
        out[:, col] = bfill_1d_nb(a[:, col])
    return out



@njit(cache=True)
def ffill_1d_nb(a: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Fill NaNs by propagating last valid observation forward.

    Numba equivalent to `pd.Series(a).fillna(method=&#39;ffill&#39;)`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    lastval = a[0]
    for i in range(a.shape[0]):
        if np.isnan(a[i]):
            out[i] = lastval
        else:
            lastval = out[i] = a[i]
    return out


@njit(cache=True)
def ffill_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `ffill_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    for col in range(a.shape[1]):
        out[:, col] = ffill_1d_nb(a[:, col])
    return out


@generated_jit(nopython=True, cache=True)
def nanprod_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanprod` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nanprod_nb(a):
        out = np.empty(a.shape[1], dtype=dtype)
        for col in range(a.shape[1]):
            out[col] = np.nanprod(a[:, col])
        return out

    if not nb_enabled:
        return _nanprod_nb(a)

    return _nanprod_nb


@generated_jit(nopython=True, cache=True)
def nancumsum_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;Numba-equivalent of `np.nancumsum` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nancumsum_nb(a):
        out = np.empty(a.shape, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = np.nancumsum(a[:, col])
        return out

    if not nb_enabled:
        return _nancumsum_nb(a)

    return _nancumsum_nb


@generated_jit(nopython=True, cache=True)
def nancumprod_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;Numba-equivalent of `np.nancumprod` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nancumprod_nb(a):
        out = np.empty(a.shape, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = np.nancumprod(a[:, col])
        return out

    if not nb_enabled:
        return _nancumprod_nb(a)

    return _nancumprod_nb


@njit(cache=True)
def nancnt_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Compute count while ignoring NaNs.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.int_)
    for col in range(a.shape[1]):
        out[col] = np.sum(~np.isnan(a[:, col]))
    return out


@generated_jit(nopython=True, cache=True)
def nansum_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nansum` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nansum_nb(a):
        out = np.empty(a.shape[1], dtype=dtype)
        for col in range(a.shape[1]):
            out[col] = np.nansum(a[:, col])
        return out

    if not nb_enabled:
        return _nansum_nb(a)

    return _nansum_nb


@njit(cache=True)
def nanmin_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmin` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=a.dtype)
    for col in range(a.shape[1]):
        out[col] = np.nanmin(a[:, col])
    return out


@njit(cache=True)
def nanmax_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmax` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=a.dtype)
    for col in range(a.shape[1]):
        out[col] = np.nanmax(a[:, col])
    return out


@njit(cache=True)
def nanmean_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmean` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.float_)
    for col in range(a.shape[1]):
        out[col] = np.nanmean(a[:, col])
    return out


@njit(cache=True)
def nanmedian_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmedian` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.float_)
    for col in range(a.shape[1]):
        out[col] = np.nanmedian(a[:, col])
    return out


@njit(cache=True)
def nanstd_1d_nb(a: tp.Array1d, ddof: int = 0) -&gt; float:
    &#34;&#34;&#34;Numba-equivalent of `np.nanstd`.&#34;&#34;&#34;
    cnt = a.shape[0] - np.count_nonzero(np.isnan(a))
    rcount = max(cnt - ddof, 0)
    if rcount == 0:
        return np.nan
    return np.sqrt(np.nanvar(a) * cnt / rcount)


@njit(cache=True)
def nanstd_nb(a: tp.Array2d, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;2-dim version of `nanstd_1d_nb`.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.float_)
    for col in range(a.shape[1]):
        out[col] = nanstd_1d_nb(a[:, col], ddof=ddof)
    return out


# ############# Rolling functions ############# #


@njit(cache=True)
def rolling_min_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling min.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).min()`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    for i in range(a.shape[0]):
        minv = a[i]
        cnt = 0
        for j in range(max(i - window + 1, 0), i + 1):
            if np.isnan(a[j]):
                continue
            if np.isnan(minv) or a[j] &lt; minv:
                minv = a[j]
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = minv
    return out


@njit(cache=True)
def rolling_min_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_min_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_min_1d_nb(a[:, col], window, minp=minp)
    return out


@njit(cache=True)
def rolling_max_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling max.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).max()`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    for i in range(a.shape[0]):
        maxv = a[i]
        cnt = 0
        for j in range(max(i - window + 1, 0), i + 1):
            if np.isnan(a[j]):
                continue
            if np.isnan(maxv) or a[j] &gt; maxv:
                maxv = a[j]
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = maxv
    return out


@njit(cache=True)
def rolling_max_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_max_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_max_1d_nb(a[:, col], window, minp=minp)
    return out


@njit(cache=True)
def rolling_mean_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling mean.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).mean()`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    cumsum_arr = np.zeros_like(a)
    cumsum = 0
    nancnt_arr = np.zeros_like(a)
    nancnt = 0
    for i in range(a.shape[0]):
        if np.isnan(a[i]):
            nancnt = nancnt + 1
        else:
            cumsum = cumsum + a[i]
        nancnt_arr[i] = nancnt
        cumsum_arr[i] = cumsum
        if i &lt; window:
            window_len = i + 1 - nancnt
            window_cumsum = cumsum
        else:
            window_len = window - (nancnt - nancnt_arr[i - window])
            window_cumsum = cumsum - cumsum_arr[i - window]
        if window_len &lt; minp:
            out[i] = np.nan
        else:
            out[i] = window_cumsum / window_len
    return out


@njit(cache=True)
def rolling_mean_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_mean_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_mean_1d_nb(a[:, col], window, minp=minp)
    return out


@njit(cache=True)
def rolling_std_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling standard deviation.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).std(ddof=ddof)`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    cumsum_arr = np.zeros_like(a)
    cumsum = 0
    cumsum_sq_arr = np.zeros_like(a)
    cumsum_sq = 0
    nancnt_arr = np.zeros_like(a)
    nancnt = 0
    for i in range(a.shape[0]):
        if np.isnan(a[i]):
            nancnt = nancnt + 1
        else:
            cumsum = cumsum + a[i]
            cumsum_sq = cumsum_sq + a[i] ** 2
        nancnt_arr[i] = nancnt
        cumsum_arr[i] = cumsum
        cumsum_sq_arr[i] = cumsum_sq
        if i &lt; window:
            window_len = i + 1 - nancnt
            window_cumsum = cumsum
            window_cumsum_sq = cumsum_sq
        else:
            window_len = window - (nancnt - nancnt_arr[i - window])
            window_cumsum = cumsum - cumsum_arr[i - window]
            window_cumsum_sq = cumsum_sq - cumsum_sq_arr[i - window]
        if window_len &lt; minp or window_len == ddof:
            out[i] = np.nan
        else:
            mean = window_cumsum / window_len
            out[i] = np.sqrt(np.abs(window_cumsum_sq - 2 * window_cumsum *
                                    mean + window_len * mean ** 2) / (window_len - ddof))
    return out


@njit(cache=True)
def rolling_std_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None, ddof: int = 0) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_std_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_std_1d_nb(a[:, col], window, minp=minp, ddof=ddof)
    return out


@njit(cache=True)
def ewm_mean_1d_nb(a: tp.Array1d, span: int, minp: int = 0, adjust: bool = False) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return exponential weighted average.

    Numba equivalent to `pd.Series(a).ewm(span=span, min_periods=minp, adjust=adjust).mean()`.

    Adaptation of `pd._libs.window.aggregations.window_aggregations.ewma` with default arguments.&#34;&#34;&#34;
    if minp is None:
        minp = span
    if minp &gt; span:
        raise ValueError(&#34;minp must be &lt;= span&#34;)
    N = len(a)
    out = np.empty(N, dtype=np.float_)
    if N == 0:
        return out
    com = (span - 1) / 2.0
    alpha = 1. / (1. + com)
    old_wt_factor = 1. - alpha
    new_wt = 1. if adjust else alpha
    weighted_avg = a[0]
    is_observation = (weighted_avg == weighted_avg)
    nobs = int(is_observation)
    out[0] = weighted_avg if (nobs &gt;= minp) else np.nan
    old_wt = 1.

    for i in range(1, N):
        cur = a[i]
        is_observation = (cur == cur)
        nobs += is_observation
        if weighted_avg == weighted_avg:
            old_wt *= old_wt_factor
            if is_observation:
                # avoid numerical errors on constant series
                if weighted_avg != cur:
                    weighted_avg = ((old_wt * weighted_avg) + (new_wt * cur)) / (old_wt + new_wt)
                if adjust:
                    old_wt += new_wt
                else:
                    old_wt = 1.
        elif is_observation:
            weighted_avg = cur
        out[i] = weighted_avg if (nobs &gt;= minp) else np.nan
    return out


@njit(cache=True)
def ewm_mean_nb(a: tp.Array2d, span: int, minp: int = 0, adjust: bool = False) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `ewm_mean_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = ewm_mean_1d_nb(a[:, col], span, minp=minp, adjust=adjust)
    return out


@njit(cache=True)
def ewm_std_1d_nb(a: tp.Array1d, span: int, minp: int = 0, adjust: bool = False, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return exponential weighted standard deviation.

    Numba equivalent to `pd.Series(a).ewm(span=span, min_periods=minp).std(ddof=ddof)`.

    Adaptation of `pd._libs.window.aggregations.window_aggregations.ewmcov` with default arguments.&#34;&#34;&#34;
    if minp is None:
        minp = span
    if minp &gt; span:
        raise ValueError(&#34;minp must be &lt;= span&#34;)
    N = len(a)
    out = np.empty(N, dtype=np.float_)
    if N == 0:
        return out
    com = (span - 1) / 2.0
    alpha = 1. / (1. + com)
    old_wt_factor = 1. - alpha
    new_wt = 1. if adjust else alpha
    mean_x = a[0]
    mean_y = a[0]
    is_observation = ((mean_x == mean_x) and (mean_y == mean_y))
    nobs = int(is_observation)
    if not is_observation:
        mean_x = np.nan
        mean_y = np.nan
    out[0] = np.nan
    cov = 0.
    sum_wt = 1.
    sum_wt2 = 1.
    old_wt = 1.

    for i in range(1, N):
        cur_x = a[i]
        cur_y = a[i]
        is_observation = ((cur_x == cur_x) and (cur_y == cur_y))
        nobs += is_observation
        if mean_x == mean_x:
            sum_wt *= old_wt_factor
            sum_wt2 *= (old_wt_factor * old_wt_factor)
            old_wt *= old_wt_factor
            if is_observation:
                old_mean_x = mean_x
                old_mean_y = mean_y

                # avoid numerical errors on constant series
                if mean_x != cur_x:
                    mean_x = ((old_wt * old_mean_x) +
                              (new_wt * cur_x)) / (old_wt + new_wt)

                # avoid numerical errors on constant series
                if mean_y != cur_y:
                    mean_y = ((old_wt * old_mean_y) +
                              (new_wt * cur_y)) / (old_wt + new_wt)
                cov = ((old_wt * (cov + ((old_mean_x - mean_x) *
                                         (old_mean_y - mean_y)))) +
                       (new_wt * ((cur_x - mean_x) *
                                  (cur_y - mean_y)))) / (old_wt + new_wt)
                sum_wt += new_wt
                sum_wt2 += (new_wt * new_wt)
                old_wt += new_wt
                if not adjust:
                    sum_wt /= old_wt
                    sum_wt2 /= (old_wt * old_wt)
                    old_wt = 1.
        elif is_observation:
            mean_x = cur_x
            mean_y = cur_y

        if nobs &gt;= minp:
            numerator = sum_wt * sum_wt
            denominator = numerator - sum_wt2
            if denominator &gt; 0.:
                out[i] = ((numerator / denominator) * cov)
            else:
                out[i] = np.nan
        else:
            out[i] = np.nan
    return np.sqrt(out)


@njit(cache=True)
def ewm_std_nb(a: tp.Array2d, span: int, minp: int = 0, adjust: bool = False, ddof: int = 0) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `ewm_std_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = ewm_std_1d_nb(a[:, col], span, minp=minp, adjust=adjust, ddof=ddof)
    return out


# ############# Expanding functions ############# #


@njit(cache=True)
def expanding_min_1d_nb(a: tp.Array1d, minp: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding min.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).min()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    minv = a[0]
    cnt = 0
    for i in range(a.shape[0]):
        if np.isnan(minv) or a[i] &lt; minv:
            minv = a[i]
        if not np.isnan(a[i]):
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = minv
    return out


@njit(cache=True)
def expanding_min_nb(a: tp.Array2d, minp: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_min_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = expanding_min_1d_nb(a[:, col], minp=minp)
    return out


@njit(cache=True)
def expanding_max_1d_nb(a: tp.Array1d, minp: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding max.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).max()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    maxv = a[0]
    cnt = 0
    for i in range(a.shape[0]):
        if np.isnan(maxv) or a[i] &gt; maxv:
            maxv = a[i]
        if not np.isnan(a[i]):
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = maxv
    return out


@njit(cache=True)
def expanding_max_nb(a: tp.Array2d, minp: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_max_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = expanding_max_1d_nb(a[:, col], minp=minp)
    return out


@njit(cache=True)
def expanding_mean_1d_nb(a: tp.Array1d, minp: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding mean.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).mean()`.&#34;&#34;&#34;
    return rolling_mean_1d_nb(a, a.shape[0], minp=minp)


@njit(cache=True)
def expanding_mean_nb(a: tp.Array2d, minp: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_mean_1d_nb`.&#34;&#34;&#34;
    return rolling_mean_nb(a, a.shape[0], minp=minp)


@njit(cache=True)
def expanding_std_1d_nb(a: tp.Array1d, minp: int = 1, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding standard deviation.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).std(ddof=ddof)`.&#34;&#34;&#34;
    return rolling_std_1d_nb(a, a.shape[0], minp=minp, ddof=ddof)


@njit(cache=True)
def expanding_std_nb(a: tp.Array2d, minp: int = 1, ddof: int = 0) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_std_1d_nb`.&#34;&#34;&#34;
    return rolling_std_nb(a, a.shape[0], minp=minp, ddof=ddof)


# ############# Apply functions ############# #


@njit
def apply_nb(a: tp.Array2d, apply_func_nb: tp.ApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Apply function on each column.

    `apply_func_nb` should accept index of the column, the array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        _out = apply_func_nb(col, a[:, col], *args)
        if col == 0:
            out = np.empty_like(a, dtype=np.asarray(_out).dtype)
        out[:, col] = _out
    return out


@njit
def row_apply_nb(a: tp.Array2d, apply_func_nb: tp.RowApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Apply function on each row.

    `apply_func_nb` should accept index of the row, the array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    for i in range(a.shape[0]):
        _out = apply_func_nb(i, a[i, :], *args)
        if i == 0:
            out = np.empty_like(a, dtype=np.asarray(_out).dtype)
        out[i, :] = _out
    return out


@njit
def rolling_apply_nb(a: tp.Array2d, window: int, minp: tp.Optional[int],
                     apply_func_nb: tp.RollApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Provide rolling window calculations.

    `apply_func_nb` should accept index of the row, index of the column,
    the array, and `*args`. Should return a single value.&#34;&#34;&#34;
    if minp is None:
        minp = window
    out = np.empty_like(a, dtype=np.float_)
    nancnt_arr = np.empty((a.shape[0],), dtype=np.int_)
    for col in range(a.shape[1]):
        nancnt = 0
        for i in range(a.shape[0]):
            if np.isnan(a[i, col]):
                nancnt = nancnt + 1
            nancnt_arr[i] = nancnt
            if i &lt; window:
                valid_cnt = i + 1 - nancnt
            else:
                valid_cnt = window - (nancnt - nancnt_arr[i - window])
            if valid_cnt &lt; minp:
                out[i, col] = np.nan
            else:
                window_a = a[max(0, i + 1 - window):i + 1, col]
                out[i, col] = apply_func_nb(i, col, window_a, *args)
    return out


@njit
def rolling_matrix_apply_nb(a: tp.Array2d, window: int, minp: tp.Optional[int],
                            apply_func_nb: tp.RollMatrixApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;`rolling_apply_nb` with `apply_func_nb` being applied on all columns at once.

    `apply_func_nb` should accept index of the row, the 2-dim array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    out = np.empty_like(a, dtype=np.float_)
    nancnt_arr = np.empty((a.shape[0],), dtype=np.int_)
    for i in range(a.shape[0]):
        nancnt = 0
        for col in range(a.shape[1]):
            if np.isnan(a[i, col]):
                nancnt = nancnt + 1
        nancnt_arr[i] = nancnt
        if i &lt; window:
            valid_cnt = i + 1 - nancnt
        else:
            valid_cnt = window - (nancnt - nancnt_arr[i - window])
        if valid_cnt &lt; minp:
            out[i, :] = np.nan
        else:
            window_a = a[max(0, i + 1 - window):i + 1, :]
            out[i, :] = apply_func_nb(i, window_a, *args)
    return out


@njit
def expanding_apply_nb(a: tp.Array2d, minp: tp.Optional[int],
                       apply_func_nb: tp.RollApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Expanding version of `rolling_apply_nb`.&#34;&#34;&#34;
    return rolling_apply_nb(a, a.shape[0], minp, apply_func_nb, *args)


@njit
def expanding_matrix_apply_nb(a: tp.Array2d, minp: tp.Optional[int],
                              apply_func_nb: tp.RollMatrixApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Expanding version of `rolling_matrix_apply_nb`.&#34;&#34;&#34;
    return rolling_matrix_apply_nb(a, a.shape[0], minp, apply_func_nb, *args)


@njit
def groupby_apply_nb(a: tp.Array2d, groups: Dict,
                     apply_func_nb: tp.GroupByApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Provide group-by calculations.

    `groups` should be a dictionary, where each key is an index that points to an element in the new array
    where a group-by result will be stored, while the value should be an array of indices in `a`
    to apply `apply_func_nb` on.

    `apply_func_nb` should accept indices of the group, index of the column,
    the array, and `*args`. Should return a single value.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        for g, (i, idxs) in enumerate(groups.items()):
            _out = apply_func_nb(idxs, col, a[idxs, col], *args)
            if col == 0 and g == 0:
                out = np.empty((len(groups), a.shape[1]), dtype=np.asarray(_out).dtype)
            out[i, col] = _out
    return out


@njit
def groupby_matrix_apply_nb(a: tp.Array2d, groups: Dict,
                            apply_func_nb: tp.GroupByMatrixApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;`groupby_apply_nb` with `apply_func_nb` being applied on all columns at once.

    `apply_func_nb` should accept indices of the group, the 2-dim array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    for g, (i, idxs) in enumerate(groups.items()):
        _out = apply_func_nb(idxs, a[idxs, :], *args)
        if g == 0:
            out = np.empty((len(groups), a.shape[1]), dtype=np.asarray(_out).dtype)
        out[i, :] = _out
    return out


# ############# Map, filter and reduce ############# #


@njit
def applymap_nb(a: tp.Array2d, map_func_nb: tp.ApplyMapFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Map non-NA elements element-wise using `map_func_nb`.

    `map_func_nb` should accept index of the row, index of the column,
    the element itself, and `*args`. Should return a single value.&#34;&#34;&#34;
    out = np.full_like(a, np.nan, dtype=np.float_)

    for col in range(out.shape[1]):
        idxs = np.flatnonzero(~np.isnan(a[:, col]))
        for i in idxs:
            out[i, col] = map_func_nb(i, col, a[i, col], *args)
    return out


@njit
def filter_nb(a: tp.Array2d, filter_func_nb: tp.FilterFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Filter non-NA elements elementwise using `filter_func_nb`. 
    The filtered out elements will become NA.

    `filter_func_nb` should accept index of the row, index of the column,
    the element itself, and `*args`. Should return a bool.&#34;&#34;&#34;
    out = a.astype(np.float_)

    for col in range(out.shape[1]):
        idxs = np.flatnonzero(~np.isnan(a[:, col]))
        for i in idxs:
            if not filter_func_nb(i, col, a[i, col], *args):
                out[i, col] = np.nan
    return out


@njit
def apply_and_reduce_nb(a: tp.Array2d, apply_func_nb: tp.ApplyFunc, apply_args: tuple,
                        reduce_func_nb: tp.ReduceFunc, reduce_args: tuple) -&gt; tp.Array1d:
    &#34;&#34;&#34;Apply `apply_func_nb` on each column and reduce into a single value using `reduce_func_nb`.

    `apply_func_nb` should accept index of the column, the column itself, and `*apply_args`.
    Should return an array.

    `reduce_func_nb` should accept index of the column, the array of results from
    `apply_func_nb` for that column, and `*reduce_args`. Should return a single value.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        mapped = apply_func_nb(col, a[:, col], *apply_args)
        _out = reduce_func_nb(col, mapped, *reduce_args)
        if col == 0:
            out = np.empty(a.shape[1], dtype=np.asarray(_out).dtype)
        out[col] = _out
    return out


@njit
def reduce_nb(a: tp.Array2d, reduce_func_nb: tp.ReduceFunc, *args) -&gt; tp.Array1d:
    &#34;&#34;&#34;Reduce each column into a single value using `reduce_func_nb`.

    `reduce_func_nb` should accept index of the column, the array, and `*args`.
    Should return a single value.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        _out = reduce_func_nb(col, a[:, col], *args)
        if col == 0:
            out = np.empty(a.shape[1], dtype=np.asarray(_out).dtype)
        out[col] = _out
    return out


@njit
def reduce_to_array_nb(a: tp.Array2d, reduce_func_nb: tp.ReduceArrayFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Reduce each column into an array of values using `reduce_func_nb`.

    `reduce_func_nb` same as for `reduce_nb` but should return an array.

    !!! note
        Output of `reduce_func_nb` should be strictly homogeneous.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        _out = reduce_func_nb(col, a[:, col], *args)
        if col == 0:
            out = np.empty((_out.shape[0], a.shape[1]), dtype=_out.dtype)
        out[:, col] = _out
    return out


@njit
def reduce_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d,
                      reduce_func_nb: tp.GroupReduceFunc, *args) -&gt; tp.Array1d:
    &#34;&#34;&#34;Reduce each group of columns into a single value using `reduce_func_nb`.

    `reduce_func_nb` should accept index of the group, the array of row values, and `*args`.
    Should return a single value.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        _out = reduce_func_nb(group, a[:, from_col:to_col], *args)
        if group == 0:
            out = np.empty(len(group_lens), dtype=np.asarray(_out).dtype)
        out[group] = _out
        from_col = to_col
    return out


@njit(cache=True)
def flatten_forder_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Flatten `a` in F order.&#34;&#34;&#34;
    out = np.empty(a.shape[0] * a.shape[1], dtype=a.dtype)
    for col in range(a.shape[1]):
        out[col * a.shape[0]:(col + 1) * a.shape[0]] = a[:, col]
    return out


@njit
def flat_reduce_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool,
                           reduce_func_nb: tp.FlatGroupReduceFunc, *args) -&gt; tp.Array1d:
    &#34;&#34;&#34;Same as `reduce_grouped_nb` but passes flattened array.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        if in_c_order:
            _out = reduce_func_nb(group, a[:, from_col:to_col].flatten(), *args)
        else:
            _out = reduce_func_nb(group, flatten_forder_nb(a[:, from_col:to_col]), *args)
        if group == 0:
            out = np.empty(len(group_lens), dtype=np.asarray(_out).dtype)
        out[group] = _out
        from_col = to_col
    return out


@njit
def reduce_grouped_to_array_nb(a: tp.Array2d, group_lens: tp.Array1d,
                               reduce_func_nb: tp.GroupReduceArrayFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Reduce each group of columns into an array of values using `reduce_func_nb`.

    `reduce_func_nb` same as for `reduce_grouped_nb` but should return an array.

    !!! note
        Output of `reduce_func_nb` should be strictly homogeneous.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        _out = reduce_func_nb(group, a[:, from_col:to_col], *args)
        if group == 0:
            out = np.empty((_out.shape[0], len(group_lens)), dtype=_out.dtype)
        out[:, group] = _out
        from_col = to_col
    return out


@njit
def flat_reduce_grouped_to_array_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool,
                                    reduce_func_nb: tp.FlatGroupReduceArrayFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Same as `reduce_grouped_to_array_nb` but passes flattened 1D array.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        if in_c_order:
            _out = reduce_func_nb(group, a[:, from_col:to_col].flatten(), *args)
        else:
            _out = reduce_func_nb(group, flatten_forder_nb(a[:, from_col:to_col]), *args)
        if group == 0:
            out = np.full((_out.shape[0], len(group_lens)), np.nan, dtype=_out.dtype)
        out[:, group] = _out
        from_col = to_col
    return out


@njit
def squeeze_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d,
                       squeeze_func_nb: tp.GroupSqueezeFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Squeeze each group of columns into a single column using `squeeze_func_nb`.

    `squeeze_func_nb` should accept index of the row, index of the group,
    the array, and `*args`. Should return a single value.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        for i in range(a.shape[0]):
            _out = squeeze_func_nb(i, group, a[i, from_col:to_col], *args)
            if group == 0 and i == 0:
                out = np.empty((a.shape[0], len(group_lens)), dtype=np.asarray(_out).dtype)
            out[i, group] = _out
        from_col = to_col
    return out


# ############# Reshaping ############# #

@njit(cache=True)
def flatten_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool) -&gt; tp.Array2d:
    &#34;&#34;&#34;Flatten each group of columns.&#34;&#34;&#34;
    out = np.full((a.shape[0] * np.max(group_lens), len(group_lens)), np.nan, dtype=np.float_)
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        group_len = to_col - from_col
        for k in range(group_len):
            if in_c_order:
                out[k::np.max(group_lens), group] = a[:, from_col + k]
            else:
                out[k * a.shape[0]:(k + 1) * a.shape[0], group] = a[:, from_col + k]
        from_col = to_col
    return out


@njit(cache=True)
def flatten_uniform_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool) -&gt; tp.Array2d:
    &#34;&#34;&#34;Flatten each group of columns of the same length.&#34;&#34;&#34;
    out = np.empty((a.shape[0] * np.max(group_lens), len(group_lens)), dtype=a.dtype)
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        group_len = to_col - from_col
        for k in range(group_len):
            if in_c_order:
                out[k::np.max(group_lens), group] = a[:, from_col + k]
            else:
                out[k * a.shape[0]:(k + 1) * a.shape[0], group] = a[:, from_col + k]
        from_col = to_col
    return out


# ############# Reducers ############# #


@njit(cache=True)
def nth_reduce_nb(col: int, a: tp.Array1d, n: int) -&gt; float:
    &#34;&#34;&#34;Return n-th element.&#34;&#34;&#34;
    if (n &lt; 0 and abs(n) &gt; a.shape[0]) or n &gt;= a.shape[0]:
        raise ValueError(&#34;index is out of bounds&#34;)
    return a[n]


@njit(cache=True)
def nth_index_reduce_nb(col: int, a: tp.Array1d, n: int) -&gt; int:
    &#34;&#34;&#34;Return index of n-th element.&#34;&#34;&#34;
    if (n &lt; 0 and abs(n) &gt; a.shape[0]) or n &gt;= a.shape[0]:
        raise ValueError(&#34;index is out of bounds&#34;)
    if n &gt;= 0:
        return n
    return a.shape[0] + n


@njit(cache=True)
def min_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return min (ignores NaNs).&#34;&#34;&#34;
    return np.nanmin(a)


@njit(cache=True)
def max_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return max (ignores NaNs).&#34;&#34;&#34;
    return np.nanmax(a)


@njit(cache=True)
def mean_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return mean (ignores NaNs).&#34;&#34;&#34;
    return np.nanmean(a)


@njit(cache=True)
def median_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return median (ignores NaNs).&#34;&#34;&#34;
    return np.nanmedian(a)


@njit(cache=True)
def std_reduce_nb(col: int, a: tp.Array1d, ddof) -&gt; float:
    &#34;&#34;&#34;Return std (ignores NaNs).&#34;&#34;&#34;
    return nanstd_1d_nb(a, ddof=ddof)


@njit(cache=True)
def sum_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return sum (ignores NaNs).&#34;&#34;&#34;
    return np.nansum(a)


@njit(cache=True)
def count_reduce_nb(col: int, a: tp.Array1d) -&gt; int:
    &#34;&#34;&#34;Return count (ignores NaNs).&#34;&#34;&#34;
    return np.sum(~np.isnan(a))


@njit(cache=True)
def argmin_reduce_nb(col: int, a: tp.Array1d) -&gt; int:
    &#34;&#34;&#34;Return position of min.&#34;&#34;&#34;
    a = np.copy(a)
    mask = np.isnan(a)
    if np.all(mask):
        raise ValueError(&#34;All-NaN slice encountered&#34;)
    a[mask] = np.inf
    return np.argmin(a)


@njit(cache=True)
def argmax_reduce_nb(col: int, a: tp.Array1d) -&gt; int:
    &#34;&#34;&#34;Return position of max.&#34;&#34;&#34;
    a = np.copy(a)
    mask = np.isnan(a)
    if np.all(mask):
        raise ValueError(&#34;All-NaN slice encountered&#34;)
    a[mask] = -np.inf
    return np.argmax(a)


@njit(cache=True)
def describe_reduce_nb(col: int, a: tp.Array1d, perc: tp.Array1d, ddof: int) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return descriptive statistics (ignores NaNs).

    Numba equivalent to `pd.Series(a).describe(perc)`.&#34;&#34;&#34;
    a = a[~np.isnan(a)]
    out = np.empty(5 + len(perc), dtype=np.float_)
    out[0] = len(a)
    if len(a) &gt; 0:
        out[1] = np.mean(a)
        out[2] = nanstd_1d_nb(a, ddof=ddof)
        out[3] = np.min(a)
        out[4:-1] = np.percentile(a, perc * 100)
        out[4 + len(perc)] = np.max(a)
    else:
        out[1:] = np.nan
    return out


# ############# Value counts ############# #


@njit(cache=True)
def value_counts_nb(codes: tp.Array2d, n_uniques: int, group_lens: tp.Array1d) -&gt; tp.Array2d:
    &#34;&#34;&#34;Return value counts per column/group.&#34;&#34;&#34;
    out = np.full((n_uniques, group_lens.shape[0]), 0, dtype=np.int_)

    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        for col in range(from_col, to_col):
            for i in range(codes.shape[0]):
                out[codes[i, col], group] += 1
        from_col = to_col
    return out


# ############# Group squeezers ############# #


@njit(cache=True)
def min_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return min (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.nanmin(a)


@njit(cache=True)
def max_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return max (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.nanmax(a)


@njit(cache=True)
def sum_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return sum (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.nansum(a)


@njit(cache=True)
def any_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; bool:
    &#34;&#34;&#34;Return any (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.any(a)


# ############# Ranges ############# #

@njit(cache=True)
def find_ranges_nb(ts: tp.Array2d, gap_value: tp.Scalar) -&gt; tp.RecordArray:
    &#34;&#34;&#34;Find ranges and store their information as records to an array.

    ## Example

    Find ranges in time series:
    ```python-repl
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; from vectorbt.generic.nb import find_ranges_nb

    &gt;&gt;&gt; ts = np.asarray([
    ...     [np.nan, np.nan, np.nan, np.nan],
    ...     [     2, np.nan, np.nan, np.nan],
    ...     [     3,      3, np.nan, np.nan],
    ...     [np.nan,      4,      4, np.nan],
    ...     [     5, np.nan,      5,      5],
    ...     [     6,      6, np.nan,      6]
    ... ])
    &gt;&gt;&gt; records = find_ranges_nb(ts, np.nan)

    &gt;&gt;&gt; pd.DataFrame.from_records(records)
       id  col  start_idx  end_idx
    0   0    0          1        3
    1   1    0          4        6
    2   2    1          2        4
    3   3    1          5        6
    4   4    2          3        5
    5   5    3          4        6
    ```
    &#34;&#34;&#34;
    out = np.empty(ts.shape[0] * ts.shape[1], dtype=range_dt)
    ridx = 0

    for col in range(ts.shape[1]):
        range_started = False
        start_idx = -1
        end_idx = -1
        store_record = False
        status = -1

        for i in range(ts.shape[0]):
            cur_val = ts[i, col]

            if cur_val == gap_value or np.isnan(cur_val) and np.isnan(gap_value):
                if range_started:
                    # If stopped, save the current range
                    end_idx = i
                    range_started = False
                    store_record = True
                    status = RangeStatus.Closed
            else:
                if not range_started:
                    # If started, register a new range
                    start_idx = i
                    range_started = True

            if i == ts.shape[0] - 1 and range_started:
                # If still running, mark for save
                end_idx = ts.shape[0] - 1
                range_started = False
                store_record = True
                status = RangeStatus.Open

            if store_record:
                # Save range to the records
                out[ridx][&#39;id&#39;] = ridx
                out[ridx][&#39;col&#39;] = col
                out[ridx][&#39;start_idx&#39;] = start_idx
                out[ridx][&#39;end_idx&#39;] = end_idx
                out[ridx][&#39;status&#39;] = status
                ridx += 1

                # Reset running vars for a new range
                store_record = False

    return out[:ridx]


@njit(cache=True)
def range_duration_nb(start_idx_arr: tp.Array1d,
                      end_idx_arr: tp.Array1d,
                      status_arr: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Get duration of each duration record.&#34;&#34;&#34;
    out = np.empty(start_idx_arr.shape[0], dtype=np.int_)
    for ridx in range(out.shape[0]):
        if status_arr[ridx] == RangeStatus.Open:
            out[ridx] = end_idx_arr[ridx] - start_idx_arr[ridx] + 1
        else:
            out[ridx] = end_idx_arr[ridx] - start_idx_arr[ridx]
    return out


@njit(cache=True)
def range_coverage_nb(start_idx_arr: tp.Array1d,
                      end_idx_arr: tp.Array1d,
                      status_arr: tp.Array2d,
                      col_map: tp.ColMap,
                      index_lens: tp.Array1d,
                      overlapping: bool = False,
                      normalize: bool = False) -&gt; tp.Array1d:
    &#34;&#34;&#34;Get coverage of range records.

    Set `overlapping` to True to get the number of overlapping steps.
    Set `normalize` to True to get the number of steps in relation either to the total number of steps
    (when `overlapping=False`) or to the number of covered steps (when `overlapping=True`).
    &#34;&#34;&#34;
    col_idxs, col_lens = col_map
    col_start_idxs = np.cumsum(col_lens) - col_lens
    out = np.full(col_lens.shape[0], np.nan, dtype=np.float_)

    for col in range(col_lens.shape[0]):
        col_len = col_lens[col]
        if col_len == 0:
            continue
        col_start_idx = col_start_idxs[col]
        ridxs = col_idxs[col_start_idx:col_start_idx + col_len]
        temp = np.full(index_lens[col], 0, dtype=np.int_)
        for ridx in ridxs:
            if status_arr[ridx] == RangeStatus.Open:
                temp[start_idx_arr[ridx]:end_idx_arr[ridx] + 1] += 1
            else:
                temp[start_idx_arr[ridx]:end_idx_arr[ridx]] += 1
        if overlapping:
            if normalize:
                out[col] = np.sum(temp &gt; 1) / np.sum(temp &gt; 0)
            else:
                out[col] = np.sum(temp &gt; 1)
        else:
            if normalize:
                out[col] = np.sum(temp &gt; 0) / index_lens[col]
            else:
                out[col] = np.sum(temp &gt; 0)
    return out


@njit(cache=True)
def ranges_to_mask_nb(start_idx_arr: tp.Array1d,
                      end_idx_arr: tp.Array1d,
                      status_arr: tp.Array2d,
                      col_map: tp.ColMap,
                      index_len: int) -&gt; tp.Array2d:
    &#34;&#34;&#34;Convert ranges to 2-dim mask.&#34;&#34;&#34;
    col_idxs, col_lens = col_map
    col_start_idxs = np.cumsum(col_lens) - col_lens
    out = np.full((index_len, col_lens.shape[0]), False, dtype=np.bool_)

    for col in range(col_lens.shape[0]):
        col_len = col_lens[col]
        if col_len == 0:
            continue
        col_start_idx = col_start_idxs[col]
        ridxs = col_idxs[col_start_idx:col_start_idx + col_len]
        for ridx in ridxs:
            if status_arr[ridx] == RangeStatus.Open:
                out[start_idx_arr[ridx]:end_idx_arr[ridx] + 1, col] = True
            else:
                out[start_idx_arr[ridx]:end_idx_arr[ridx], col] = True

    return out


# ############# Drawdowns ############# #

@njit(cache=True)
def get_drawdowns_nb(ts: tp.Array2d) -&gt; tp.RecordArray:
    &#34;&#34;&#34;Fill drawdown records by analyzing a time series.

    ## Example

    ```python-repl
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; from vectorbt.generic.nb import get_drawdowns_nb

    &gt;&gt;&gt; ts = np.asarray([
    ...     [1, 5, 1, 3],
    ...     [2, 4, 2, 2],
    ...     [3, 3, 3, 1],
    ...     [4, 2, 2, 2],
    ...     [5, 1, 1, 3]
    ... ])
    &gt;&gt;&gt; records = get_drawdowns_nb(ts)

    &gt;&gt;&gt; pd.DataFrame.from_records(records)
       id  col  peak_idx  start_idx  valley_idx  end_idx  peak_val  valley_val  \\
    0   0    1         0          1           4        4       5.0         1.0
    1   1    2         2          3           4        4       3.0         1.0
    2   2    3         0          1           2        4       3.0         1.0

       end_val  status
    0      1.0       0
    1      1.0       0
    2      3.0       1
    ```
    &#34;&#34;&#34;
    out = np.empty(ts.shape[0] * ts.shape[1], dtype=drawdown_dt)
    ddidx = 0

    for col in range(ts.shape[1]):
        drawdown_started = False
        peak_idx = -1
        valley_idx = -1
        peak_val = ts[0, col]
        valley_val = ts[0, col]
        store_record = False
        status = -1

        for i in range(ts.shape[0]):
            cur_val = ts[i, col]

            if not np.isnan(cur_val):
                if np.isnan(peak_val) or cur_val &gt;= peak_val:
                    # Value increased
                    if not drawdown_started:
                        # If not running, register new peak
                        peak_val = cur_val
                        peak_idx = i
                    else:
                        # If running, potential recovery
                        if cur_val &gt;= peak_val:
                            drawdown_started = False
                            store_record = True
                            status = DrawdownStatus.Recovered
                else:
                    # Value decreased
                    if not drawdown_started:
                        # If not running, start new drawdown
                        drawdown_started = True
                        valley_val = cur_val
                        valley_idx = i
                    else:
                        # If running, potential valley
                        if cur_val &lt; valley_val:
                            valley_val = cur_val
                            valley_idx = i

                if i == ts.shape[0] - 1 and drawdown_started:
                    # If still running, mark for save
                    drawdown_started = False
                    store_record = True
                    status = DrawdownStatus.Active

                if store_record:
                    # Save drawdown to the records
                    out[ddidx][&#39;id&#39;] = ddidx
                    out[ddidx][&#39;col&#39;] = col
                    out[ddidx][&#39;peak_idx&#39;] = peak_idx
                    out[ddidx][&#39;start_idx&#39;] = peak_idx + 1
                    out[ddidx][&#39;valley_idx&#39;] = valley_idx
                    out[ddidx][&#39;end_idx&#39;] = i
                    out[ddidx][&#39;peak_val&#39;] = peak_val
                    out[ddidx][&#39;valley_val&#39;] = valley_val
                    out[ddidx][&#39;end_val&#39;] = cur_val
                    out[ddidx][&#39;status&#39;] = status
                    ddidx += 1

                    # Reset running vars for a new drawdown
                    peak_idx = i
                    valley_idx = i
                    peak_val = cur_val
                    valley_val = cur_val
                    store_record = False
                    status = -1

    return out[:ddidx]


@njit(cache=True)
def dd_drawdown_nb(peak_val_arr: tp.Array1d, valley_val_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the drawdown of each drawdown record.&#34;&#34;&#34;
    return (valley_val_arr - peak_val_arr) / peak_val_arr


@njit(cache=True)
def dd_decline_duration_nb(start_idx_arr: tp.Array1d, valley_idx_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the duration of the peak-to-valley phase of each drawdown record.&#34;&#34;&#34;
    return valley_idx_arr - start_idx_arr + 1


@njit(cache=True)
def dd_recovery_duration_nb(valley_idx_arr: tp.Array1d,
                            end_idx_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the duration of the valley-to-recovery phase of each drawdown record.&#34;&#34;&#34;
    return end_idx_arr - valley_idx_arr


@njit(cache=True)
def dd_recovery_duration_ratio_nb(start_idx_arr: tp.Array1d,
                                  valley_idx_arr: tp.Array1d,
                                  end_idx_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the ratio of the recovery duration to the decline duration of each drawdown record.&#34;&#34;&#34;
    recovery_duration = dd_recovery_duration_nb(valley_idx_arr, end_idx_arr)
    decline_duration = dd_decline_duration_nb(start_idx_arr, valley_idx_arr)
    return recovery_duration / decline_duration


@njit(cache=True)
def dd_recovery_return_nb(valley_val_arr: tp.Array1d, end_val_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the recovery return of each drawdown record.&#34;&#34;&#34;
    return (end_val_arr - valley_val_arr) / valley_val_arr</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="vectorbt.generic.nb.any_squeeze_nb"><code class="name flex">
<span>def <span class="ident parent-name">any_squeeze_nb</span></span>(<span class="params">col, group, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return any (ignores NaNs) of a group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def any_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; bool:
    &#34;&#34;&#34;Return any (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.any(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.apply_and_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">apply_and_reduce_nb</span></span>(<span class="params">a, apply_func_nb, apply_args, reduce_func_nb, reduce_args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Apply <code>apply_func_nb</code> on each column and reduce into a single value using <code>reduce_func_nb</code>.</p>
<p><code>apply_func_nb</code> should accept index of the column, the column itself, and <code>*apply_args</code>.
Should return an array.</p>
<p><code>reduce_func_nb</code> should accept index of the column, the array of results from
<code>apply_func_nb</code> for that column, and <code>*reduce_args</code>. Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def apply_and_reduce_nb(a: tp.Array2d, apply_func_nb: tp.ApplyFunc, apply_args: tuple,
                        reduce_func_nb: tp.ReduceFunc, reduce_args: tuple) -&gt; tp.Array1d:
    &#34;&#34;&#34;Apply `apply_func_nb` on each column and reduce into a single value using `reduce_func_nb`.

    `apply_func_nb` should accept index of the column, the column itself, and `*apply_args`.
    Should return an array.

    `reduce_func_nb` should accept index of the column, the array of results from
    `apply_func_nb` for that column, and `*reduce_args`. Should return a single value.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        mapped = apply_func_nb(col, a[:, col], *apply_args)
        _out = reduce_func_nb(col, mapped, *reduce_args)
        if col == 0:
            out = np.empty(a.shape[1], dtype=np.asarray(_out).dtype)
        out[col] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">apply_nb</span></span>(<span class="params">a, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Apply function on each column.</p>
<p><code>apply_func_nb</code> should accept index of the column, the array, and <code>*args</code>.
Should return a single value or an array of shape <code>a.shape[1]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def apply_nb(a: tp.Array2d, apply_func_nb: tp.ApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Apply function on each column.

    `apply_func_nb` should accept index of the column, the array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        _out = apply_func_nb(col, a[:, col], *args)
        if col == 0:
            out = np.empty_like(a, dtype=np.asarray(_out).dtype)
        out[:, col] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.applymap_nb"><code class="name flex">
<span>def <span class="ident parent-name">applymap_nb</span></span>(<span class="params">a, map_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Map non-NA elements element-wise using <code>map_func_nb</code>.</p>
<p><code>map_func_nb</code> should accept index of the row, index of the column,
the element itself, and <code>*args</code>. Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def applymap_nb(a: tp.Array2d, map_func_nb: tp.ApplyMapFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Map non-NA elements element-wise using `map_func_nb`.

    `map_func_nb` should accept index of the row, index of the column,
    the element itself, and `*args`. Should return a single value.&#34;&#34;&#34;
    out = np.full_like(a, np.nan, dtype=np.float_)

    for col in range(out.shape[1]):
        idxs = np.flatnonzero(~np.isnan(a[:, col]))
        for i in idxs:
            out[i, col] = map_func_nb(i, col, a[i, col], *args)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.argmax_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">argmax_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return position of max.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def argmax_reduce_nb(col: int, a: tp.Array1d) -&gt; int:
    &#34;&#34;&#34;Return position of max.&#34;&#34;&#34;
    a = np.copy(a)
    mask = np.isnan(a)
    if np.all(mask):
        raise ValueError(&#34;All-NaN slice encountered&#34;)
    a[mask] = -np.inf
    return np.argmax(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.argmin_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">argmin_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return position of min.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def argmin_reduce_nb(col: int, a: tp.Array1d) -&gt; int:
    &#34;&#34;&#34;Return position of min.&#34;&#34;&#34;
    a = np.copy(a)
    mask = np.isnan(a)
    if np.all(mask):
        raise ValueError(&#34;All-NaN slice encountered&#34;)
    a[mask] = np.inf
    return np.argmin(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.bfill_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">bfill_1d_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Fill NaNs by propagating first valid observation backward.</p>
<p>Numba equivalent to <code>pd.Series(a).fillna(method='bfill')</code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This operation looks ahead.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def bfill_1d_nb(a: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Fill NaNs by propagating first valid observation backward.

    Numba equivalent to `pd.Series(a).fillna(method=&#39;bfill&#39;)`.

    !!! warning
        This operation looks ahead.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    lastval = a[-1]
    for i in range(a.shape[0] - 1, -1, -1):
        if np.isnan(a[i]):
            out[i] = lastval
        else:
            lastval = out[i] = a[i]
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.bfill_nb"><code class="name flex">
<span>def <span class="ident parent-name">bfill_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.bfill_1d_nb" href="#vectorbt.generic.nb.bfill_1d_nb">bfill_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def bfill_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `bfill_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    for col in range(a.shape[1]):
        out[:, col] = bfill_1d_nb(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.bshift_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">bshift_1d_nb</span></span>(<span class="params">a, n=1, fill_value=nan)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Shift backward by <code>n</code> positions.</p>
<p>Numba equivalent to <code>pd.Series(a).shift(n)</code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This operation looks ahead.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def bshift_1d_nb(a: tp.Array1d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array1d:
    &#34;&#34;&#34;Shift backward by `n` positions.

    Numba equivalent to `pd.Series(a).shift(n)`.

    !!! warning
        This operation looks ahead.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _bshift_1d_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        out[-n:] = fill_value
        out[:-n] = a[n:]
        return out

    if not nb_enabled:
        return _bshift_1d_nb(a, n, fill_value)

    return _bshift_1d_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.bshift_nb"><code class="name flex">
<span>def <span class="ident parent-name">bshift_nb</span></span>(<span class="params">a, n=1, fill_value=nan)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.bshift_1d_nb" href="#vectorbt.generic.nb.bshift_1d_nb">bshift_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def bshift_nb(a: tp.Array2d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `bshift_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _bshift_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = bshift_1d_nb(a[:, col], n=n, fill_value=fill_value)
        return out

    if not nb_enabled:
        return _bshift_nb(a, n, fill_value)

    return _bshift_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.count_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">count_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return count (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def count_reduce_nb(col: int, a: tp.Array1d) -&gt; int:
    &#34;&#34;&#34;Return count (ignores NaNs).&#34;&#34;&#34;
    return np.sum(~np.isnan(a))</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.dd_decline_duration_nb"><code class="name flex">
<span>def <span class="ident parent-name">dd_decline_duration_nb</span></span>(<span class="params">start_idx_arr, valley_idx_arr)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the duration of the peak-to-valley phase of each drawdown record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def dd_decline_duration_nb(start_idx_arr: tp.Array1d, valley_idx_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the duration of the peak-to-valley phase of each drawdown record.&#34;&#34;&#34;
    return valley_idx_arr - start_idx_arr + 1</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.dd_drawdown_nb"><code class="name flex">
<span>def <span class="ident parent-name">dd_drawdown_nb</span></span>(<span class="params">peak_val_arr, valley_val_arr)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the drawdown of each drawdown record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def dd_drawdown_nb(peak_val_arr: tp.Array1d, valley_val_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the drawdown of each drawdown record.&#34;&#34;&#34;
    return (valley_val_arr - peak_val_arr) / peak_val_arr</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.dd_recovery_duration_nb"><code class="name flex">
<span>def <span class="ident parent-name">dd_recovery_duration_nb</span></span>(<span class="params">valley_idx_arr, end_idx_arr)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the duration of the valley-to-recovery phase of each drawdown record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def dd_recovery_duration_nb(valley_idx_arr: tp.Array1d,
                            end_idx_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the duration of the valley-to-recovery phase of each drawdown record.&#34;&#34;&#34;
    return end_idx_arr - valley_idx_arr</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.dd_recovery_duration_ratio_nb"><code class="name flex">
<span>def <span class="ident parent-name">dd_recovery_duration_ratio_nb</span></span>(<span class="params">start_idx_arr, valley_idx_arr, end_idx_arr)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the ratio of the recovery duration to the decline duration of each drawdown record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def dd_recovery_duration_ratio_nb(start_idx_arr: tp.Array1d,
                                  valley_idx_arr: tp.Array1d,
                                  end_idx_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the ratio of the recovery duration to the decline duration of each drawdown record.&#34;&#34;&#34;
    recovery_duration = dd_recovery_duration_nb(valley_idx_arr, end_idx_arr)
    decline_duration = dd_decline_duration_nb(start_idx_arr, valley_idx_arr)
    return recovery_duration / decline_duration</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.dd_recovery_return_nb"><code class="name flex">
<span>def <span class="ident parent-name">dd_recovery_return_nb</span></span>(<span class="params">valley_val_arr, end_val_arr)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the recovery return of each drawdown record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def dd_recovery_return_nb(valley_val_arr: tp.Array1d, end_val_arr: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the recovery return of each drawdown record.&#34;&#34;&#34;
    return (end_val_arr - valley_val_arr) / valley_val_arr</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.describe_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">describe_reduce_nb</span></span>(<span class="params">col, a, perc, ddof)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return descriptive statistics (ignores NaNs).</p>
<p>Numba equivalent to <code>pd.Series(a).describe(perc)</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def describe_reduce_nb(col: int, a: tp.Array1d, perc: tp.Array1d, ddof: int) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return descriptive statistics (ignores NaNs).

    Numba equivalent to `pd.Series(a).describe(perc)`.&#34;&#34;&#34;
    a = a[~np.isnan(a)]
    out = np.empty(5 + len(perc), dtype=np.float_)
    out[0] = len(a)
    if len(a) &gt; 0:
        out[1] = np.mean(a)
        out[2] = nanstd_1d_nb(a, ddof=ddof)
        out[3] = np.min(a)
        out[4:-1] = np.percentile(a, perc * 100)
        out[4 + len(perc)] = np.max(a)
    else:
        out[1:] = np.nan
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.diff_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">diff_1d_nb</span></span>(<span class="params">a, n=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the 1-th discrete difference.</p>
<p>Numba equivalent to <code>pd.Series(a).diff()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def diff_1d_nb(a: tp.Array1d, n: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the 1-th discrete difference.

    Numba equivalent to `pd.Series(a).diff()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    out[:n] = np.nan
    out[n:] = a[n:] - a[:-n]
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.diff_nb"><code class="name flex">
<span>def <span class="ident parent-name">diff_nb</span></span>(<span class="params">a, n=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.diff_1d_nb" href="#vectorbt.generic.nb.diff_1d_nb">diff_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def diff_nb(a: tp.Array2d, n: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `diff_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = diff_1d_nb(a[:, col], n=n)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ewm_mean_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">ewm_mean_1d_nb</span></span>(<span class="params">a, span, minp=0, adjust=False)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return exponential weighted average.</p>
<p>Numba equivalent to <code>pd.Series(a).ewm(span=span, min_periods=minp, adjust=adjust).mean()</code>.</p>
<p>Adaptation of <code>pd._libs.window.aggregations.window_aggregations.ewma</code> with default arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ewm_mean_1d_nb(a: tp.Array1d, span: int, minp: int = 0, adjust: bool = False) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return exponential weighted average.

    Numba equivalent to `pd.Series(a).ewm(span=span, min_periods=minp, adjust=adjust).mean()`.

    Adaptation of `pd._libs.window.aggregations.window_aggregations.ewma` with default arguments.&#34;&#34;&#34;
    if minp is None:
        minp = span
    if minp &gt; span:
        raise ValueError(&#34;minp must be &lt;= span&#34;)
    N = len(a)
    out = np.empty(N, dtype=np.float_)
    if N == 0:
        return out
    com = (span - 1) / 2.0
    alpha = 1. / (1. + com)
    old_wt_factor = 1. - alpha
    new_wt = 1. if adjust else alpha
    weighted_avg = a[0]
    is_observation = (weighted_avg == weighted_avg)
    nobs = int(is_observation)
    out[0] = weighted_avg if (nobs &gt;= minp) else np.nan
    old_wt = 1.

    for i in range(1, N):
        cur = a[i]
        is_observation = (cur == cur)
        nobs += is_observation
        if weighted_avg == weighted_avg:
            old_wt *= old_wt_factor
            if is_observation:
                # avoid numerical errors on constant series
                if weighted_avg != cur:
                    weighted_avg = ((old_wt * weighted_avg) + (new_wt * cur)) / (old_wt + new_wt)
                if adjust:
                    old_wt += new_wt
                else:
                    old_wt = 1.
        elif is_observation:
            weighted_avg = cur
        out[i] = weighted_avg if (nobs &gt;= minp) else np.nan
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ewm_mean_nb"><code class="name flex">
<span>def <span class="ident parent-name">ewm_mean_nb</span></span>(<span class="params">a, span, minp=0, adjust=False)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.ewm_mean_1d_nb" href="#vectorbt.generic.nb.ewm_mean_1d_nb">ewm_mean_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ewm_mean_nb(a: tp.Array2d, span: int, minp: int = 0, adjust: bool = False) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `ewm_mean_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = ewm_mean_1d_nb(a[:, col], span, minp=minp, adjust=adjust)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ewm_std_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">ewm_std_1d_nb</span></span>(<span class="params">a, span, minp=0, adjust=False, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return exponential weighted standard deviation.</p>
<p>Numba equivalent to <code>pd.Series(a).ewm(span=span, min_periods=minp).std(ddof=ddof)</code>.</p>
<p>Adaptation of <code>pd._libs.window.aggregations.window_aggregations.ewmcov</code> with default arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ewm_std_1d_nb(a: tp.Array1d, span: int, minp: int = 0, adjust: bool = False, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return exponential weighted standard deviation.

    Numba equivalent to `pd.Series(a).ewm(span=span, min_periods=minp).std(ddof=ddof)`.

    Adaptation of `pd._libs.window.aggregations.window_aggregations.ewmcov` with default arguments.&#34;&#34;&#34;
    if minp is None:
        minp = span
    if minp &gt; span:
        raise ValueError(&#34;minp must be &lt;= span&#34;)
    N = len(a)
    out = np.empty(N, dtype=np.float_)
    if N == 0:
        return out
    com = (span - 1) / 2.0
    alpha = 1. / (1. + com)
    old_wt_factor = 1. - alpha
    new_wt = 1. if adjust else alpha
    mean_x = a[0]
    mean_y = a[0]
    is_observation = ((mean_x == mean_x) and (mean_y == mean_y))
    nobs = int(is_observation)
    if not is_observation:
        mean_x = np.nan
        mean_y = np.nan
    out[0] = np.nan
    cov = 0.
    sum_wt = 1.
    sum_wt2 = 1.
    old_wt = 1.

    for i in range(1, N):
        cur_x = a[i]
        cur_y = a[i]
        is_observation = ((cur_x == cur_x) and (cur_y == cur_y))
        nobs += is_observation
        if mean_x == mean_x:
            sum_wt *= old_wt_factor
            sum_wt2 *= (old_wt_factor * old_wt_factor)
            old_wt *= old_wt_factor
            if is_observation:
                old_mean_x = mean_x
                old_mean_y = mean_y

                # avoid numerical errors on constant series
                if mean_x != cur_x:
                    mean_x = ((old_wt * old_mean_x) +
                              (new_wt * cur_x)) / (old_wt + new_wt)

                # avoid numerical errors on constant series
                if mean_y != cur_y:
                    mean_y = ((old_wt * old_mean_y) +
                              (new_wt * cur_y)) / (old_wt + new_wt)
                cov = ((old_wt * (cov + ((old_mean_x - mean_x) *
                                         (old_mean_y - mean_y)))) +
                       (new_wt * ((cur_x - mean_x) *
                                  (cur_y - mean_y)))) / (old_wt + new_wt)
                sum_wt += new_wt
                sum_wt2 += (new_wt * new_wt)
                old_wt += new_wt
                if not adjust:
                    sum_wt /= old_wt
                    sum_wt2 /= (old_wt * old_wt)
                    old_wt = 1.
        elif is_observation:
            mean_x = cur_x
            mean_y = cur_y

        if nobs &gt;= minp:
            numerator = sum_wt * sum_wt
            denominator = numerator - sum_wt2
            if denominator &gt; 0.:
                out[i] = ((numerator / denominator) * cov)
            else:
                out[i] = np.nan
        else:
            out[i] = np.nan
    return np.sqrt(out)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ewm_std_nb"><code class="name flex">
<span>def <span class="ident parent-name">ewm_std_nb</span></span>(<span class="params">a, span, minp=0, adjust=False, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.ewm_std_1d_nb" href="#vectorbt.generic.nb.ewm_std_1d_nb">ewm_std_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ewm_std_nb(a: tp.Array2d, span: int, minp: int = 0, adjust: bool = False, ddof: int = 0) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `ewm_std_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = ewm_std_1d_nb(a[:, col], span, minp=minp, adjust=adjust, ddof=ddof)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_apply_nb</span></span>(<span class="params">a, minp, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Expanding version of <code><a title="vectorbt.generic.nb.rolling_apply_nb" href="#vectorbt.generic.nb.rolling_apply_nb">rolling_apply_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def expanding_apply_nb(a: tp.Array2d, minp: tp.Optional[int],
                       apply_func_nb: tp.RollApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Expanding version of `rolling_apply_nb`.&#34;&#34;&#34;
    return rolling_apply_nb(a, a.shape[0], minp, apply_func_nb, *args)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_matrix_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_matrix_apply_nb</span></span>(<span class="params">a, minp, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Expanding version of <code><a title="vectorbt.generic.nb.rolling_matrix_apply_nb" href="#vectorbt.generic.nb.rolling_matrix_apply_nb">rolling_matrix_apply_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def expanding_matrix_apply_nb(a: tp.Array2d, minp: tp.Optional[int],
                              apply_func_nb: tp.RollMatrixApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Expanding version of `rolling_matrix_apply_nb`.&#34;&#34;&#34;
    return rolling_matrix_apply_nb(a, a.shape[0], minp, apply_func_nb, *args)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_max_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_max_1d_nb</span></span>(<span class="params">a, minp=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return expanding max.</p>
<p>Numba equivalent to <code>pd.Series(a).expanding(min_periods=minp).max()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_max_1d_nb(a: tp.Array1d, minp: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding max.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).max()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    maxv = a[0]
    cnt = 0
    for i in range(a.shape[0]):
        if np.isnan(maxv) or a[i] &gt; maxv:
            maxv = a[i]
        if not np.isnan(a[i]):
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = maxv
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_max_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_max_nb</span></span>(<span class="params">a, minp=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.expanding_max_1d_nb" href="#vectorbt.generic.nb.expanding_max_1d_nb">expanding_max_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_max_nb(a: tp.Array2d, minp: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_max_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = expanding_max_1d_nb(a[:, col], minp=minp)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_mean_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_mean_1d_nb</span></span>(<span class="params">a, minp=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return expanding mean.</p>
<p>Numba equivalent to <code>pd.Series(a).expanding(min_periods=minp).mean()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_mean_1d_nb(a: tp.Array1d, minp: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding mean.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).mean()`.&#34;&#34;&#34;
    return rolling_mean_1d_nb(a, a.shape[0], minp=minp)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_mean_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_mean_nb</span></span>(<span class="params">a, minp=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.expanding_mean_1d_nb" href="#vectorbt.generic.nb.expanding_mean_1d_nb">expanding_mean_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_mean_nb(a: tp.Array2d, minp: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_mean_1d_nb`.&#34;&#34;&#34;
    return rolling_mean_nb(a, a.shape[0], minp=minp)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_min_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_min_1d_nb</span></span>(<span class="params">a, minp=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return expanding min.</p>
<p>Numba equivalent to <code>pd.Series(a).expanding(min_periods=minp).min()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_min_1d_nb(a: tp.Array1d, minp: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding min.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).min()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    minv = a[0]
    cnt = 0
    for i in range(a.shape[0]):
        if np.isnan(minv) or a[i] &lt; minv:
            minv = a[i]
        if not np.isnan(a[i]):
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = minv
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_min_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_min_nb</span></span>(<span class="params">a, minp=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.expanding_min_1d_nb" href="#vectorbt.generic.nb.expanding_min_1d_nb">expanding_min_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_min_nb(a: tp.Array2d, minp: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_min_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = expanding_min_1d_nb(a[:, col], minp=minp)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_std_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_std_1d_nb</span></span>(<span class="params">a, minp=1, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return expanding standard deviation.</p>
<p>Numba equivalent to <code>pd.Series(a).expanding(min_periods=minp).std(ddof=ddof)</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_std_1d_nb(a: tp.Array1d, minp: int = 1, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return expanding standard deviation.

    Numba equivalent to `pd.Series(a).expanding(min_periods=minp).std(ddof=ddof)`.&#34;&#34;&#34;
    return rolling_std_1d_nb(a, a.shape[0], minp=minp, ddof=ddof)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.expanding_std_nb"><code class="name flex">
<span>def <span class="ident parent-name">expanding_std_nb</span></span>(<span class="params">a, minp=1, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.expanding_std_1d_nb" href="#vectorbt.generic.nb.expanding_std_1d_nb">expanding_std_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def expanding_std_nb(a: tp.Array2d, minp: int = 1, ddof: int = 0) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `expanding_std_1d_nb`.&#34;&#34;&#34;
    return rolling_std_nb(a, a.shape[0], minp=minp, ddof=ddof)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ffill_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">ffill_1d_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Fill NaNs by propagating last valid observation forward.</p>
<p>Numba equivalent to <code>pd.Series(a).fillna(method='ffill')</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ffill_1d_nb(a: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Fill NaNs by propagating last valid observation forward.

    Numba equivalent to `pd.Series(a).fillna(method=&#39;ffill&#39;)`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    lastval = a[0]
    for i in range(a.shape[0]):
        if np.isnan(a[i]):
            out[i] = lastval
        else:
            lastval = out[i] = a[i]
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ffill_nb"><code class="name flex">
<span>def <span class="ident parent-name">ffill_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.ffill_1d_nb" href="#vectorbt.generic.nb.ffill_1d_nb">ffill_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ffill_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `ffill_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=a.dtype)
    for col in range(a.shape[1]):
        out[:, col] = ffill_1d_nb(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.fillna_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">fillna_1d_nb</span></span>(<span class="params">a, value)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Replace NaNs with value.</p>
<p>Numba equivalent to <code>pd.Series(a).fillna(value)</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def fillna_1d_nb(a: tp.Array1d, value: tp.Scalar) -&gt; tp.Array1d:
    &#34;&#34;&#34;Replace NaNs with value.

    Numba equivalent to `pd.Series(a).fillna(value)`.&#34;&#34;&#34;
    return set_by_mask_1d_nb(a, np.isnan(a), value)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.fillna_nb"><code class="name flex">
<span>def <span class="ident parent-name">fillna_nb</span></span>(<span class="params">a, value)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.fillna_1d_nb" href="#vectorbt.generic.nb.fillna_1d_nb">fillna_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def fillna_nb(a: tp.Array2d, value: tp.Scalar) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `fillna_1d_nb`.&#34;&#34;&#34;
    return set_by_mask_nb(a, np.isnan(a), value)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.filter_nb"><code class="name flex">
<span>def <span class="ident parent-name">filter_nb</span></span>(<span class="params">a, filter_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Filter non-NA elements elementwise using <code>filter_func_nb</code>.
The filtered out elements will become NA.</p>
<p><code>filter_func_nb</code> should accept index of the row, index of the column,
the element itself, and <code>*args</code>. Should return a bool.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def filter_nb(a: tp.Array2d, filter_func_nb: tp.FilterFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Filter non-NA elements elementwise using `filter_func_nb`. 
    The filtered out elements will become NA.

    `filter_func_nb` should accept index of the row, index of the column,
    the element itself, and `*args`. Should return a bool.&#34;&#34;&#34;
    out = a.astype(np.float_)

    for col in range(out.shape[1]):
        idxs = np.flatnonzero(~np.isnan(a[:, col]))
        for i in idxs:
            if not filter_func_nb(i, col, a[i, col], *args):
                out[i, col] = np.nan
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.find_ranges_nb"><code class="name flex">
<span>def <span class="ident parent-name">find_ranges_nb</span></span>(<span class="params">ts, gap_value)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Find ranges and store their information as records to an array.</p>
<h2 id="example">Example</h2>
<p>Find ranges in time series:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from vectorbt.generic.nb import find_ranges_nb

&gt;&gt;&gt; ts = np.asarray([
...     [np.nan, np.nan, np.nan, np.nan],
...     [     2, np.nan, np.nan, np.nan],
...     [     3,      3, np.nan, np.nan],
...     [np.nan,      4,      4, np.nan],
...     [     5, np.nan,      5,      5],
...     [     6,      6, np.nan,      6]
... ])
&gt;&gt;&gt; records = find_ranges_nb(ts, np.nan)

&gt;&gt;&gt; pd.DataFrame.from_records(records)
   id  col  start_idx  end_idx
0   0    0          1        3
1   1    0          4        6
2   2    1          2        4
3   3    1          5        6
4   4    2          3        5
5   5    3          4        6
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def find_ranges_nb(ts: tp.Array2d, gap_value: tp.Scalar) -&gt; tp.RecordArray:
    &#34;&#34;&#34;Find ranges and store their information as records to an array.

    ## Example

    Find ranges in time series:
    ```python-repl
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; from vectorbt.generic.nb import find_ranges_nb

    &gt;&gt;&gt; ts = np.asarray([
    ...     [np.nan, np.nan, np.nan, np.nan],
    ...     [     2, np.nan, np.nan, np.nan],
    ...     [     3,      3, np.nan, np.nan],
    ...     [np.nan,      4,      4, np.nan],
    ...     [     5, np.nan,      5,      5],
    ...     [     6,      6, np.nan,      6]
    ... ])
    &gt;&gt;&gt; records = find_ranges_nb(ts, np.nan)

    &gt;&gt;&gt; pd.DataFrame.from_records(records)
       id  col  start_idx  end_idx
    0   0    0          1        3
    1   1    0          4        6
    2   2    1          2        4
    3   3    1          5        6
    4   4    2          3        5
    5   5    3          4        6
    ```
    &#34;&#34;&#34;
    out = np.empty(ts.shape[0] * ts.shape[1], dtype=range_dt)
    ridx = 0

    for col in range(ts.shape[1]):
        range_started = False
        start_idx = -1
        end_idx = -1
        store_record = False
        status = -1

        for i in range(ts.shape[0]):
            cur_val = ts[i, col]

            if cur_val == gap_value or np.isnan(cur_val) and np.isnan(gap_value):
                if range_started:
                    # If stopped, save the current range
                    end_idx = i
                    range_started = False
                    store_record = True
                    status = RangeStatus.Closed
            else:
                if not range_started:
                    # If started, register a new range
                    start_idx = i
                    range_started = True

            if i == ts.shape[0] - 1 and range_started:
                # If still running, mark for save
                end_idx = ts.shape[0] - 1
                range_started = False
                store_record = True
                status = RangeStatus.Open

            if store_record:
                # Save range to the records
                out[ridx][&#39;id&#39;] = ridx
                out[ridx][&#39;col&#39;] = col
                out[ridx][&#39;start_idx&#39;] = start_idx
                out[ridx][&#39;end_idx&#39;] = end_idx
                out[ridx][&#39;status&#39;] = status
                ridx += 1

                # Reset running vars for a new range
                store_record = False

    return out[:ridx]</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.flat_reduce_grouped_nb"><code class="name flex">
<span>def <span class="ident parent-name">flat_reduce_grouped_nb</span></span>(<span class="params">a, group_lens, in_c_order, reduce_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Same as <code><a title="vectorbt.generic.nb.reduce_grouped_nb" href="#vectorbt.generic.nb.reduce_grouped_nb">reduce_grouped_nb()</a></code> but passes flattened array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def flat_reduce_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool,
                           reduce_func_nb: tp.FlatGroupReduceFunc, *args) -&gt; tp.Array1d:
    &#34;&#34;&#34;Same as `reduce_grouped_nb` but passes flattened array.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        if in_c_order:
            _out = reduce_func_nb(group, a[:, from_col:to_col].flatten(), *args)
        else:
            _out = reduce_func_nb(group, flatten_forder_nb(a[:, from_col:to_col]), *args)
        if group == 0:
            out = np.empty(len(group_lens), dtype=np.asarray(_out).dtype)
        out[group] = _out
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.flat_reduce_grouped_to_array_nb"><code class="name flex">
<span>def <span class="ident parent-name">flat_reduce_grouped_to_array_nb</span></span>(<span class="params">a, group_lens, in_c_order, reduce_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Same as <code><a title="vectorbt.generic.nb.reduce_grouped_to_array_nb" href="#vectorbt.generic.nb.reduce_grouped_to_array_nb">reduce_grouped_to_array_nb()</a></code> but passes flattened 1D array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def flat_reduce_grouped_to_array_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool,
                                    reduce_func_nb: tp.FlatGroupReduceArrayFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Same as `reduce_grouped_to_array_nb` but passes flattened 1D array.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        if in_c_order:
            _out = reduce_func_nb(group, a[:, from_col:to_col].flatten(), *args)
        else:
            _out = reduce_func_nb(group, flatten_forder_nb(a[:, from_col:to_col]), *args)
        if group == 0:
            out = np.full((_out.shape[0], len(group_lens)), np.nan, dtype=_out.dtype)
        out[:, group] = _out
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.flatten_forder_nb"><code class="name flex">
<span>def <span class="ident parent-name">flatten_forder_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Flatten <code>a</code> in F order.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def flatten_forder_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Flatten `a` in F order.&#34;&#34;&#34;
    out = np.empty(a.shape[0] * a.shape[1], dtype=a.dtype)
    for col in range(a.shape[1]):
        out[col * a.shape[0]:(col + 1) * a.shape[0]] = a[:, col]
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.flatten_grouped_nb"><code class="name flex">
<span>def <span class="ident parent-name">flatten_grouped_nb</span></span>(<span class="params">a, group_lens, in_c_order)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Flatten each group of columns.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def flatten_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool) -&gt; tp.Array2d:
    &#34;&#34;&#34;Flatten each group of columns.&#34;&#34;&#34;
    out = np.full((a.shape[0] * np.max(group_lens), len(group_lens)), np.nan, dtype=np.float_)
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        group_len = to_col - from_col
        for k in range(group_len):
            if in_c_order:
                out[k::np.max(group_lens), group] = a[:, from_col + k]
            else:
                out[k * a.shape[0]:(k + 1) * a.shape[0], group] = a[:, from_col + k]
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.flatten_uniform_grouped_nb"><code class="name flex">
<span>def <span class="ident parent-name">flatten_uniform_grouped_nb</span></span>(<span class="params">a, group_lens, in_c_order)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Flatten each group of columns of the same length.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def flatten_uniform_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d, in_c_order: bool) -&gt; tp.Array2d:
    &#34;&#34;&#34;Flatten each group of columns of the same length.&#34;&#34;&#34;
    out = np.empty((a.shape[0] * np.max(group_lens), len(group_lens)), dtype=a.dtype)
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        group_len = to_col - from_col
        for k in range(group_len):
            if in_c_order:
                out[k::np.max(group_lens), group] = a[:, from_col + k]
            else:
                out[k * a.shape[0]:(k + 1) * a.shape[0], group] = a[:, from_col + k]
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.fshift_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">fshift_1d_nb</span></span>(<span class="params">a, n=1, fill_value=nan)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Shift forward by <code>n</code> positions.</p>
<p>Numba equivalent to <code>pd.Series(a).shift(n)</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def fshift_1d_nb(a: tp.Array1d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array1d:
    &#34;&#34;&#34;Shift forward by `n` positions.

    Numba equivalent to `pd.Series(a).shift(n)`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _fshift_1d_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        out[:n] = fill_value
        out[n:] = a[:-n]
        return out

    if not nb_enabled:
        return _fshift_1d_nb(a, n, fill_value)

    return _fshift_1d_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.fshift_nb"><code class="name flex">
<span>def <span class="ident parent-name">fshift_nb</span></span>(<span class="params">a, n=1, fill_value=nan)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.fshift_1d_nb" href="#vectorbt.generic.nb.fshift_1d_nb">fshift_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def fshift_nb(a: tp.Array2d, n: int = 1, fill_value: tp.Scalar = np.nan) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `fshift_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        if isinstance(fill_value, Omitted):
            fill_value_dtype = np.asarray(fill_value.value).dtype
        else:
            fill_value_dtype = as_dtype(fill_value)
    else:
        a_dtype = a.dtype
        fill_value_dtype = np.array(fill_value).dtype
    dtype = np.promote_types(a_dtype, fill_value_dtype)

    def _fshift_nb(a, n, fill_value):
        out = np.empty_like(a, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = fshift_1d_nb(a[:, col], n=n, fill_value=fill_value)
        return out

    if not nb_enabled:
        return _fshift_nb(a, n, fill_value)

    return _fshift_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.get_drawdowns_nb"><code class="name flex">
<span>def <span class="ident parent-name">get_drawdowns_nb</span></span>(<span class="params">ts)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Fill drawdown records by analyzing a time series.</p>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from vectorbt.generic.nb import get_drawdowns_nb

&gt;&gt;&gt; ts = np.asarray([
...     [1, 5, 1, 3],
...     [2, 4, 2, 2],
...     [3, 3, 3, 1],
...     [4, 2, 2, 2],
...     [5, 1, 1, 3]
... ])
&gt;&gt;&gt; records = get_drawdowns_nb(ts)

&gt;&gt;&gt; pd.DataFrame.from_records(records)
   id  col  peak_idx  start_idx  valley_idx  end_idx  peak_val  valley_val  \
0   0    1         0          1           4        4       5.0         1.0
1   1    2         2          3           4        4       3.0         1.0
2   2    3         0          1           2        4       3.0         1.0

   end_val  status
0      1.0       0
1      1.0       0
2      3.0       1
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def get_drawdowns_nb(ts: tp.Array2d) -&gt; tp.RecordArray:
    &#34;&#34;&#34;Fill drawdown records by analyzing a time series.

    ## Example

    ```python-repl
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; from vectorbt.generic.nb import get_drawdowns_nb

    &gt;&gt;&gt; ts = np.asarray([
    ...     [1, 5, 1, 3],
    ...     [2, 4, 2, 2],
    ...     [3, 3, 3, 1],
    ...     [4, 2, 2, 2],
    ...     [5, 1, 1, 3]
    ... ])
    &gt;&gt;&gt; records = get_drawdowns_nb(ts)

    &gt;&gt;&gt; pd.DataFrame.from_records(records)
       id  col  peak_idx  start_idx  valley_idx  end_idx  peak_val  valley_val  \\
    0   0    1         0          1           4        4       5.0         1.0
    1   1    2         2          3           4        4       3.0         1.0
    2   2    3         0          1           2        4       3.0         1.0

       end_val  status
    0      1.0       0
    1      1.0       0
    2      3.0       1
    ```
    &#34;&#34;&#34;
    out = np.empty(ts.shape[0] * ts.shape[1], dtype=drawdown_dt)
    ddidx = 0

    for col in range(ts.shape[1]):
        drawdown_started = False
        peak_idx = -1
        valley_idx = -1
        peak_val = ts[0, col]
        valley_val = ts[0, col]
        store_record = False
        status = -1

        for i in range(ts.shape[0]):
            cur_val = ts[i, col]

            if not np.isnan(cur_val):
                if np.isnan(peak_val) or cur_val &gt;= peak_val:
                    # Value increased
                    if not drawdown_started:
                        # If not running, register new peak
                        peak_val = cur_val
                        peak_idx = i
                    else:
                        # If running, potential recovery
                        if cur_val &gt;= peak_val:
                            drawdown_started = False
                            store_record = True
                            status = DrawdownStatus.Recovered
                else:
                    # Value decreased
                    if not drawdown_started:
                        # If not running, start new drawdown
                        drawdown_started = True
                        valley_val = cur_val
                        valley_idx = i
                    else:
                        # If running, potential valley
                        if cur_val &lt; valley_val:
                            valley_val = cur_val
                            valley_idx = i

                if i == ts.shape[0] - 1 and drawdown_started:
                    # If still running, mark for save
                    drawdown_started = False
                    store_record = True
                    status = DrawdownStatus.Active

                if store_record:
                    # Save drawdown to the records
                    out[ddidx][&#39;id&#39;] = ddidx
                    out[ddidx][&#39;col&#39;] = col
                    out[ddidx][&#39;peak_idx&#39;] = peak_idx
                    out[ddidx][&#39;start_idx&#39;] = peak_idx + 1
                    out[ddidx][&#39;valley_idx&#39;] = valley_idx
                    out[ddidx][&#39;end_idx&#39;] = i
                    out[ddidx][&#39;peak_val&#39;] = peak_val
                    out[ddidx][&#39;valley_val&#39;] = valley_val
                    out[ddidx][&#39;end_val&#39;] = cur_val
                    out[ddidx][&#39;status&#39;] = status
                    ddidx += 1

                    # Reset running vars for a new drawdown
                    peak_idx = i
                    valley_idx = i
                    peak_val = cur_val
                    valley_val = cur_val
                    store_record = False
                    status = -1

    return out[:ddidx]</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.groupby_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">groupby_apply_nb</span></span>(<span class="params">a, groups, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Provide group-by calculations.</p>
<p><code>groups</code> should be a dictionary, where each key is an index that points to an element in the new array
where a group-by result will be stored, while the value should be an array of indices in <code>a</code>
to apply <code>apply_func_nb</code> on.</p>
<p><code>apply_func_nb</code> should accept indices of the group, index of the column,
the array, and <code>*args</code>. Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def groupby_apply_nb(a: tp.Array2d, groups: Dict,
                     apply_func_nb: tp.GroupByApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Provide group-by calculations.

    `groups` should be a dictionary, where each key is an index that points to an element in the new array
    where a group-by result will be stored, while the value should be an array of indices in `a`
    to apply `apply_func_nb` on.

    `apply_func_nb` should accept indices of the group, index of the column,
    the array, and `*args`. Should return a single value.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        for g, (i, idxs) in enumerate(groups.items()):
            _out = apply_func_nb(idxs, col, a[idxs, col], *args)
            if col == 0 and g == 0:
                out = np.empty((len(groups), a.shape[1]), dtype=np.asarray(_out).dtype)
            out[i, col] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.groupby_matrix_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">groupby_matrix_apply_nb</span></span>(<span class="params">a, groups, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.nb.groupby_apply_nb" href="#vectorbt.generic.nb.groupby_apply_nb">groupby_apply_nb()</a></code> with <code>apply_func_nb</code> being applied on all columns at once.</p>
<p><code>apply_func_nb</code> should accept indices of the group, the 2-dim array, and <code>*args</code>.
Should return a single value or an array of shape <code>a.shape[1]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def groupby_matrix_apply_nb(a: tp.Array2d, groups: Dict,
                            apply_func_nb: tp.GroupByMatrixApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;`groupby_apply_nb` with `apply_func_nb` being applied on all columns at once.

    `apply_func_nb` should accept indices of the group, the 2-dim array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    for g, (i, idxs) in enumerate(groups.items()):
        _out = apply_func_nb(idxs, a[idxs, :], *args)
        if g == 0:
            out = np.empty((len(groups), a.shape[1]), dtype=np.asarray(_out).dtype)
        out[i, :] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.max_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">max_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return max (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def max_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return max (ignores NaNs).&#34;&#34;&#34;
    return np.nanmax(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.max_squeeze_nb"><code class="name flex">
<span>def <span class="ident parent-name">max_squeeze_nb</span></span>(<span class="params">col, group, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return max (ignores NaNs) of a group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def max_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return max (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.nanmax(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.mean_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">mean_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return mean (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def mean_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return mean (ignores NaNs).&#34;&#34;&#34;
    return np.nanmean(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.median_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">median_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return median (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def median_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return median (ignores NaNs).&#34;&#34;&#34;
    return np.nanmedian(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.min_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">min_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return min (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def min_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return min (ignores NaNs).&#34;&#34;&#34;
    return np.nanmin(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.min_squeeze_nb"><code class="name flex">
<span>def <span class="ident parent-name">min_squeeze_nb</span></span>(<span class="params">col, group, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return min (ignores NaNs) of a group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def min_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return min (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.nanmin(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nancnt_nb"><code class="name flex">
<span>def <span class="ident parent-name">nancnt_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Compute count while ignoring NaNs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nancnt_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Compute count while ignoring NaNs.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.int_)
    for col in range(a.shape[1]):
        out[col] = np.sum(~np.isnan(a[:, col]))
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nancumprod_nb"><code class="name flex">
<span>def <span class="ident parent-name">nancumprod_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nancumprod</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def nancumprod_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;Numba-equivalent of `np.nancumprod` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nancumprod_nb(a):
        out = np.empty(a.shape, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = np.nancumprod(a[:, col])
        return out

    if not nb_enabled:
        return _nancumprod_nb(a)

    return _nancumprod_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nancumsum_nb"><code class="name flex">
<span>def <span class="ident parent-name">nancumsum_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nancumsum</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def nancumsum_nb(a: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;Numba-equivalent of `np.nancumsum` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nancumsum_nb(a):
        out = np.empty(a.shape, dtype=dtype)
        for col in range(a.shape[1]):
            out[:, col] = np.nancumsum(a[:, col])
        return out

    if not nb_enabled:
        return _nancumsum_nb(a)

    return _nancumsum_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanmax_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanmax_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nanmax</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nanmax_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmax` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=a.dtype)
    for col in range(a.shape[1]):
        out[col] = np.nanmax(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanmean_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanmean_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nanmean</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nanmean_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmean` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.float_)
    for col in range(a.shape[1]):
        out[col] = np.nanmean(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanmedian_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanmedian_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nanmedian</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nanmedian_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmedian` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.float_)
    for col in range(a.shape[1]):
        out[col] = np.nanmedian(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanmin_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanmin_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nanmin</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nanmin_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanmin` along axis 0.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=a.dtype)
    for col in range(a.shape[1]):
        out[col] = np.nanmin(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanprod_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanprod_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nanprod</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def nanprod_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nanprod` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nanprod_nb(a):
        out = np.empty(a.shape[1], dtype=dtype)
        for col in range(a.shape[1]):
            out[col] = np.nanprod(a[:, col])
        return out

    if not nb_enabled:
        return _nanprod_nb(a)

    return _nanprod_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanstd_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanstd_1d_nb</span></span>(<span class="params">a, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nanstd</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nanstd_1d_nb(a: tp.Array1d, ddof: int = 0) -&gt; float:
    &#34;&#34;&#34;Numba-equivalent of `np.nanstd`.&#34;&#34;&#34;
    cnt = a.shape[0] - np.count_nonzero(np.isnan(a))
    rcount = max(cnt - ddof, 0)
    if rcount == 0:
        return np.nan
    return np.sqrt(np.nanvar(a) * cnt / rcount)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nanstd_nb"><code class="name flex">
<span>def <span class="ident parent-name">nanstd_nb</span></span>(<span class="params">a, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.nanstd_1d_nb" href="#vectorbt.generic.nb.nanstd_1d_nb">nanstd_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nanstd_nb(a: tp.Array2d, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;2-dim version of `nanstd_1d_nb`.&#34;&#34;&#34;
    out = np.empty(a.shape[1], dtype=np.float_)
    for col in range(a.shape[1]):
        out[col] = nanstd_1d_nb(a[:, col], ddof=ddof)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nansum_nb"><code class="name flex">
<span>def <span class="ident parent-name">nansum_nb</span></span>(<span class="params">a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Numba-equivalent of <code>np.nansum</code> along axis 0.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def nansum_nb(a: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Numba-equivalent of `np.nansum` along axis 0.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
    else:
        a_dtype = a.dtype
    dtype = np.promote_types(a_dtype, int)

    def _nansum_nb(a):
        out = np.empty(a.shape[1], dtype=dtype)
        for col in range(a.shape[1]):
            out[col] = np.nansum(a[:, col])
        return out

    if not nb_enabled:
        return _nansum_nb(a)

    return _nansum_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nth_index_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">nth_index_reduce_nb</span></span>(<span class="params">col, a, n)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return index of n-th element.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nth_index_reduce_nb(col: int, a: tp.Array1d, n: int) -&gt; int:
    &#34;&#34;&#34;Return index of n-th element.&#34;&#34;&#34;
    if (n &lt; 0 and abs(n) &gt; a.shape[0]) or n &gt;= a.shape[0]:
        raise ValueError(&#34;index is out of bounds&#34;)
    if n &gt;= 0:
        return n
    return a.shape[0] + n</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.nth_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">nth_reduce_nb</span></span>(<span class="params">col, a, n)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return n-th element.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def nth_reduce_nb(col: int, a: tp.Array1d, n: int) -&gt; float:
    &#34;&#34;&#34;Return n-th element.&#34;&#34;&#34;
    if (n &lt; 0 and abs(n) &gt; a.shape[0]) or n &gt;= a.shape[0]:
        raise ValueError(&#34;index is out of bounds&#34;)
    return a[n]</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.pct_change_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">pct_change_1d_nb</span></span>(<span class="params">a, n=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return the percentage change.</p>
<p>Numba equivalent to <code>pd.Series(a).pct_change()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def pct_change_1d_nb(a: tp.Array1d, n: int = 1) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return the percentage change.

    Numba equivalent to `pd.Series(a).pct_change()`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    out[:n] = np.nan
    out[n:] = a[n:] / a[:-n] - 1
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.pct_change_nb"><code class="name flex">
<span>def <span class="ident parent-name">pct_change_nb</span></span>(<span class="params">a, n=1)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.pct_change_1d_nb" href="#vectorbt.generic.nb.pct_change_1d_nb">pct_change_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def pct_change_nb(a: tp.Array2d, n: int = 1) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `pct_change_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = pct_change_1d_nb(a[:, col], n=n)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.range_coverage_nb"><code class="name flex">
<span>def <span class="ident parent-name">range_coverage_nb</span></span>(<span class="params">start_idx_arr, end_idx_arr, status_arr, col_map, index_lens, overlapping=False, normalize=False)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Get coverage of range records.</p>
<p>Set <code>overlapping</code> to True to get the number of overlapping steps.
Set <code>normalize</code> to True to get the number of steps in relation either to the total number of steps
(when <code>overlapping=False</code>) or to the number of covered steps (when <code>overlapping=True</code>).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def range_coverage_nb(start_idx_arr: tp.Array1d,
                      end_idx_arr: tp.Array1d,
                      status_arr: tp.Array2d,
                      col_map: tp.ColMap,
                      index_lens: tp.Array1d,
                      overlapping: bool = False,
                      normalize: bool = False) -&gt; tp.Array1d:
    &#34;&#34;&#34;Get coverage of range records.

    Set `overlapping` to True to get the number of overlapping steps.
    Set `normalize` to True to get the number of steps in relation either to the total number of steps
    (when `overlapping=False`) or to the number of covered steps (when `overlapping=True`).
    &#34;&#34;&#34;
    col_idxs, col_lens = col_map
    col_start_idxs = np.cumsum(col_lens) - col_lens
    out = np.full(col_lens.shape[0], np.nan, dtype=np.float_)

    for col in range(col_lens.shape[0]):
        col_len = col_lens[col]
        if col_len == 0:
            continue
        col_start_idx = col_start_idxs[col]
        ridxs = col_idxs[col_start_idx:col_start_idx + col_len]
        temp = np.full(index_lens[col], 0, dtype=np.int_)
        for ridx in ridxs:
            if status_arr[ridx] == RangeStatus.Open:
                temp[start_idx_arr[ridx]:end_idx_arr[ridx] + 1] += 1
            else:
                temp[start_idx_arr[ridx]:end_idx_arr[ridx]] += 1
        if overlapping:
            if normalize:
                out[col] = np.sum(temp &gt; 1) / np.sum(temp &gt; 0)
            else:
                out[col] = np.sum(temp &gt; 1)
        else:
            if normalize:
                out[col] = np.sum(temp &gt; 0) / index_lens[col]
            else:
                out[col] = np.sum(temp &gt; 0)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.range_duration_nb"><code class="name flex">
<span>def <span class="ident parent-name">range_duration_nb</span></span>(<span class="params">start_idx_arr, end_idx_arr, status_arr)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Get duration of each duration record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def range_duration_nb(start_idx_arr: tp.Array1d,
                      end_idx_arr: tp.Array1d,
                      status_arr: tp.Array2d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Get duration of each duration record.&#34;&#34;&#34;
    out = np.empty(start_idx_arr.shape[0], dtype=np.int_)
    for ridx in range(out.shape[0]):
        if status_arr[ridx] == RangeStatus.Open:
            out[ridx] = end_idx_arr[ridx] - start_idx_arr[ridx] + 1
        else:
            out[ridx] = end_idx_arr[ridx] - start_idx_arr[ridx]
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.ranges_to_mask_nb"><code class="name flex">
<span>def <span class="ident parent-name">ranges_to_mask_nb</span></span>(<span class="params">start_idx_arr, end_idx_arr, status_arr, col_map, index_len)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Convert ranges to 2-dim mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def ranges_to_mask_nb(start_idx_arr: tp.Array1d,
                      end_idx_arr: tp.Array1d,
                      status_arr: tp.Array2d,
                      col_map: tp.ColMap,
                      index_len: int) -&gt; tp.Array2d:
    &#34;&#34;&#34;Convert ranges to 2-dim mask.&#34;&#34;&#34;
    col_idxs, col_lens = col_map
    col_start_idxs = np.cumsum(col_lens) - col_lens
    out = np.full((index_len, col_lens.shape[0]), False, dtype=np.bool_)

    for col in range(col_lens.shape[0]):
        col_len = col_lens[col]
        if col_len == 0:
            continue
        col_start_idx = col_start_idxs[col]
        ridxs = col_idxs[col_start_idx:col_start_idx + col_len]
        for ridx in ridxs:
            if status_arr[ridx] == RangeStatus.Open:
                out[start_idx_arr[ridx]:end_idx_arr[ridx] + 1, col] = True
            else:
                out[start_idx_arr[ridx]:end_idx_arr[ridx], col] = True

    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.reduce_grouped_nb"><code class="name flex">
<span>def <span class="ident parent-name">reduce_grouped_nb</span></span>(<span class="params">a, group_lens, reduce_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce each group of columns into a single value using <code>reduce_func_nb</code>.</p>
<p><code>reduce_func_nb</code> should accept index of the group, the array of row values, and <code>*args</code>.
Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def reduce_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d,
                      reduce_func_nb: tp.GroupReduceFunc, *args) -&gt; tp.Array1d:
    &#34;&#34;&#34;Reduce each group of columns into a single value using `reduce_func_nb`.

    `reduce_func_nb` should accept index of the group, the array of row values, and `*args`.
    Should return a single value.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        _out = reduce_func_nb(group, a[:, from_col:to_col], *args)
        if group == 0:
            out = np.empty(len(group_lens), dtype=np.asarray(_out).dtype)
        out[group] = _out
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.reduce_grouped_to_array_nb"><code class="name flex">
<span>def <span class="ident parent-name">reduce_grouped_to_array_nb</span></span>(<span class="params">a, group_lens, reduce_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce each group of columns into an array of values using <code>reduce_func_nb</code>.</p>
<p><code>reduce_func_nb</code> same as for <code><a title="vectorbt.generic.nb.reduce_grouped_nb" href="#vectorbt.generic.nb.reduce_grouped_nb">reduce_grouped_nb()</a></code> but should return an array.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Output of <code>reduce_func_nb</code> should be strictly homogeneous.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def reduce_grouped_to_array_nb(a: tp.Array2d, group_lens: tp.Array1d,
                               reduce_func_nb: tp.GroupReduceArrayFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Reduce each group of columns into an array of values using `reduce_func_nb`.

    `reduce_func_nb` same as for `reduce_grouped_nb` but should return an array.

    !!! note
        Output of `reduce_func_nb` should be strictly homogeneous.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        _out = reduce_func_nb(group, a[:, from_col:to_col], *args)
        if group == 0:
            out = np.empty((_out.shape[0], len(group_lens)), dtype=_out.dtype)
        out[:, group] = _out
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">reduce_nb</span></span>(<span class="params">a, reduce_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce each column into a single value using <code>reduce_func_nb</code>.</p>
<p><code>reduce_func_nb</code> should accept index of the column, the array, and <code>*args</code>.
Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def reduce_nb(a: tp.Array2d, reduce_func_nb: tp.ReduceFunc, *args) -&gt; tp.Array1d:
    &#34;&#34;&#34;Reduce each column into a single value using `reduce_func_nb`.

    `reduce_func_nb` should accept index of the column, the array, and `*args`.
    Should return a single value.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        _out = reduce_func_nb(col, a[:, col], *args)
        if col == 0:
            out = np.empty(a.shape[1], dtype=np.asarray(_out).dtype)
        out[col] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.reduce_to_array_nb"><code class="name flex">
<span>def <span class="ident parent-name">reduce_to_array_nb</span></span>(<span class="params">a, reduce_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce each column into an array of values using <code>reduce_func_nb</code>.</p>
<p><code>reduce_func_nb</code> same as for <code><a title="vectorbt.generic.nb.reduce_nb" href="#vectorbt.generic.nb.reduce_nb">reduce_nb()</a></code> but should return an array.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Output of <code>reduce_func_nb</code> should be strictly homogeneous.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def reduce_to_array_nb(a: tp.Array2d, reduce_func_nb: tp.ReduceArrayFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Reduce each column into an array of values using `reduce_func_nb`.

    `reduce_func_nb` same as for `reduce_nb` but should return an array.

    !!! note
        Output of `reduce_func_nb` should be strictly homogeneous.&#34;&#34;&#34;
    for col in range(a.shape[1]):
        _out = reduce_func_nb(col, a[:, col], *args)
        if col == 0:
            out = np.empty((_out.shape[0], a.shape[1]), dtype=_out.dtype)
        out[:, col] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_apply_nb</span></span>(<span class="params">a, window, minp, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Provide rolling window calculations.</p>
<p><code>apply_func_nb</code> should accept index of the row, index of the column,
the array, and <code>*args</code>. Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def rolling_apply_nb(a: tp.Array2d, window: int, minp: tp.Optional[int],
                     apply_func_nb: tp.RollApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Provide rolling window calculations.

    `apply_func_nb` should accept index of the row, index of the column,
    the array, and `*args`. Should return a single value.&#34;&#34;&#34;
    if minp is None:
        minp = window
    out = np.empty_like(a, dtype=np.float_)
    nancnt_arr = np.empty((a.shape[0],), dtype=np.int_)
    for col in range(a.shape[1]):
        nancnt = 0
        for i in range(a.shape[0]):
            if np.isnan(a[i, col]):
                nancnt = nancnt + 1
            nancnt_arr[i] = nancnt
            if i &lt; window:
                valid_cnt = i + 1 - nancnt
            else:
                valid_cnt = window - (nancnt - nancnt_arr[i - window])
            if valid_cnt &lt; minp:
                out[i, col] = np.nan
            else:
                window_a = a[max(0, i + 1 - window):i + 1, col]
                out[i, col] = apply_func_nb(i, col, window_a, *args)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_matrix_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_matrix_apply_nb</span></span>(<span class="params">a, window, minp, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p><code><a title="vectorbt.generic.nb.rolling_apply_nb" href="#vectorbt.generic.nb.rolling_apply_nb">rolling_apply_nb()</a></code> with <code>apply_func_nb</code> being applied on all columns at once.</p>
<p><code>apply_func_nb</code> should accept index of the row, the 2-dim array, and <code>*args</code>.
Should return a single value or an array of shape <code>a.shape[1]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def rolling_matrix_apply_nb(a: tp.Array2d, window: int, minp: tp.Optional[int],
                            apply_func_nb: tp.RollMatrixApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;`rolling_apply_nb` with `apply_func_nb` being applied on all columns at once.

    `apply_func_nb` should accept index of the row, the 2-dim array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    out = np.empty_like(a, dtype=np.float_)
    nancnt_arr = np.empty((a.shape[0],), dtype=np.int_)
    for i in range(a.shape[0]):
        nancnt = 0
        for col in range(a.shape[1]):
            if np.isnan(a[i, col]):
                nancnt = nancnt + 1
        nancnt_arr[i] = nancnt
        if i &lt; window:
            valid_cnt = i + 1 - nancnt
        else:
            valid_cnt = window - (nancnt - nancnt_arr[i - window])
        if valid_cnt &lt; minp:
            out[i, :] = np.nan
        else:
            window_a = a[max(0, i + 1 - window):i + 1, :]
            out[i, :] = apply_func_nb(i, window_a, *args)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_max_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_max_1d_nb</span></span>(<span class="params">a, window, minp=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return rolling max.</p>
<p>Numba equivalent to <code>pd.Series(a).rolling(window, min_periods=minp).max()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_max_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling max.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).max()`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    for i in range(a.shape[0]):
        maxv = a[i]
        cnt = 0
        for j in range(max(i - window + 1, 0), i + 1):
            if np.isnan(a[j]):
                continue
            if np.isnan(maxv) or a[j] &gt; maxv:
                maxv = a[j]
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = maxv
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_max_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_max_nb</span></span>(<span class="params">a, window, minp=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.rolling_max_1d_nb" href="#vectorbt.generic.nb.rolling_max_1d_nb">rolling_max_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_max_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_max_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_max_1d_nb(a[:, col], window, minp=minp)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_mean_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_mean_1d_nb</span></span>(<span class="params">a, window, minp=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return rolling mean.</p>
<p>Numba equivalent to <code>pd.Series(a).rolling(window, min_periods=minp).mean()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_mean_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling mean.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).mean()`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    cumsum_arr = np.zeros_like(a)
    cumsum = 0
    nancnt_arr = np.zeros_like(a)
    nancnt = 0
    for i in range(a.shape[0]):
        if np.isnan(a[i]):
            nancnt = nancnt + 1
        else:
            cumsum = cumsum + a[i]
        nancnt_arr[i] = nancnt
        cumsum_arr[i] = cumsum
        if i &lt; window:
            window_len = i + 1 - nancnt
            window_cumsum = cumsum
        else:
            window_len = window - (nancnt - nancnt_arr[i - window])
            window_cumsum = cumsum - cumsum_arr[i - window]
        if window_len &lt; minp:
            out[i] = np.nan
        else:
            out[i] = window_cumsum / window_len
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_mean_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_mean_nb</span></span>(<span class="params">a, window, minp=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.rolling_mean_1d_nb" href="#vectorbt.generic.nb.rolling_mean_1d_nb">rolling_mean_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_mean_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_mean_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_mean_1d_nb(a[:, col], window, minp=minp)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_min_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_min_1d_nb</span></span>(<span class="params">a, window, minp=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return rolling min.</p>
<p>Numba equivalent to <code>pd.Series(a).rolling(window, min_periods=minp).min()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_min_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling min.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).min()`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    for i in range(a.shape[0]):
        minv = a[i]
        cnt = 0
        for j in range(max(i - window + 1, 0), i + 1):
            if np.isnan(a[j]):
                continue
            if np.isnan(minv) or a[j] &lt; minv:
                minv = a[j]
            cnt += 1
        if cnt &lt; minp:
            out[i] = np.nan
        else:
            out[i] = minv
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_min_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_min_nb</span></span>(<span class="params">a, window, minp=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.rolling_min_1d_nb" href="#vectorbt.generic.nb.rolling_min_1d_nb">rolling_min_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_min_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_min_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_min_1d_nb(a[:, col], window, minp=minp)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_std_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_std_1d_nb</span></span>(<span class="params">a, window, minp=None, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return rolling standard deviation.</p>
<p>Numba equivalent to <code>pd.Series(a).rolling(window, min_periods=minp).std(ddof=ddof)</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_std_1d_nb(a: tp.Array1d, window: int, minp: tp.Optional[int] = None, ddof: int = 0) -&gt; tp.Array1d:
    &#34;&#34;&#34;Return rolling standard deviation.

    Numba equivalent to `pd.Series(a).rolling(window, min_periods=minp).std(ddof=ddof)`.&#34;&#34;&#34;
    if minp is None:
        minp = window
    if minp &gt; window:
        raise ValueError(&#34;minp must be &lt;= window&#34;)
    out = np.empty_like(a, dtype=np.float_)
    cumsum_arr = np.zeros_like(a)
    cumsum = 0
    cumsum_sq_arr = np.zeros_like(a)
    cumsum_sq = 0
    nancnt_arr = np.zeros_like(a)
    nancnt = 0
    for i in range(a.shape[0]):
        if np.isnan(a[i]):
            nancnt = nancnt + 1
        else:
            cumsum = cumsum + a[i]
            cumsum_sq = cumsum_sq + a[i] ** 2
        nancnt_arr[i] = nancnt
        cumsum_arr[i] = cumsum
        cumsum_sq_arr[i] = cumsum_sq
        if i &lt; window:
            window_len = i + 1 - nancnt
            window_cumsum = cumsum
            window_cumsum_sq = cumsum_sq
        else:
            window_len = window - (nancnt - nancnt_arr[i - window])
            window_cumsum = cumsum - cumsum_arr[i - window]
            window_cumsum_sq = cumsum_sq - cumsum_sq_arr[i - window]
        if window_len &lt; minp or window_len == ddof:
            out[i] = np.nan
        else:
            mean = window_cumsum / window_len
            out[i] = np.sqrt(np.abs(window_cumsum_sq - 2 * window_cumsum *
                                    mean + window_len * mean ** 2) / (window_len - ddof))
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.rolling_std_nb"><code class="name flex">
<span>def <span class="ident parent-name">rolling_std_nb</span></span>(<span class="params">a, window, minp=None, ddof=0)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.rolling_std_1d_nb" href="#vectorbt.generic.nb.rolling_std_1d_nb">rolling_std_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def rolling_std_nb(a: tp.Array2d, window: int, minp: tp.Optional[int] = None, ddof: int = 0) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `rolling_std_1d_nb`.&#34;&#34;&#34;
    out = np.empty_like(a, dtype=np.float_)
    for col in range(a.shape[1]):
        out[:, col] = rolling_std_1d_nb(a[:, col], window, minp=minp, ddof=ddof)
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.row_apply_nb"><code class="name flex">
<span>def <span class="ident parent-name">row_apply_nb</span></span>(<span class="params">a, apply_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Apply function on each row.</p>
<p><code>apply_func_nb</code> should accept index of the row, the array, and <code>*args</code>.
Should return a single value or an array of shape <code>a.shape[1]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def row_apply_nb(a: tp.Array2d, apply_func_nb: tp.RowApplyFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Apply function on each row.

    `apply_func_nb` should accept index of the row, the array, and `*args`.
    Should return a single value or an array of shape `a.shape[1]`.&#34;&#34;&#34;
    for i in range(a.shape[0]):
        _out = apply_func_nb(i, a[i, :], *args)
        if i == 0:
            out = np.empty_like(a, dtype=np.asarray(_out).dtype)
        out[i, :] = _out
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.set_by_mask_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">set_by_mask_1d_nb</span></span>(<span class="params">a, mask, value)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Set each element to a value by boolean mask.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def set_by_mask_1d_nb(a: tp.Array1d, mask: tp.Array1d, value: tp.Scalar) -&gt; tp.Array1d:
    &#34;&#34;&#34;Set each element to a value by boolean mask.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(value)
    else:
        a_dtype = a.dtype
        value_dtype = np.array(value).dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_1d_nb(a, mask, value):
        out = a.astype(dtype)
        out[mask] = value
        return out

    if not nb_enabled:
        return _set_by_mask_1d_nb(a, mask, value)

    return _set_by_mask_1d_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.set_by_mask_mult_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">set_by_mask_mult_1d_nb</span></span>(<span class="params">a, mask, values)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Set each element in one array to the corresponding element in another by boolean mask.</p>
<p><code>values</code> should be of the same shape as in <code>a</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def set_by_mask_mult_1d_nb(a: tp.Array1d, mask: tp.Array1d, values: tp.Array1d) -&gt; tp.Array1d:
    &#34;&#34;&#34;Set each element in one array to the corresponding element in another by boolean mask.

    `values` should be of the same shape as in `a`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(values.dtype)
    else:
        a_dtype = a.dtype
        value_dtype = values.dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_mult_1d_nb(a, mask, values):
        out = a.astype(dtype)
        out[mask] = values[mask]
        return out

    if not nb_enabled:
        return _set_by_mask_mult_1d_nb(a, mask, values)

    return _set_by_mask_mult_1d_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.set_by_mask_mult_nb"><code class="name flex">
<span>def <span class="ident parent-name">set_by_mask_mult_nb</span></span>(<span class="params">a, mask, values)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.set_by_mask_mult_1d_nb" href="#vectorbt.generic.nb.set_by_mask_mult_1d_nb">set_by_mask_mult_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def set_by_mask_mult_nb(a: tp.Array2d, mask: tp.Array2d, values: tp.Array2d) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `set_by_mask_mult_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(values.dtype)
    else:
        a_dtype = a.dtype
        value_dtype = values.dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_mult_nb(a, mask, values):
        out = a.astype(dtype)
        for col in range(a.shape[1]):
            out[mask[:, col], col] = values[mask[:, col], col]
        return out

    if not nb_enabled:
        return _set_by_mask_mult_nb(a, mask, values)

    return _set_by_mask_mult_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.set_by_mask_nb"><code class="name flex">
<span>def <span class="ident parent-name">set_by_mask_nb</span></span>(<span class="params">a, mask, value)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.set_by_mask_1d_nb" href="#vectorbt.generic.nb.set_by_mask_1d_nb">set_by_mask_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@generated_jit(nopython=True, cache=True)
def set_by_mask_nb(a: tp.Array2d, mask: tp.Array2d, value: tp.Scalar) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `set_by_mask_1d_nb`.&#34;&#34;&#34;
    nb_enabled = not isinstance(a, np.ndarray)
    if nb_enabled:
        a_dtype = as_dtype(a.dtype)
        value_dtype = as_dtype(value)
    else:
        a_dtype = a.dtype
        value_dtype = np.array(value).dtype
    dtype = np.promote_types(a_dtype, value_dtype)

    def _set_by_mask_nb(a, mask, value):
        out = a.astype(dtype)
        for col in range(a.shape[1]):
            out[mask[:, col], col] = value
        return out

    if not nb_enabled:
        return _set_by_mask_nb(a, mask, value)

    return _set_by_mask_nb</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.shuffle_1d_nb"><code class="name flex">
<span>def <span class="ident parent-name">shuffle_1d_nb</span></span>(<span class="params">a, seed=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Shuffle each column in <code>a</code>.</p>
<p>Specify <code>seed</code> to make output deterministic.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def shuffle_1d_nb(a: tp.Array1d, seed: tp.Optional[int] = None) -&gt; tp.Array1d:
    &#34;&#34;&#34;Shuffle each column in `a`.

    Specify `seed` to make output deterministic.&#34;&#34;&#34;
    if seed is not None:
        np.random.seed(seed)
    return np.random.permutation(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.shuffle_nb"><code class="name flex">
<span>def <span class="ident parent-name">shuffle_nb</span></span>(<span class="params">a, seed=None)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>2-dim version of <code><a title="vectorbt.generic.nb.shuffle_1d_nb" href="#vectorbt.generic.nb.shuffle_1d_nb">shuffle_1d_nb()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def shuffle_nb(a: tp.Array2d, seed: tp.Optional[int] = None) -&gt; tp.Array2d:
    &#34;&#34;&#34;2-dim version of `shuffle_1d_nb`.&#34;&#34;&#34;
    if seed is not None:
        np.random.seed(seed)
    out = np.empty_like(a, dtype=a.dtype)

    for col in range(a.shape[1]):
        out[:, col] = np.random.permutation(a[:, col])
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.squeeze_grouped_nb"><code class="name flex">
<span>def <span class="ident parent-name">squeeze_grouped_nb</span></span>(<span class="params">a, group_lens, squeeze_func_nb, *args)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Squeeze each group of columns into a single column using <code>squeeze_func_nb</code>.</p>
<p><code>squeeze_func_nb</code> should accept index of the row, index of the group,
the array, and <code>*args</code>. Should return a single value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit
def squeeze_grouped_nb(a: tp.Array2d, group_lens: tp.Array1d,
                       squeeze_func_nb: tp.GroupSqueezeFunc, *args) -&gt; tp.Array2d:
    &#34;&#34;&#34;Squeeze each group of columns into a single column using `squeeze_func_nb`.

    `squeeze_func_nb` should accept index of the row, index of the group,
    the array, and `*args`. Should return a single value.&#34;&#34;&#34;
    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        for i in range(a.shape[0]):
            _out = squeeze_func_nb(i, group, a[i, from_col:to_col], *args)
            if group == 0 and i == 0:
                out = np.empty((a.shape[0], len(group_lens)), dtype=np.asarray(_out).dtype)
            out[i, group] = _out
        from_col = to_col
    return out</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.std_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">std_reduce_nb</span></span>(<span class="params">col, a, ddof)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return std (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def std_reduce_nb(col: int, a: tp.Array1d, ddof) -&gt; float:
    &#34;&#34;&#34;Return std (ignores NaNs).&#34;&#34;&#34;
    return nanstd_1d_nb(a, ddof=ddof)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.sum_reduce_nb"><code class="name flex">
<span>def <span class="ident parent-name">sum_reduce_nb</span></span>(<span class="params">col, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return sum (ignores NaNs).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def sum_reduce_nb(col: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return sum (ignores NaNs).&#34;&#34;&#34;
    return np.nansum(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.sum_squeeze_nb"><code class="name flex">
<span>def <span class="ident parent-name">sum_squeeze_nb</span></span>(<span class="params">col, group, a)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return sum (ignores NaNs) of a group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def sum_squeeze_nb(col: int, group: int, a: tp.Array1d) -&gt; float:
    &#34;&#34;&#34;Return sum (ignores NaNs) of a group.&#34;&#34;&#34;
    return np.nansum(a)</code></pre>
</details>
</dd>
<dt id="vectorbt.generic.nb.value_counts_nb"><code class="name flex">
<span>def <span class="ident parent-name">value_counts_nb</span></span>(<span class="params">codes, n_uniques, group_lens)</span><span class="return_type"></span>
</code></dt>
<dd>
<div class="desc"><p>Return value counts per column/group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@njit(cache=True)
def value_counts_nb(codes: tp.Array2d, n_uniques: int, group_lens: tp.Array1d) -&gt; tp.Array2d:
    &#34;&#34;&#34;Return value counts per column/group.&#34;&#34;&#34;
    out = np.full((n_uniques, group_lens.shape[0]), 0, dtype=np.int_)

    from_col = 0
    for group in range(len(group_lens)):
        to_col = from_col + group_lens[group]
        for col in range(from_col, to_col):
            for i in range(codes.shape[0]):
                out[codes[i, col], group] += 1
        from_col = to_col
    return out</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://github.com/polakowo/vectorbt">
<img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI1LjAuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkNhcGFfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiCgkgdmlld0JveD0iMCAwIDUxMiA1MTIiIHN0eWxlPSJlbmFibGUtYmFja2dyb3VuZDpuZXcgMCAwIDUxMiA1MTI7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDojRUYwMDAwO30KCS5zdDF7ZmlsbDojRkY5MDAwO30KCS5zdDJ7ZmlsbDojRkZERjAwO30KCS5zdDN7ZmlsbDojMjgyQzM0O30KPC9zdHlsZT4KPGc+Cgk8Zz4KCQk8Zz4KCQkJPHBvbHlnb24gY2xhc3M9InN0MCIgcG9pbnRzPSIxNTUuMywzMDAuMSAyODMuMSwwIDIwOCwwIDExMC44LDAgMzUuOCwwIDEuMiw0NTAuMiA3Ni4zLDQ1MC4yIAkJCSIvPgoJCTwvZz4KCTwvZz4KCTxnPgoJCTxnPgoJCQk8cG9seWdvbiBjbGFzcz0ic3QxIiBwb2ludHM9IjIzMC40LDMwMC4xIDM1OC4xLDAgMjgzLjEsMCAxODUuOCwwIDExMC44LDAgNzYuMyw0NTAuMiAxNTEuMyw0NTAuMiAJCQkiLz4KCQk8L2c+Cgk8L2c+Cgk8Zz4KCQk8Zz4KCQkJPHBvbHlnb24gY2xhc3M9InN0MiIgcG9pbnRzPSIzMDUuNCwzMDAuMSA0MzMuMSwwIDM1OC4xLDAgMzMxLjYsNjIuMyAyNjAuOCwwIDE4NS44LDAgMTUxLjMsNDUwLjIgMjI2LjQsNDUwLjIgCQkJIi8+CgkJPC9nPgoJPC9nPgoJPGc+CgkJPGc+CgkJCTxwb2x5Z29uIGNsYXNzPSJzdDMiIHBvaW50cz0iNTEwLjgsMCA0MzMuMSwwIDMwNS40LDMwMC4xIDMzOC40LDAgMjYwLjgsMCAyMjYuNCw0NTAuMiAzMDQsNDUwLjIgCQkJIi8+CgkJPC9nPgoJPC9nPgo8L2c+Cjwvc3ZnPgo="/>
vectorbt <span class="version">0.21.0</span></a>
</header>
<div class="search-container">
<input
id="search_input"
type="text"
placeholder="Search"
title="Search"
/>
</div>
<div class="scrollable-index">
<h1 class="index-caption">Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="vectorbt.generic" href="index.html">vectorbt.generic</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="vectorbt.generic.nb.any_squeeze_nb" href="#vectorbt.generic.nb.any_squeeze_nb">any_squeeze_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.apply_and_reduce_nb" href="#vectorbt.generic.nb.apply_and_reduce_nb">apply_and_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.apply_nb" href="#vectorbt.generic.nb.apply_nb">apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.applymap_nb" href="#vectorbt.generic.nb.applymap_nb">applymap_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.argmax_reduce_nb" href="#vectorbt.generic.nb.argmax_reduce_nb">argmax_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.argmin_reduce_nb" href="#vectorbt.generic.nb.argmin_reduce_nb">argmin_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.bfill_1d_nb" href="#vectorbt.generic.nb.bfill_1d_nb">bfill_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.bfill_nb" href="#vectorbt.generic.nb.bfill_nb">bfill_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.bshift_1d_nb" href="#vectorbt.generic.nb.bshift_1d_nb">bshift_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.bshift_nb" href="#vectorbt.generic.nb.bshift_nb">bshift_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.count_reduce_nb" href="#vectorbt.generic.nb.count_reduce_nb">count_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.dd_decline_duration_nb" href="#vectorbt.generic.nb.dd_decline_duration_nb">dd_decline_duration_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.dd_drawdown_nb" href="#vectorbt.generic.nb.dd_drawdown_nb">dd_drawdown_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.dd_recovery_duration_nb" href="#vectorbt.generic.nb.dd_recovery_duration_nb">dd_recovery_duration_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.dd_recovery_duration_ratio_nb" href="#vectorbt.generic.nb.dd_recovery_duration_ratio_nb">dd_recovery_duration_ratio_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.dd_recovery_return_nb" href="#vectorbt.generic.nb.dd_recovery_return_nb">dd_recovery_return_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.describe_reduce_nb" href="#vectorbt.generic.nb.describe_reduce_nb">describe_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.diff_1d_nb" href="#vectorbt.generic.nb.diff_1d_nb">diff_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.diff_nb" href="#vectorbt.generic.nb.diff_nb">diff_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ewm_mean_1d_nb" href="#vectorbt.generic.nb.ewm_mean_1d_nb">ewm_mean_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ewm_mean_nb" href="#vectorbt.generic.nb.ewm_mean_nb">ewm_mean_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ewm_std_1d_nb" href="#vectorbt.generic.nb.ewm_std_1d_nb">ewm_std_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ewm_std_nb" href="#vectorbt.generic.nb.ewm_std_nb">ewm_std_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_apply_nb" href="#vectorbt.generic.nb.expanding_apply_nb">expanding_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_matrix_apply_nb" href="#vectorbt.generic.nb.expanding_matrix_apply_nb">expanding_matrix_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_max_1d_nb" href="#vectorbt.generic.nb.expanding_max_1d_nb">expanding_max_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_max_nb" href="#vectorbt.generic.nb.expanding_max_nb">expanding_max_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_mean_1d_nb" href="#vectorbt.generic.nb.expanding_mean_1d_nb">expanding_mean_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_mean_nb" href="#vectorbt.generic.nb.expanding_mean_nb">expanding_mean_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_min_1d_nb" href="#vectorbt.generic.nb.expanding_min_1d_nb">expanding_min_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_min_nb" href="#vectorbt.generic.nb.expanding_min_nb">expanding_min_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_std_1d_nb" href="#vectorbt.generic.nb.expanding_std_1d_nb">expanding_std_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.expanding_std_nb" href="#vectorbt.generic.nb.expanding_std_nb">expanding_std_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ffill_1d_nb" href="#vectorbt.generic.nb.ffill_1d_nb">ffill_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ffill_nb" href="#vectorbt.generic.nb.ffill_nb">ffill_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.fillna_1d_nb" href="#vectorbt.generic.nb.fillna_1d_nb">fillna_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.fillna_nb" href="#vectorbt.generic.nb.fillna_nb">fillna_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.filter_nb" href="#vectorbt.generic.nb.filter_nb">filter_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.find_ranges_nb" href="#vectorbt.generic.nb.find_ranges_nb">find_ranges_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.flat_reduce_grouped_nb" href="#vectorbt.generic.nb.flat_reduce_grouped_nb">flat_reduce_grouped_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.flat_reduce_grouped_to_array_nb" href="#vectorbt.generic.nb.flat_reduce_grouped_to_array_nb">flat_reduce_grouped_to_array_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.flatten_forder_nb" href="#vectorbt.generic.nb.flatten_forder_nb">flatten_forder_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.flatten_grouped_nb" href="#vectorbt.generic.nb.flatten_grouped_nb">flatten_grouped_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.flatten_uniform_grouped_nb" href="#vectorbt.generic.nb.flatten_uniform_grouped_nb">flatten_uniform_grouped_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.fshift_1d_nb" href="#vectorbt.generic.nb.fshift_1d_nb">fshift_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.fshift_nb" href="#vectorbt.generic.nb.fshift_nb">fshift_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.get_drawdowns_nb" href="#vectorbt.generic.nb.get_drawdowns_nb">get_drawdowns_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.groupby_apply_nb" href="#vectorbt.generic.nb.groupby_apply_nb">groupby_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.groupby_matrix_apply_nb" href="#vectorbt.generic.nb.groupby_matrix_apply_nb">groupby_matrix_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.max_reduce_nb" href="#vectorbt.generic.nb.max_reduce_nb">max_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.max_squeeze_nb" href="#vectorbt.generic.nb.max_squeeze_nb">max_squeeze_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.mean_reduce_nb" href="#vectorbt.generic.nb.mean_reduce_nb">mean_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.median_reduce_nb" href="#vectorbt.generic.nb.median_reduce_nb">median_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.min_reduce_nb" href="#vectorbt.generic.nb.min_reduce_nb">min_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.min_squeeze_nb" href="#vectorbt.generic.nb.min_squeeze_nb">min_squeeze_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nancnt_nb" href="#vectorbt.generic.nb.nancnt_nb">nancnt_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nancumprod_nb" href="#vectorbt.generic.nb.nancumprod_nb">nancumprod_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nancumsum_nb" href="#vectorbt.generic.nb.nancumsum_nb">nancumsum_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanmax_nb" href="#vectorbt.generic.nb.nanmax_nb">nanmax_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanmean_nb" href="#vectorbt.generic.nb.nanmean_nb">nanmean_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanmedian_nb" href="#vectorbt.generic.nb.nanmedian_nb">nanmedian_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanmin_nb" href="#vectorbt.generic.nb.nanmin_nb">nanmin_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanprod_nb" href="#vectorbt.generic.nb.nanprod_nb">nanprod_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanstd_1d_nb" href="#vectorbt.generic.nb.nanstd_1d_nb">nanstd_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nanstd_nb" href="#vectorbt.generic.nb.nanstd_nb">nanstd_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nansum_nb" href="#vectorbt.generic.nb.nansum_nb">nansum_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nth_index_reduce_nb" href="#vectorbt.generic.nb.nth_index_reduce_nb">nth_index_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.nth_reduce_nb" href="#vectorbt.generic.nb.nth_reduce_nb">nth_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.pct_change_1d_nb" href="#vectorbt.generic.nb.pct_change_1d_nb">pct_change_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.pct_change_nb" href="#vectorbt.generic.nb.pct_change_nb">pct_change_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.range_coverage_nb" href="#vectorbt.generic.nb.range_coverage_nb">range_coverage_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.range_duration_nb" href="#vectorbt.generic.nb.range_duration_nb">range_duration_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.ranges_to_mask_nb" href="#vectorbt.generic.nb.ranges_to_mask_nb">ranges_to_mask_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.reduce_grouped_nb" href="#vectorbt.generic.nb.reduce_grouped_nb">reduce_grouped_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.reduce_grouped_to_array_nb" href="#vectorbt.generic.nb.reduce_grouped_to_array_nb">reduce_grouped_to_array_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.reduce_nb" href="#vectorbt.generic.nb.reduce_nb">reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.reduce_to_array_nb" href="#vectorbt.generic.nb.reduce_to_array_nb">reduce_to_array_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_apply_nb" href="#vectorbt.generic.nb.rolling_apply_nb">rolling_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_matrix_apply_nb" href="#vectorbt.generic.nb.rolling_matrix_apply_nb">rolling_matrix_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_max_1d_nb" href="#vectorbt.generic.nb.rolling_max_1d_nb">rolling_max_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_max_nb" href="#vectorbt.generic.nb.rolling_max_nb">rolling_max_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_mean_1d_nb" href="#vectorbt.generic.nb.rolling_mean_1d_nb">rolling_mean_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_mean_nb" href="#vectorbt.generic.nb.rolling_mean_nb">rolling_mean_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_min_1d_nb" href="#vectorbt.generic.nb.rolling_min_1d_nb">rolling_min_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_min_nb" href="#vectorbt.generic.nb.rolling_min_nb">rolling_min_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_std_1d_nb" href="#vectorbt.generic.nb.rolling_std_1d_nb">rolling_std_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.rolling_std_nb" href="#vectorbt.generic.nb.rolling_std_nb">rolling_std_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.row_apply_nb" href="#vectorbt.generic.nb.row_apply_nb">row_apply_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.set_by_mask_1d_nb" href="#vectorbt.generic.nb.set_by_mask_1d_nb">set_by_mask_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.set_by_mask_mult_1d_nb" href="#vectorbt.generic.nb.set_by_mask_mult_1d_nb">set_by_mask_mult_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.set_by_mask_mult_nb" href="#vectorbt.generic.nb.set_by_mask_mult_nb">set_by_mask_mult_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.set_by_mask_nb" href="#vectorbt.generic.nb.set_by_mask_nb">set_by_mask_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.shuffle_1d_nb" href="#vectorbt.generic.nb.shuffle_1d_nb">shuffle_1d_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.shuffle_nb" href="#vectorbt.generic.nb.shuffle_nb">shuffle_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.squeeze_grouped_nb" href="#vectorbt.generic.nb.squeeze_grouped_nb">squeeze_grouped_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.std_reduce_nb" href="#vectorbt.generic.nb.std_reduce_nb">std_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.sum_reduce_nb" href="#vectorbt.generic.nb.sum_reduce_nb">sum_reduce_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.sum_squeeze_nb" href="#vectorbt.generic.nb.sum_squeeze_nb">sum_squeeze_nb</a></code></li>
<li><code><a title="vectorbt.generic.nb.value_counts_nb" href="#vectorbt.generic.nb.value_counts_nb">value_counts_nb</a></code></li>
</ul>
</li>
</nav>
</main>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript">
docsearch({
apiKey: 'ac97cfdd96a6e6fcdc67c570adaeaf94',
indexName: 'vectorbt',
inputSelector: '#search_input',
autocompleteOptions: {
autoWidth: false
},
debug: true // Set debug to true if you want to inspect the dropdown
});
</script>
<script src="https://buttons.github.io/buttons.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
<script>
// Turn off ESLint for this file because it's sent down to users as-is.
/* eslint-disable */
window.addEventListener('load', function() {
function button(label, ariaLabel, icon, className) {
const btn = document.createElement('button');
btn.classList.add('btnIcon', className);
btn.setAttribute('type', 'button');
btn.setAttribute('aria-label', ariaLabel);
btn.innerHTML =
'<div class="btnIcon__body">' +
icon +
'<strong class="btnIcon__label">' +
label +
'</strong>' +
'</div>';
return btn;
}
function addButtons(codeBlockSelector, btn) {
document.querySelectorAll(codeBlockSelector).forEach(function(code) {
code.parentNode.appendChild(btn.cloneNode(true));
});
}
const copyIcon =
'<svg width="12" height="12" viewBox="340 364 14 15" xmlns="http://www.w3.org/2000/svg"><path fill="currentColor" d="M342 375.974h4v.998h-4v-.998zm5-5.987h-5v.998h5v-.998zm2 2.994v-1.995l-3 2.993 3 2.994v-1.996h5v-1.995h-5zm-4.5-.997H342v.998h2.5v-.997zm-2.5 2.993h2.5v-.998H342v.998zm9 .998h1v1.996c-.016.28-.11.514-.297.702-.187.187-.422.28-.703.296h-10c-.547 0-1-.452-1-.998v-10.976c0-.546.453-.998 1-.998h3c0-1.107.89-1.996 2-1.996 1.11 0 2 .89 2 1.996h3c.547 0 1 .452 1 .998v4.99h-1v-2.995h-10v8.98h10v-1.996zm-9-7.983h8c0-.544-.453-.996-1-.996h-1c-.547 0-1-.453-1-.998 0-.546-.453-.998-1-.998-.547 0-1 .452-1 .998 0 .545-.453.998-1 .998h-1c-.547 0-1 .452-1 .997z" fill-rule="evenodd"/></svg>';
addButtons(
'.hljs',
button('Copy', 'Copy code to clipboard', copyIcon, 'btnClipboard'),
);
const clipboard = new ClipboardJS('.btnClipboard', {
target: function(trigger) {
return trigger.parentNode.querySelector('code');
},
});
clipboard.on('success', function(event) {
event.clearSelection();
const textEl = event.trigger.querySelector('.btnIcon__label');
textEl.textContent = 'Copied';
setTimeout(function() {
textEl.textContent = 'Copy';
}, 2000);
});
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous"></script>
<script>
$(document).ready(function() {
$("article dt[id], #section-intro [id]").each(function() {
const thisId = $(this).attr('id');
$(this).wrap('<a class="headerlink" href="#' + thisId + '">');
});
});
</script>
</body>
</html>