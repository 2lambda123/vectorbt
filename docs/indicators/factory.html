<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>vectorbt.indicators.factory API documentation</title>
<meta name="description" content="An indicator factory `vectorbt.indicators.factory.IndicatorFactory` for building new indicators with ease â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold;word-break:break-all}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>vectorbt.indicators.factory</code></h1>
</header>
<section id="section-intro">
<p>An indicator factory <code><a title="vectorbt.indicators.factory.IndicatorFactory" href="#vectorbt.indicators.factory.IndicatorFactory">IndicatorFactory</a></code> for building new indicators with ease.</p>
<p>Each indicator is basically a pipeline that</p>
<ul>
<li>Accepts a list of time series objects (for example, OHLCV data)</li>
<li>Accepts a list of parameter arrays (for example, rolling windows)</li>
<li>Accepts other relevant arguments and keyword arguments</li>
<li>Performs calculations to produce new time series objects (for example, rolling average)</li>
</ul>
<p>This pipeline can be well standardized, which is done by this indicatory factory.</p>
<p>On top of this pipeline, it also does the following:</p>
<ul>
<li>Creates a new indicator class</li>
<li>Creates an <code>__init__</code> method where it stores all inputs, outputs, and other artifacts</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code>__init__</code> method is never used for running the indicator, for this use <code>from_params</code>.
The reason for this is indexing, which requires a clean <code>__init__</code> method for creating
a new indicator object with newly indexed attributes.</p>
</div>
<ul>
<li>Creates a <code>from_params</code> method that runs the main pipeline using <code><a title="vectorbt.indicators.factory.from_params_pipeline" href="#vectorbt.indicators.factory.from_params_pipeline">from_params_pipeline()</a></code></li>
<li>Adds pandas indexing, i.e., you can use <code>iloc</code>, <code>loc</code>, <code>xs</code>, and <code>__getitem__</code> on the class itself</li>
<li>Adds parameter indexing, i.e., use <code>*your_param*_loc</code> on the class to slice using parameters</li>
<li>Adds user-defined properties</li>
<li>Adds common comparison methods for all inputs, outputs and properties, e.g., crossovers</li>
</ul>
<h2 id="example">Example</h2>
<p>Consider the following smaller price DataFrame <code>price_sm</code>:</p>
<pre><code class="python-repl">&gt;&gt;&gt; index = pd.Index([
...     datetime(2018, 1, 1),
...     datetime(2018, 1, 2),
...     datetime(2018, 1, 3),
...     datetime(2018, 1, 4),
...     datetime(2018, 1, 5),
... ])
&gt;&gt;&gt; price_sm = pd.DataFrame({
...     'a': [1, 2, 3, 4, 5], 
...     'b': [5, 4, 3, 2, 1]}, index=index).astype(float)
&gt;&gt;&gt; print(price_sm)
            a    b
2018-01-01  1.0  5.0
2018-01-02  2.0  4.0
2018-01-03  3.0  3.0
2018-01-04  4.0  2.0
2018-01-05  5.0  1.0
</code></pre>
<p>For each column in the DataFrame, let's calculate a simple moving average and get signals
of price crossing it. In particular, we want to test two different window sizes: 2 and 3.</p>
<p>A naive way of doing this:</p>
<pre><code class="python-repl">&gt;&gt;&gt; ma_df = pd.DataFrame.vbt.concat(
...     price_sm.rolling(window=2).mean(), 
...     price_sm.rolling(window=3).mean(), 
...     as_columns=pd.Index([2, 3], name='ma_window'))
&gt;&gt;&gt; print(ma_df)
ma_window          2         3
            a    b    a    b
2018-01-01  NaN  NaN  NaN  NaN
2018-01-02  1.5  4.5  NaN  NaN
2018-01-03  2.5  3.5  2.0  4.0
2018-01-04  3.5  2.5  3.0  3.0
2018-01-05  4.5  1.5  4.0  2.0

&gt;&gt;&gt; above_signals = (price_sm.vbt.tile(2).vbt &gt; ma_df)
&gt;&gt;&gt; above_signals = above_signals.vbt.signals.first(after_false=True)
&gt;&gt;&gt; print(above_signals)
ma_window              2             3
                a      b      a      b
2018-01-01  False  False  False  False
2018-01-02   True  False  False  False
2018-01-03  False  False   True  False
2018-01-04  False  False  False  False
2018-01-05  False  False  False  False

&gt;&gt;&gt; below_signals = (price_sm.vbt.tile(2).vbt &lt; ma_df)
&gt;&gt;&gt; below_signals = below_signals.vbt.signals.first(after_false=True)
&gt;&gt;&gt; print(below_signals)
ma_window              2             3
                a      b      a      b
2018-01-01  False  False  False  False
2018-01-02  False   True  False  False
2018-01-03  False  False  False   True
2018-01-04  False  False  False  False
2018-01-05  False  False  False  False
</code></pre>
<p>Now the same using <code><a title="vectorbt.indicators.factory.IndicatorFactory" href="#vectorbt.indicators.factory.IndicatorFactory">IndicatorFactory</a></code>:</p>
<pre><code class="python-repl">&gt;&gt;&gt; MyMA = vbt.IndicatorFactory(
...     ts_names=['price_sm'],
...     param_names=['window'],
...     output_names=['ma'],
...     name='myma'
... ).from_apply_func(vbt.timeseries.nb.rolling_mean_nb)

&gt;&gt;&gt; myma = MyMA.from_params(price_sm, [2, 3])
&gt;&gt;&gt; above_signals = myma.price_sm_above(myma.ma, crossover=True)
&gt;&gt;&gt; below_signals = myma.price_sm_below(myma.ma, crossover=True)
</code></pre>
<p>It not only produced the handy <code>from_params</code> method, but generated a whole infrastructure to be run with
an arbitrary number of windows. </p>
<p>For all our inputs in <code>ts_names</code> and outputs in <code>output_names</code>, it created a bunch of comparison methods
for generating signals, such as <code>above</code>, <code>below</code> and <code>equal</code> (use <code>doc()</code>): </p>
<pre><code class="python-repl">'ma_above'
'ma_below'
'ma_equal'
'price_sm_above'
'price_sm_below'
'price_sm_equal'
</code></pre>
<p>Each of these methods uses vectorbt's own broadcasting, so you can compare time series objects with an
arbitrary array-like object, given their shapes can be broadcasted together. You can also compare them
to multiple objects at once, for example:</p>
<pre><code class="python-repl">&gt;&gt;&gt; myma.ma_above([1.5, 2.5], multiple=True)
myma_ma_above                         1.5                         2.5
myma_window               2             3             2             3
                a      b      a      b      a      b      a      b
2018-01-01     False  False  False  False  False  False  False  False
2018-01-02     False   True  False  False  False   True  False  False
2018-01-03      True   True   True   True  False   True  False   True
2018-01-04      True   True   True   True   True  False   True   True
2018-01-05      True  False   True   True   True  False   True  False
</code></pre>
<p><code><a title="vectorbt.indicators.factory.IndicatorFactory" href="#vectorbt.indicators.factory.IndicatorFactory">IndicatorFactory</a></code> also attached pandas indexing to the indicator class: </p>
<pre><code class="python-repl">'iloc'
'loc'
'window_loc'
'xs'
</code></pre>
<p>This makes accessing rows and columns by labels, integer positions, and parameters much easier.</p>
<p>The other advantage of using <code><a title="vectorbt.indicators.factory.IndicatorFactory" href="#vectorbt.indicators.factory.IndicatorFactory">IndicatorFactory</a></code> is broadcasting:</p>
<ul>
<li>Passing multiple time series objects will broadcast them to the same shape and index/columns</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; price_sm2 = price_sm.copy() + 1
&gt;&gt;&gt; price_sm2.columns = ['a2', 'b2']

&gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
...     ts_names=['price_sm', 'price_sm2'],
...     param_names=['p1', 'p2']
... ).from_apply_func(
...     lambda price_sm, price_sm2, p1, p2: price_sm * p1 + price_sm2 * p2
... )

&gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, 1, 2)
&gt;&gt;&gt; print(myInd.price_sm)
            a    b
            a2   b2
2018-01-01  1.0  5.0
2018-01-02  2.0  4.0
2018-01-03  3.0  3.0
2018-01-04  4.0  2.0
2018-01-05  5.0  1.0
&gt;&gt;&gt; print(myInd.price_sm2)
            a    b
            a2   b2
2018-01-01  2.0  6.0
2018-01-02  3.0  5.0
2018-01-03  4.0  4.0
2018-01-04  5.0  3.0
2018-01-05  6.0  2.0
</code></pre>
<ul>
<li>Passing multiple parameters will broadcast them to arrays of the same shape</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, 1, 2)
&gt;&gt;&gt; print(myInd._p1_array)
&gt;&gt;&gt; print(myInd._p2_array)
[1]
[2]

&gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, 1, [2, 3])
&gt;&gt;&gt; print(myInd._p1_array)
&gt;&gt;&gt; print(myInd._p2_array)
[1 1]
[2 3]

&gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, [1, 2], [3, 4], param_product=True)
&gt;&gt;&gt; print(myInd._p1_array)
&gt;&gt;&gt; print(myInd._p2_array)
[1 1 2 2]
[3 4 3 4]
</code></pre>
<p>This way, you can define parameter combinations of any order and shape.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;An indicator factory `vectorbt.indicators.factory.IndicatorFactory` for building new indicators with ease.

Each indicator is basically a pipeline that

* Accepts a list of time series objects (for example, OHLCV data)
* Accepts a list of parameter arrays (for example, rolling windows)
* Accepts other relevant arguments and keyword arguments
* Performs calculations to produce new time series objects (for example, rolling average)

This pipeline can be well standardized, which is done by this indicatory factory.

On top of this pipeline, it also does the following:

* Creates a new indicator class
* Creates an `__init__` method where it stores all inputs, outputs, and other artifacts

!!! note
    The `__init__` method is never used for running the indicator, for this use `from_params`.
    The reason for this is indexing, which requires a clean `__init__` method for creating 
    a new indicator object with newly indexed attributes.

* Creates a `from_params` method that runs the main pipeline using `from_params_pipeline`
* Adds pandas indexing, i.e., you can use `iloc`, `loc`, `xs`, and `__getitem__` on the class itself
* Adds parameter indexing, i.e., use `*your_param*_loc` on the class to slice using parameters
* Adds user-defined properties
* Adds common comparison methods for all inputs, outputs and properties, e.g., crossovers

Example:
    Consider the following smaller price DataFrame `price_sm`:

    ```python-repl
    &gt;&gt;&gt; index = pd.Index([
    ...     datetime(2018, 1, 1),
    ...     datetime(2018, 1, 2),
    ...     datetime(2018, 1, 3),
    ...     datetime(2018, 1, 4),
    ...     datetime(2018, 1, 5),
    ... ])
    &gt;&gt;&gt; price_sm = pd.DataFrame({
    ...     &#39;a&#39;: [1, 2, 3, 4, 5], 
    ...     &#39;b&#39;: [5, 4, 3, 2, 1]}, index=index).astype(float)
    &gt;&gt;&gt; print(price_sm)
                a    b
    2018-01-01  1.0  5.0
    2018-01-02  2.0  4.0
    2018-01-03  3.0  3.0
    2018-01-04  4.0  2.0
    2018-01-05  5.0  1.0
    ```

    For each column in the DataFrame, let&#39;s calculate a simple moving average and get signals 
    of price crossing it. In particular, we want to test two different window sizes: 2 and 3.

    A naive way of doing this:

    ```python-repl
    &gt;&gt;&gt; ma_df = pd.DataFrame.vbt.concat(
    ...     price_sm.rolling(window=2).mean(), 
    ...     price_sm.rolling(window=3).mean(), 
    ...     as_columns=pd.Index([2, 3], name=&#39;ma_window&#39;))
    &gt;&gt;&gt; print(ma_df)
    ma_window          2         3
                a    b    a    b
    2018-01-01  NaN  NaN  NaN  NaN
    2018-01-02  1.5  4.5  NaN  NaN
    2018-01-03  2.5  3.5  2.0  4.0
    2018-01-04  3.5  2.5  3.0  3.0
    2018-01-05  4.5  1.5  4.0  2.0

    &gt;&gt;&gt; above_signals = (price_sm.vbt.tile(2).vbt &gt; ma_df)
    &gt;&gt;&gt; above_signals = above_signals.vbt.signals.first(after_false=True)
    &gt;&gt;&gt; print(above_signals)
    ma_window              2             3
                    a      b      a      b
    2018-01-01  False  False  False  False
    2018-01-02   True  False  False  False
    2018-01-03  False  False   True  False
    2018-01-04  False  False  False  False
    2018-01-05  False  False  False  False

    &gt;&gt;&gt; below_signals = (price_sm.vbt.tile(2).vbt &lt; ma_df)
    &gt;&gt;&gt; below_signals = below_signals.vbt.signals.first(after_false=True)
    &gt;&gt;&gt; print(below_signals)
    ma_window              2             3
                    a      b      a      b
    2018-01-01  False  False  False  False
    2018-01-02  False   True  False  False
    2018-01-03  False  False  False   True
    2018-01-04  False  False  False  False
    2018-01-05  False  False  False  False
    ```

    Now the same using `IndicatorFactory`:

    ```python-repl
    &gt;&gt;&gt; MyMA = vbt.IndicatorFactory(
    ...     ts_names=[&#39;price_sm&#39;],
    ...     param_names=[&#39;window&#39;],
    ...     output_names=[&#39;ma&#39;],
    ...     name=&#39;myma&#39;
    ... ).from_apply_func(vbt.timeseries.nb.rolling_mean_nb)

    &gt;&gt;&gt; myma = MyMA.from_params(price_sm, [2, 3])
    &gt;&gt;&gt; above_signals = myma.price_sm_above(myma.ma, crossover=True)
    &gt;&gt;&gt; below_signals = myma.price_sm_below(myma.ma, crossover=True)
    ```

    It not only produced the handy `from_params` method, but generated a whole infrastructure to be run with
    an arbitrary number of windows. 

    For all our inputs in `ts_names` and outputs in `output_names`, it created a bunch of comparison methods 
    for generating signals, such as `above`, `below` and `equal` (use `doc()`): 

    ```python-repl
    &#39;ma_above&#39;
    &#39;ma_below&#39;
    &#39;ma_equal&#39;
    &#39;price_sm_above&#39;
    &#39;price_sm_below&#39;
    &#39;price_sm_equal&#39;
    ```

    Each of these methods uses vectorbt&#39;s own broadcasting, so you can compare time series objects with an 
    arbitrary array-like object, given their shapes can be broadcasted together. You can also compare them
    to multiple objects at once, for example:

    ```python-repl
    &gt;&gt;&gt; myma.ma_above([1.5, 2.5], multiple=True)
    myma_ma_above                         1.5                         2.5
    myma_window               2             3             2             3
                    a      b      a      b      a      b      a      b
    2018-01-01     False  False  False  False  False  False  False  False
    2018-01-02     False   True  False  False  False   True  False  False
    2018-01-03      True   True   True   True  False   True  False   True
    2018-01-04      True   True   True   True   True  False   True   True
    2018-01-05      True  False   True   True   True  False   True  False
    ```

    `IndicatorFactory` also attached pandas indexing to the indicator class: 

    ```python-repl
    &#39;iloc&#39;
    &#39;loc&#39;
    &#39;window_loc&#39;
    &#39;xs&#39;
    ```

    This makes accessing rows and columns by labels, integer positions, and parameters much easier.

    The other advantage of using `IndicatorFactory` is broadcasting:

    * Passing multiple time series objects will broadcast them to the same shape and index/columns

    ```python-repl
    &gt;&gt;&gt; price_sm2 = price_sm.copy() + 1
    &gt;&gt;&gt; price_sm2.columns = [&#39;a2&#39;, &#39;b2&#39;]

    &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
    ...     ts_names=[&#39;price_sm&#39;, &#39;price_sm2&#39;],
    ...     param_names=[&#39;p1&#39;, &#39;p2&#39;]
    ... ).from_apply_func(
    ...     lambda price_sm, price_sm2, p1, p2: price_sm * p1 + price_sm2 * p2
    ... )

    &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, 1, 2)
    &gt;&gt;&gt; print(myInd.price_sm)
                a    b
                a2   b2
    2018-01-01  1.0  5.0
    2018-01-02  2.0  4.0
    2018-01-03  3.0  3.0
    2018-01-04  4.0  2.0
    2018-01-05  5.0  1.0
    &gt;&gt;&gt; print(myInd.price_sm2)
                a    b
                a2   b2
    2018-01-01  2.0  6.0
    2018-01-02  3.0  5.0
    2018-01-03  4.0  4.0
    2018-01-04  5.0  3.0
    2018-01-05  6.0  2.0
    ```

    * Passing multiple parameters will broadcast them to arrays of the same shape

    ```python-repl
    &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, 1, 2)
    &gt;&gt;&gt; print(myInd._p1_array)
    &gt;&gt;&gt; print(myInd._p2_array)
    [1]
    [2]

    &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, 1, [2, 3])
    &gt;&gt;&gt; print(myInd._p1_array)
    &gt;&gt;&gt; print(myInd._p2_array)
    [1 1]
    [2 3]

    &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm2, [1, 2], [3, 4], param_product=True)
    &gt;&gt;&gt; print(myInd._p1_array)
    &gt;&gt;&gt; print(myInd._p2_array)
    [1 1 2 2]
    [3 4 3 4]
    ```

    This way, you can define parameter combinations of any order and shape. 
&#34;&#34;&#34;
import numpy as np
import pandas as pd
from numba import njit
from numba.typed import List
import itertools

from vectorbt.utils import checks, index_fns, reshape_fns, indexing, combine_fns
from vectorbt.utils.common import cached_property


def build_column_hierarchy(param_list, level_names, ts_columns):
    &#34;&#34;&#34;For each parameter in `param_list`, create a new column level with parameter values. 
    Combine this level with columns `ts_columns` using Cartesian product.&#34;&#34;&#34;
    checks.assert_same_shape(param_list, level_names, axis=0)
    param_indexes = [index_fns.from_values(param_list[i], name=level_names[i]) for i in range(len(param_list))]
    param_columns = None
    for param_index in param_indexes:
        if param_columns is None:
            param_columns = param_index
        else:
            param_columns = index_fns.stack(param_columns, param_index)
    if param_columns is not None:
        return index_fns.combine(param_columns, ts_columns)
    return ts_columns


def build_mapper(params, ts, new_columns, level_name):
    &#34;&#34;&#34;Build a mapper that maps parameter values in `params` to columns in `new_columns`.&#34;&#34;&#34;
    params_mapper = np.repeat(params, len(ts.vbt.columns))
    params_mapper = pd.Series(params_mapper, index=new_columns, name=level_name)
    return params_mapper


def build_tuple_mapper(mappers_list, new_columns, level_names):
    &#34;&#34;&#34;Build a tuple mapper that maps tuples of parameter values to columns in `new_columns`.&#34;&#34;&#34;
    tuple_mapper = list(zip(*list(map(lambda x: x.values, mappers_list))))
    tuple_mapper = pd.Series(tuple_mapper, index=new_columns, name=level_names)
    return tuple_mapper


def wrap_output(output, ts, new_columns):
    &#34;&#34;&#34;Wrap a NumPy array into a pandas object with meta from `ts` and `new_columns`.&#34;&#34;&#34;
    return ts.vbt.wrap_array(output, columns=new_columns)


def broadcast_ts(ts, params_len, new_columns):
    &#34;&#34;&#34;Broadcast time series `ts` to match the length of `new_columns` through tiling.&#34;&#34;&#34;
    if checks.is_series(ts) or len(new_columns) &gt; ts.shape[1]:
        return ts.vbt.wrap_array(reshape_fns.tile(ts.values, params_len, axis=1), columns=new_columns)
    else:
        return ts.vbt.wrap_array(ts, columns=new_columns)


def from_params_pipeline(ts_list, param_list, level_names, num_outputs, custom_func, *args, pass_lists=False,
                         pass_2d=True, param_product=False, broadcast_kwargs={}, return_raw=False, **kwargs):
    &#34;&#34;&#34;A pipeline for calculating an indicator, used by `IndicatorFactory`.

    Does the following:

    * Takes one or multiple time series objects in `ts_list` and broadcasts them. For example:

    ```python-repl
    &gt;&gt;&gt; sr = pd.Series([1, 2], index=[&#39;x&#39;, &#39;y&#39;])
    &gt;&gt;&gt; df = pd.DataFrame([[3, 4], [5, 6]], index=[&#39;x&#39;, &#39;y&#39;], columns=[&#39;a&#39;, &#39;b&#39;])
    &gt;&gt;&gt; ts_list = [sr, df]

    &gt;&gt;&gt; ts_list = vbt.utils.reshape_fns.broadcast(*ts_list)
    &gt;&gt;&gt; print(ts_list[0])
       a  b
    x  1  1
    y  2  2
    &gt;&gt;&gt; print(ts_list[1])
       a  b
    x  3  4
    y  5  6
    ```

    * Takes one or multiple parameters in `param_list`, converts them to NumPy arrays and 
        broadcasts them. For example:

    ```python-repl
    &gt;&gt;&gt; p1, p2, p3 = 1, [2, 3, 4], [False]
    &gt;&gt;&gt; param_list = [p1, p2, p3]

    &gt;&gt;&gt; param_list = vbt.utils.reshape_fns.broadcast(*param_list)
    &gt;&gt;&gt; print(param_list[0])
    array([1, 1, 1])
    &gt;&gt;&gt; print(param_list[1])
    array([2, 3, 4])
    &gt;&gt;&gt; print(param_list[2])
    array([False, False, False])
    ```

    * Performs calculation using `custom_func` to build output arrays (`output_list`) and 
        other objects (`other_list`, optionally). For example:

    ```python-repl
    &gt;&gt;&gt; def custom_func(ts1, ts2, p1, p2, p3, *args, **kwargs):
    ...     return np.hstack((
    ...         ts1 + ts2 + p1[0] * p2[0],
    ...         ts1 + ts2 + p1[1] * p2[1],
    ...         ts1 + ts2 + p1[2] * p2[2],
    ...     ))

    &gt;&gt;&gt; output = custom_func(*ts_list, *param_list)
    &gt;&gt;&gt; print(output)
    array([[ 6,  7,  7,  8,  8,  9],
           [ 9, 10, 10, 11, 11, 12]])
    ```

    * Creates new column hierarchy based on parameters and level names. For example:

    ```python-repl
    &gt;&gt;&gt; p1_columns = pd.Index(param_list[0], name=&#39;p1&#39;)
    &gt;&gt;&gt; p2_columns = pd.Index(param_list[1], name=&#39;p2&#39;)
    &gt;&gt;&gt; p3_columns = pd.Index(param_list[2], name=&#39;p3&#39;)
    &gt;&gt;&gt; p_columns = vbt.utils.index_fns.stack(p1_columns, p2_columns, p3_columns)
    &gt;&gt;&gt; new_columns = vbt.utils.index_fns.combine(p_columns, ts_list[0].columns)

    &gt;&gt;&gt; output_df = pd.DataFrame(output, columns=new_columns)
    &gt;&gt;&gt; print(output_df)
    p1                                         1                        
    p2             2             3             4    
    p3  False  False  False  False  False  False    
            a      b      a      b      a      b
    0       6      7      7      8      8      9
    1       9     10     10     11     11     12
    ```

    * Broadcasts objects in `ts_list` to match the shape of objects in `output_list` through tiling.
        This is done to be able to compare them and generate signals, since you cannot compare NumPy 
        arrays that have totally different shapes, such as (2, 2) and (2, 6). For example:

    ```python-repl
    &gt;&gt;&gt; new_ts_list = [
    ...     ts_list[0].vbt.tile(len(param_list[0]), as_columns=p_columns),
    ...     ts_list[1].vbt.tile(len(param_list[0]), as_columns=p_columns)
    ... ]
    &gt;&gt;&gt; print(new_ts_list[0])
    p1                                         1                        
    p2             2             3             4    
    p3  False  False  False  False  False  False     
            a      b      a      b      a      b
    0       1      1      1      1      1      1
    1       2      2      2      2      2      2
    ```

    * Builds parameter mappers that will link parameters from `param_list` to columns in 
        `ts_list` and `output_list`. This is done to enable column indexing using parameter values.

    Args:
        ts_list (list of array_like): A list of time series objects. At least one must be a pandas object.
        param_list (list of array_like): A list of parameters. Each element is either an array-like object
            or a single value of any type.
        level_names (list of str): A list of column level names corresponding to each parameter.
        num_outputs (int): The number of output arrays.
        custom_func (function): A custom calculation function. See `IndicatorFactory.from_custom_func`.
        *args: Arguments passed to the `custom_func`.
        pass_lists (bool): If `True`, arguments are passed to the `custom_func` as lists.
        pass_2d (bool): If `True`, time series arrays will be passed as two-dimensional, otherwise as is.
        param_product (bool): If `True`, builds a Cartesian product out of all parameters.
        broadcast_kwargs (dict): Keyword arguments passed to the `vectorbt.utils.reshape_fns.broadcast` 
            on time series objects.
        return_raw (bool): If `True`, returns the raw output without post-processing.
        **kwargs: Keyword arguments passed to the `custom_func`.

            Some common arguments include `return_cache` to return cache and `cache` to pass cache. 
            Those are only applicable to `custom_func` that supports it (`custom_func` created using
            `IndicatorFactory.from_apply_func` are supported by default).
    Returns:
        A list of transformed inputs (`pandas_like`), a list of generated outputs (`pandas_like`), 
        a list of parameter arrays (`numpy.ndarray`), a list of parameter mappers (`pandas.Series`),
        a list of other generated outputs that are outside of  `num_outputs`.
    &#34;&#34;&#34;
    # Check time series objects
    checks.assert_type(ts_list[0], (pd.Series, pd.DataFrame))
    if len(ts_list) &gt; 1:
        # Broadcast time series
        ts_list = reshape_fns.broadcast(*ts_list, **broadcast_kwargs, writeable=True)
    # Check level names
    checks.assert_type(level_names, (list, tuple))
    checks.assert_same_len(param_list, level_names)
    for ts in ts_list:
        # Every time series object should be free of the specified level names in its columns
        for level_name in level_names:
            checks.assert_level_not_exists(ts, level_name)
    # Convert params to 1-dim arrays
    param_list = list(map(reshape_fns.to_1d, param_list))
    if len(param_list) &gt; 1:
        if param_product:
            # Make Cartesian product out of all params
            param_list = list(map(reshape_fns.to_1d, param_list))
            param_list = list(zip(*list(itertools.product(*param_list))))
            param_list = list(map(np.asarray, param_list))
        else:
            # Broadcast such that each array has the same length
            param_list = reshape_fns.broadcast(*param_list, writeable=True)
    # Perform main calculation
    if pass_2d:
        array_list = tuple(map(lambda x: reshape_fns.to_2d(np.asarray(x)), ts_list))
    else:
        array_list = tuple(map(lambda x: np.asarray(x), ts_list))
    if pass_lists:
        output_list = custom_func(array_list, param_list, *args, **kwargs)
    else:
        output_list = custom_func(*array_list, *param_list, *args, **kwargs)
    if return_raw or kwargs.get(&#39;return_cache&#39;, False):
        return output_list  # return raw cache outputs
    if not isinstance(output_list, (tuple, list, List)):
        output_list = [output_list]
    else:
        output_list = list(output_list)
    # Other outputs should be returned without post-processing (for example cache_dict)
    if len(output_list) &gt; num_outputs:
        other_list = output_list[num_outputs:]
    else:
        other_list = []
    # Process only the num_outputs outputs
    output_list = output_list[:num_outputs]
    if len(param_list) &gt; 0:
        # Build new column levels on top of time series levels
        new_columns = build_column_hierarchy(param_list, level_names, ts_list[0].vbt.columns)
        # Wrap into new pandas objects both time series and output objects
        new_ts_list = list(map(lambda x: broadcast_ts(x, param_list[0].shape[0], new_columns), ts_list))
        # Build mappers to easily map between parameters and columns
        mapper_list = [build_mapper(x, ts_list[0], new_columns, level_names[i]) for i, x in enumerate(param_list)]
    else:
        # Some indicators don&#39;t have any params
        new_columns = ts_list[0].vbt.columns
        new_ts_list = list(ts_list)
        mapper_list = []
    output_list = list(map(lambda x: wrap_output(x, ts_list[0], new_columns), output_list))
    if len(mapper_list) &gt; 1:
        # Tuple object is a mapper that accepts tuples of parameters
        tuple_mapper = build_tuple_mapper(mapper_list, new_columns, tuple(level_names))
        mapper_list.append(tuple_mapper)
    return new_ts_list, output_list, param_list, mapper_list, other_list


def perform_init_checks(ts_list, output_list, param_list, mapper_list, name):
    &#34;&#34;&#34;Perform checks on objects created by running or slicing an indicator.&#34;&#34;&#34;
    for ts in ts_list:
        checks.assert_type(ts, (pd.Series, pd.DataFrame))
    for i in range(1, len(ts_list) + len(output_list)):
        checks.assert_same_meta((ts_list + output_list)[i-1], (ts_list + output_list)[i])
    for i in range(1, len(param_list)):
        checks.assert_same_shape(param_list[i-1], param_list[i])
    for mapper in mapper_list:
        checks.assert_type(mapper, pd.Series)
        checks.assert_same_index(reshape_fns.to_2d(ts_list[0]).iloc[0, :], mapper)
    checks.assert_type(name, str)

def compare(obj, other, compare_func, multiple=False, name=None, as_columns=None, **kwargs):
    &#34;&#34;&#34;Compares `obj` to `other` to generate signals.
    
    Both will be broadcasted together. Set `multiple` to `True` to compare with multiple arguments. In this case,
    a new column level will be created with the name `name`.
    
    See `vectorbt.utils.accessors.Base_Accessor.combine_with`.&#34;&#34;&#34;
    if multiple:
        if as_columns is None:
            as_columns = index_fns.from_values(other, name=name)
        return obj.vbt.combine_with_multiple(other, combine_func=compare_func, as_columns=as_columns, concat=True, **kwargs)
    return obj.vbt.combine_with(other, combine_func=compare_func, **kwargs)

class IndicatorFactory():
    def __init__(self,
                 ts_names=[&#39;ts&#39;],
                 param_names=[&#39;param&#39;],
                 output_names=[&#39;output&#39;],
                 name=&#39;custom&#39;,
                 custom_properties={}):
        &#34;&#34;&#34;A factory for creating new indicators.

        Args:
            ts_names (list of str): A list of names of input time series objects.
            param_names (list of str): A list of names of parameters.
            output_names (list of str): A list of names of outputs time series objects.
            name (str): A short name of the indicator.
            custom_properties (dict): A dictionary with user-defined functions that will be
                bound to the indicator class and wrapped with `@cached_property`.
        &#34;&#34;&#34;
        self.ts_names = ts_names
        self.param_names = param_names
        self.output_names = output_names
        self.name = name
        self.custom_properties = custom_properties

    def from_custom_func(self, custom_func, **pipeline_kwargs):
        &#34;&#34;&#34;Build indicator class around a custom calculation function.

        !!! note
            Time series passed to `apply_func` will be 2-dimensional NumPy arrays.

            In contrast to `IndicatorFactory.from_apply_func`, it&#39;s up to you to handle caching
            and concatenate columns for each parameter (for example, by using 
            `vectorbt.utils.combine_fns.apply_and_concat_one`). Also, you must ensure that each output 
            array has an appropriate number of columns, which is the number of columns in input time 
            series multiplied by the number of parameter values.

        Args:
            custom_func (function): A function that takes broadcasted time series corresponding 
                to `ts_names`, broadcasted parameter arrays corresponding to `param_names`, and other 
                arguments and keyword arguments, and returns outputs corresponding to `output_names` 
                and other objects that are then returned with the indicator class instance.
                Can be Numba-compiled.
            **pipeline_kwargs: Default keyword arguments passed to `from_params_pipeline`.
        Returns:
            `CustomIndicator`, and optionally other objects that are returned by `custom_func`
            and exceed `output_names`.
        Example:
            The following example does the same as the example in `IndicatorFactory.from_apply_func`.

            ```python-repl
            &gt;&gt;&gt; @njit
            &gt;&gt;&gt; def apply_func_nb(i, ts1, ts2, p1, p2, arg1):
            ...     return ts1 * p1[i] + arg1, ts2 * p2[i] + arg1

            &gt;&gt;&gt; @njit
            ... def custom_func(ts1, ts2, p1, p2, *args):
            ...     return vbt.utils.combine_fns.apply_and_concat_multiple_nb(
            ...         len(p1), apply_func_nb, ts1, ts2, p1, p2, *args)

            &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
            ...     ts_names=[&#39;ts1&#39;, &#39;ts2&#39;],
            ...     param_names=[&#39;p1&#39;, &#39;p2&#39;],
            ...     output_names=[&#39;o1&#39;, &#39;o2&#39;]
            ... ).from_custom_func(custom_func)

            &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
            &gt;&gt;&gt; print(myInd.o1)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  101.0  105.0  102.0  110.0
            2018-01-02  102.0  104.0  104.0  108.0
            2018-01-03  103.0  103.0  106.0  106.0
            2018-01-04  104.0  102.0  108.0  104.0
            2018-01-05  105.0  101.0  110.0  102.0
            &gt;&gt;&gt; print(myInd.o2)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  106.0  130.0  108.0  140.0
            2018-01-02  112.0  124.0  116.0  132.0
            2018-01-03  118.0  118.0  124.0  124.0
            2018-01-04  124.0  112.0  132.0  116.0
            2018-01-05  130.0  106.0  140.0  108.0
            ```
        &#34;&#34;&#34;

        CustomIndicator = type(&#39;CustomIndicator&#39;, (), {})
        ts_names = self.ts_names
        param_names = self.param_names
        output_names = self.output_names
        name = self.name
        custom_properties = self.custom_properties

        # For name and each input and output, create read-only properties
        prop = property(lambda self: self._name)
        prop.__doc__ = f&#34;&#34;&#34;Name of the indicator (read-only).&#34;&#34;&#34;
        setattr(CustomIndicator, &#39;name&#39;, prop)

        for ts_name in ts_names:
            prop = property(lambda self, ts_name=ts_name: getattr(self, &#39;_&#39; + ts_name))
            prop.__doc__ = f&#34;&#34;&#34;Input time series (read-only).&#34;&#34;&#34;
            setattr(CustomIndicator, ts_name, prop)

        for output_name in output_names:
            prop = property(lambda self, output_name=output_name: getattr(self, &#39;_&#39; + output_name))
            prop.__doc__ = f&#34;&#34;&#34;Output time series (read-only).&#34;&#34;&#34;
            setattr(CustomIndicator, output_name, prop)

        for prop in custom_properties.values():
            if prop.__doc__ is None:
                prop.__doc__ = f&#34;&#34;&#34;Custom property.&#34;&#34;&#34;

        # Add __init__ method
        def __init__(self, ts_list, output_list, param_list, mapper_list, name):
            perform_init_checks(ts_list, output_list, param_list, mapper_list, name)

            for i, ts_name in enumerate(ts_names):
                setattr(self, f&#39;_{ts_name}&#39;, ts_list[i])
            for i, output_name in enumerate(output_names):
                setattr(self, f&#39;_{output_name}&#39;, output_list[i])
            for i, param_name in enumerate(param_names):
                setattr(self, f&#39;_{param_name}_array&#39;, param_list[i])
                setattr(self, f&#39;_{param_name}_mapper&#39;, mapper_list[i])
            if len(param_names) &gt; 1:
                setattr(self, &#39;_tuple_mapper&#39;, mapper_list[-1])
            setattr(self, &#39;_name&#39;, name)

        setattr(CustomIndicator, &#39;__init__&#39;, __init__)

        # Add from_params method
        @classmethod
        def from_params(cls, *args, name=name.lower(), return_raw=False, pipeline_kwargs=pipeline_kwargs, **kwargs):
            level_names = tuple([name + &#39;_&#39; + param_name for param_name in param_names])
            args = list(args)
            ts_list = args[:len(ts_names)]
            param_list = args[len(ts_names):len(ts_names)+len(param_names)]
            new_args = args[len(ts_names)+len(param_names):]
            kwargs = {**pipeline_kwargs, **kwargs} # overwirte default pipeline kwargs
            results = from_params_pipeline(
                ts_list, param_list, level_names, len(output_names),
                custom_func, *new_args, return_raw=return_raw, **kwargs)
            if return_raw or kwargs.get(&#39;return_cache&#39;, False):
                return results
            new_ts_list, output_list, new_param_list, mapper_list, other_list = results
            obj = cls(new_ts_list, output_list, new_param_list, mapper_list, name)
            if len(other_list) &gt; 0:
                return (obj,) + other_list
            return obj

        setattr(CustomIndicator, &#39;from_params&#39;, from_params)

        # Add indexing methods
        def indexing_func(obj, pd_indexing_func):
            ts_list = []
            for ts_name in ts_names:
                ts_list.append(pd_indexing_func(getattr(obj, ts_name)))
            output_list = []
            for output_name in output_names:
                output_list.append(pd_indexing_func(getattr(obj, output_name)))
            param_list = []
            for param_name in param_names:
                # TODO: adapt params array according to the indexing operation
                param_list.append(getattr(obj, f&#39;_{param_name}_array&#39;))
            mapper_list = []
            for param_name in param_names:
                mapper_list.append(indexing.mapper_indexing_func(
                    getattr(obj, f&#39;_{param_name}_mapper&#39;),
                    getattr(obj, ts_names[0]), pd_indexing_func))
            if len(param_names) &gt; 1:
                mapper_list.append(indexing.mapper_indexing_func(
                    obj._tuple_mapper, getattr(obj, ts_names[0]), pd_indexing_func))

            return obj.__class__(ts_list, output_list, param_list, mapper_list, obj.name)

        CustomIndicator = indexing.add_pd_indexing(indexing_func)(CustomIndicator)
        for i, param_name in enumerate(param_names):
            CustomIndicator = indexing.add_param_indexing(param_name, indexing_func)(CustomIndicator)
        if len(param_names) &gt; 1:
            CustomIndicator = indexing.add_param_indexing(&#39;tuple&#39;, indexing_func)(CustomIndicator)

        # Add user-defined properties
        for prop_name, prop in custom_properties.items():
            prop.__name__ = prop_name
            if not isinstance(prop, property):
                prop = cached_property(prop)
            setattr(CustomIndicator, prop_name, prop)

        # Add comparison methods for all inputs, outputs, and user-defined properties
        comparison_attrs = set(ts_names + output_names + list(custom_properties.keys()))
        for attr in comparison_attrs:
            def assign_comparison_method(func_name, compare_func, attr=attr):
                def comparison_method(self, other, crossover=False, wait=0, name=None, **kwargs):
                    if isinstance(other, self.__class__):
                        other = getattr(other, attr)
                    if name is None:
                        if attr == self.name:
                            name = f&#39;{self.name}_{func_name}&#39;
                        else:
                            name = f&#39;{self.name}_{attr}_{func_name}&#39;
                    result = compare(getattr(self, attr), other, compare_func, name=name, **kwargs)
                    if crossover:
                        return result.vbt.signals.nst(wait+1, after_false=True)
                    return result
                comparison_method.__qualname__ = f&#39;{CustomIndicator.__name__}.{attr}_{func_name}&#39;
                comparison_method.__doc__ = f&#34;&#34;&#34;Return `True` for each element where `{attr}` is {func_name} `other`. 

                Set `crossover` to `True` to return the first `True` after crossover. Specify `wait` to return 
                `True` only when `{attr}` is {func_name} for a number of time steps in a row after crossover.

                See `vectorbt.indicators.factory.compare`.&#34;&#34;&#34;
                setattr(CustomIndicator, f&#39;{attr}_{func_name}&#39;, comparison_method)

            assign_comparison_method(&#39;above&#39;, np.greater)
            assign_comparison_method(&#39;below&#39;, np.less)
            assign_comparison_method(&#39;equal&#39;, np.equal)

        return CustomIndicator

    def from_apply_func(self, apply_func, caching_func=None, **kwargs):
        &#34;&#34;&#34;Build indicator class around a custom apply function.

        In contrast to `IndicatorFactory.from_custom_func`, this method handles a lot of things for you,
        such as caching, parameter selection, and concatenation. All you have to do is to write `apply_func`
        that accepts a selection of parameters (single values as opposed to multiple values in 
        `IndicatorFactory.from_custom_func`) and does the calculation. It then automatically concatenates
        the results into a single array per output.

        While this approach is much more simpler, it is also less flexible, since you can only work with 
        one parameter selection at a time, and can&#39;t view all parameters.

        !!! note
            Time series passed to `apply_func` will be 2-dimensional NumPy arrays.

            If `apply_func` is a Numba-compiled function: 

            * All inputs are automatically converted to NumPy arrays
            * Each argument in `*args` must be of a Numba-compatible type
            * You cannot pass keyword arguments
            * Your outputs must be arrays of the same shape, data type and data order

        Args:
            apply_func (function): A function that takes broadcasted time series arrays corresponding 
                to `ts_names`, single parameter selection corresponding to `param_names`, and other 
                arguments and keyword arguments, and returns outputs corresponding to `output_names`.
                Can be Numba-compiled.
            caching_func (function): A caching function to preprocess data beforehand.
                All returned objects will be passed as additional arguments to `apply_func`.
            **kwargs: Keyword arguments passed to `IndicatorFactory.from_custom_func`.
        Returns:
            CustomIndicator
        Example:
            ```python-repl
            &gt;&gt;&gt; @njit
            ... def apply_func_nb(ts1, ts2, p1, p2, arg1):
            ...     return ts1 * p1 + arg1, ts2 * p2 + arg1

            &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
            ...     ts_names=[&#39;ts1&#39;, &#39;ts2&#39;],
            ...     param_names=[&#39;p1&#39;, &#39;p2&#39;],
            ...     output_names=[&#39;o1&#39;, &#39;o2&#39;]
            ... ).from_apply_func(apply_func_nb)

            &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
            &gt;&gt;&gt; print(myInd.o1)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  101.0  105.0  102.0  110.0
            2018-01-02  102.0  104.0  104.0  108.0
            2018-01-03  103.0  103.0  106.0  106.0
            2018-01-04  104.0  102.0  108.0  104.0
            2018-01-05  105.0  101.0  110.0  102.0
            &gt;&gt;&gt; print(myInd.o2)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  106.0  130.0  108.0  140.0
            2018-01-02  112.0  124.0  116.0  132.0
            2018-01-03  118.0  118.0  124.0  124.0
            2018-01-04  124.0  112.0  132.0  116.0
            2018-01-05  130.0  106.0  140.0  108.0
            ```
        &#34;&#34;&#34;
        output_names = self.output_names

        num_outputs = len(output_names)

        if checks.is_numba_func(apply_func):
            if num_outputs &gt; 1:
                apply_and_concat_func = combine_fns.apply_and_concat_multiple_nb
            else:
                apply_and_concat_func = combine_fns.apply_and_concat_one_nb

            @njit
            def select_params_func_nb(i, apply_func, ts_arr_list, param_tuples, *args):
                # Select the next tuple of parameters
                return apply_func(*ts_arr_list, *param_tuples[i], *args)

            def custom_func(ts_arr_list, param_list, *args, return_cache=False, cache=None):
                # avoid deprecation warnings
                ts_arr_list = tuple(map(np.asarray, ts_arr_list))
                typed_param_tuples = List()
                for param_tuple in list(zip(*param_list)):
                    typed_param_tuples.append(param_tuple)

                # Caching
                if cache is None and caching_func is not None:
                    cache = caching_func(*ts_arr_list, *param_list, *args)
                if return_cache:
                    return cache
                if cache is None:
                    cache = ()
                if not isinstance(cache, (tuple, list, List)):
                    cache = (cache,)

                return apply_and_concat_func(
                    param_list[0].shape[0],
                    select_params_func_nb,
                    apply_func,
                    ts_arr_list,
                    typed_param_tuples,
                    *args,
                    *cache)
        else:
            if num_outputs &gt; 1:
                apply_and_concat_func = combine_fns.apply_and_concat_multiple
            else:
                apply_and_concat_func = combine_fns.apply_and_concat_one

            def select_params_func(i, apply_func, ts_arr_list, param_list, *args, **kwargs):
                    # Select the next tuple of parameters
                param_is = list(map(lambda x: x[i], param_list))
                return apply_func(*ts_arr_list, *param_is, *args, **kwargs)

            def custom_func(ts_arr_list, param_list, *args, return_cache=False, cache=None, **kwargs):
                ts_arr_list = tuple(map(np.asarray, ts_arr_list))
                # Caching
                if cache is None and caching_func is not None:
                    cache = caching_func(*ts_arr_list, *param_list, *args, **kwargs)
                if return_cache:
                    return cache
                if cache is None:
                    cache = ()
                if not isinstance(cache, (tuple, list, List)):
                    cache = (cache,)

                return apply_and_concat_func(
                    param_list[0].shape[0],
                    select_params_func,
                    apply_func,
                    ts_arr_list,
                    param_list,
                    *args,
                    *cache,
                    **kwargs)

        return self.from_custom_func(custom_func, pass_lists=True, **kwargs)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="vectorbt.indicators.factory.broadcast_ts"><code class="name flex">
<span>def <span class="ident">broadcast_ts</span></span>(<span>ts, params_len, new_columns)</span>
</code></dt>
<dd>
<div class="desc"><p>Broadcast time series <code>ts</code> to match the length of <code>new_columns</code> through tiling.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def broadcast_ts(ts, params_len, new_columns):
    &#34;&#34;&#34;Broadcast time series `ts` to match the length of `new_columns` through tiling.&#34;&#34;&#34;
    if checks.is_series(ts) or len(new_columns) &gt; ts.shape[1]:
        return ts.vbt.wrap_array(reshape_fns.tile(ts.values, params_len, axis=1), columns=new_columns)
    else:
        return ts.vbt.wrap_array(ts, columns=new_columns)</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.build_column_hierarchy"><code class="name flex">
<span>def <span class="ident">build_column_hierarchy</span></span>(<span>param_list, level_names, ts_columns)</span>
</code></dt>
<dd>
<div class="desc"><p>For each parameter in <code>param_list</code>, create a new column level with parameter values.
Combine this level with columns <code>ts_columns</code> using Cartesian product.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_column_hierarchy(param_list, level_names, ts_columns):
    &#34;&#34;&#34;For each parameter in `param_list`, create a new column level with parameter values. 
    Combine this level with columns `ts_columns` using Cartesian product.&#34;&#34;&#34;
    checks.assert_same_shape(param_list, level_names, axis=0)
    param_indexes = [index_fns.from_values(param_list[i], name=level_names[i]) for i in range(len(param_list))]
    param_columns = None
    for param_index in param_indexes:
        if param_columns is None:
            param_columns = param_index
        else:
            param_columns = index_fns.stack(param_columns, param_index)
    if param_columns is not None:
        return index_fns.combine(param_columns, ts_columns)
    return ts_columns</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.build_mapper"><code class="name flex">
<span>def <span class="ident">build_mapper</span></span>(<span>params, ts, new_columns, level_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Build a mapper that maps parameter values in <code>params</code> to columns in <code>new_columns</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_mapper(params, ts, new_columns, level_name):
    &#34;&#34;&#34;Build a mapper that maps parameter values in `params` to columns in `new_columns`.&#34;&#34;&#34;
    params_mapper = np.repeat(params, len(ts.vbt.columns))
    params_mapper = pd.Series(params_mapper, index=new_columns, name=level_name)
    return params_mapper</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.build_tuple_mapper"><code class="name flex">
<span>def <span class="ident">build_tuple_mapper</span></span>(<span>mappers_list, new_columns, level_names)</span>
</code></dt>
<dd>
<div class="desc"><p>Build a tuple mapper that maps tuples of parameter values to columns in <code>new_columns</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_tuple_mapper(mappers_list, new_columns, level_names):
    &#34;&#34;&#34;Build a tuple mapper that maps tuples of parameter values to columns in `new_columns`.&#34;&#34;&#34;
    tuple_mapper = list(zip(*list(map(lambda x: x.values, mappers_list))))
    tuple_mapper = pd.Series(tuple_mapper, index=new_columns, name=level_names)
    return tuple_mapper</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.compare"><code class="name flex">
<span>def <span class="ident">compare</span></span>(<span>obj, other, compare_func, multiple=False, name=None, as_columns=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Compares <code>obj</code> to <code>other</code> to generate signals.</p>
<p>Both will be broadcasted together. Set <code>multiple</code> to <code>True</code> to compare with multiple arguments. In this case,
a new column level will be created with the name <code>name</code>.</p>
<p>See <code><a title="vectorbt.utils.accessors.Base_Accessor.combine_with" href="../utils/accessors.html#vectorbt.utils.accessors.Base_Accessor.combine_with">Base_Accessor.combine_with()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare(obj, other, compare_func, multiple=False, name=None, as_columns=None, **kwargs):
    &#34;&#34;&#34;Compares `obj` to `other` to generate signals.
    
    Both will be broadcasted together. Set `multiple` to `True` to compare with multiple arguments. In this case,
    a new column level will be created with the name `name`.
    
    See `vectorbt.utils.accessors.Base_Accessor.combine_with`.&#34;&#34;&#34;
    if multiple:
        if as_columns is None:
            as_columns = index_fns.from_values(other, name=name)
        return obj.vbt.combine_with_multiple(other, combine_func=compare_func, as_columns=as_columns, concat=True, **kwargs)
    return obj.vbt.combine_with(other, combine_func=compare_func, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.from_params_pipeline"><code class="name flex">
<span>def <span class="ident">from_params_pipeline</span></span>(<span>ts_list, param_list, level_names, num_outputs, custom_func, *args, pass_lists=False, pass_2d=True, param_product=False, broadcast_kwargs={}, return_raw=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A pipeline for calculating an indicator, used by <code><a title="vectorbt.indicators.factory.IndicatorFactory" href="#vectorbt.indicators.factory.IndicatorFactory">IndicatorFactory</a></code>.</p>
<p>Does the following:</p>
<ul>
<li>Takes one or multiple time series objects in <code>ts_list</code> and broadcasts them. For example:</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; sr = pd.Series([1, 2], index=['x', 'y'])
&gt;&gt;&gt; df = pd.DataFrame([[3, 4], [5, 6]], index=['x', 'y'], columns=['a', 'b'])
&gt;&gt;&gt; ts_list = [sr, df]

&gt;&gt;&gt; ts_list = vbt.utils.reshape_fns.broadcast(*ts_list)
&gt;&gt;&gt; print(ts_list[0])
   a  b
x  1  1
y  2  2
&gt;&gt;&gt; print(ts_list[1])
   a  b
x  3  4
y  5  6
</code></pre>
<ul>
<li>Takes one or multiple parameters in <code>param_list</code>, converts them to NumPy arrays and
broadcasts them. For example:</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; p1, p2, p3 = 1, [2, 3, 4], [False]
&gt;&gt;&gt; param_list = [p1, p2, p3]

&gt;&gt;&gt; param_list = vbt.utils.reshape_fns.broadcast(*param_list)
&gt;&gt;&gt; print(param_list[0])
array([1, 1, 1])
&gt;&gt;&gt; print(param_list[1])
array([2, 3, 4])
&gt;&gt;&gt; print(param_list[2])
array([False, False, False])
</code></pre>
<ul>
<li>Performs calculation using <code>custom_func</code> to build output arrays (<code>output_list</code>) and
other objects (<code>other_list</code>, optionally). For example:</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; def custom_func(ts1, ts2, p1, p2, p3, *args, **kwargs):
...     return np.hstack((
...         ts1 + ts2 + p1[0] * p2[0],
...         ts1 + ts2 + p1[1] * p2[1],
...         ts1 + ts2 + p1[2] * p2[2],
...     ))

&gt;&gt;&gt; output = custom_func(*ts_list, *param_list)
&gt;&gt;&gt; print(output)
array([[ 6,  7,  7,  8,  8,  9],
       [ 9, 10, 10, 11, 11, 12]])
</code></pre>
<ul>
<li>Creates new column hierarchy based on parameters and level names. For example:</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; p1_columns = pd.Index(param_list[0], name='p1')
&gt;&gt;&gt; p2_columns = pd.Index(param_list[1], name='p2')
&gt;&gt;&gt; p3_columns = pd.Index(param_list[2], name='p3')
&gt;&gt;&gt; p_columns = vbt.utils.index_fns.stack(p1_columns, p2_columns, p3_columns)
&gt;&gt;&gt; new_columns = vbt.utils.index_fns.combine(p_columns, ts_list[0].columns)

&gt;&gt;&gt; output_df = pd.DataFrame(output, columns=new_columns)
&gt;&gt;&gt; print(output_df)
p1                                         1                        
p2             2             3             4    
p3  False  False  False  False  False  False    
        a      b      a      b      a      b
0       6      7      7      8      8      9
1       9     10     10     11     11     12
</code></pre>
<ul>
<li>Broadcasts objects in <code>ts_list</code> to match the shape of objects in <code>output_list</code> through tiling.
This is done to be able to compare them and generate signals, since you cannot compare NumPy
arrays that have totally different shapes, such as (2, 2) and (2, 6). For example:</li>
</ul>
<pre><code class="python-repl">&gt;&gt;&gt; new_ts_list = [
...     ts_list[0].vbt.tile(len(param_list[0]), as_columns=p_columns),
...     ts_list[1].vbt.tile(len(param_list[0]), as_columns=p_columns)
... ]
&gt;&gt;&gt; print(new_ts_list[0])
p1                                         1                        
p2             2             3             4    
p3  False  False  False  False  False  False     
        a      b      a      b      a      b
0       1      1      1      1      1      1
1       2      2      2      2      2      2
</code></pre>
<ul>
<li>Builds parameter mappers that will link parameters from <code>param_list</code> to columns in
<code>ts_list</code> and <code>output_list</code>. This is done to enable column indexing using parameter values.</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ts_list</code></strong> :&ensp;<code>list</code> of <code>array_like</code></dt>
<dd>A list of time series objects. At least one must be a pandas object.</dd>
<dt><strong><code>param_list</code></strong> :&ensp;<code>list</code> of <code>array_like</code></dt>
<dd>A list of parameters. Each element is either an array-like object
or a single value of any type.</dd>
<dt><strong><code>level_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>A list of column level names corresponding to each parameter.</dd>
<dt><strong><code>num_outputs</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of output arrays.</dd>
<dt><strong><code>custom_func</code></strong> :&ensp;<code>function</code></dt>
<dd>A custom calculation function. See <code><a title="vectorbt.indicators.factory.IndicatorFactory.from_custom_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_custom_func">IndicatorFactory.from_custom_func()</a></code>.</dd>
<dt><strong><code>*args</code></strong></dt>
<dd>Arguments passed to the <code>custom_func</code>.</dd>
<dt><strong><code>pass_lists</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, arguments are passed to the <code>custom_func</code> as lists.</dd>
<dt><strong><code>pass_2d</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, time series arrays will be passed as two-dimensional, otherwise as is.</dd>
<dt><strong><code>param_product</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, builds a Cartesian product out of all parameters.</dd>
<dt><strong><code>broadcast_kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to the <code><a title="vectorbt.utils.reshape_fns.broadcast" href="../utils/reshape_fns.html#vectorbt.utils.reshape_fns.broadcast">broadcast()</a></code>
on time series objects.</dd>
<dt><strong><code>return_raw</code></strong> :&ensp;<code>bool</code></dt>
<dd>If <code>True</code>, returns the raw output without post-processing.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>
<p>Keyword arguments passed to the <code>custom_func</code>.</p>
<p>Some common arguments include <code>return_cache</code> to return cache and <code>cache</code> to pass cache.
Those are only applicable to <code>custom_func</code> that supports it (<code>custom_func</code> created using
<code><a title="vectorbt.indicators.factory.IndicatorFactory.from_apply_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_apply_func">IndicatorFactory.from_apply_func()</a></code> are supported by default).</p>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of transformed inputs (<code>pandas_like</code>), a list of generated outputs (<code>pandas_like</code>),
a list of parameter arrays (<code>numpy.ndarray</code>), a list of parameter mappers (<code>pandas.Series</code>),
a list of other generated outputs that are outside of
<code>num_outputs</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_params_pipeline(ts_list, param_list, level_names, num_outputs, custom_func, *args, pass_lists=False,
                         pass_2d=True, param_product=False, broadcast_kwargs={}, return_raw=False, **kwargs):
    &#34;&#34;&#34;A pipeline for calculating an indicator, used by `IndicatorFactory`.

    Does the following:

    * Takes one or multiple time series objects in `ts_list` and broadcasts them. For example:

    ```python-repl
    &gt;&gt;&gt; sr = pd.Series([1, 2], index=[&#39;x&#39;, &#39;y&#39;])
    &gt;&gt;&gt; df = pd.DataFrame([[3, 4], [5, 6]], index=[&#39;x&#39;, &#39;y&#39;], columns=[&#39;a&#39;, &#39;b&#39;])
    &gt;&gt;&gt; ts_list = [sr, df]

    &gt;&gt;&gt; ts_list = vbt.utils.reshape_fns.broadcast(*ts_list)
    &gt;&gt;&gt; print(ts_list[0])
       a  b
    x  1  1
    y  2  2
    &gt;&gt;&gt; print(ts_list[1])
       a  b
    x  3  4
    y  5  6
    ```

    * Takes one or multiple parameters in `param_list`, converts them to NumPy arrays and 
        broadcasts them. For example:

    ```python-repl
    &gt;&gt;&gt; p1, p2, p3 = 1, [2, 3, 4], [False]
    &gt;&gt;&gt; param_list = [p1, p2, p3]

    &gt;&gt;&gt; param_list = vbt.utils.reshape_fns.broadcast(*param_list)
    &gt;&gt;&gt; print(param_list[0])
    array([1, 1, 1])
    &gt;&gt;&gt; print(param_list[1])
    array([2, 3, 4])
    &gt;&gt;&gt; print(param_list[2])
    array([False, False, False])
    ```

    * Performs calculation using `custom_func` to build output arrays (`output_list`) and 
        other objects (`other_list`, optionally). For example:

    ```python-repl
    &gt;&gt;&gt; def custom_func(ts1, ts2, p1, p2, p3, *args, **kwargs):
    ...     return np.hstack((
    ...         ts1 + ts2 + p1[0] * p2[0],
    ...         ts1 + ts2 + p1[1] * p2[1],
    ...         ts1 + ts2 + p1[2] * p2[2],
    ...     ))

    &gt;&gt;&gt; output = custom_func(*ts_list, *param_list)
    &gt;&gt;&gt; print(output)
    array([[ 6,  7,  7,  8,  8,  9],
           [ 9, 10, 10, 11, 11, 12]])
    ```

    * Creates new column hierarchy based on parameters and level names. For example:

    ```python-repl
    &gt;&gt;&gt; p1_columns = pd.Index(param_list[0], name=&#39;p1&#39;)
    &gt;&gt;&gt; p2_columns = pd.Index(param_list[1], name=&#39;p2&#39;)
    &gt;&gt;&gt; p3_columns = pd.Index(param_list[2], name=&#39;p3&#39;)
    &gt;&gt;&gt; p_columns = vbt.utils.index_fns.stack(p1_columns, p2_columns, p3_columns)
    &gt;&gt;&gt; new_columns = vbt.utils.index_fns.combine(p_columns, ts_list[0].columns)

    &gt;&gt;&gt; output_df = pd.DataFrame(output, columns=new_columns)
    &gt;&gt;&gt; print(output_df)
    p1                                         1                        
    p2             2             3             4    
    p3  False  False  False  False  False  False    
            a      b      a      b      a      b
    0       6      7      7      8      8      9
    1       9     10     10     11     11     12
    ```

    * Broadcasts objects in `ts_list` to match the shape of objects in `output_list` through tiling.
        This is done to be able to compare them and generate signals, since you cannot compare NumPy 
        arrays that have totally different shapes, such as (2, 2) and (2, 6). For example:

    ```python-repl
    &gt;&gt;&gt; new_ts_list = [
    ...     ts_list[0].vbt.tile(len(param_list[0]), as_columns=p_columns),
    ...     ts_list[1].vbt.tile(len(param_list[0]), as_columns=p_columns)
    ... ]
    &gt;&gt;&gt; print(new_ts_list[0])
    p1                                         1                        
    p2             2             3             4    
    p3  False  False  False  False  False  False     
            a      b      a      b      a      b
    0       1      1      1      1      1      1
    1       2      2      2      2      2      2
    ```

    * Builds parameter mappers that will link parameters from `param_list` to columns in 
        `ts_list` and `output_list`. This is done to enable column indexing using parameter values.

    Args:
        ts_list (list of array_like): A list of time series objects. At least one must be a pandas object.
        param_list (list of array_like): A list of parameters. Each element is either an array-like object
            or a single value of any type.
        level_names (list of str): A list of column level names corresponding to each parameter.
        num_outputs (int): The number of output arrays.
        custom_func (function): A custom calculation function. See `IndicatorFactory.from_custom_func`.
        *args: Arguments passed to the `custom_func`.
        pass_lists (bool): If `True`, arguments are passed to the `custom_func` as lists.
        pass_2d (bool): If `True`, time series arrays will be passed as two-dimensional, otherwise as is.
        param_product (bool): If `True`, builds a Cartesian product out of all parameters.
        broadcast_kwargs (dict): Keyword arguments passed to the `vectorbt.utils.reshape_fns.broadcast` 
            on time series objects.
        return_raw (bool): If `True`, returns the raw output without post-processing.
        **kwargs: Keyword arguments passed to the `custom_func`.

            Some common arguments include `return_cache` to return cache and `cache` to pass cache. 
            Those are only applicable to `custom_func` that supports it (`custom_func` created using
            `IndicatorFactory.from_apply_func` are supported by default).
    Returns:
        A list of transformed inputs (`pandas_like`), a list of generated outputs (`pandas_like`), 
        a list of parameter arrays (`numpy.ndarray`), a list of parameter mappers (`pandas.Series`),
        a list of other generated outputs that are outside of  `num_outputs`.
    &#34;&#34;&#34;
    # Check time series objects
    checks.assert_type(ts_list[0], (pd.Series, pd.DataFrame))
    if len(ts_list) &gt; 1:
        # Broadcast time series
        ts_list = reshape_fns.broadcast(*ts_list, **broadcast_kwargs, writeable=True)
    # Check level names
    checks.assert_type(level_names, (list, tuple))
    checks.assert_same_len(param_list, level_names)
    for ts in ts_list:
        # Every time series object should be free of the specified level names in its columns
        for level_name in level_names:
            checks.assert_level_not_exists(ts, level_name)
    # Convert params to 1-dim arrays
    param_list = list(map(reshape_fns.to_1d, param_list))
    if len(param_list) &gt; 1:
        if param_product:
            # Make Cartesian product out of all params
            param_list = list(map(reshape_fns.to_1d, param_list))
            param_list = list(zip(*list(itertools.product(*param_list))))
            param_list = list(map(np.asarray, param_list))
        else:
            # Broadcast such that each array has the same length
            param_list = reshape_fns.broadcast(*param_list, writeable=True)
    # Perform main calculation
    if pass_2d:
        array_list = tuple(map(lambda x: reshape_fns.to_2d(np.asarray(x)), ts_list))
    else:
        array_list = tuple(map(lambda x: np.asarray(x), ts_list))
    if pass_lists:
        output_list = custom_func(array_list, param_list, *args, **kwargs)
    else:
        output_list = custom_func(*array_list, *param_list, *args, **kwargs)
    if return_raw or kwargs.get(&#39;return_cache&#39;, False):
        return output_list  # return raw cache outputs
    if not isinstance(output_list, (tuple, list, List)):
        output_list = [output_list]
    else:
        output_list = list(output_list)
    # Other outputs should be returned without post-processing (for example cache_dict)
    if len(output_list) &gt; num_outputs:
        other_list = output_list[num_outputs:]
    else:
        other_list = []
    # Process only the num_outputs outputs
    output_list = output_list[:num_outputs]
    if len(param_list) &gt; 0:
        # Build new column levels on top of time series levels
        new_columns = build_column_hierarchy(param_list, level_names, ts_list[0].vbt.columns)
        # Wrap into new pandas objects both time series and output objects
        new_ts_list = list(map(lambda x: broadcast_ts(x, param_list[0].shape[0], new_columns), ts_list))
        # Build mappers to easily map between parameters and columns
        mapper_list = [build_mapper(x, ts_list[0], new_columns, level_names[i]) for i, x in enumerate(param_list)]
    else:
        # Some indicators don&#39;t have any params
        new_columns = ts_list[0].vbt.columns
        new_ts_list = list(ts_list)
        mapper_list = []
    output_list = list(map(lambda x: wrap_output(x, ts_list[0], new_columns), output_list))
    if len(mapper_list) &gt; 1:
        # Tuple object is a mapper that accepts tuples of parameters
        tuple_mapper = build_tuple_mapper(mapper_list, new_columns, tuple(level_names))
        mapper_list.append(tuple_mapper)
    return new_ts_list, output_list, param_list, mapper_list, other_list</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.perform_init_checks"><code class="name flex">
<span>def <span class="ident">perform_init_checks</span></span>(<span>ts_list, output_list, param_list, mapper_list, name)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform checks on objects created by running or slicing an indicator.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def perform_init_checks(ts_list, output_list, param_list, mapper_list, name):
    &#34;&#34;&#34;Perform checks on objects created by running or slicing an indicator.&#34;&#34;&#34;
    for ts in ts_list:
        checks.assert_type(ts, (pd.Series, pd.DataFrame))
    for i in range(1, len(ts_list) + len(output_list)):
        checks.assert_same_meta((ts_list + output_list)[i-1], (ts_list + output_list)[i])
    for i in range(1, len(param_list)):
        checks.assert_same_shape(param_list[i-1], param_list[i])
    for mapper in mapper_list:
        checks.assert_type(mapper, pd.Series)
        checks.assert_same_index(reshape_fns.to_2d(ts_list[0]).iloc[0, :], mapper)
    checks.assert_type(name, str)</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.wrap_output"><code class="name flex">
<span>def <span class="ident">wrap_output</span></span>(<span>output, ts, new_columns)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrap a NumPy array into a pandas object with meta from <code>ts</code> and <code>new_columns</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wrap_output(output, ts, new_columns):
    &#34;&#34;&#34;Wrap a NumPy array into a pandas object with meta from `ts` and `new_columns`.&#34;&#34;&#34;
    return ts.vbt.wrap_array(output, columns=new_columns)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="vectorbt.indicators.factory.IndicatorFactory"><code class="flex name class">
<span>class <span class="ident">IndicatorFactory</span></span>
<span>(</span><span>ts_names=['ts'], param_names=['param'], output_names=['output'], name='custom', custom_properties={})</span>
</code></dt>
<dd>
<div class="desc"><p>A factory for creating new indicators.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ts_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>A list of names of input time series objects.</dd>
<dt><strong><code>param_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>A list of names of parameters.</dd>
<dt><strong><code>output_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>A list of names of outputs time series objects.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>A short name of the indicator.</dd>
<dt><strong><code>custom_properties</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary with user-defined functions that will be
bound to the indicator class and wrapped with <code>@cached_property</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IndicatorFactory():
    def __init__(self,
                 ts_names=[&#39;ts&#39;],
                 param_names=[&#39;param&#39;],
                 output_names=[&#39;output&#39;],
                 name=&#39;custom&#39;,
                 custom_properties={}):
        &#34;&#34;&#34;A factory for creating new indicators.

        Args:
            ts_names (list of str): A list of names of input time series objects.
            param_names (list of str): A list of names of parameters.
            output_names (list of str): A list of names of outputs time series objects.
            name (str): A short name of the indicator.
            custom_properties (dict): A dictionary with user-defined functions that will be
                bound to the indicator class and wrapped with `@cached_property`.
        &#34;&#34;&#34;
        self.ts_names = ts_names
        self.param_names = param_names
        self.output_names = output_names
        self.name = name
        self.custom_properties = custom_properties

    def from_custom_func(self, custom_func, **pipeline_kwargs):
        &#34;&#34;&#34;Build indicator class around a custom calculation function.

        !!! note
            Time series passed to `apply_func` will be 2-dimensional NumPy arrays.

            In contrast to `IndicatorFactory.from_apply_func`, it&#39;s up to you to handle caching
            and concatenate columns for each parameter (for example, by using 
            `vectorbt.utils.combine_fns.apply_and_concat_one`). Also, you must ensure that each output 
            array has an appropriate number of columns, which is the number of columns in input time 
            series multiplied by the number of parameter values.

        Args:
            custom_func (function): A function that takes broadcasted time series corresponding 
                to `ts_names`, broadcasted parameter arrays corresponding to `param_names`, and other 
                arguments and keyword arguments, and returns outputs corresponding to `output_names` 
                and other objects that are then returned with the indicator class instance.
                Can be Numba-compiled.
            **pipeline_kwargs: Default keyword arguments passed to `from_params_pipeline`.
        Returns:
            `CustomIndicator`, and optionally other objects that are returned by `custom_func`
            and exceed `output_names`.
        Example:
            The following example does the same as the example in `IndicatorFactory.from_apply_func`.

            ```python-repl
            &gt;&gt;&gt; @njit
            &gt;&gt;&gt; def apply_func_nb(i, ts1, ts2, p1, p2, arg1):
            ...     return ts1 * p1[i] + arg1, ts2 * p2[i] + arg1

            &gt;&gt;&gt; @njit
            ... def custom_func(ts1, ts2, p1, p2, *args):
            ...     return vbt.utils.combine_fns.apply_and_concat_multiple_nb(
            ...         len(p1), apply_func_nb, ts1, ts2, p1, p2, *args)

            &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
            ...     ts_names=[&#39;ts1&#39;, &#39;ts2&#39;],
            ...     param_names=[&#39;p1&#39;, &#39;p2&#39;],
            ...     output_names=[&#39;o1&#39;, &#39;o2&#39;]
            ... ).from_custom_func(custom_func)

            &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
            &gt;&gt;&gt; print(myInd.o1)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  101.0  105.0  102.0  110.0
            2018-01-02  102.0  104.0  104.0  108.0
            2018-01-03  103.0  103.0  106.0  106.0
            2018-01-04  104.0  102.0  108.0  104.0
            2018-01-05  105.0  101.0  110.0  102.0
            &gt;&gt;&gt; print(myInd.o2)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  106.0  130.0  108.0  140.0
            2018-01-02  112.0  124.0  116.0  132.0
            2018-01-03  118.0  118.0  124.0  124.0
            2018-01-04  124.0  112.0  132.0  116.0
            2018-01-05  130.0  106.0  140.0  108.0
            ```
        &#34;&#34;&#34;

        CustomIndicator = type(&#39;CustomIndicator&#39;, (), {})
        ts_names = self.ts_names
        param_names = self.param_names
        output_names = self.output_names
        name = self.name
        custom_properties = self.custom_properties

        # For name and each input and output, create read-only properties
        prop = property(lambda self: self._name)
        prop.__doc__ = f&#34;&#34;&#34;Name of the indicator (read-only).&#34;&#34;&#34;
        setattr(CustomIndicator, &#39;name&#39;, prop)

        for ts_name in ts_names:
            prop = property(lambda self, ts_name=ts_name: getattr(self, &#39;_&#39; + ts_name))
            prop.__doc__ = f&#34;&#34;&#34;Input time series (read-only).&#34;&#34;&#34;
            setattr(CustomIndicator, ts_name, prop)

        for output_name in output_names:
            prop = property(lambda self, output_name=output_name: getattr(self, &#39;_&#39; + output_name))
            prop.__doc__ = f&#34;&#34;&#34;Output time series (read-only).&#34;&#34;&#34;
            setattr(CustomIndicator, output_name, prop)

        for prop in custom_properties.values():
            if prop.__doc__ is None:
                prop.__doc__ = f&#34;&#34;&#34;Custom property.&#34;&#34;&#34;

        # Add __init__ method
        def __init__(self, ts_list, output_list, param_list, mapper_list, name):
            perform_init_checks(ts_list, output_list, param_list, mapper_list, name)

            for i, ts_name in enumerate(ts_names):
                setattr(self, f&#39;_{ts_name}&#39;, ts_list[i])
            for i, output_name in enumerate(output_names):
                setattr(self, f&#39;_{output_name}&#39;, output_list[i])
            for i, param_name in enumerate(param_names):
                setattr(self, f&#39;_{param_name}_array&#39;, param_list[i])
                setattr(self, f&#39;_{param_name}_mapper&#39;, mapper_list[i])
            if len(param_names) &gt; 1:
                setattr(self, &#39;_tuple_mapper&#39;, mapper_list[-1])
            setattr(self, &#39;_name&#39;, name)

        setattr(CustomIndicator, &#39;__init__&#39;, __init__)

        # Add from_params method
        @classmethod
        def from_params(cls, *args, name=name.lower(), return_raw=False, pipeline_kwargs=pipeline_kwargs, **kwargs):
            level_names = tuple([name + &#39;_&#39; + param_name for param_name in param_names])
            args = list(args)
            ts_list = args[:len(ts_names)]
            param_list = args[len(ts_names):len(ts_names)+len(param_names)]
            new_args = args[len(ts_names)+len(param_names):]
            kwargs = {**pipeline_kwargs, **kwargs} # overwirte default pipeline kwargs
            results = from_params_pipeline(
                ts_list, param_list, level_names, len(output_names),
                custom_func, *new_args, return_raw=return_raw, **kwargs)
            if return_raw or kwargs.get(&#39;return_cache&#39;, False):
                return results
            new_ts_list, output_list, new_param_list, mapper_list, other_list = results
            obj = cls(new_ts_list, output_list, new_param_list, mapper_list, name)
            if len(other_list) &gt; 0:
                return (obj,) + other_list
            return obj

        setattr(CustomIndicator, &#39;from_params&#39;, from_params)

        # Add indexing methods
        def indexing_func(obj, pd_indexing_func):
            ts_list = []
            for ts_name in ts_names:
                ts_list.append(pd_indexing_func(getattr(obj, ts_name)))
            output_list = []
            for output_name in output_names:
                output_list.append(pd_indexing_func(getattr(obj, output_name)))
            param_list = []
            for param_name in param_names:
                # TODO: adapt params array according to the indexing operation
                param_list.append(getattr(obj, f&#39;_{param_name}_array&#39;))
            mapper_list = []
            for param_name in param_names:
                mapper_list.append(indexing.mapper_indexing_func(
                    getattr(obj, f&#39;_{param_name}_mapper&#39;),
                    getattr(obj, ts_names[0]), pd_indexing_func))
            if len(param_names) &gt; 1:
                mapper_list.append(indexing.mapper_indexing_func(
                    obj._tuple_mapper, getattr(obj, ts_names[0]), pd_indexing_func))

            return obj.__class__(ts_list, output_list, param_list, mapper_list, obj.name)

        CustomIndicator = indexing.add_pd_indexing(indexing_func)(CustomIndicator)
        for i, param_name in enumerate(param_names):
            CustomIndicator = indexing.add_param_indexing(param_name, indexing_func)(CustomIndicator)
        if len(param_names) &gt; 1:
            CustomIndicator = indexing.add_param_indexing(&#39;tuple&#39;, indexing_func)(CustomIndicator)

        # Add user-defined properties
        for prop_name, prop in custom_properties.items():
            prop.__name__ = prop_name
            if not isinstance(prop, property):
                prop = cached_property(prop)
            setattr(CustomIndicator, prop_name, prop)

        # Add comparison methods for all inputs, outputs, and user-defined properties
        comparison_attrs = set(ts_names + output_names + list(custom_properties.keys()))
        for attr in comparison_attrs:
            def assign_comparison_method(func_name, compare_func, attr=attr):
                def comparison_method(self, other, crossover=False, wait=0, name=None, **kwargs):
                    if isinstance(other, self.__class__):
                        other = getattr(other, attr)
                    if name is None:
                        if attr == self.name:
                            name = f&#39;{self.name}_{func_name}&#39;
                        else:
                            name = f&#39;{self.name}_{attr}_{func_name}&#39;
                    result = compare(getattr(self, attr), other, compare_func, name=name, **kwargs)
                    if crossover:
                        return result.vbt.signals.nst(wait+1, after_false=True)
                    return result
                comparison_method.__qualname__ = f&#39;{CustomIndicator.__name__}.{attr}_{func_name}&#39;
                comparison_method.__doc__ = f&#34;&#34;&#34;Return `True` for each element where `{attr}` is {func_name} `other`. 

                Set `crossover` to `True` to return the first `True` after crossover. Specify `wait` to return 
                `True` only when `{attr}` is {func_name} for a number of time steps in a row after crossover.

                See `vectorbt.indicators.factory.compare`.&#34;&#34;&#34;
                setattr(CustomIndicator, f&#39;{attr}_{func_name}&#39;, comparison_method)

            assign_comparison_method(&#39;above&#39;, np.greater)
            assign_comparison_method(&#39;below&#39;, np.less)
            assign_comparison_method(&#39;equal&#39;, np.equal)

        return CustomIndicator

    def from_apply_func(self, apply_func, caching_func=None, **kwargs):
        &#34;&#34;&#34;Build indicator class around a custom apply function.

        In contrast to `IndicatorFactory.from_custom_func`, this method handles a lot of things for you,
        such as caching, parameter selection, and concatenation. All you have to do is to write `apply_func`
        that accepts a selection of parameters (single values as opposed to multiple values in 
        `IndicatorFactory.from_custom_func`) and does the calculation. It then automatically concatenates
        the results into a single array per output.

        While this approach is much more simpler, it is also less flexible, since you can only work with 
        one parameter selection at a time, and can&#39;t view all parameters.

        !!! note
            Time series passed to `apply_func` will be 2-dimensional NumPy arrays.

            If `apply_func` is a Numba-compiled function: 

            * All inputs are automatically converted to NumPy arrays
            * Each argument in `*args` must be of a Numba-compatible type
            * You cannot pass keyword arguments
            * Your outputs must be arrays of the same shape, data type and data order

        Args:
            apply_func (function): A function that takes broadcasted time series arrays corresponding 
                to `ts_names`, single parameter selection corresponding to `param_names`, and other 
                arguments and keyword arguments, and returns outputs corresponding to `output_names`.
                Can be Numba-compiled.
            caching_func (function): A caching function to preprocess data beforehand.
                All returned objects will be passed as additional arguments to `apply_func`.
            **kwargs: Keyword arguments passed to `IndicatorFactory.from_custom_func`.
        Returns:
            CustomIndicator
        Example:
            ```python-repl
            &gt;&gt;&gt; @njit
            ... def apply_func_nb(ts1, ts2, p1, p2, arg1):
            ...     return ts1 * p1 + arg1, ts2 * p2 + arg1

            &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
            ...     ts_names=[&#39;ts1&#39;, &#39;ts2&#39;],
            ...     param_names=[&#39;p1&#39;, &#39;p2&#39;],
            ...     output_names=[&#39;o1&#39;, &#39;o2&#39;]
            ... ).from_apply_func(apply_func_nb)

            &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
            &gt;&gt;&gt; print(myInd.o1)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  101.0  105.0  102.0  110.0
            2018-01-02  102.0  104.0  104.0  108.0
            2018-01-03  103.0  103.0  106.0  106.0
            2018-01-04  104.0  102.0  108.0  104.0
            2018-01-05  105.0  101.0  110.0  102.0
            &gt;&gt;&gt; print(myInd.o2)
            custom_p1              1             2
            custom_p2              3             4
                            a      b      a      b
            2018-01-01  106.0  130.0  108.0  140.0
            2018-01-02  112.0  124.0  116.0  132.0
            2018-01-03  118.0  118.0  124.0  124.0
            2018-01-04  124.0  112.0  132.0  116.0
            2018-01-05  130.0  106.0  140.0  108.0
            ```
        &#34;&#34;&#34;
        output_names = self.output_names

        num_outputs = len(output_names)

        if checks.is_numba_func(apply_func):
            if num_outputs &gt; 1:
                apply_and_concat_func = combine_fns.apply_and_concat_multiple_nb
            else:
                apply_and_concat_func = combine_fns.apply_and_concat_one_nb

            @njit
            def select_params_func_nb(i, apply_func, ts_arr_list, param_tuples, *args):
                # Select the next tuple of parameters
                return apply_func(*ts_arr_list, *param_tuples[i], *args)

            def custom_func(ts_arr_list, param_list, *args, return_cache=False, cache=None):
                # avoid deprecation warnings
                ts_arr_list = tuple(map(np.asarray, ts_arr_list))
                typed_param_tuples = List()
                for param_tuple in list(zip(*param_list)):
                    typed_param_tuples.append(param_tuple)

                # Caching
                if cache is None and caching_func is not None:
                    cache = caching_func(*ts_arr_list, *param_list, *args)
                if return_cache:
                    return cache
                if cache is None:
                    cache = ()
                if not isinstance(cache, (tuple, list, List)):
                    cache = (cache,)

                return apply_and_concat_func(
                    param_list[0].shape[0],
                    select_params_func_nb,
                    apply_func,
                    ts_arr_list,
                    typed_param_tuples,
                    *args,
                    *cache)
        else:
            if num_outputs &gt; 1:
                apply_and_concat_func = combine_fns.apply_and_concat_multiple
            else:
                apply_and_concat_func = combine_fns.apply_and_concat_one

            def select_params_func(i, apply_func, ts_arr_list, param_list, *args, **kwargs):
                    # Select the next tuple of parameters
                param_is = list(map(lambda x: x[i], param_list))
                return apply_func(*ts_arr_list, *param_is, *args, **kwargs)

            def custom_func(ts_arr_list, param_list, *args, return_cache=False, cache=None, **kwargs):
                ts_arr_list = tuple(map(np.asarray, ts_arr_list))
                # Caching
                if cache is None and caching_func is not None:
                    cache = caching_func(*ts_arr_list, *param_list, *args, **kwargs)
                if return_cache:
                    return cache
                if cache is None:
                    cache = ()
                if not isinstance(cache, (tuple, list, List)):
                    cache = (cache,)

                return apply_and_concat_func(
                    param_list[0].shape[0],
                    select_params_func,
                    apply_func,
                    ts_arr_list,
                    param_list,
                    *args,
                    *cache,
                    **kwargs)

        return self.from_custom_func(custom_func, pass_lists=True, **kwargs)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="vectorbt.indicators.factory.IndicatorFactory.from_apply_func"><code class="name flex">
<span>def <span class="ident">from_apply_func</span></span>(<span>self, apply_func, caching_func=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Build indicator class around a custom apply function.</p>
<p>In contrast to <code><a title="vectorbt.indicators.factory.IndicatorFactory.from_custom_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_custom_func">IndicatorFactory.from_custom_func()</a></code>, this method handles a lot of things for you,
such as caching, parameter selection, and concatenation. All you have to do is to write <code>apply_func</code>
that accepts a selection of parameters (single values as opposed to multiple values in
<code><a title="vectorbt.indicators.factory.IndicatorFactory.from_custom_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_custom_func">IndicatorFactory.from_custom_func()</a></code>) and does the calculation. It then automatically concatenates
the results into a single array per output.</p>
<p>While this approach is much more simpler, it is also less flexible, since you can only work with
one parameter selection at a time, and can't view all parameters.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Time series passed to <code>apply_func</code> will be 2-dimensional NumPy arrays.</p>
<p>If <code>apply_func</code> is a Numba-compiled function: </p>
<ul>
<li>All inputs are automatically converted to NumPy arrays</li>
<li>Each argument in <code>*args</code> must be of a Numba-compatible type</li>
<li>You cannot pass keyword arguments</li>
<li>Your outputs must be arrays of the same shape, data type and data order</li>
</ul>
</div>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>apply_func</code></strong> :&ensp;<code>function</code></dt>
<dd>A function that takes broadcasted time series arrays corresponding
to <code>ts_names</code>, single parameter selection corresponding to <code>param_names</code>, and other
arguments and keyword arguments, and returns outputs corresponding to <code>output_names</code>.
Can be Numba-compiled.</dd>
<dt><strong><code>caching_func</code></strong> :&ensp;<code>function</code></dt>
<dd>A caching function to preprocess data beforehand.
All returned objects will be passed as additional arguments to <code>apply_func</code>.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Keyword arguments passed to <code><a title="vectorbt.indicators.factory.IndicatorFactory.from_custom_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_custom_func">IndicatorFactory.from_custom_func()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>CustomIndicator</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="python-repl">&gt;&gt;&gt; @njit
... def apply_func_nb(ts1, ts2, p1, p2, arg1):
...     return ts1 * p1 + arg1, ts2 * p2 + arg1

&gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
...     ts_names=['ts1', 'ts2'],
...     param_names=['p1', 'p2'],
...     output_names=['o1', 'o2']
... ).from_apply_func(apply_func_nb)

&gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
&gt;&gt;&gt; print(myInd.o1)
custom_p1              1             2
custom_p2              3             4
                a      b      a      b
2018-01-01  101.0  105.0  102.0  110.0
2018-01-02  102.0  104.0  104.0  108.0
2018-01-03  103.0  103.0  106.0  106.0
2018-01-04  104.0  102.0  108.0  104.0
2018-01-05  105.0  101.0  110.0  102.0
&gt;&gt;&gt; print(myInd.o2)
custom_p1              1             2
custom_p2              3             4
                a      b      a      b
2018-01-01  106.0  130.0  108.0  140.0
2018-01-02  112.0  124.0  116.0  132.0
2018-01-03  118.0  118.0  124.0  124.0
2018-01-04  124.0  112.0  132.0  116.0
2018-01-05  130.0  106.0  140.0  108.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_apply_func(self, apply_func, caching_func=None, **kwargs):
    &#34;&#34;&#34;Build indicator class around a custom apply function.

    In contrast to `IndicatorFactory.from_custom_func`, this method handles a lot of things for you,
    such as caching, parameter selection, and concatenation. All you have to do is to write `apply_func`
    that accepts a selection of parameters (single values as opposed to multiple values in 
    `IndicatorFactory.from_custom_func`) and does the calculation. It then automatically concatenates
    the results into a single array per output.

    While this approach is much more simpler, it is also less flexible, since you can only work with 
    one parameter selection at a time, and can&#39;t view all parameters.

    !!! note
        Time series passed to `apply_func` will be 2-dimensional NumPy arrays.

        If `apply_func` is a Numba-compiled function: 

        * All inputs are automatically converted to NumPy arrays
        * Each argument in `*args` must be of a Numba-compatible type
        * You cannot pass keyword arguments
        * Your outputs must be arrays of the same shape, data type and data order

    Args:
        apply_func (function): A function that takes broadcasted time series arrays corresponding 
            to `ts_names`, single parameter selection corresponding to `param_names`, and other 
            arguments and keyword arguments, and returns outputs corresponding to `output_names`.
            Can be Numba-compiled.
        caching_func (function): A caching function to preprocess data beforehand.
            All returned objects will be passed as additional arguments to `apply_func`.
        **kwargs: Keyword arguments passed to `IndicatorFactory.from_custom_func`.
    Returns:
        CustomIndicator
    Example:
        ```python-repl
        &gt;&gt;&gt; @njit
        ... def apply_func_nb(ts1, ts2, p1, p2, arg1):
        ...     return ts1 * p1 + arg1, ts2 * p2 + arg1

        &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
        ...     ts_names=[&#39;ts1&#39;, &#39;ts2&#39;],
        ...     param_names=[&#39;p1&#39;, &#39;p2&#39;],
        ...     output_names=[&#39;o1&#39;, &#39;o2&#39;]
        ... ).from_apply_func(apply_func_nb)

        &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
        &gt;&gt;&gt; print(myInd.o1)
        custom_p1              1             2
        custom_p2              3             4
                        a      b      a      b
        2018-01-01  101.0  105.0  102.0  110.0
        2018-01-02  102.0  104.0  104.0  108.0
        2018-01-03  103.0  103.0  106.0  106.0
        2018-01-04  104.0  102.0  108.0  104.0
        2018-01-05  105.0  101.0  110.0  102.0
        &gt;&gt;&gt; print(myInd.o2)
        custom_p1              1             2
        custom_p2              3             4
                        a      b      a      b
        2018-01-01  106.0  130.0  108.0  140.0
        2018-01-02  112.0  124.0  116.0  132.0
        2018-01-03  118.0  118.0  124.0  124.0
        2018-01-04  124.0  112.0  132.0  116.0
        2018-01-05  130.0  106.0  140.0  108.0
        ```
    &#34;&#34;&#34;
    output_names = self.output_names

    num_outputs = len(output_names)

    if checks.is_numba_func(apply_func):
        if num_outputs &gt; 1:
            apply_and_concat_func = combine_fns.apply_and_concat_multiple_nb
        else:
            apply_and_concat_func = combine_fns.apply_and_concat_one_nb

        @njit
        def select_params_func_nb(i, apply_func, ts_arr_list, param_tuples, *args):
            # Select the next tuple of parameters
            return apply_func(*ts_arr_list, *param_tuples[i], *args)

        def custom_func(ts_arr_list, param_list, *args, return_cache=False, cache=None):
            # avoid deprecation warnings
            ts_arr_list = tuple(map(np.asarray, ts_arr_list))
            typed_param_tuples = List()
            for param_tuple in list(zip(*param_list)):
                typed_param_tuples.append(param_tuple)

            # Caching
            if cache is None and caching_func is not None:
                cache = caching_func(*ts_arr_list, *param_list, *args)
            if return_cache:
                return cache
            if cache is None:
                cache = ()
            if not isinstance(cache, (tuple, list, List)):
                cache = (cache,)

            return apply_and_concat_func(
                param_list[0].shape[0],
                select_params_func_nb,
                apply_func,
                ts_arr_list,
                typed_param_tuples,
                *args,
                *cache)
    else:
        if num_outputs &gt; 1:
            apply_and_concat_func = combine_fns.apply_and_concat_multiple
        else:
            apply_and_concat_func = combine_fns.apply_and_concat_one

        def select_params_func(i, apply_func, ts_arr_list, param_list, *args, **kwargs):
                # Select the next tuple of parameters
            param_is = list(map(lambda x: x[i], param_list))
            return apply_func(*ts_arr_list, *param_is, *args, **kwargs)

        def custom_func(ts_arr_list, param_list, *args, return_cache=False, cache=None, **kwargs):
            ts_arr_list = tuple(map(np.asarray, ts_arr_list))
            # Caching
            if cache is None and caching_func is not None:
                cache = caching_func(*ts_arr_list, *param_list, *args, **kwargs)
            if return_cache:
                return cache
            if cache is None:
                cache = ()
            if not isinstance(cache, (tuple, list, List)):
                cache = (cache,)

            return apply_and_concat_func(
                param_list[0].shape[0],
                select_params_func,
                apply_func,
                ts_arr_list,
                param_list,
                *args,
                *cache,
                **kwargs)

    return self.from_custom_func(custom_func, pass_lists=True, **kwargs)</code></pre>
</details>
</dd>
<dt id="vectorbt.indicators.factory.IndicatorFactory.from_custom_func"><code class="name flex">
<span>def <span class="ident">from_custom_func</span></span>(<span>self, custom_func, **pipeline_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Build indicator class around a custom calculation function.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Time series passed to <code>apply_func</code> will be 2-dimensional NumPy arrays.</p>
<p>In contrast to <code><a title="vectorbt.indicators.factory.IndicatorFactory.from_apply_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_apply_func">IndicatorFactory.from_apply_func()</a></code>, it's up to you to handle caching
and concatenate columns for each parameter (for example, by using
<code><a title="vectorbt.utils.combine_fns.apply_and_concat_one" href="../utils/combine_fns.html#vectorbt.utils.combine_fns.apply_and_concat_one">apply_and_concat_one()</a></code>). Also, you must ensure that each output
array has an appropriate number of columns, which is the number of columns in input time
series multiplied by the number of parameter values.</p>
</div>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>custom_func</code></strong> :&ensp;<code>function</code></dt>
<dd>A function that takes broadcasted time series corresponding
to <code>ts_names</code>, broadcasted parameter arrays corresponding to <code>param_names</code>, and other
arguments and keyword arguments, and returns outputs corresponding to <code>output_names</code>
and other objects that are then returned with the indicator class instance.
Can be Numba-compiled.</dd>
<dt><strong><code>**pipeline_kwargs</code></strong></dt>
<dd>Default keyword arguments passed to <code><a title="vectorbt.indicators.factory.from_params_pipeline" href="#vectorbt.indicators.factory.from_params_pipeline">from_params_pipeline()</a></code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p><code>CustomIndicator</code>, and optionally other objects that are returned by <code>custom_func</code>
and exceed <code>output_names</code>.</p>
<h2 id="example">Example</h2>
<p>The following example does the same as the example in <code><a title="vectorbt.indicators.factory.IndicatorFactory.from_apply_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_apply_func">IndicatorFactory.from_apply_func()</a></code>.</p>
<pre><code class="python-repl">&gt;&gt;&gt; @njit
&gt;&gt;&gt; def apply_func_nb(i, ts1, ts2, p1, p2, arg1):
...     return ts1 * p1[i] + arg1, ts2 * p2[i] + arg1

&gt;&gt;&gt; @njit
... def custom_func(ts1, ts2, p1, p2, *args):
...     return vbt.utils.combine_fns.apply_and_concat_multiple_nb(
...         len(p1), apply_func_nb, ts1, ts2, p1, p2, *args)

&gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
...     ts_names=['ts1', 'ts2'],
...     param_names=['p1', 'p2'],
...     output_names=['o1', 'o2']
... ).from_custom_func(custom_func)

&gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
&gt;&gt;&gt; print(myInd.o1)
custom_p1              1             2
custom_p2              3             4
                a      b      a      b
2018-01-01  101.0  105.0  102.0  110.0
2018-01-02  102.0  104.0  104.0  108.0
2018-01-03  103.0  103.0  106.0  106.0
2018-01-04  104.0  102.0  108.0  104.0
2018-01-05  105.0  101.0  110.0  102.0
&gt;&gt;&gt; print(myInd.o2)
custom_p1              1             2
custom_p2              3             4
                a      b      a      b
2018-01-01  106.0  130.0  108.0  140.0
2018-01-02  112.0  124.0  116.0  132.0
2018-01-03  118.0  118.0  124.0  124.0
2018-01-04  124.0  112.0  132.0  116.0
2018-01-05  130.0  106.0  140.0  108.0
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_custom_func(self, custom_func, **pipeline_kwargs):
    &#34;&#34;&#34;Build indicator class around a custom calculation function.

    !!! note
        Time series passed to `apply_func` will be 2-dimensional NumPy arrays.

        In contrast to `IndicatorFactory.from_apply_func`, it&#39;s up to you to handle caching
        and concatenate columns for each parameter (for example, by using 
        `vectorbt.utils.combine_fns.apply_and_concat_one`). Also, you must ensure that each output 
        array has an appropriate number of columns, which is the number of columns in input time 
        series multiplied by the number of parameter values.

    Args:
        custom_func (function): A function that takes broadcasted time series corresponding 
            to `ts_names`, broadcasted parameter arrays corresponding to `param_names`, and other 
            arguments and keyword arguments, and returns outputs corresponding to `output_names` 
            and other objects that are then returned with the indicator class instance.
            Can be Numba-compiled.
        **pipeline_kwargs: Default keyword arguments passed to `from_params_pipeline`.
    Returns:
        `CustomIndicator`, and optionally other objects that are returned by `custom_func`
        and exceed `output_names`.
    Example:
        The following example does the same as the example in `IndicatorFactory.from_apply_func`.

        ```python-repl
        &gt;&gt;&gt; @njit
        &gt;&gt;&gt; def apply_func_nb(i, ts1, ts2, p1, p2, arg1):
        ...     return ts1 * p1[i] + arg1, ts2 * p2[i] + arg1

        &gt;&gt;&gt; @njit
        ... def custom_func(ts1, ts2, p1, p2, *args):
        ...     return vbt.utils.combine_fns.apply_and_concat_multiple_nb(
        ...         len(p1), apply_func_nb, ts1, ts2, p1, p2, *args)

        &gt;&gt;&gt; MyInd = vbt.IndicatorFactory(
        ...     ts_names=[&#39;ts1&#39;, &#39;ts2&#39;],
        ...     param_names=[&#39;p1&#39;, &#39;p2&#39;],
        ...     output_names=[&#39;o1&#39;, &#39;o2&#39;]
        ... ).from_custom_func(custom_func)

        &gt;&gt;&gt; myInd = MyInd.from_params(price_sm, price_sm * 2, [1, 2], [3, 4], 100)
        &gt;&gt;&gt; print(myInd.o1)
        custom_p1              1             2
        custom_p2              3             4
                        a      b      a      b
        2018-01-01  101.0  105.0  102.0  110.0
        2018-01-02  102.0  104.0  104.0  108.0
        2018-01-03  103.0  103.0  106.0  106.0
        2018-01-04  104.0  102.0  108.0  104.0
        2018-01-05  105.0  101.0  110.0  102.0
        &gt;&gt;&gt; print(myInd.o2)
        custom_p1              1             2
        custom_p2              3             4
                        a      b      a      b
        2018-01-01  106.0  130.0  108.0  140.0
        2018-01-02  112.0  124.0  116.0  132.0
        2018-01-03  118.0  118.0  124.0  124.0
        2018-01-04  124.0  112.0  132.0  116.0
        2018-01-05  130.0  106.0  140.0  108.0
        ```
    &#34;&#34;&#34;

    CustomIndicator = type(&#39;CustomIndicator&#39;, (), {})
    ts_names = self.ts_names
    param_names = self.param_names
    output_names = self.output_names
    name = self.name
    custom_properties = self.custom_properties

    # For name and each input and output, create read-only properties
    prop = property(lambda self: self._name)
    prop.__doc__ = f&#34;&#34;&#34;Name of the indicator (read-only).&#34;&#34;&#34;
    setattr(CustomIndicator, &#39;name&#39;, prop)

    for ts_name in ts_names:
        prop = property(lambda self, ts_name=ts_name: getattr(self, &#39;_&#39; + ts_name))
        prop.__doc__ = f&#34;&#34;&#34;Input time series (read-only).&#34;&#34;&#34;
        setattr(CustomIndicator, ts_name, prop)

    for output_name in output_names:
        prop = property(lambda self, output_name=output_name: getattr(self, &#39;_&#39; + output_name))
        prop.__doc__ = f&#34;&#34;&#34;Output time series (read-only).&#34;&#34;&#34;
        setattr(CustomIndicator, output_name, prop)

    for prop in custom_properties.values():
        if prop.__doc__ is None:
            prop.__doc__ = f&#34;&#34;&#34;Custom property.&#34;&#34;&#34;

    # Add __init__ method
    def __init__(self, ts_list, output_list, param_list, mapper_list, name):
        perform_init_checks(ts_list, output_list, param_list, mapper_list, name)

        for i, ts_name in enumerate(ts_names):
            setattr(self, f&#39;_{ts_name}&#39;, ts_list[i])
        for i, output_name in enumerate(output_names):
            setattr(self, f&#39;_{output_name}&#39;, output_list[i])
        for i, param_name in enumerate(param_names):
            setattr(self, f&#39;_{param_name}_array&#39;, param_list[i])
            setattr(self, f&#39;_{param_name}_mapper&#39;, mapper_list[i])
        if len(param_names) &gt; 1:
            setattr(self, &#39;_tuple_mapper&#39;, mapper_list[-1])
        setattr(self, &#39;_name&#39;, name)

    setattr(CustomIndicator, &#39;__init__&#39;, __init__)

    # Add from_params method
    @classmethod
    def from_params(cls, *args, name=name.lower(), return_raw=False, pipeline_kwargs=pipeline_kwargs, **kwargs):
        level_names = tuple([name + &#39;_&#39; + param_name for param_name in param_names])
        args = list(args)
        ts_list = args[:len(ts_names)]
        param_list = args[len(ts_names):len(ts_names)+len(param_names)]
        new_args = args[len(ts_names)+len(param_names):]
        kwargs = {**pipeline_kwargs, **kwargs} # overwirte default pipeline kwargs
        results = from_params_pipeline(
            ts_list, param_list, level_names, len(output_names),
            custom_func, *new_args, return_raw=return_raw, **kwargs)
        if return_raw or kwargs.get(&#39;return_cache&#39;, False):
            return results
        new_ts_list, output_list, new_param_list, mapper_list, other_list = results
        obj = cls(new_ts_list, output_list, new_param_list, mapper_list, name)
        if len(other_list) &gt; 0:
            return (obj,) + other_list
        return obj

    setattr(CustomIndicator, &#39;from_params&#39;, from_params)

    # Add indexing methods
    def indexing_func(obj, pd_indexing_func):
        ts_list = []
        for ts_name in ts_names:
            ts_list.append(pd_indexing_func(getattr(obj, ts_name)))
        output_list = []
        for output_name in output_names:
            output_list.append(pd_indexing_func(getattr(obj, output_name)))
        param_list = []
        for param_name in param_names:
            # TODO: adapt params array according to the indexing operation
            param_list.append(getattr(obj, f&#39;_{param_name}_array&#39;))
        mapper_list = []
        for param_name in param_names:
            mapper_list.append(indexing.mapper_indexing_func(
                getattr(obj, f&#39;_{param_name}_mapper&#39;),
                getattr(obj, ts_names[0]), pd_indexing_func))
        if len(param_names) &gt; 1:
            mapper_list.append(indexing.mapper_indexing_func(
                obj._tuple_mapper, getattr(obj, ts_names[0]), pd_indexing_func))

        return obj.__class__(ts_list, output_list, param_list, mapper_list, obj.name)

    CustomIndicator = indexing.add_pd_indexing(indexing_func)(CustomIndicator)
    for i, param_name in enumerate(param_names):
        CustomIndicator = indexing.add_param_indexing(param_name, indexing_func)(CustomIndicator)
    if len(param_names) &gt; 1:
        CustomIndicator = indexing.add_param_indexing(&#39;tuple&#39;, indexing_func)(CustomIndicator)

    # Add user-defined properties
    for prop_name, prop in custom_properties.items():
        prop.__name__ = prop_name
        if not isinstance(prop, property):
            prop = cached_property(prop)
        setattr(CustomIndicator, prop_name, prop)

    # Add comparison methods for all inputs, outputs, and user-defined properties
    comparison_attrs = set(ts_names + output_names + list(custom_properties.keys()))
    for attr in comparison_attrs:
        def assign_comparison_method(func_name, compare_func, attr=attr):
            def comparison_method(self, other, crossover=False, wait=0, name=None, **kwargs):
                if isinstance(other, self.__class__):
                    other = getattr(other, attr)
                if name is None:
                    if attr == self.name:
                        name = f&#39;{self.name}_{func_name}&#39;
                    else:
                        name = f&#39;{self.name}_{attr}_{func_name}&#39;
                result = compare(getattr(self, attr), other, compare_func, name=name, **kwargs)
                if crossover:
                    return result.vbt.signals.nst(wait+1, after_false=True)
                return result
            comparison_method.__qualname__ = f&#39;{CustomIndicator.__name__}.{attr}_{func_name}&#39;
            comparison_method.__doc__ = f&#34;&#34;&#34;Return `True` for each element where `{attr}` is {func_name} `other`. 

            Set `crossover` to `True` to return the first `True` after crossover. Specify `wait` to return 
            `True` only when `{attr}` is {func_name} for a number of time steps in a row after crossover.

            See `vectorbt.indicators.factory.compare`.&#34;&#34;&#34;
            setattr(CustomIndicator, f&#39;{attr}_{func_name}&#39;, comparison_method)

        assign_comparison_method(&#39;above&#39;, np.greater)
        assign_comparison_method(&#39;below&#39;, np.less)
        assign_comparison_method(&#39;equal&#39;, np.equal)

    return CustomIndicator</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="vectorbt.indicators" href="index.html">vectorbt.indicators</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="vectorbt.indicators.factory.broadcast_ts" href="#vectorbt.indicators.factory.broadcast_ts">broadcast_ts</a></code></li>
<li><code><a title="vectorbt.indicators.factory.build_column_hierarchy" href="#vectorbt.indicators.factory.build_column_hierarchy">build_column_hierarchy</a></code></li>
<li><code><a title="vectorbt.indicators.factory.build_mapper" href="#vectorbt.indicators.factory.build_mapper">build_mapper</a></code></li>
<li><code><a title="vectorbt.indicators.factory.build_tuple_mapper" href="#vectorbt.indicators.factory.build_tuple_mapper">build_tuple_mapper</a></code></li>
<li><code><a title="vectorbt.indicators.factory.compare" href="#vectorbt.indicators.factory.compare">compare</a></code></li>
<li><code><a title="vectorbt.indicators.factory.from_params_pipeline" href="#vectorbt.indicators.factory.from_params_pipeline">from_params_pipeline</a></code></li>
<li><code><a title="vectorbt.indicators.factory.perform_init_checks" href="#vectorbt.indicators.factory.perform_init_checks">perform_init_checks</a></code></li>
<li><code><a title="vectorbt.indicators.factory.wrap_output" href="#vectorbt.indicators.factory.wrap_output">wrap_output</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="vectorbt.indicators.factory.IndicatorFactory" href="#vectorbt.indicators.factory.IndicatorFactory">IndicatorFactory</a></code></h4>
<ul class="">
<li><code><a title="vectorbt.indicators.factory.IndicatorFactory.from_apply_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_apply_func">from_apply_func</a></code></li>
<li><code><a title="vectorbt.indicators.factory.IndicatorFactory.from_custom_func" href="#vectorbt.indicators.factory.IndicatorFactory.from_custom_func">from_custom_func</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>