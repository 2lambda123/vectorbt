{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'vectorbt.utils' has no attribute 'is_numba_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f7f528ceb5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchecks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/SourceTree/vectorbt/vectorbt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mportfolio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHistogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mportfolio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPortfolio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndicatorFactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSTD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBollingerBands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRSI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStochastic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOBV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mATR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SourceTree/vectorbt/vectorbt/indicators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m!\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIndicators_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbollinger_bands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndicatorFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SourceTree/vectorbt/vectorbt/indicators/ma.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ma'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m ).from_apply_func(ma_apply_func_nb, caching_func=ma_caching_nb)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SourceTree/vectorbt/vectorbt/indicators/factory.py\u001b[0m in \u001b[0;36mfrom_apply_func\u001b[0;34m(self, apply_func, caching_func)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mnum_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_numba_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0mapply_and_concat_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_and_concat_multiple_nb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_outputs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_and_concat_one_nb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'vectorbt.utils' has no attribute 'is_numba_func'"
     ]
    }
   ],
   "source": [
    "from vectorbt.utils import checks, combine, common, indexes, indexing, reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from numba import njit, f8, i8, b1, optional\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 0\n",
    "a1 = np.array([1])\n",
    "a2 = np.array([1, 2, 3])\n",
    "a3 = np.array([[1, 2, 3]])\n",
    "a4 = np.array([[1], [2], [3]])\n",
    "a5 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "sr1 = pd.Series([1], \n",
    "                index=pd.Index(['x1'], name='i1'), \n",
    "                name='a1')\n",
    "print(sr1)\n",
    "sr2 = pd.Series([1, 2, 3], \n",
    "                index=pd.Index(['x2', 'y2', 'z2'], name='i2'), \n",
    "                name='a2')\n",
    "print(sr2)\n",
    "df1 = pd.DataFrame([[1]], \n",
    "                   index=pd.Index(['x3'], name='i3'), \n",
    "                   columns=pd.Index(['a3'], name='c3'))\n",
    "print(df1)\n",
    "df2 = pd.DataFrame([[1], [2], [3]], \n",
    "                   index=pd.Index(['x4', 'y4', 'z4'], name='i4'), \n",
    "                   columns=pd.Index(['a4'], name='c4'))\n",
    "print(df2)\n",
    "df3 = pd.DataFrame([[1, 2, 3]], \n",
    "                   index=pd.Index(['x5'], name='i5'), \n",
    "                   columns=pd.Index(['a5', 'b5', 'c5'], name='c5'))\n",
    "print(df3)\n",
    "df4 = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], \n",
    "                   index=pd.Index(['x6', 'y6', 'z6'], name='i6'), \n",
    "                   columns=pd.Index(['a6', 'b6', 'c6'], name='c6'))\n",
    "print(df4)\n",
    "\n",
    "multi_i = pd.MultiIndex.from_arrays([['x7', 'y7', 'z7'], ['x8', 'y8', 'z8']], names=['i7', 'i8']) \n",
    "multi_c = pd.MultiIndex.from_arrays([['a7', 'b7', 'c7'], ['a8', 'b8', 'c8']], names=['c7', 'c8'])\n",
    "df5 = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], index=multi_i, columns=multi_c)\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checks.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checks.is_series(v1))\n",
    "print(checks.is_series(a1))\n",
    "print(checks.is_series(sr1))\n",
    "print(checks.is_series(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checks.is_frame(v1))\n",
    "print(checks.is_frame(a1))\n",
    "print(checks.is_frame(sr1))\n",
    "print(checks.is_frame(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checks.is_pandas(v1))\n",
    "print(checks.is_pandas(a1))\n",
    "print(checks.is_pandas(sr1))\n",
    "print(checks.is_pandas(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checks.is_array(v1))\n",
    "print(checks.is_array(a1))\n",
    "print(checks.is_array(sr1))\n",
    "print(checks.is_array(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checks.is_array_like(v1))\n",
    "print(checks.is_array_like(a1))\n",
    "print(checks.is_array_like(sr1))\n",
    "print(checks.is_array_like(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checks.is_numba_func(lambda x: x))\n",
    "print(checks.is_numba_func(njit(lambda x: x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_not_none(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_type(v1, int)\n",
    "checks.assert_type(a1, np.ndarray)\n",
    "checks.assert_type(sr1, (np.ndarray, pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_not_type(sr1, (int, pd.DataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_type(v1, v1)\n",
    "checks.assert_same_type(a1, a2)\n",
    "checks.assert_same_type(sr1, sr1)\n",
    "checks.assert_same_type(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_dtype(a1, np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_dtype(v1, a1)\n",
    "checks.assert_same_dtype(a1, df1)\n",
    "checks.assert_same_dtype(df1, df2)\n",
    "checks.assert_same_dtype(df2, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_ndim(v1, 0)\n",
    "checks.assert_ndim(a1, 1)\n",
    "checks.assert_ndim(df1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_len([[1]], [[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_shape(a1, sr1)\n",
    "checks.assert_same_shape(df2, df4, along_axis=0)\n",
    "checks.assert_same_shape(df3, df4, along_axis=1)\n",
    "checks.assert_same_shape(df2, df3, along_axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_index(df3, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_columns(df3, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same_meta(df3, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_same(df3, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks.assert_level_not_exists(df3, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = indexes.from_values([0.1, 0.2], name='a')\n",
    "i2 = indexes.from_values(np.tile(np.arange(1, 4)[:, None][:, None], (1, 3, 3)), name='b')\n",
    "i3 = indexes.from_values(np.random.uniform(size=(3, 3, 3)), name='c')\n",
    "\n",
    "print(i1)\n",
    "print(i2)\n",
    "print(i3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.repeat(i2, 3))\n",
    "print(indexes.repeat(multi_c, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.tile(i2, 3))\n",
    "print(indexes.tile(multi_c, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i23 = indexes.stack(i2, i3)\n",
    "i32 = indexes.stack(i3, i2)\n",
    "\n",
    "print(i23)\n",
    "print(i32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.combine(i1, i2)) # combine uses stack\n",
    "print(indexes.combine(i2, i3))\n",
    "print(indexes.combine(i23, i23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.drop_levels(i23, 'b'))\n",
    "print(indexes.drop_levels(i23, 'c'))\n",
    "print(indexes.drop_levels(i23, ['b', 'c'])) # you can't remove all levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.rename_levels(i23, {'b': 'd', 'c': 'e'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.select_levels(i23, 'b'))\n",
    "print(indexes.select_levels(i23, ['b']))\n",
    "print(indexes.select_levels(i23, ['b', 'c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.drop_redundant_levels(pd.Index(['a', 'a']))) # ignores levels with single element\n",
    "print(indexes.drop_redundant_levels(pd.Index(['a', 'a'], name='hi')))\n",
    "print(indexes.drop_redundant_levels(pd.MultiIndex.from_arrays([['a', 'a'], ['b', 'b']], names=['hi', 'hi2'])))\n",
    "print(indexes.drop_redundant_levels(pd.MultiIndex.from_arrays([['a', 'b'], ['a', 'b']], names=['hi', 'hi2'])))\n",
    "print(indexes.drop_redundant_levels(pd.MultiIndex.from_arrays([[0, 1], ['a', 'b']], names=[None, 'hi2']))) # ignores 0-to-n\n",
    "print(indexes.drop_redundant_levels(pd.MultiIndex.from_arrays([[0, 2], ['a', 'b']], names=[None, 'hi2']))) # legit\n",
    "print(indexes.drop_redundant_levels(pd.MultiIndex.from_arrays([[0, 1], ['a', 'b']], names=['hi', 'hi2']))) # legit (w/ name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes.drop_duplicate_levels(pd.MultiIndex.from_arrays(\n",
    "    [[1, 2, 3], [1, 2, 3]], names=['a', 'a'])))\n",
    "print(indexes.drop_duplicate_levels(pd.MultiIndex.from_tuples(\n",
    "    [(0, 1, 2, 1), ('a', 'b', 'c', 'b')], names=['x', 'y', 'z', 'y']), keep='last'))\n",
    "print(indexes.drop_duplicate_levels(pd.MultiIndex.from_tuples(\n",
    "    [(0, 1, 2, 1), ('a', 'b', 'c', 'b')], names=['x', 'y', 'z', 'y']), keep='first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_c1 = pd.MultiIndex.from_arrays([['a8', 'b8']], names=['c8'])\n",
    "multi_c2 = pd.MultiIndex.from_arrays([['a7', 'a7', 'c7', 'c7'], ['a8', 'b8', 'a8', 'b8']], names=['c7', 'c8'])\n",
    "\n",
    "indexes.align_to(multi_c1, multi_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.soft_broadcast_to_ndim(a2, 1))\n",
    "print(reshape.soft_broadcast_to_ndim(sr2, 1))\n",
    "print(reshape.soft_broadcast_to_ndim(df2, 1))\n",
    "print(reshape.soft_broadcast_to_ndim(df4, 1)) # cannot -> do nothing\n",
    "print(reshape.soft_broadcast_to_ndim(a2, 2))\n",
    "print(reshape.soft_broadcast_to_ndim(sr2, 2))\n",
    "print(reshape.soft_broadcast_to_ndim(df2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.wrap_array(a1, index=sr1.index, columns=[sr1.name], to_ndim=1))\n",
    "print(reshape.wrap_array(a1, index=sr1.index, columns=[sr1.name], to_ndim=2))\n",
    "print(reshape.wrap_array(a2, index=sr2.index, columns=[sr2.name], to_ndim=1))\n",
    "print(reshape.wrap_array(a2, index=sr2.index, columns=[sr2.name], to_ndim=2))\n",
    "print(reshape.wrap_array(a2, index=df2.index, columns=df2.columns, to_ndim=1))\n",
    "print(reshape.wrap_array(a2, index=df2.index, columns=df2.columns, to_ndim=2))\n",
    "print(reshape.wrap_array(a2, index=df4.index, columns=None, default_index=df2.index, default_columns=df2.columns, to_ndim=1))\n",
    "print(reshape.wrap_array(a2, index=df4.index, columns=None, default_index=df2.index, default_columns=df2.columns, to_ndim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.to_1d(None))\n",
    "print(reshape.to_1d(v1))\n",
    "print(reshape.to_1d(a1))\n",
    "print(reshape.to_1d(a2))\n",
    "print(reshape.to_1d(sr1))\n",
    "print(reshape.to_1d(sr2))\n",
    "print(reshape.to_1d(df1))\n",
    "print(reshape.to_1d(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.to_2d(None))\n",
    "print(reshape.to_2d(v1))\n",
    "print(reshape.to_2d(a1))\n",
    "print(reshape.to_2d(a2))\n",
    "print(reshape.to_2d(sr1))\n",
    "print(reshape.to_2d(sr2))\n",
    "print(reshape.to_2d(sr2, expand_axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.repeat(v1, 3, along_axis=0))\n",
    "print(reshape.repeat(a1, 3, along_axis=0))\n",
    "print(reshape.repeat(a2, 3, along_axis=0))\n",
    "print(reshape.repeat(a3, 3, along_axis=0))\n",
    "print(reshape.repeat(a4, 3, along_axis=0))\n",
    "print(reshape.repeat(a5, 3, along_axis=0))\n",
    "print(reshape.repeat(sr1, 3, along_axis=0))\n",
    "print(reshape.repeat(sr2, 3, along_axis=0))\n",
    "print(reshape.repeat(df1, 3, along_axis=0))\n",
    "print(reshape.repeat(df2, 3, along_axis=0))\n",
    "print(reshape.repeat(df3, 3, along_axis=0))\n",
    "print(reshape.repeat(df4, 3, along_axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.repeat(v1, 3, along_axis=1))\n",
    "print(reshape.repeat(a1, 3, along_axis=1))\n",
    "print(reshape.repeat(a2, 3, along_axis=1))\n",
    "print(reshape.repeat(a3, 3, along_axis=1))\n",
    "print(reshape.repeat(a4, 3, along_axis=1))\n",
    "print(reshape.repeat(a5, 3, along_axis=1))\n",
    "print(reshape.repeat(sr1, 3, along_axis=1))\n",
    "print(reshape.repeat(sr2, 3, along_axis=1))\n",
    "print(reshape.repeat(df1, 3, along_axis=1))\n",
    "print(reshape.repeat(df2, 3, along_axis=1))\n",
    "print(reshape.repeat(df3, 3, along_axis=1))\n",
    "print(reshape.repeat(df4, 3, along_axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.tile(v1, 3, along_axis=0))\n",
    "print(reshape.tile(a1, 3, along_axis=0))\n",
    "print(reshape.tile(a2, 3, along_axis=0))\n",
    "print(reshape.tile(a3, 3, along_axis=0))\n",
    "print(reshape.tile(a4, 3, along_axis=0))\n",
    "print(reshape.tile(a5, 3, along_axis=0))\n",
    "print(reshape.tile(sr1, 3, along_axis=0))\n",
    "print(reshape.tile(sr2, 3, along_axis=0))\n",
    "print(reshape.tile(df1, 3, along_axis=0))\n",
    "print(reshape.tile(df2, 3, along_axis=0))\n",
    "print(reshape.tile(df3, 3, along_axis=0))\n",
    "print(reshape.tile(df4, 3, along_axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.tile(v1, 3, along_axis=1))\n",
    "print(reshape.tile(a1, 3, along_axis=1))\n",
    "print(reshape.tile(a2, 3, along_axis=1))\n",
    "print(reshape.tile(a3, 3, along_axis=1))\n",
    "print(reshape.tile(a4, 3, along_axis=1))\n",
    "print(reshape.tile(a5, 3, along_axis=1))\n",
    "print(reshape.tile(sr1, 3, along_axis=1))\n",
    "print(reshape.tile(sr2, 3, along_axis=1))\n",
    "print(reshape.tile(df1, 3, along_axis=1))\n",
    "print(reshape.tile(df2, 3, along_axis=1))\n",
    "print(reshape.tile(df3, 3, along_axis=1))\n",
    "print(reshape.tile(df4, 3, along_axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change broadcasting rules globally\n",
    "reshape.broadcast_defaults['index_from'] = 'stack' # default is 'strict'\n",
    "reshape.broadcast_defaults['columns_from'] = 'stack'\n",
    "\n",
    "print(reshape.broadcast_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting arrays\n",
    "args = [\n",
    "    ('v1', v1),\n",
    "    ('a1', a1),\n",
    "    ('a2', a2),\n",
    "    ('a3', a3),\n",
    "    ('a4', a4),\n",
    "    ('a5', a5)\n",
    "]\n",
    "arg_combs = list(itertools.combinations_with_replacement(args, 2))\n",
    "\n",
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    print(reshape.is_broadcasting_needed(arg1, arg2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    arg1, arg2 = reshape.broadcast(arg1, arg2)\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting series\n",
    "args = [\n",
    "    ('sr1', sr1),\n",
    "    ('sr2', sr2)\n",
    "]\n",
    "arg_combs = list(itertools.combinations_with_replacement(args, 2))\n",
    "\n",
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    arg1, arg2 = reshape.broadcast(arg1, arg2)\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting arrays and series\n",
    "a_args = [\n",
    "    ('v1', v1),\n",
    "    ('a1', a1),\n",
    "    ('a2', a2),\n",
    "    ('a3', a3),\n",
    "    ('a4', a4),\n",
    "    ('a5', a5)\n",
    "]\n",
    "sr_args = [\n",
    "    ('sr1', sr1),\n",
    "    ('sr2', sr2)\n",
    "]\n",
    "arg_combs = list(itertools.product(a_args, sr_args))\n",
    "\n",
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    arg1, arg2 = reshape.broadcast(arg1, arg2)\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting dataframes\n",
    "args = [\n",
    "    ('df1', df1),\n",
    "    ('df2', df2),\n",
    "    ('df3', df3),\n",
    "    ('df4', df4)\n",
    "]\n",
    "arg_combs = list(itertools.combinations_with_replacement(args, 2))\n",
    "\n",
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    arg1, arg2 = reshape.broadcast(arg1, arg2)\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting arrays and dataframes\n",
    "a_args = [\n",
    "    ('v1', v1),\n",
    "    ('a1', a1),\n",
    "    ('a2', a2),\n",
    "    ('a3', a3),\n",
    "    ('a4', a4),\n",
    "    ('a5', a5)\n",
    "]\n",
    "sr_args = [\n",
    "    ('df1', df1),\n",
    "    ('df2', df2),\n",
    "    ('df3', df3),\n",
    "    ('df4', df4)\n",
    "]\n",
    "arg_combs = list(itertools.product(a_args, sr_args))\n",
    "\n",
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    arg1, arg2 = reshape.broadcast(arg1, arg2)\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting series and dataframes\n",
    "a_args = [\n",
    "    ('sr1', sr1),\n",
    "    ('sr2', sr2)\n",
    "]\n",
    "sr_args = [\n",
    "    ('df1', df1),\n",
    "    ('df2', df2),\n",
    "    ('df3', df3),\n",
    "    ('df4', df4)\n",
    "]\n",
    "arg_combs = list(itertools.product(a_args, sr_args))\n",
    "\n",
    "for (n1, arg1), (n2, arg2) in arg_combs:\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(\"================\")\n",
    "    arg1, arg2 = reshape.broadcast(arg1, arg2)\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting all at once\n",
    "for i in reshape.broadcast(\n",
    "    v1, a1, a2, a3, a4, a5, sr1, sr2, df1, df2, df3, df4,\n",
    "    index_from='stack',\n",
    "    columns_from='stack'\n",
    "):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reshape.broadcast(\n",
    "    v1, a1, a2, a3, a4, a5, sr1, sr2, df1, df2, df3, df4,\n",
    "    index_from=None, # use as-is\n",
    "    columns_from=None\n",
    "):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reshape.broadcast(\n",
    "    v1, a1, a2, a3, a4, a5, sr1, sr2, df1, df2, df3, df4,\n",
    "    index_from=-1, # take index from the last dataframe\n",
    "    columns_from=-1\n",
    "):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not clean columns\n",
    "reshape.broadcast_defaults['drop_duplicates'] = False\n",
    "reshape.broadcast_defaults['ignore_single'] = False\n",
    "\n",
    "for i in reshape.broadcast(\n",
    "    v1, a1, a2, a3, a4, a5, sr1, sr2, df1, df2, df3, df4,\n",
    "    index_from='stack', # stack but do not clean\n",
    "    columns_from='stack'\n",
    "):\n",
    "    print(i)\n",
    "    \n",
    "reshape.broadcast_defaults.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_a = np.empty((1000, 1000))\n",
    "\n",
    "%timeit reshape.broadcast(np.empty((1,)), big_a) # readonly arrays\n",
    "%timeit reshape.broadcast(np.empty((1,)), big_a, writeable=True) # writable arrays\n",
    "%timeit reshape.broadcast(np.empty((1,)), big_a, writeable=True, copy_kwargs={'order': 'C'}) # writable arrays in same order\n",
    "%timeit reshape.broadcast(big_a, big_a) # no broadcasting\n",
    "%timeit reshape.broadcast(big_a, big_a, writeable=True) # no broadcasting, writeable has no effect\n",
    "%timeit reshape.broadcast(big_a, big_a, writeable=True, copy_kwargs={'order': 'C'}) # no copy\n",
    "%timeit reshape.broadcast(big_a, big_a, writeable=True, copy_kwargs={'order': 'F'}) # copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-side broadcasting, default behaviour is copying index/columns from the second argument\n",
    "print(reshape.broadcast_to(sr1, sr1))\n",
    "print(reshape.broadcast_to(sr1, sr2))\n",
    "print(reshape.broadcast_to(sr1, df1))\n",
    "print(reshape.broadcast_to(sr1, df2))\n",
    "print(reshape.broadcast_to(sr1, df3))\n",
    "print(reshape.broadcast_to(sr1, df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting first element to be an array out of the second argument\n",
    "print(reshape.broadcast_to_array_of(0.1, v1))\n",
    "print(reshape.broadcast_to_array_of([0.1], v1))\n",
    "print(reshape.broadcast_to_array_of([0.1, 0.2], v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.broadcast_to_array_of(0.1, sr2))\n",
    "print(reshape.broadcast_to_array_of([0.1], sr2))\n",
    "print(reshape.broadcast_to_array_of([0.1, 0.2], sr2))\n",
    "print(reshape.broadcast_to_array_of([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]], sr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.broadcast_to_array_of(0.1, df2))\n",
    "print(reshape.broadcast_to_array_of([0.1], df2))\n",
    "print(reshape.broadcast_to_array_of([0.1, 0.2], df2))\n",
    "print(reshape.broadcast_to_array_of([[[0.1], [0.2], [0.3]], [[0.4], [0.5], [0.6]]], df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.broadcast_to_array_of(0.1, np.empty((2, 2, 2)))) # works even for ndim > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.unstack_to_array(df5.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.make_symmetric(sr1))\n",
    "print(reshape.make_symmetric(sr2))\n",
    "print(reshape.make_symmetric(df1))\n",
    "print(reshape.make_symmetric(df2))\n",
    "print(reshape.make_symmetric(df3))\n",
    "print(reshape.make_symmetric(df4))\n",
    "print(reshape.make_symmetric(pd.Series([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reshape.unstack_to_df(df5.iloc[0]))\n",
    "print(reshape.unstack_to_df(df5.iloc[0], symmetric=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing_func(obj, loc_pandas_func): \n",
    "    # As soon as you call iloc etc., performs it on each dataframe and mapper and returns a new class instance\n",
    "    param1_mapper = indexing.loc_mapper(obj._param1_mapper, obj.a, loc_pandas_func)\n",
    "    param2_mapper = indexing.loc_mapper(obj._param2_mapper, obj.a, loc_pandas_func)\n",
    "    tuple_mapper = indexing.loc_mapper(obj._tuple_mapper, obj.a, loc_pandas_func)\n",
    "    return H(loc_pandas_func(obj.a), param1_mapper, param2_mapper, tuple_mapper)\n",
    "\n",
    "@indexing.add_indexing(indexing_func) # indexing using pandas\n",
    "@indexing.add_param_indexing('param1', indexing_func) # indexing using params\n",
    "@indexing.add_param_indexing('param2', indexing_func)\n",
    "@indexing.add_param_indexing('tuple', indexing_func)\n",
    "class H():\n",
    "    def __init__(self, a, param1_mapper, param2_mapper, tuple_mapper):\n",
    "        self.a = a\n",
    "        self._param1_mapper = param1_mapper\n",
    "        self._param2_mapper = param2_mapper\n",
    "        self._tuple_mapper = tuple_mapper\n",
    "        \n",
    "    @classmethod\n",
    "    def from_params(cls, a, params1, params2, level_names=('p1', 'p2')):\n",
    "        a = reshape.to_2d(a)\n",
    "        # Build column hierarchy\n",
    "        params1_idx = pd.Index(params1, name=level_names[0])\n",
    "        params2_idx = pd.Index(params2, name=level_names[1])\n",
    "        params_idx = indexes.stack(params1_idx, params2_idx)\n",
    "        new_columns = indexes.combine(params_idx, a.columns)\n",
    "        \n",
    "        # Build mappers\n",
    "        param1_mapper = np.repeat(params1, len(a.columns))\n",
    "        param1_mapper = pd.Series(param1_mapper, index=new_columns, name=params1_idx.name)\n",
    "        \n",
    "        param2_mapper = np.repeat(params2, len(a.columns))\n",
    "        param2_mapper = pd.Series(param2_mapper, index=new_columns, name=params2_idx.name)\n",
    "        \n",
    "        tuple_mapper = list(zip(*list(map(lambda x: x.values, [param1_mapper, param2_mapper]))))\n",
    "        tuple_mapper = pd.Series(tuple_mapper, index=new_columns, name=(params1_idx.name, params2_idx.name))\n",
    "        \n",
    "        # Tile a to match the length of new_columns\n",
    "        a = reshape.wrap_array(reshape.tile(a.values, 4, along_axis=1), index=a.index, columns=new_columns)\n",
    "        return cls(a, param1_mapper, param2_mapper, tuple_mapper)\n",
    "        \n",
    "\n",
    "# Similate an indicator with two params\n",
    "h = H.from_params(df4, [0.1, 0.1, 0.2, 0.2], [0.3, 0.4, 0.5, 0.6])\n",
    "\n",
    "print(df4)\n",
    "print(h.a)\n",
    "print(h._param1_mapper)\n",
    "print(h._param2_mapper)\n",
    "print(h._tuple_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing operations are delegated to the underlying dataframes\n",
    "print(h[(0.1, 0.3, 'a6')].a)\n",
    "print(h.loc[:, (0.1, 0.3, 'a6'):(0.1, 0.3, 'c6')].a)\n",
    "print(h.iloc[-2:, -2:].a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h.param1_loc[0.1].a)\n",
    "print(h.param1_loc[0.1:0.1].a)\n",
    "print(h.param1_loc[[0.1, 0.1]].a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h.param2_loc[0.3].a)\n",
    "print(h.param2_loc[0.3:0.3].a)\n",
    "print(h.param2_loc[[0.3, 0.3]].a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h.tuple_loc[(0.1, 0.3)].a)\n",
    "print(h.tuple_loc[(0.1, 0.3):(0.1, 0.3)].a)\n",
    "print(h.tuple_loc[[(0.1, 0.3), (0.1, 0.3)]].a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape.broadcast_defaults['index_from'] = 'stack'\n",
    "reshape.broadcast_defaults['columns_from'] = 'stack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combine.apply_and_concat_one(3, lambda i, x, a: x + a[i], sr2.values, [10, 20, 30]))\n",
    "print(combine.apply_and_concat_one_nb(3, njit(lambda i, x, a: x + a[i]), sr2.values, (10, 20, 30)))\n",
    "print(combine.apply_and_concat_one(3, lambda i, x, a: x + a[i], df4.values, [10, 20, 30]))\n",
    "print(combine.apply_and_concat_one_nb(3, njit(lambda i, x, a: x + a[i]), df4.values, (10, 20, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 1, 1],\n",
      "       [2, 2, 2],\n",
      "       [3, 3, 3]]), array([[11, 21, 31],\n",
      "       [12, 22, 32],\n",
      "       [13, 23, 33]])]\n",
      "[array([[1, 1, 1],\n",
      "       [2, 2, 2],\n",
      "       [3, 3, 3]]), array([[11, 21, 31],\n",
      "       [12, 22, 32],\n",
      "       [13, 23, 33]])]\n",
      "[array([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "       [4, 5, 6, 4, 5, 6, 4, 5, 6],\n",
      "       [7, 8, 9, 7, 8, 9, 7, 8, 9]]), array([[11, 12, 13, 21, 22, 23, 31, 32, 33],\n",
      "       [14, 15, 16, 24, 25, 26, 34, 35, 36],\n",
      "       [17, 18, 19, 27, 28, 29, 37, 38, 39]])]\n",
      "[array([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "       [4, 5, 6, 4, 5, 6, 4, 5, 6],\n",
      "       [7, 8, 9, 7, 8, 9, 7, 8, 9]]), array([[11, 12, 13, 21, 22, 23, 31, 32, 33],\n",
      "       [14, 15, 16, 24, 25, 26, 34, 35, 36],\n",
      "       [17, 18, 19, 27, 28, 29, 37, 38, 39]])]\n"
     ]
    }
   ],
   "source": [
    "print(apply_and_concat_multiple(3, lambda i, x, a: (x, x + a[i]), sr2.values, [10, 20, 30]))\n",
    "print(apply_and_concat_multiple_nb(3, njit(lambda i, x, a: (x, x + a[i])), sr2.values, (10, 20, 30)))\n",
    "print(apply_and_concat_multiple(3, lambda i, x, a: (x, x + a[i]), df4.values, [10, 20, 30]))\n",
    "print(apply_and_concat_multiple_nb(3, njit(lambda i, x, a: (x, x + a[i])), df4.values, (10, 20, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 21 31]\n",
      " [12 22 32]\n",
      " [13 23 33]]\n",
      "[[11 21 31]\n",
      " [12 22 32]\n",
      " [13 23 33]]\n",
      "[[11 12 13 21 22 23 31 32 33]\n",
      " [14 15 16 24 25 26 34 35 36]\n",
      " [17 18 19 27 28 29 37 38 39]]\n",
      "[[11 12 13 21 22 23 31 32 33]\n",
      " [14 15 16 24 25 26 34 35 36]\n",
      " [17 18 19 27 28 29 37 38 39]]\n"
     ]
    }
   ],
   "source": [
    "print(apply_and_concat(sr2.values, 3, lambda i, x, a: x + a[i], [10, 20, 30]))\n",
    "print(apply_and_concat_nb(sr2.values, 3, njit(lambda i, x, a: x + a[i]), (10, 20, 30)))\n",
    "print(apply_and_concat(df4.values, 3, lambda i, x, a: x + a[i], [10, 20, 30]))\n",
    "print(apply_and_concat_nb(df4.values, 3, njit(lambda i, x, a: x + a[i]), (10, 20, 30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111 121 131]\n",
      " [112 122 132]\n",
      " [113 123 133]]\n",
      "[[111 121 131]\n",
      " [112 122 132]\n",
      " [113 123 133]]\n",
      "[[111 112 113 121 122 123 131 132 133]\n",
      " [114 115 116 124 125 126 134 135 136]\n",
      " [117 118 119 127 128 129 137 138 139]]\n",
      "[[111 112 113 121 122 123 131 132 133]\n",
      " [114 115 116 124 125 126 134 135 136]\n",
      " [117 118 119 127 128 129 137 138 139]]\n"
     ]
    }
   ],
   "source": [
    "print(combine_and_concat(sr2.values, (10, 20, 30), lambda x, y, a: x + y + a, 100))\n",
    "print(combine_and_concat_nb(sr2.values, (10, 20, 30), njit(lambda x, y, a: x + y + a), 100))\n",
    "print(combine_and_concat(df4.values, (10, 20, 30), lambda x, y, a: x + y + a, 100))\n",
    "print(combine_and_concat_nb(df4.values, (10, 20, 30), njit(lambda x, y, a: x + y + a), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206 212 218]\n",
      "[206 212 218]\n",
      "[[206 212 218]\n",
      " [224 230 236]\n",
      " [242 248 254]]\n",
      "[[206 212 218]\n",
      " [224 230 236]\n",
      " [242 248 254]]\n"
     ]
    }
   ],
   "source": [
    "print(combine_multiple((sr2.values, sr2.values*2, sr2.values*3), lambda x, y, a: x + y + a, 100))\n",
    "print(combine_multiple_nb((sr2.values, sr2.values*2, sr2.values*3), njit(lambda x, y, a: x + y + a), 100))\n",
    "print(combine_multiple((df4.values, df4.values*2, df4.values*3), lambda x, y, a: x + y + a, 100))\n",
    "print(combine_multiple_nb((df4.values, df4.values*2, df4.values*3), njit(lambda x, y, a: x + y + a), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a1\n",
      "i1    \n",
      "x1   1\n"
     ]
    }
   ],
   "source": [
    "def a_nb(self): return self ** 2\n",
    "\n",
    "@add_safe_nb_methods(a_nb)\n",
    "class H(pd.DataFrame):\n",
    "    def h(self): return self\n",
    "\n",
    "print(H(sr1).h())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G():\n",
    "    @cached_property\n",
    "    def cache_me(self): return np.random.uniform(size=(10000, 10000))\n",
    "    \n",
    "g = G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 347 ms, total: 1.95 s\n",
      "Wall time: 3.25 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = g.cache_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 µs, sys: 44 µs, total: 162 µs\n",
      "Wall time: 167 µs\n"
     ]
    }
   ],
   "source": [
    "%time _ = g.cache_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom accessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "print(sr2.vbt.to_1d_array())\n",
    "print(sr2.vbt.to_2d_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i2\n",
      "x2    1\n",
      "y2    2\n",
      "z2    3\n",
      "Name: a2, dtype: int64\n",
      "i2\n",
      "x2    1\n",
      "y2    2\n",
      "z2    3\n",
      "Name: a2, dtype: int64\n",
      "i4\n",
      "x4    1\n",
      "y4    2\n",
      "z4    3\n",
      "Name: a4, dtype: int64\n",
      "c6  a6  b6  c6\n",
      "i2            \n",
      "x2   1   2   3\n",
      "y2   4   5   6\n",
      "z2   7   8   9\n",
      "c6  a6  b6  c6\n",
      "i6            \n",
      "x6   1   2   3\n",
      "y6   4   5   6\n",
      "z6   7   8   9\n"
     ]
    }
   ],
   "source": [
    "# It will try to return pd.Series\n",
    "print(sr2.vbt.wrap_array(a2)) # returns sr\n",
    "print(sr2.vbt.wrap_array(df2.values)) # returns sr\n",
    "print(sr2.vbt.wrap_array(df2.values, index=df2.index, columns=df2.columns)) # returns sr\n",
    "print(sr2.vbt.wrap_array(df4.values, columns=df4.columns)) # returns df\n",
    "print(sr2.vbt.wrap_array(df4.values, index=df4.index, columns=df4.columns)) # returns df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c4  a4\n",
      "i4    \n",
      "x4   1\n",
      "y4   2\n",
      "z4   3\n",
      "c4  a4\n",
      "i4    \n",
      "x4   1\n",
      "y4   2\n",
      "z4   3\n",
      "c6  a6  b6  c6\n",
      "i4            \n",
      "x4   1   2   3\n",
      "y4   4   5   6\n",
      "z4   7   8   9\n",
      "c6  a6  b6  c6\n",
      "i6            \n",
      "x6   1   2   3\n",
      "y6   4   5   6\n",
      "z6   7   8   9\n"
     ]
    }
   ],
   "source": [
    "# It will try to return pd.DataFrame\n",
    "print(df2.vbt.wrap_array(a2)) # returns df\n",
    "print(df2.vbt.wrap_array(sr2.values)) # returns df\n",
    "print(df2.vbt.wrap_array(df4.values, columns=df4.columns)) # returns df\n",
    "print(df2.vbt.wrap_array(df4.values, index=df4.index, columns=df4.columns)) # returns df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a        b      \n",
      "c6 a6 b6 c6 a6 b6 c6\n",
      "i6                  \n",
      "x6  1  2  3  1  2  3\n",
      "y6  4  5  6  4  5  6\n",
      "z6  7  8  9  7  8  9\n",
      "c6 a6    b6    c6   \n",
      "    a  b  a  b  a  b\n",
      "i6                  \n",
      "x6  1  1  2  2  3  3\n",
      "y6  4  4  5  5  6  6\n",
      "z6  7  7  8  8  9  9\n"
     ]
    }
   ],
   "source": [
    "print(df4.vbt.tile(2, as_columns=['a', 'b']))\n",
    "print(df4.vbt.repeat(2, as_columns=['a', 'b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_index_to(multi_c1, multi_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c8 a8 b8\n",
      "0   1  2\n",
      "1   4  5\n",
      "2   7  8\n",
      "c7 a7    c7    \n",
      "c8 a8 b8 a8  b8\n",
      "0   1  2  3   4\n",
      "1   4  5  6   7\n",
      "2   7  8  9  10\n",
      "c7 a7    c7   \n",
      "c8 a8 b8 a8 b8\n",
      "0   1  2  1  2\n",
      "1   4  5  4  5\n",
      "2   7  8  7  8\n"
     ]
    }
   ],
   "source": [
    "df10 = pd.DataFrame([[1, 2], [4, 5], [7, 8]], columns=multi_c1)\n",
    "df20 = pd.DataFrame([[1, 2, 3, 4], [4, 5, 6, 7], [7, 8, 9, 10]], columns=multi_c2)\n",
    "\n",
    "print(df10)\n",
    "print(df20)\n",
    "print(df10.vbt.align_to(df20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i2\n",
      "x2    1\n",
      "y2    2\n",
      "z2    3\n",
      "Name: a2, dtype: int64, i2\n",
      "x2    10\n",
      "y2    10\n",
      "z2    10\n",
      "Name: a2, dtype: int64)\n",
      "(i2\n",
      "x2    1\n",
      "y2    2\n",
      "z2    3\n",
      "Name: a2, dtype: int64, i2\n",
      "x2    10\n",
      "y2    10\n",
      "z2    10\n",
      "Name: a2, dtype: int64)\n",
      "c4  a4\n",
      "i4    \n",
      "x4   1\n",
      "y4   2\n",
      "z4   3\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.vbt.broadcast(\n",
    "    sr2,\n",
    "    10\n",
    "))\n",
    "print(sr2.vbt.broadcast(\n",
    "    10\n",
    "))\n",
    "print(sr2.vbt.broadcast_to(\n",
    "    df2\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i2', None)   a2   x2   y2   z2\n",
      "(i2, None)                      \n",
      "a2            NaN  1.0  2.0  3.0\n",
      "x2            1.0  NaN  NaN  NaN\n",
      "y2            2.0  NaN  NaN  NaN\n",
      "z2            3.0  NaN  NaN  NaN\n",
      "('i4', 'c4')   a4   x4   y4   z4\n",
      "(i4, c4)                        \n",
      "a4            NaN  1.0  2.0  3.0\n",
      "x4            1.0  NaN  NaN  NaN\n",
      "y4            2.0  NaN  NaN  NaN\n",
      "z4            3.0  NaN  NaN  NaN\n",
      "('i5', 'c5')   a5   b5   c5   x5\n",
      "(i5, c5)                        \n",
      "a5            NaN  NaN  NaN  1.0\n",
      "b5            NaN  NaN  NaN  2.0\n",
      "c5            NaN  NaN  NaN  3.0\n",
      "x5            1.0  2.0  3.0  NaN\n",
      "('i6', 'c6')   a6   b6   c6   x6   y6   z6\n",
      "(i6, c6)                                  \n",
      "a6            NaN  NaN  NaN  1.0  4.0  7.0\n",
      "b6            NaN  NaN  NaN  2.0  5.0  8.0\n",
      "c6            NaN  NaN  NaN  3.0  6.0  9.0\n",
      "x6            1.0  2.0  3.0  NaN  NaN  NaN\n",
      "y6            4.0  5.0  6.0  NaN  NaN  NaN\n",
      "z6            7.0  8.0  9.0  NaN  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "print(sr2.vbt.make_symmetric())\n",
    "print(df2.vbt.make_symmetric())\n",
    "print(df3.vbt.make_symmetric())\n",
    "print(df4.vbt.make_symmetric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan nan]\n",
      " [nan  4. nan]\n",
      " [nan nan  7.]]\n"
     ]
    }
   ],
   "source": [
    "print(df5.iloc[:, 0].vbt.unstack_to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    x8   y8   z8\n",
      "0                \n",
      "x7  1.0  NaN  NaN\n",
      "y7  NaN  4.0  NaN\n",
      "z7  NaN  NaN  7.0\n"
     ]
    }
   ],
   "source": [
    "print(df5.iloc[:, 0].vbt.unstack_to_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c6       a6  b6  c6  a6  b6  c6  a6  b6  c6  a6  ...  c6  a6  b6  c6  a6  b6  \\\n",
      "i2   i6                                          ...                           \n",
      "x2 0 x6   1   1   1  10  10  10  10  20  30  10  ...  30  10  10  10   1   1   \n",
      "y2 1 y6   2   2   2  10  10  10  10  20  30  10  ...  30  20  20  20   1   1   \n",
      "z2 2 z6   3   3   3  10  10  10  10  20  30  10  ...  30  30  30  30   1   1   \n",
      "\n",
      "c6       c6  a6  b6  c6  \n",
      "i2   i6                  \n",
      "x2 0 x6   1   1   2   3  \n",
      "y2 1 y6   1   4   5   6  \n",
      "z2 2 z6   1   7   8   9  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "c6       a6  b6  c6  a6  b6  c6  a6  b6  c6  a6  ...  c6  a6  b6  c6  a6  b6  \\\n",
      "i2   i6                                          ...                           \n",
      "x2 0 x6   1   1   1  10  10  10  10  20  30  10  ...  30  10  10  10   1   1   \n",
      "y2 1 y6   2   2   2  10  10  10  10  20  30  10  ...  30  20  20  20   1   1   \n",
      "z2 2 z6   3   3   3  10  10  10  10  20  30  10  ...  30  30  30  30   1   1   \n",
      "\n",
      "c6       c6  a6  b6  c6  \n",
      "i2   i6                  \n",
      "x2 0 x6   1   1   2   3  \n",
      "y2 1 y6   1   4   5   6  \n",
      "z2 2 z6   1   7   8   9  \n",
      "\n",
      "[3 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.vbt.concat(\n",
    "    sr2,\n",
    "    10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df4\n",
    "))\n",
    "print(sr2.vbt.concat(\n",
    "    10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a2   a2   a2\n",
      "i2               \n",
      "x2  112  113  114\n",
      "y2  113  114  115\n",
      "z2  114  115  116\n",
      "     a2   a2   a2\n",
      "i2               \n",
      "x2  112  113  114\n",
      "y2  113  114  115\n",
      "z2  114  115  116\n",
      "     a2   a2   a2\n",
      "i2               \n",
      "x2  112  113  114\n",
      "y2  116  117  118\n",
      "z2  120  121  122\n",
      "     a2   a2   a2\n",
      "i2               \n",
      "x2  112  113  114\n",
      "y2  116  117  118\n",
      "z2  120  121  122\n",
      "c6   a6   b6   c6   a6   b6   c6   a6   b6   c6\n",
      "i6                                             \n",
      "x6  112  116  120  113  117  121  114  118  122\n",
      "y6  115  119  123  116  120  124  117  121  125\n",
      "z6  118  122  126  119  123  127  120  124  128\n",
      "hello    a              b              c          \n",
      "c6      a6   b6   c6   a6   b6   c6   a6   b6   c6\n",
      "i6                                                \n",
      "x6     112  116  120  113  117  121  114  118  122\n",
      "y6     115  119  123  116  120  124  117  121  125\n",
      "z6     118  122  126  119  123  127  120  124  128\n"
     ]
    }
   ],
   "source": [
    "print(sr2.vbt.apply_and_concat(3, sr2.values, 10, apply_func=lambda i, x, y, c, d=1: x + y[i] + c + d, d=100))\n",
    "print(sr2.vbt.apply_and_concat(3, sr2.values, 10, apply_func=njit(lambda i, x, y, c: x + y[i] + c + 100)))\n",
    "print(sr2.vbt.apply_and_concat(3, df4.values, 10, apply_func=lambda i, x, y, c, d=1: x + y[:, i] + c + d, d=100))\n",
    "print(sr2.vbt.apply_and_concat(3, df4.values, 10, apply_func=njit(lambda i, x, y, c: x + y[:, i] + c + 100)))\n",
    "print(df4.vbt.apply_and_concat(3, df4.values, 10, apply_func=lambda i, x, y, c, d=1: x + y[:, i] + c + d, d=100))\n",
    "print(df4.vbt.apply_and_concat(\n",
    "    3, \n",
    "    df4.values, \n",
    "    10, \n",
    "    apply_func=njit(lambda i, x, y, c: x + y[:, i] + c + 100), \n",
    "    as_columns=pd.Index(['a', 'b', 'c'], name='hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i2\n",
      "x2    11.0\n",
      "y2    12.0\n",
      "z2    13.0\n",
      "Name: a2, dtype: float64\n",
      "i2\n",
      "x2    1111\n",
      "y2    1112\n",
      "z2    1113\n",
      "Name: a2, dtype: int64\n",
      "i2\n",
      "x2    11\n",
      "y2    22\n",
      "z2    33\n",
      "Name: a2, dtype: int64\n",
      "    a2  a2  a2\n",
      "i2            \n",
      "x2  11  21  31\n",
      "y2  12  22  32\n",
      "z2  13  23  33\n",
      "i2\n",
      "x2    2\n",
      "y2    3\n",
      "z2    4\n",
      "Name: (a2, a1), dtype: int64\n",
      "i2\n",
      "x2    2\n",
      "y2    4\n",
      "z2    6\n",
      "Name: a2, dtype: int64\n",
      "      a2\n",
      "c4    a4\n",
      "i2 i4   \n",
      "x2 x4  2\n",
      "y2 y4  4\n",
      "z2 z4  6\n",
      "c5  a5  b5  c5\n",
      "i2            \n",
      "x2   2   3   4\n",
      "y2   3   4   5\n",
      "z2   4   5   6\n",
      "c6     a6  b6  c6\n",
      "i2 i6            \n",
      "x2 x6   2   3   4\n",
      "y2 y6   6   7   8\n",
      "z2 z6  10  11  12\n",
      "c7        a7  b7  c7\n",
      "c8        a8  b8  c8\n",
      "i2 i7 i8            \n",
      "x2 x7 x8   2   3   4\n",
      "y2 y7 y8   6   7   8\n",
      "z2 z7 z8  10  11  12\n"
     ]
    }
   ],
   "source": [
    "print(sr2.vbt.combine_with(10., combine_func=lambda x, y: x + y))\n",
    "print(sr2.vbt.combine_with(10, 100, d=1000, combine_func=lambda x, y, c, d=1: x + y + c + d)) # test args and kwargs\n",
    "print(sr2.vbt.combine_with([10, 20, 30], combine_func=lambda x, y: x + y))\n",
    "print(sr2.vbt.combine_with([[10, 20, 30]], combine_func=lambda x, y: x + y))\n",
    "print(sr2.vbt.combine_with(sr1, combine_func=lambda x, y: x + y, broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with(sr2, combine_func=lambda x, y: x + y, broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with(df2, combine_func=lambda x, y: x + y, broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with(df3, combine_func=lambda x, y: x + y, broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with(df4, combine_func=lambda x, y: x + y, broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with(df5, combine_func=lambda x, y: x + y, broadcast_kwargs=dict(index_from='stack')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i2   \n",
      "x2  0    361\n",
      "y2  1    382\n",
      "z2  2    403\n",
      "Name: (a2, 0), dtype: int64\n",
      "c5     a5   b5   c5\n",
      "i2                 \n",
      "x2 0  703  724  745\n",
      "y2 1  714  735  756\n",
      "z2 2  725  746  767\n",
      "c5     a5   b5   c5\n",
      "i2                 \n",
      "x2 0  703  724  745\n",
      "y2 1  714  735  756\n",
      "z2 2  725  746  767\n",
      "c5     a5   b5   c5\n",
      "i2                 \n",
      "x2 0  703  724  745\n",
      "y2 1  714  735  756\n",
      "z2 2  725  746  767\n"
     ]
    }
   ],
   "source": [
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    pd.Series([10, 20, 30])],\n",
    "    10, b=100,\n",
    "    combine_func=lambda x, y, a, b=1: x + y + a + b, \n",
    "    broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df3],\n",
    "    10, b=100,\n",
    "    combine_func=lambda x, y, a, b=1: x + y + a + b, \n",
    "    broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df3],\n",
    "    10,\n",
    "    combine_func=njit(lambda x, y, a, b=1: x + y + a + 100), \n",
    "    broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df3],\n",
    "    10,\n",
    "    combine_func=njit(lambda x, y, a, b=1: x + y + a + 100), \n",
    "    broadcast_kwargs=dict(index_from='stack')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       a2          \n",
      "        0    0    0\n",
      "i2                 \n",
      "x2 0  121  121  121\n",
      "y2 1  122  132  132\n",
      "z2 2  123  143  143\n",
      "c5     a5   b5   c5   a5   b5   c5   a5   b5   c5   a5   b5   c5   a5   b5  \\\n",
      "i2                                                                           \n",
      "x2 0  121  121  121  121  131  141  121  131  141  121  121  121  112  112   \n",
      "y2 1  122  122  122  122  132  142  122  132  142  132  132  132  113  113   \n",
      "z2 2  123  123  123  123  133  143  123  133  143  143  143  143  114  114   \n",
      "\n",
      "c5     c5   a5   b5   c5  \n",
      "i2                        \n",
      "x2 0  112  112  113  114  \n",
      "y2 1  113  113  114  115  \n",
      "z2 2  114  114  115  116  \n",
      "c5     a5   b5   c5   a5   b5   c5   a5   b5   c5   a5   b5   c5   a5   b5  \\\n",
      "i2                                                                           \n",
      "x2 0  121  121  121  121  131  141  121  131  141  121  121  121  112  112   \n",
      "y2 1  122  122  122  122  132  142  122  132  142  132  132  132  113  113   \n",
      "z2 2  123  123  123  123  133  143  123  133  143  143  143  143  114  114   \n",
      "\n",
      "c5     c5   a5   b5   c5  \n",
      "i2                        \n",
      "x2 0  112  112  113  114  \n",
      "y2 1  113  113  114  115  \n",
      "z2 2  114  114  115  116  \n",
      "        a              b              c              d              e       \\\n",
      "c5     a5   b5   c5   a5   b5   c5   a5   b5   c5   a5   b5   c5   a5   b5   \n",
      "i2                                                                           \n",
      "x2 0  121  121  121  121  131  141  121  131  141  121  121  121  112  112   \n",
      "y2 1  122  122  122  122  132  142  122  132  142  132  132  132  113  113   \n",
      "z2 2  123  123  123  123  133  143  123  133  143  143  143  143  114  114   \n",
      "\n",
      "             f            \n",
      "c5     c5   a5   b5   c5  \n",
      "i2                        \n",
      "x2 0  112  112  113  114  \n",
      "y2 1  113  113  114  115  \n",
      "z2 2  114  114  115  116  \n"
     ]
    }
   ],
   "source": [
    "# Test concat=True\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    pd.Series([10, 20, 30])],\n",
    "    10, b=100,\n",
    "    combine_func=lambda x, y, a, b=1: x + y + a + b, \n",
    "    concat=True,\n",
    "    broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df3],\n",
    "    10, b=100,\n",
    "    combine_func=lambda x, y, a, b=1: x + y + a + b, \n",
    "    concat=True,\n",
    "    broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df3],\n",
    "    10,\n",
    "    combine_func=njit(lambda x, y, a, b=1: x + y + a + 100),\n",
    "    concat=True,\n",
    "    broadcast_kwargs=dict(index_from='stack')))\n",
    "print(sr2.vbt.combine_with_multiple(\n",
    "    [10, \n",
    "    [10, 20, 30],\n",
    "    [[10, 20, 30]],\n",
    "    pd.Series([10, 20, 30]),\n",
    "    df1,\n",
    "    df3],\n",
    "    10,\n",
    "    combine_func=njit(lambda x, y, a, b=1: x + y + a + 100),\n",
    "    concat=True,\n",
    "    as_columns=['a', 'b', 'c', 'd', 'e', 'f'],\n",
    "    broadcast_kwargs=dict(index_from='stack')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c5 a5  b5  c5\n",
      "c6 a6  b6  c6\n",
      "i6           \n",
      "x6  2   4   6\n",
      "y6  5   7   9\n",
      "z6  8  10  12\n"
     ]
    }
   ],
   "source": [
    "# Use magic methods with .vbt to do operations with custom broadcasting\n",
    "# Regular df3 + df4 will return nans\n",
    "print(df3.vbt + df4.vbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
